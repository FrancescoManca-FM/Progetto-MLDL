{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia di iCarl.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MA0oBz0z50P-",
        "QrC-hzLj6C89",
        "Z65ZOHUH6ViD"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa321edb0e254fe380af53e7c6a643e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3a93980c9654f2290fce1861e7ba59e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f10c1431480457d8bc543af2706cec1",
              "IPY_MODEL_2331b34e83b644e0807d8a6d00cb3dcb"
            ]
          }
        },
        "c3a93980c9654f2290fce1861e7ba59e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f10c1431480457d8bc543af2706cec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08daba753dc44f469016a0c80f42e6dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c657b45c6504388b7d88e3aee42a2c9"
          }
        },
        "2331b34e83b644e0807d8a6d00cb3dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_33d14b3f266148d5977ab45959389c79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:05&lt;00:00, 28645534.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28d3ef42f6d84234b1b9c970f98703d7"
          }
        },
        "08daba753dc44f469016a0c80f42e6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c657b45c6504388b7d88e3aee42a2c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33d14b3f266148d5977ab45959389c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28d3ef42f6d84234b1b9c970f98703d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoManca-FM/Progetto-MLDL/blob/master/Copia_di_iCarl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQzsqHPNcc3V",
        "outputId": "08c00622-dadc-48ef-cf2c-0c9f8168a4c8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun  2 07:39:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUHNE0YdXMlR"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torchvision.transforms as transforms \n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "from torch.nn.init import xavier_uniform_ \n",
        "from torch.nn.init import kaiming_uniform_"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA0oBz0z50P-"
      },
      "source": [
        "### DATA LOADER RANDOM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "fa321edb0e254fe380af53e7c6a643e1",
            "c3a93980c9654f2290fce1861e7ba59e",
            "4f10c1431480457d8bc543af2706cec1",
            "2331b34e83b644e0807d8a6d00cb3dcb",
            "08daba753dc44f469016a0c80f42e6dc",
            "7c657b45c6504388b7d88e3aee42a2c9",
            "33d14b3f266148d5977ab45959389c79",
            "28d3ef42f6d84234b1b9c970f98703d7"
          ]
        },
        "id": "ulGEC0Yw5znL",
        "outputId": "09084b2e-adeb-42a6-ad5a-b6c9c37768db"
      },
      "source": [
        "# we build a transform to normalize images: Data normalization is an important step which ensures \n",
        "# each input parameter (pixel, in this case) has a similar data distribution. This makes convergence \n",
        "# faster while training the network.\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 128\n",
        "\n",
        "trainset_raw = torchvision.datasets.CIFAR100(root='./data', train=True, \n",
        "                                         download=True, transform=transform)\n",
        "\n",
        "for i in range(len(trainset_raw)):\n",
        "  if(i==0):\n",
        "    trainset = [[trainset_raw[i][0], trainset_raw[i][1]]]\n",
        "  else:\n",
        "    trainset.append([trainset_raw[i][0], trainset_raw[i][1]])\n",
        "\n",
        "\n",
        "# DataLoader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "# batch_size = how many samples per batch to load\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa321edb0e254fe380af53e7c6a643e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrC-hzLj6C89"
      },
      "source": [
        "### NETWORK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMloq5CL6E6z"
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        \n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        self.inplanes = 16\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def addOutputNodes(self, num_new_outputs):\n",
        "        in_features = self.fc.in_features\n",
        "        out_features = self.fc.out_features\n",
        "        weight = self.fc.weight.data\n",
        "\n",
        "        self.fc = nn.Linear(in_features, out_features + num_new_outputs)\n",
        "\n",
        "        #xavier initialization\n",
        "        # xavier_uniform_(self.fc.weight)\n",
        "\n",
        "        #kaiming initialization\n",
        "        # kaiming_uniform_(self.fc.weight)\n",
        "        self.fc.weight.data[:out_features] = weight\n",
        "        \n",
        "\n",
        "\n",
        "def resnet20(pretrained=False, **kwargs):\n",
        "    n = 3\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet32(pretrained=False, **kwargs):\n",
        "    n = 5\n",
        "    model = ResNet(BasicBlock, [n, n, n], **kwargs)\n",
        "    return model\n",
        "\n",
        "def resnet56(pretrained=False, **kwargs):\n",
        "    n = 9\n",
        "    model = ResNet(Bottleneck, [n, n, n], **kwargs)\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1JeZ9NB4ZxS",
        "outputId": "fd9f4008-b469-40d3-9e58-5fe73869643b"
      },
      "source": [
        "net = resnet32()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z65ZOHUH6ViD"
      },
      "source": [
        "### LOSS and PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbhVE5N6U-5"
      },
      "source": [
        "lr = 0.01\n",
        "decay = 0.0001\n",
        "epochs = 30\n",
        "momentum = 0.9\n",
        "factor = 5"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLf5BCR-4c3X"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.SGD(net.parameters(), lr = lr, weight_decay=decay,momentum= momentum)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A3VnShN54du"
      },
      "source": [
        "### ICARL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctP6_Hr2mdEX"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def constructExemplarSet(Xclass, m):\n",
        "#Xclass contiene immagini e label della classe X\n",
        "  exemplars_set = []\n",
        "  feature_exemplars = []\n",
        "  indexes = []\n",
        "  features = [] \n",
        "\n",
        "  with torch.no_grad():\n",
        "    XtrainLoader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=128, num_workers=2)\n",
        "    for i, data in enumerate(XtrainLoader, 0):\n",
        "      image = data[0].to(device)\n",
        "      # per ogni immagine della classe x, prendiamo le rispettive feature e le uniamo nel vettore features, che contiene tutte quelle delle immagini della classe x\n",
        "      feature = net.forward(image)\n",
        "      feature.data = feature.data/feature.data.norm()\n",
        "      features.append(feature)\n",
        "    #for data in Xclass:\n",
        "    #  image = data[0]\n",
        "    #  print(image.size())\n",
        "    #  # per ogni immagine della classe x, prendiamo le rispettive feature e le uniamo nel vettore features, che contiene tutte quelle delle immagini della classe x\n",
        "    #  feature = net.forward(image)\n",
        "    #  feature.data = feature.data/feature.data.norm()\n",
        "    #  features.append(feature)\n",
        "\n",
        "  features = torch.cat(features,dim=0) #cat solve the problem of inequal size of tensors \n",
        "  current_class_mean = features.mean(0) # mu = media delle features delle immagini della classe\n",
        "  current_class_mean = current_class_mean / np.linalg.norm(current_class_mean.cpu()) # Normalize\n",
        "  current_class_mean = torch.stack([current_class_mean]*features.size()[0]).sum()\n",
        "\n",
        "  # for k in (1, m+1), calcolare pi = argmin (mu - 1/k(phi(x) - sumj(phi(pj))))\n",
        "  # aggiungere pi all'exemplar set della classe x\n",
        "  for k in range(1, m+1):\n",
        "    min = 10000000000.00\n",
        "    sum = 0\n",
        "    for j in range(k-1):\n",
        "      sum += feature_exemplars[j]\n",
        "    for x in range(len(Xclass)): \n",
        "      if (x not in indexes):\n",
        "        phiX = features[x]\n",
        "        val = current_class_mean - ((phiX + sum)/k).sum()\n",
        "        if (val < min):\n",
        "          min = val\n",
        "          feature_min = phiX\n",
        "          index_min = x\n",
        "          #print(min, index_min)\n",
        "          indexes.append(index_min)\n",
        "          feature_exemplars.append(feature_min)\n",
        "          exemplars_set.append(Xclass[index_min])\n",
        "\n",
        "    \n",
        "  return exemplars_set\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2g4GowGwusw"
      },
      "source": [
        "# DA CHIAMARE PER OGNI CLASSE k: riduce il numero di exemplars all'interno dell'exemplar_set della classe k \n",
        "def reduceExemplarSet(m, exemplars_set):\n",
        "  exemplars_new = []\n",
        "  for i in range(m):\n",
        "    exemplars_new.append(exemplars_set[i])\n",
        "\n",
        "  return exemplars_new"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYbMVq01yO4l"
      },
      "source": [
        "def updateRepresentation(train_iter, exemplars_set_tot, network, iteration, device, epochs, num_classes):\n",
        "  #exemplars_set_tot contiene tutti gli exemplars set ottenuti fino ad ora\n",
        "  #train_iter contiene tutti i dati (immagini + labels) delle classi nuove (s, .., t)\n",
        "  \n",
        "  for k, v in exemplars_set_tot.items():\n",
        "    train_iter += v \n",
        "  train_loader = torch.utils.data.DataLoader(train_iter, shuffle = True, batch_size=batch_size, num_workers=2)\n",
        "  # train_loader è la concatenazione delle nuove classi con gli exemplar_sets calcolati fino a questo punto \n",
        "  training(train_loader, iteration, network, device, epochs, num_classes)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khi5A-jN0tHO"
      },
      "source": [
        "def incrementalTrain(train_iter, iteration, network, device, epochs, num_classes, K, exemplars_set_tot):\n",
        "  print(\"Starting the update reprensentation\")\n",
        "  updateRepresentation(train_iter, exemplars_set_tot, network, iteration, device, epochs, num_classes)\n",
        "  \n",
        "  t = (num_classes * iteration) + num_classes # num_classes ricevute fino a questo momento \n",
        "  m = math.ceil(K/t)\n",
        "  s = num_classes * iteration\n",
        "\n",
        "  print(\"reducing examplar for each class\")\n",
        "  for y in range(1, s):\n",
        "    exemplar_y_new = reduceExemplarSet(m, exemplars_set_tot[y]) # valore associato alla chiave y che rappresenta il label della classe \n",
        "    exemplars_set_tot[y] = exemplar_y_new\n",
        "  \n",
        "  for y in range(s, t):\n",
        "    class_y = []\n",
        "    for i in range(len(train_iter)):\n",
        "      if(train_iter[i][1]==y):\n",
        "        class_y.append(train_iter[i])\n",
        "    print(\"Constructing examplars of class\", y)\n",
        "    exemplars_set = constructExemplarSet(class_y, m)\n",
        "    exemplars_set_tot[y] = exemplars_set"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcVC8cDM5lOv"
      },
      "source": [
        "def training(trainloader, iteration, network, device, epochs, num_classes):\n",
        "  distillation_loss = 0\n",
        "  old_net = copy.deepcopy(network)\n",
        "  n = num_classes * (iteration + 1)\n",
        "  m = num_classes\n",
        "  lambdaL = 0\n",
        "  if (iteration != 0):\n",
        "    # add 10 output nodes to the network\n",
        "    network.addOutputNodes(num_classes)\n",
        "    network.to(device)\n",
        "  \n",
        "  #train the network\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "      inputs = data[0].to(device)\n",
        "      labels = data[1].to(device)\n",
        "      \n",
        "      # Sets the gradients of all optimized torch.Tensor to zero.\n",
        "      optimizer.zero_grad() \n",
        "\n",
        "      # forward: assign weights to each edge in each layer\n",
        "      outputs = network.forward(inputs) \n",
        "\n",
        "       # calculate the classification loss \n",
        "      classification_loss = criterion(outputs,labels) \n",
        "\n",
        "      if (iteration > 0):\n",
        "      # calculate the distillation loss\n",
        "        distillation_loss = dist_loss(outputs, old_net, inputs) \n",
        "        lambdaL = n/(n+m)\n",
        "      \n",
        "      #loss = classification_loss + lambdaL*distillation_loss\n",
        "      loss = classification_loss\n",
        "\n",
        "      # redesign the weights evaluating the performance of the network\n",
        "      loss.backward() \n",
        "\n",
        "      # update parameters\n",
        "      optimizer.step()  \n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      # print every 20 mini-batches the average value of the loss accumulated in each batch\n",
        "      if i % 200 == 199:    \n",
        "        print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 20))\n",
        "        running_loss = 0.0"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkon7J1N5mei"
      },
      "source": [
        "def dist_loss(outputs, old_net, inputs):\n",
        "    out_old = torch.sigmoid(old_net.forward(inputs))\n",
        "    out_old_new = torch.argmax(out_old, dim=1)\n",
        "    distillation_loss = criterion(outputs, out_old_new)\n",
        "    return distillation_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIa7_nXx6k5i"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def test(testloader, iteration, network, acc):\n",
        "  confusion_matrix = torch.zeros(iteration*10+10,iteration*10+10)\n",
        "  print(\"confusion matrix shape: \", confusion_matrix.shape)\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  print(\"ITERATION: \", iteration)\n",
        "  \n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = network.forward(images)\n",
        "\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "         \n",
        "          for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
        "            confusion_matrix[t.long(),p.long()] += 1\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.plasma)\n",
        "  plt.show()\n",
        "  acc.append(100*correct/total)\n",
        "  print(f'Accuracy of the network on the {iteration} iteration: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsvUAIJTwCLH"
      },
      "source": [
        "###MAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqRdXKNR6oD1"
      },
      "source": [
        "# 1 update\n",
        "# 2 update m\n",
        "# 3 reduce_exemplar_set\n",
        "# 4 for every class just seen construct exemplar set "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a-Os_LIG3588",
        "outputId": "ae47ce8d-bbaf-46af-c8a4-502002735166"
      },
      "source": [
        "# MAIN\n",
        "K = 2000\n",
        "iterations = 10\n",
        "num_classes = 10\n",
        "acc = []\n",
        "test_set = [] #initialized here because we test over all the classes not only those one in which I train\n",
        "exemplars_set_tot = {new_list: [] for new_list in range(100)}\n",
        "for i in range(iterations):\n",
        "  classes_current_iter = range(i*num_classes, i*num_classes+num_classes)\n",
        "  train_iter = []\n",
        "  for j in range(len(trainset)):\n",
        "    if(trainset[j][-1] in classes_current_iter):\n",
        "      test_set.append(trainset[j]) \n",
        "      train_iter.append(trainset[j])\n",
        "  \n",
        "  valid_loader = torch.utils.data.DataLoader(test_set, shuffle = True, batch_size = batch_size, num_workers=2) \n",
        "  print(\"Train the network, iteration: \", i, \" on classes: \", classes_current_iter)\n",
        "  incrementalTrain(train_iter, i, net, device, epochs, num_classes, K, exemplars_set_tot) # Train the network with 10 classes at a time\n",
        "  test(valid_loader, i, net, acc) # Test the network with all classes seen until this iteration"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train the network, iteration:  0  on classes:  range(0, 10)\n",
            "Starting the update reprensentation\n",
            "reducing examplar for each class\n",
            "Constructing examplars of class 0\n",
            "Constructing examplars of class 1\n",
            "Constructing examplars of class 2\n",
            "Constructing examplars of class 3\n",
            "Constructing examplars of class 4\n",
            "Constructing examplars of class 5\n",
            "Constructing examplars of class 6\n",
            "Constructing examplars of class 7\n",
            "Constructing examplars of class 8\n",
            "Constructing examplars of class 9\n",
            "confusion matrix shape:  torch.Size([10, 10])\n",
            "ITERATION:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 0 iteration: 69 %\n",
            "Train the network, iteration:  1  on classes:  range(10, 20)\n",
            "Starting the update reprensentation\n",
            "reducing examplar for each class\n",
            "Constructing examplars of class 10\n",
            "Constructing examplars of class 11\n",
            "Constructing examplars of class 12\n",
            "Constructing examplars of class 13\n",
            "Constructing examplars of class 14\n",
            "Constructing examplars of class 15\n",
            "Constructing examplars of class 16\n",
            "Constructing examplars of class 17\n",
            "Constructing examplars of class 18\n",
            "Constructing examplars of class 19\n",
            "confusion matrix shape:  torch.Size([20, 20])\n",
            "ITERATION:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 1 iteration: 37 %\n",
            "Train the network, iteration:  2  on classes:  range(20, 30)\n",
            "Starting the update reprensentation\n",
            "reducing examplar for each class\n",
            "Constructing examplars of class 20\n",
            "Constructing examplars of class 21\n",
            "Constructing examplars of class 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-11b45a683d18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train the network, iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" on classes: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_current_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mincrementalTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexemplars_set_tot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Train the network with 10 classes at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Test the network with all classes seen until this iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9be264e8bdeb>\u001b[0m in \u001b[0;36mincrementalTrain\u001b[0;34m(train_iter, iteration, network, device, epochs, num_classes, K, exemplars_set_tot)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mclass_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Constructing examplars of class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mexemplars_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstructExemplarSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mexemplars_set_tot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexemplars_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-06c4ff280c45>\u001b[0m in \u001b[0;36mconstructExemplarSet\u001b[0;34m(Xclass, m)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mphiX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_class_mean\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphiX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTXBHFyOoFmn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uthfwYiapyyx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}