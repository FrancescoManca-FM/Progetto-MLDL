{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FUNZIONANTE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j40FSXGxD2VD",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudv9Cj8E8OI",
        "colab_type": "code",
        "outputId": "2ec89ff5-bbe9-4d93-f1da-802acca17cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\"\n",
        "# !pip install --upgrade wandb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dC-rYdjD-E3",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5c063fef-3cbc-4513-bd96-39135de37a26"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet # , resnet18, resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XOn3bHMEBzX",
        "colab_type": "text"
      },
      "source": [
        "**Set arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmMFuQNV2ueu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "NUM_CLASSES = 100 \n",
        "\n",
        "# @toupdate the following vals (look at icarl paper)\n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 0.01           # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 10      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 49       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lf-WK3hEJCM",
        "colab_type": "text"
      },
      "source": [
        "**Retrieving dataset CIFAR1000**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1do9ln3OVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "0a9b764e-df23-4a98-e387-bd245fbdaa0d"
      },
      "source": [
        "# Clone github repository with dataset handler\n",
        "# !rm -r Cifar100/ #debug purposes\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 139 (delta 57), reused 99 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (139/139), 3.46 MiB | 2.78 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab_type": "code",
        "outputId": "7dae2cf6-ddbc-4197-c360-bcb81643a807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "# Download dataset from the official sourse and save it into DATA\n",
        "\n",
        "# if not os.path.isdir('./{}'.format(DATA_DIR)):\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "!tar -xf 'cifar-100-python.tar.gz'  \n",
        "!mv 'cifar-100-python' $DATA_DIR\n",
        "!rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-19 13:47:12--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  16.8MB/s    in 11s     \n",
            "\n",
            "2020-05-19 13:47:24 (14.9 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oJ5m4V-ERDh",
        "colab_type": "text"
      },
      "source": [
        "**Define data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD2_Re8kPxRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# it is ok to use also .5 mean and .5 std (faq1)\n",
        "# @tocheck\n",
        "# ref: https://github.com/chengyangfu/pytorch-vgg-cifar10/blob/master/main.py + pytorch resnet documentation\n",
        "# Define transformations for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "])\n",
        "\n",
        "# Define transformations for evaluation\n",
        "eval_transform = transforms.Compose([transforms.Resize(32),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                                   \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7EVuDrcJj2N"
      },
      "source": [
        "**Prepare dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJKwvGljJj2T",
        "outputId": "e5273818-4211-4b6d-a99d-056eea44ad8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "# Import dataset\n",
        "# full_dataset = CIFAR100(DATA_DIR, split='train', transform=transform_train)\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=transform_train)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "\n",
        "# @todo\n",
        "# split into train, test, \n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n",
        "\n",
        "# random.seed(30)\n",
        "# rand_subset = random.sample(list(full_dataset.df.index), 10000)\n",
        "# dataset = Subset(full_dataset, rand_subset)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ckn3H69iJj2X",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def build_reverse_index(dataset, splits):\n",
        "    reverse_index = pd.DataFrame(columns=['group', 'labels'])\n",
        "\n",
        "    for k in splits.keys():\n",
        "        labels = list(dataset.df.loc[splits[k]['train'],'labels'].value_counts().index)\n",
        "        group = [k for i in range(len(labels))]\n",
        "        data = pd.DataFrame(np.array([group, labels]).T, columns=['group', 'labels'])\n",
        "        reverse_index = reverse_index.append(data, ignore_index=True)\n",
        "\n",
        "    reverse_index['nodes'] = reverse_index.index\n",
        "    return reverse_index\n",
        "\n",
        "def changeIndex(reverse_index, column):\n",
        "    reverse_index = reverse_index.set_index(column)\n",
        "    reverse_index[column] = reverse_index.index\n",
        "    return reverse_index\n",
        "\n",
        "def getLabels(reverse_index, outputs):\n",
        "    outs = outputs.cpu().numpy()\n",
        "    reverse_index = changeIndex(outputs_labels_mapping, 'nodes')\n",
        "    labels = reverse_index.loc[outs, 'labels']\n",
        "\n",
        "    labels = torch.tensor(list(labels))\n",
        "    return labels.to(DEVICE)\n",
        "\n",
        "def getNodes(reverse_index, labels):\n",
        "    labels = labels.cpu().numpy()\n",
        "    reverse_index = changeIndex(outputs_labels_mapping, 'labels')\n",
        "    nodes = reverse_index.loc[labels, 'nodes']\n",
        "\n",
        "    nodes = torch.tensor(list(nodes))\n",
        "    return nodes.to(DEVICE)\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = (reverse_index['group'].value_counts().index)\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.loc[reverse_index['group'] == g, 'labels']\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLmmQn7JOLc",
        "colab_type": "text"
      },
      "source": [
        "**Build dataset splits and reverse index**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=30)\n",
        "outputs_labels_mapping = build_reverse_index(train_dataset, train_splits)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fov9YAFTlj",
        "colab_type": "text"
      },
      "source": [
        "**Prepare dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn",
        "colab_type": "code",
        "outputId": "83f1d569-a34b-4f5f-e398-b232a5bb0cca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    # train_dl = DataLoader(train_subs, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
        "    # val_dl = DataLoader(train_subs, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    # test_dl = DataLoader(test_subs, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "    test_subsets.append(test_subs)\n",
        "\n",
        "\n",
        "\n",
        "# test to check classes in different dataset\n",
        "dict_train={}\n",
        "for img_train in train_subsets[0]:\n",
        "  if img_train[1] not in dict_train:\n",
        "    dict_train[img_train[1]]=1\n",
        "  else:\n",
        "    dict_train[img_train[1]]+=1\n",
        "dict_val={}\n",
        "for img_val in val_subsets[0]:\n",
        "  if img_val[1] not in dict_val:\n",
        "    dict_val[img_val[1]]=1\n",
        "  else:\n",
        "    dict_val[img_val[1]]+=1\n",
        "dict_test={}\n",
        "for img_test in test_subsets[0]:\n",
        "  if img_test[1] not in dict_test:\n",
        "    dict_test[img_test[1]]=1\n",
        "  else:\n",
        "    dict_test[img_test[1]]+=1\n",
        "\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18, 19, 23, 30, 39, 46, 53, 60, 98, 99]\n",
            "[18, 19, 23, 30, 39, 46, 53, 60, 98, 99]\n",
            "[18, 19, 23, 30, 39, 46, 53, 60, 98, 99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzG6w15UudAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def fake_train(net, train_dataloader, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):\n",
        "    # By default, everything is loaded to cpu\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    \n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_dataloader:\n",
        "            print(labels)\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            print(preds)\n",
        "            preds = getLabels(outputs_labels_mapping, preds)\n",
        "            print(preds)\n",
        "\n",
        "            break\n",
        "        break\n",
        "    print('end of fake train')\n",
        "    \n",
        "\n",
        "\n",
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS):     \n",
        "    # By default, everything is loaded to cpu\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    \n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_dataloader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            # preds = getLabels(outputs_labels_mapping, preds)\n",
        "            # print(preds)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        # wandb.log({'Epochs': epoch, 'Train Accuracy': epoch_acc, 'Train Loss': epoch_loss})\n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion=None):\n",
        "    net.eval()\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for images, labels in val_dataloader:\n",
        "        # Bring data over the device of choice\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(images)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # preds = getLabels(outputs_labels_mapping, preds)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "    # Calculate Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def test(net, test_dataloader):\n",
        "    acc, _ = validate(net, test_dataloader)\n",
        "    return acc\n",
        "\n",
        "# Joins 2+ subsets into a new Subset\n",
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "def jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets):\n",
        "    # wandb.init(project=\"progetto-mldl\", name='joint-training', anonymous='never')\n",
        "\n",
        "    net, criterion, optimizer, scheduler = getNet()\n",
        "    # wandb.watch(net)\n",
        "\n",
        "    train_set = None\n",
        "    test_set = None\n",
        "    first_pass = True\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "\n",
        "        # Builds growing train and test set. The new sets include data from previous class groups and current class group\n",
        "        if train_set is None:\n",
        "            train_set = train_subset\n",
        "        else:\n",
        "            train_set = joinSubsets(train_dataset, [train_set, train_subset])\n",
        "        if test_set is None:\n",
        "            test_set = test_subset\n",
        "        else:\n",
        "            test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        if first_pass:\n",
        "            first_pass = False\n",
        "        else:\n",
        "            addOutputs(net, 10)\n",
        "\n",
        "        # Trains model on previous and current class groups\n",
        "        _, _, optimizer, scheduler = getNet()\n",
        "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        train(net, train_loader, criterion, optimizer, scheduler)\n",
        "\n",
        "        # Validate model on current class group\n",
        "        val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        acc, loss = validate(net, val_loader, criterion)\n",
        "        print(acc, loss)\n",
        "\n",
        "        # Test the model on previous and current class groups\n",
        "        test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        print(acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ff9pwV10b0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.resnet import resnet34\n",
        "\n",
        "def getResNet34(output_size):\n",
        "    net = resnet34(num_classes=output_size)\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputsToResNet(net, new_outputs):\n",
        "    in_features = net.fc.in_features\n",
        "    out_features = net.fc.out_features\n",
        "    weight = net.fc.weight.data\n",
        "\n",
        "    net.fc = nn.Linear(in_features, out_features + new_outputs)\n",
        "    net.fc.weight.data[:out_features] = weight\n",
        "def getNet():\n",
        "    return getResNet34(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDecUBiHl4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# jointTraining(getNet, addOutputsToResNet, train_subsets, val_subsets, test_subsets)\n",
        "# wandb.init(project=\"progetto-mldl\", name='joint-training', anonymous='never')\n",
        "net, criterion, optimizer, scheduler = getResNet34(100)\n",
        "# wandb.watch(net)train_dataloader = DataLoader(train_subsets[0], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "train(net, train_dataloader, criterion, optimizer, scheduler)\n",
        "# outputs_labels_mapping.head(11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pts78KY42gXj",
        "colab_type": "text"
      },
      "source": [
        "**Catastrophic Forgetting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrA3WhUzuK67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Catastrophic Forgetting\n",
        "def sequentialLearning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet34(100)\n",
        "    groups_accuracies=[]\n",
        "    i=0\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      # Train on current group\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss = validate(net, val_loader, criterion)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Testo on current group\n",
        "      test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc = test(net, test_loader)\n",
        "      groups_accuracies.append(acc)\n",
        "      print(\"TEST: \",acc)\n",
        "      if i==2:\n",
        "        break\n",
        "      i+=1\n",
        "    return net, groups_accuracies\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        if id_group==2:\n",
        "          break\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb",
        "colab_type": "code",
        "outputId": "f3820078-c9c9-46e5-9d51-f288a0187bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "net, old_accuracies=sequentialLearning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/10, LR = [0.01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/Cifar100/resnet.py:105: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data, mode='fan_out')\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 6.041431427001953\n",
            "Train step - Step 10, Loss 3.998364210128784\n",
            "Train step - Step 20, Loss 2.962327003479004\n",
            "Train step - Step 30, Loss 1.9368914365768433\n",
            "Train epoch - Accuracy: 0.24868686868686868 Loss: 3.4786440383545076 Corrects: 1231\n",
            "Starting epoch 2/10, LR = [0.01]\n",
            "Train step - Step 40, Loss 1.7082616090774536\n",
            "Train step - Step 50, Loss 1.9721704721450806\n",
            "Train step - Step 60, Loss 1.6261855363845825\n",
            "Train step - Step 70, Loss 1.4314048290252686\n",
            "Train epoch - Accuracy: 0.42747474747474745 Loss: 1.6811614678604434 Corrects: 2116\n",
            "Starting epoch 3/10, LR = [0.01]\n",
            "Train step - Step 80, Loss 1.5485889911651611\n",
            "Train step - Step 90, Loss 1.4031779766082764\n",
            "Train step - Step 100, Loss 1.3329074382781982\n",
            "Train step - Step 110, Loss 1.4706218242645264\n",
            "Train epoch - Accuracy: 0.5036363636363637 Loss: 1.3856758397998232 Corrects: 2493\n",
            "Starting epoch 4/10, LR = [0.01]\n",
            "Train step - Step 120, Loss 1.2366238832473755\n",
            "Train step - Step 130, Loss 1.2114310264587402\n",
            "Train step - Step 140, Loss 1.4046801328659058\n",
            "Train step - Step 150, Loss 1.3561187982559204\n",
            "Train epoch - Accuracy: 0.5345454545454545 Loss: 1.2982078852798 Corrects: 2646\n",
            "Starting epoch 5/10, LR = [0.01]\n",
            "Train step - Step 160, Loss 1.1864956617355347\n",
            "Train step - Step 170, Loss 1.2329127788543701\n",
            "Train step - Step 180, Loss 1.2840158939361572\n",
            "Train step - Step 190, Loss 1.1502057313919067\n",
            "Train epoch - Accuracy: 0.5591919191919192 Loss: 1.221449025953659 Corrects: 2768\n",
            "Starting epoch 6/10, LR = [0.01]\n",
            "Train step - Step 200, Loss 1.1388217210769653\n",
            "Train step - Step 210, Loss 1.1212888956069946\n",
            "Train step - Step 220, Loss 1.1696447134017944\n",
            "Train step - Step 230, Loss 1.1325745582580566\n",
            "Train epoch - Accuracy: 0.5888888888888889 Loss: 1.137359106612928 Corrects: 2915\n",
            "Starting epoch 7/10, LR = [0.01]\n",
            "Train step - Step 240, Loss 0.8909832239151001\n",
            "Train step - Step 250, Loss 1.1309692859649658\n",
            "Train step - Step 260, Loss 1.0210120677947998\n",
            "Train step - Step 270, Loss 1.17332124710083\n",
            "Train epoch - Accuracy: 0.6022222222222222 Loss: 1.1118517723709647 Corrects: 2981\n",
            "Starting epoch 8/10, LR = [0.01]\n",
            "Train step - Step 280, Loss 1.1301183700561523\n",
            "Train step - Step 290, Loss 1.1109936237335205\n",
            "Train step - Step 300, Loss 1.069466471672058\n",
            "Train step - Step 310, Loss 1.0458793640136719\n",
            "Train epoch - Accuracy: 0.6228282828282828 Loss: 1.0542964077959156 Corrects: 3083\n",
            "Starting epoch 9/10, LR = [0.01]\n",
            "Train step - Step 320, Loss 0.9337620735168457\n",
            "Train step - Step 330, Loss 0.8655799627304077\n",
            "Train step - Step 340, Loss 1.0678921937942505\n",
            "Train step - Step 350, Loss 0.8540961742401123\n",
            "Train epoch - Accuracy: 0.6527272727272727 Loss: 0.9665454010048298 Corrects: 3231\n",
            "Starting epoch 10/10, LR = [0.01]\n",
            "Train step - Step 360, Loss 1.0073522329330444\n",
            "Train step - Step 370, Loss 1.078100562095642\n",
            "Train step - Step 380, Loss 0.9508401155471802\n",
            "Train epoch - Accuracy: 0.6460606060606061 Loss: 0.9723734973175358 Corrects: 3198\n",
            "Training finished in 98.2584297657013 seconds\n",
            "EVALUATION:  0.68 0.9765878319740295\n",
            "TEST:  0.673\n",
            "Starting epoch 1/10, LR = [0.01]\n",
            "Train step - Step 0, Loss 19.03013038635254\n",
            "Train step - Step 10, Loss 3.758988380432129\n",
            "Train step - Step 20, Loss 2.42307448387146\n",
            "Train step - Step 30, Loss 1.8281574249267578\n",
            "Train epoch - Accuracy: 0.19454545454545455 Loss: 3.7538429752503983 Corrects: 963\n",
            "Starting epoch 2/10, LR = [0.01]\n",
            "Train step - Step 40, Loss 1.8709055185317993\n",
            "Train step - Step 50, Loss 1.7722948789596558\n",
            "Train step - Step 60, Loss 1.7114572525024414\n",
            "Train step - Step 70, Loss 1.7232006788253784\n",
            "Train epoch - Accuracy: 0.37575757575757573 Loss: 1.7791853902315853 Corrects: 1860\n",
            "Starting epoch 3/10, LR = [0.01]\n",
            "Train step - Step 80, Loss 1.6213864088058472\n",
            "Train step - Step 90, Loss 1.6681593656539917\n",
            "Train step - Step 100, Loss 1.4521188735961914\n",
            "Train step - Step 110, Loss 1.3477091789245605\n",
            "Train epoch - Accuracy: 0.43393939393939396 Loss: 1.5790890352653735 Corrects: 2148\n",
            "Starting epoch 4/10, LR = [0.01]\n",
            "Train step - Step 120, Loss 1.5510616302490234\n",
            "Train step - Step 130, Loss 1.628129482269287\n",
            "Train step - Step 140, Loss 1.5430188179016113\n",
            "Train step - Step 150, Loss 1.7997361421585083\n",
            "Train epoch - Accuracy: 0.4868686868686869 Loss: 1.4718078051191388 Corrects: 2410\n",
            "Starting epoch 5/10, LR = [0.01]\n",
            "Train step - Step 160, Loss 1.2623436450958252\n",
            "Train step - Step 170, Loss 1.4633047580718994\n",
            "Train step - Step 180, Loss 1.548681378364563\n",
            "Train step - Step 190, Loss 1.2677167654037476\n",
            "Train epoch - Accuracy: 0.5345454545454545 Loss: 1.3348547033830123 Corrects: 2646\n",
            "Starting epoch 6/10, LR = [0.01]\n",
            "Train step - Step 200, Loss 1.4251625537872314\n",
            "Train step - Step 210, Loss 1.1918213367462158\n",
            "Train step - Step 220, Loss 1.137787938117981\n",
            "Train step - Step 230, Loss 1.4723881483078003\n",
            "Train epoch - Accuracy: 0.5642424242424242 Loss: 1.264822112863714 Corrects: 2793\n",
            "Starting epoch 7/10, LR = [0.01]\n",
            "Train step - Step 240, Loss 1.303505778312683\n",
            "Train step - Step 250, Loss 1.2372230291366577\n",
            "Train step - Step 260, Loss 0.9916830062866211\n",
            "Train step - Step 270, Loss 1.0861226320266724\n",
            "Train epoch - Accuracy: 0.5860606060606061 Loss: 1.1954221192754881 Corrects: 2901\n",
            "Starting epoch 8/10, LR = [0.01]\n",
            "Train step - Step 280, Loss 0.9070385694503784\n",
            "Train step - Step 290, Loss 1.0939885377883911\n",
            "Train step - Step 300, Loss 1.0689181089401245\n",
            "Train step - Step 310, Loss 0.8850935101509094\n",
            "Train epoch - Accuracy: 0.6238383838383839 Loss: 1.0995349398044625 Corrects: 3088\n",
            "Starting epoch 9/10, LR = [0.01]\n",
            "Train step - Step 320, Loss 0.8463886976242065\n",
            "Train step - Step 330, Loss 0.9729259610176086\n",
            "Train step - Step 340, Loss 1.0010194778442383\n",
            "Train step - Step 350, Loss 0.8938126564025879\n",
            "Train epoch - Accuracy: 0.6541414141414141 Loss: 1.0081329112582738 Corrects: 3238\n",
            "Starting epoch 10/10, LR = [0.01]\n",
            "Train step - Step 360, Loss 0.8752396106719971\n",
            "Train step - Step 370, Loss 0.9255163669586182\n",
            "Train step - Step 380, Loss 0.8648988008499146\n",
            "Train epoch - Accuracy: 0.68 Loss: 0.9418092551616707 Corrects: 3366\n",
            "Training finished in 98.46000552177429 seconds\n",
            "EVALUATION:  0.72 0.834959864616394\n",
            "TEST:  0.677\n",
            "Starting epoch 1/10, LR = [0.01]\n",
            "Train step - Step 0, Loss 18.339366912841797\n",
            "Train step - Step 10, Loss 4.20759391784668\n",
            "Train step - Step 20, Loss 3.033165216445923\n",
            "Train step - Step 30, Loss 2.275972604751587\n",
            "Train epoch - Accuracy: 0.1202020202020202 Loss: 4.28105325361695 Corrects: 595\n",
            "Starting epoch 2/10, LR = [0.01]\n",
            "Train step - Step 40, Loss 2.0884859561920166\n",
            "Train step - Step 50, Loss 2.108051300048828\n",
            "Train step - Step 60, Loss 1.8814938068389893\n",
            "Train step - Step 70, Loss 2.010483503341675\n",
            "Train epoch - Accuracy: 0.29838383838383836 Loss: 1.9845957231521607 Corrects: 1477\n",
            "Starting epoch 3/10, LR = [0.01]\n",
            "Train step - Step 80, Loss 2.0926594734191895\n",
            "Train step - Step 90, Loss 1.8332630395889282\n",
            "Train step - Step 100, Loss 1.7930281162261963\n",
            "Train step - Step 110, Loss 1.8370580673217773\n",
            "Train epoch - Accuracy: 0.36383838383838385 Loss: 1.7863558194613216 Corrects: 1801\n",
            "Starting epoch 4/10, LR = [0.01]\n",
            "Train step - Step 120, Loss 1.905837893486023\n",
            "Train step - Step 130, Loss 1.7809277772903442\n",
            "Train step - Step 140, Loss 1.511595368385315\n",
            "Train step - Step 150, Loss 1.6052111387252808\n",
            "Train epoch - Accuracy: 0.4082828282828283 Loss: 1.676853665775723 Corrects: 2021\n",
            "Starting epoch 5/10, LR = [0.01]\n",
            "Train step - Step 160, Loss 1.7796525955200195\n",
            "Train step - Step 170, Loss 1.6225900650024414\n",
            "Train step - Step 180, Loss 1.5531467199325562\n",
            "Train step - Step 190, Loss 1.7046858072280884\n",
            "Train epoch - Accuracy: 0.43656565656565655 Loss: 1.595561179199604 Corrects: 2161\n",
            "Starting epoch 6/10, LR = [0.01]\n",
            "Train step - Step 200, Loss 1.5400722026824951\n",
            "Train step - Step 210, Loss 1.6238794326782227\n",
            "Train step - Step 220, Loss 1.5587677955627441\n",
            "Train step - Step 230, Loss 1.3726587295532227\n",
            "Train epoch - Accuracy: 0.4678787878787879 Loss: 1.5122183130245017 Corrects: 2316\n",
            "Starting epoch 7/10, LR = [0.01]\n",
            "Train step - Step 240, Loss 1.5096471309661865\n",
            "Train step - Step 250, Loss 1.5310299396514893\n",
            "Train step - Step 260, Loss 1.4213361740112305\n",
            "Train step - Step 270, Loss 1.297217845916748\n",
            "Train epoch - Accuracy: 0.476969696969697 Loss: 1.4989046895383584 Corrects: 2361\n",
            "Starting epoch 8/10, LR = [0.01]\n",
            "Train step - Step 280, Loss 1.2622427940368652\n",
            "Train step - Step 290, Loss 1.3138902187347412\n",
            "Train step - Step 300, Loss 1.4518314599990845\n",
            "Train step - Step 310, Loss 1.4150587320327759\n",
            "Train epoch - Accuracy: 0.5042424242424243 Loss: 1.4214844545691905 Corrects: 2496\n",
            "Starting epoch 9/10, LR = [0.01]\n",
            "Train step - Step 320, Loss 1.3359737396240234\n",
            "Train step - Step 330, Loss 1.1666615009307861\n",
            "Train step - Step 340, Loss 1.1909266710281372\n",
            "Train step - Step 350, Loss 1.4835412502288818\n",
            "Train epoch - Accuracy: 0.5307070707070707 Loss: 1.344256421965782 Corrects: 2627\n",
            "Starting epoch 10/10, LR = [0.01]\n",
            "Train step - Step 360, Loss 1.294972538948059\n",
            "Train step - Step 370, Loss 1.2042639255523682\n",
            "Train step - Step 380, Loss 1.3057341575622559\n",
            "Train epoch - Accuracy: 0.5466666666666666 Loss: 1.286426595678233 Corrects: 2706\n",
            "Training finished in 98.3883912563324 seconds\n",
            "EVALUATION:  0.56 1.3276466131210327\n",
            "TEST:  0.544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c80e4568-67c2-46d4-adaa-7f0f31ff2dd2"
      },
      "source": [
        "dif_accuracies=printAccuracyDifference(net,old_accuracies)\n",
        "dif_accuracies"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.673, 0.0), (2, 0.677, 0.0), (3, 0.544, 0.544)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "910b3905-66f5-4c5e-ef99-599570f9ce34"
      },
      "source": [
        "data_plot=[]\n",
        "for row in dif_accuracies:\n",
        "    data_plot.append((row[0],\"Old Accuracy\",row[1]))\n",
        "    data_plot.append((row[0],\"New Accuracy\",row[2]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot, columns = ['Group','Type','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",hue=\"Type\",data=accuracyDF)\n",
        "plt.title(\"Catastrophic Forgetting\")\n",
        "plt.show()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}