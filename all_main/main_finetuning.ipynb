{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/master/main_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j40FSXGxD2VD",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudv9Cj8E8OI",
        "colab_type": "code",
        "outputId": "548829cd-1bda-4c87-9135-9a15089f89c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dC-rYdjD-E3",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7c6046ef-4c42-4e51-a675-a127e09d84e3"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lf-WK3hEJCM",
        "colab_type": "text"
      },
      "source": [
        "**Retrieving dataset CIFAR1000**<br>\n",
        "The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. There are 500 training images and 100 testing images per class.\n",
        "The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "Here is an example of classes in the CIFAR-100:<br>\n",
        "**Superclass**\t\n",
        "- aquatic mammals\t\n",
        "\n",
        "**Classes**\n",
        "- beaver, dolphin, otter, seal, whale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1do9ln3OVE",
        "colab_type": "code",
        "outputId": "15733239-1084-4484-f64d-fde8754007a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Cifar100/': No such file or directory\n",
            "rm: cannot remove 'DATA': No such file or directory\n",
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 1873 (delta 71), reused 103 (delta 37), pack-reused 1732\u001b[K\n",
            "Receiving objects: 100% (1873/1873), 11.98 MiB | 14.74 MiB/s, done.\n",
            "Resolving deltas: 100% (1126/1126), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "ecca2e5c-d5f7-43bf-9a19-962a736b3018"
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-10 06:38:33--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  32.8MB/s    in 5.5s    \n",
            "\n",
            "2020-06-10 06:38:39 (29.3 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XOn3bHMEBzX",
        "colab_type": "text"
      },
      "source": [
        "**Set arguments** - \n",
        "src: iCaRL section 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-pqSNg4_Ris",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "17143efb-fd19-418d-af58-f27e25d3abf8"
      },
      "source": [
        "from Cifar100 import utils\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = dictHyperparams[\"SEED\"]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 42, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oJ5m4V-ERDh",
        "colab_type": "text"
      },
      "source": [
        "**Define data preprocessing**<br>\n",
        "This transformations are applied to each images when they're loaded into the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_jHycn_1kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7EVuDrcJj2N"
      },
      "source": [
        "**Prepare dataset**<br>\n",
        "Loading of the train and test split as it comes with CIFAR100. <br>\n",
        "The trainset consists in 50k images, while the test set len is 10k images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJKwvGljJj2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f7b8975-4994-432e-9ab7-10d1da688d55"
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ckn3H69iJj2X",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLmmQn7JOLc",
        "colab_type": "text"
      },
      "source": [
        "**Build dataset splits and reverse index**<br>\n",
        "Here the train dataset is split into train and validation set, following the proportion XX/YY.<br>\n",
        "Furthermore train, test and validation sets are splitted into 10 groups containing 10 classes each (the split is coherent among the different sets).<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fov9YAFTlj",
        "colab_type": "text"
      },
      "source": [
        "**Prepare dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cfb39ad8-6fcf-406f-f575-822d87b805ef"
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)\n",
        "\n",
        "# [ DEBUG ]\n",
        "# test to check classes in different dataset\n",
        "# (coherent split)\n",
        "# RESULT: OK\n",
        "\"\"\"dict_train={}\n",
        "for img_train in train_subsets[0]:\n",
        "  if img_train[1] not in dict_train:\n",
        "    dict_train[img_train[1]]=1\n",
        "  else:\n",
        "    dict_train[img_train[1]]+=1\n",
        "dict_val={}\n",
        "for img_val in val_subsets[0]:\n",
        "  if img_val[1] not in dict_val:\n",
        "    dict_val[img_val[1]]=1\n",
        "  else:\n",
        "    dict_val[img_val[1]]+=1\n",
        "dict_test={}\n",
        "for img_test in test_subsets[0]:\n",
        "  if img_test[1] not in dict_test:\n",
        "    dict_test[img_test[1]]=1\n",
        "  else:\n",
        "    dict_test[img_test[1]]+=1\n",
        "\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dict_train={}\\nfor img_train in train_subsets[0]:\\n  if img_train[1] not in dict_train:\\n    dict_train[img_train[1]]=1\\n  else:\\n    dict_train[img_train[1]]+=1\\ndict_val={}\\nfor img_val in val_subsets[0]:\\n  if img_val[1] not in dict_val:\\n    dict_val[img_val[1]]=1\\n  else:\\n    dict_val[img_val[1]]+=1\\ndict_test={}\\nfor img_test in test_subsets[0]:\\n  if img_test[1] not in dict_test:\\n    dict_test[img_test[1]]=1\\n  else:\\n    dict_test[img_test[1]]+=1\\n\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d19CnhIUg0q",
        "colab_type": "text"
      },
      "source": [
        "**Utility functions to use our customized resnet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ff9pwV10b0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.resnet import resnet32\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getResNet32():\n",
        "    net = resnet32()\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = utils.getLossCriterion()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet32()\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glyt2p3XTEqt",
        "colab_type": "text"
      },
      "source": [
        "**Basic train, test and validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzG6w15UudAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, num_epochs=NUM_EPOCHS):     \n",
        "    # By default, everything is loaded to cpu\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    \n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            # preds = getLabels(outputs_labels_mapping, preds)\n",
        "            # print(preds)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    utils.getLossCriterion()\n",
        "\n",
        "    # confusion matrix\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "        # Bring data over the device of choice\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        #labels = outputs_labels_mapping.getNodes(labels)\n",
        "        labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(images)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # preds = getLabels(outputs_labels_mapping, preds)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    # Calculate Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiWapdlNNsA0",
        "colab_type": "text"
      },
      "source": [
        "**Joint Training**<br>\n",
        "In this section joint training is perfomed.<br>\n",
        "The train of the network is split into 10 stages, one for each subset classes.\n",
        "At each step, the network is trained on the images corresponding to the current 10 classes and all the data already seen in the previous steps.\n",
        "The joint training score, evaluated in terms of accuracy on the test set, gives us an UB for the next methodologies examined in this project (iCaRL, LWF).<br>\n",
        "Operatively, what happens is a very slow training and, furthermore, we break the assumption of not needing the previous batches of data at each step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4InuBhsENpV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####\n",
        "## Joint training\n",
        "####\n",
        "# Joins 2+ subsets into a new Subset (joint training)\n",
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "def jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getNet()\n",
        "\n",
        "    train_set = None\n",
        "    test_set = None\n",
        "    first_pass = True\n",
        "\n",
        "    current_train_num = 0\n",
        "    total_trains = len(train_subsets)\n",
        "    joint_start = time.time()\n",
        "\n",
        "    print('\\n\\nJoint-training start\\n\\n')\n",
        "    all_accuracies=[]\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "        phase_start = time.time()\n",
        "        print('\\n\\nJoint phase {}/{}\\n\\n'.format(current_train_num+1, total_trains))\n",
        "        current_train_num += 1\n",
        "\n",
        "        #num_classes_per_group = 10\n",
        "        num_classes_seen = current_train_num*10\n",
        "\n",
        "        # Builds growing train and test set. The new sets include data from previous class groups and current class group\n",
        "        if train_set is None:\n",
        "            train_set = train_subset\n",
        "        else:\n",
        "            train_set = joinSubsets(train_dataset, [train_set, train_subset])\n",
        "        if test_set is None:\n",
        "            test_set = test_subset\n",
        "        else:\n",
        "            test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        if first_pass:\n",
        "            first_pass = False\n",
        "        else:\n",
        "            addOutputs(net, 10)\n",
        "\n",
        "        # Trains model on previous and current class groups\n",
        "        optimizer, scheduler = getSchedulerOptimizer(net)\n",
        "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "        # Validate model on current class group\n",
        "        val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        v_acc, v_loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "        print('\\nValidation accuracy: {} - Validation loss: {}\\n'.format(v_acc, v_loss))\n",
        "\n",
        "        # Test the model on previous and current class groups\n",
        "        test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "        all_accuracies.append(acc_all)\n",
        "        print('\\nTest accuracy: {}\\n'.format(acc_all))\n",
        "\n",
        "        print('\\n\\nPhase completed in {} seconds\\n\\n'.format(time.time() - phase_start))\n",
        "    \n",
        "    print('\\n\\n Joint-training finished in {} seconds'.format(time.time() - joint_start))\n",
        "    return net, all_accuracies, all_preds_cm, all_labels_cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOiPlN8ON4Gn",
        "colab_type": "text"
      },
      "source": [
        "**Test joint training**<br>\n",
        "What we expect is a test accuracy higher of what we'll be able to achieve using iCaRL, LWF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDecUBiHl4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bc882a6-d092-4084-c7ef-959b5f2f16e0"
      },
      "source": [
        "# Test Joint training\n",
        "\n",
        "net, all_accuracies, all_preds_cm, all_labels_cm = jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets)\n",
        "\n",
        "# output Joint training\n",
        "method = \"jointtraining\"\n",
        "print(\"metrics jointtraining for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_line.append(((id+1)*10,all_accuracies[id]))\n",
        "\n",
        "#plt.figure(figsize=(20,7))\n",
        "#accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "#ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "#plt.title(\"Single Group Sequential Accuracy\")\n",
        "#plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "utils.writeMetrics(method, RANDOM_SEED, all_accuracies, confusionMatrixData)\n",
        "\n",
        "# [DEBUG]\n",
        "#net, criterion, optimizer, scheduler = getResNet32()\n",
        "#train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "#train(net, train_dataloader, criterion, optimizer, scheduler)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Joint-training start\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Joint phase 1/10\n",
            "\n",
            "\n",
            "Starting epoch 1/70, LR = [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train step - Step 4410, Loss 0.01757151633501053\n",
            "Train step - Step 4420, Loss 0.01914128288626671\n",
            "Train step - Step 4430, Loss 0.021019693464040756\n",
            "Train step - Step 4440, Loss 0.019819555804133415\n",
            "Train step - Step 4450, Loss 0.024213099852204323\n",
            "Train step - Step 4460, Loss 0.022808922454714775\n",
            "Train step - Step 4470, Loss 0.015928272157907486\n",
            "Train step - Step 4480, Loss 0.019707078114151955\n",
            "Train step - Step 4490, Loss 0.021032137796282768\n",
            "Train step - Step 4500, Loss 0.019204210489988327\n",
            "Train step - Step 4510, Loss 0.018045928329229355\n",
            "Train step - Step 4520, Loss 0.017775069922208786\n",
            "Train step - Step 4530, Loss 0.02240082435309887\n",
            "Train epoch - Accuracy: 0.682334455667789 Loss: 0.019390462218176502 Corrects: 30398\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 4540, Loss 0.02151624858379364\n",
            "Train step - Step 4550, Loss 0.024143997579813004\n",
            "Train step - Step 4560, Loss 0.021988140419125557\n",
            "Train step - Step 4570, Loss 0.019359590485692024\n",
            "Train step - Step 4580, Loss 0.020743226632475853\n",
            "Train step - Step 4590, Loss 0.02173391915857792\n",
            "Train step - Step 4600, Loss 0.01847175881266594\n",
            "Train step - Step 4610, Loss 0.018951112404465675\n",
            "Train step - Step 4620, Loss 0.017970310524106026\n",
            "Train step - Step 4630, Loss 0.020794928073883057\n",
            "Train step - Step 4640, Loss 0.017056772485375404\n",
            "Train step - Step 4650, Loss 0.020035138353705406\n",
            "Train step - Step 4660, Loss 0.019096186384558678\n",
            "Train step - Step 4670, Loss 0.021608591079711914\n",
            "Train step - Step 4680, Loss 0.017054716125130653\n",
            "Train step - Step 4690, Loss 0.02062004990875721\n",
            "Train step - Step 4700, Loss 0.018564498052001\n",
            "Train step - Step 4710, Loss 0.019192911684513092\n",
            "Train step - Step 4720, Loss 0.01945067010819912\n",
            "Train step - Step 4730, Loss 0.01826542429625988\n",
            "Train step - Step 4740, Loss 0.017320457845926285\n",
            "Train step - Step 4750, Loss 0.019629238173365593\n",
            "Train step - Step 4760, Loss 0.016788994893431664\n",
            "Train step - Step 4770, Loss 0.020332152023911476\n",
            "Train step - Step 4780, Loss 0.02218955010175705\n",
            "Train step - Step 4790, Loss 0.02071182057261467\n",
            "Train step - Step 4800, Loss 0.017311159521341324\n",
            "Train step - Step 4810, Loss 0.018723636865615845\n",
            "Train step - Step 4820, Loss 0.01901758834719658\n",
            "Train step - Step 4830, Loss 0.019800303503870964\n",
            "Train step - Step 4840, Loss 0.020219644531607628\n",
            "Train step - Step 4850, Loss 0.020290538668632507\n",
            "Train step - Step 4860, Loss 0.01840859092772007\n",
            "Train step - Step 4870, Loss 0.016488028690218925\n",
            "Train step - Step 4880, Loss 0.01881418004631996\n",
            "Train epoch - Accuracy: 0.6842648709315376 Loss: 0.019344181559402936 Corrects: 30484\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 4890, Loss 0.021653035655617714\n",
            "Train step - Step 4900, Loss 0.020980017259716988\n",
            "Train step - Step 4910, Loss 0.01922070048749447\n",
            "Train step - Step 4920, Loss 0.018616406247019768\n",
            "Train step - Step 4930, Loss 0.020478716120123863\n",
            "Train step - Step 4940, Loss 0.017656853422522545\n",
            "Train step - Step 4950, Loss 0.01974288374185562\n",
            "Train step - Step 4960, Loss 0.01963893137872219\n",
            "Train step - Step 4970, Loss 0.02174353040754795\n",
            "Train step - Step 4980, Loss 0.01923873834311962\n",
            "Train step - Step 4990, Loss 0.023697156459093094\n",
            "Train step - Step 5000, Loss 0.020115062594413757\n",
            "Train step - Step 5010, Loss 0.01792324334383011\n",
            "Train step - Step 5020, Loss 0.020376645028591156\n",
            "Train step - Step 5030, Loss 0.01842089742422104\n",
            "Train step - Step 5040, Loss 0.017634674906730652\n",
            "Train step - Step 5050, Loss 0.020023761317133904\n",
            "Train step - Step 5060, Loss 0.016105681657791138\n",
            "Train step - Step 5070, Loss 0.021251177415251732\n",
            "Train step - Step 5080, Loss 0.022340668365359306\n",
            "Train step - Step 5090, Loss 0.019725730642676353\n",
            "Train step - Step 5100, Loss 0.021063175052404404\n",
            "Train step - Step 5110, Loss 0.0232707429677248\n",
            "Train step - Step 5120, Loss 0.017612474039196968\n",
            "Train step - Step 5130, Loss 0.020248210057616234\n",
            "Train step - Step 5140, Loss 0.020776161924004555\n",
            "Train step - Step 5150, Loss 0.02080415189266205\n",
            "Train step - Step 5160, Loss 0.021872684359550476\n",
            "Train step - Step 5170, Loss 0.019676493480801582\n",
            "Train step - Step 5180, Loss 0.018891874700784683\n",
            "Train step - Step 5190, Loss 0.018395882099866867\n",
            "Train step - Step 5200, Loss 0.01840144768357277\n",
            "Train step - Step 5210, Loss 0.019145002588629723\n",
            "Train step - Step 5220, Loss 0.018716271966695786\n",
            "Train step - Step 5230, Loss 0.018082229420542717\n",
            "Train epoch - Accuracy: 0.6817732884399551 Loss: 0.019347469217983294 Corrects: 30373\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 5240, Loss 0.02453884668648243\n",
            "Train step - Step 5250, Loss 0.020305635407567024\n",
            "Train step - Step 5260, Loss 0.021141840144991875\n",
            "Train step - Step 5270, Loss 0.018865220248699188\n",
            "Train step - Step 5280, Loss 0.018346676602959633\n",
            "Train step - Step 5290, Loss 0.016907989978790283\n",
            "Train step - Step 5300, Loss 0.01893012784421444\n",
            "Train step - Step 5310, Loss 0.019776487722992897\n",
            "Train step - Step 5320, Loss 0.020281387493014336\n",
            "Train step - Step 5330, Loss 0.015867237001657486\n",
            "Train step - Step 5340, Loss 0.01941129006445408\n",
            "Train step - Step 5350, Loss 0.01956399716436863\n",
            "Train step - Step 5360, Loss 0.02138609066605568\n",
            "Train step - Step 5370, Loss 0.020150264725089073\n",
            "Train step - Step 5380, Loss 0.015904884785413742\n",
            "Train step - Step 5390, Loss 0.02130873315036297\n",
            "Train step - Step 5400, Loss 0.016242213547229767\n",
            "Train step - Step 5410, Loss 0.01636236533522606\n",
            "Train step - Step 5420, Loss 0.017980413511395454\n",
            "Train step - Step 5430, Loss 0.01685655117034912\n",
            "Train step - Step 5440, Loss 0.020316457375884056\n",
            "Train step - Step 5450, Loss 0.01845529116690159\n",
            "Train step - Step 5460, Loss 0.016620345413684845\n",
            "Train step - Step 5470, Loss 0.018933042883872986\n",
            "Train step - Step 5480, Loss 0.021280400454998016\n",
            "Train step - Step 5490, Loss 0.01741536520421505\n",
            "Train step - Step 5500, Loss 0.018044985830783844\n",
            "Train step - Step 5510, Loss 0.019105365499854088\n",
            "Train step - Step 5520, Loss 0.015080507844686508\n",
            "Train step - Step 5530, Loss 0.017661388963460922\n",
            "Train step - Step 5540, Loss 0.02199672907590866\n",
            "Train step - Step 5550, Loss 0.017317086458206177\n",
            "Train step - Step 5560, Loss 0.018229344859719276\n",
            "Train step - Step 5570, Loss 0.01973315142095089\n",
            "Train step - Step 5580, Loss 0.02366335690021515\n",
            "Train epoch - Accuracy: 0.682716049382716 Loss: 0.01935722178531817 Corrects: 30415\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 5590, Loss 0.026399631053209305\n",
            "Train step - Step 5600, Loss 0.02051362581551075\n",
            "Train step - Step 5610, Loss 0.018378546461462975\n",
            "Train step - Step 5620, Loss 0.021245822310447693\n",
            "Train step - Step 5630, Loss 0.02127308025956154\n",
            "Train step - Step 5640, Loss 0.016674740239977837\n",
            "Train step - Step 5650, Loss 0.02011190727353096\n",
            "Train step - Step 5660, Loss 0.0172894224524498\n",
            "Train step - Step 5670, Loss 0.02009078487753868\n",
            "Train step - Step 5680, Loss 0.01784299686551094\n",
            "Train step - Step 5690, Loss 0.01968616433441639\n",
            "Train step - Step 5700, Loss 0.01832546480000019\n",
            "Train step - Step 5710, Loss 0.01913335919380188\n",
            "Train step - Step 5720, Loss 0.019787386059761047\n",
            "Train step - Step 5730, Loss 0.018555117771029472\n",
            "Train step - Step 5740, Loss 0.017322540283203125\n",
            "Train step - Step 5750, Loss 0.020657552406191826\n",
            "Train step - Step 5760, Loss 0.016652721911668777\n",
            "Train step - Step 5770, Loss 0.01834198459982872\n",
            "Train step - Step 5780, Loss 0.018486201763153076\n",
            "Train step - Step 5790, Loss 0.02077828347682953\n",
            "Train step - Step 5800, Loss 0.017572911456227303\n",
            "Train step - Step 5810, Loss 0.018800457939505577\n",
            "Train step - Step 5820, Loss 0.018522923812270164\n",
            "Train step - Step 5830, Loss 0.017414715141057968\n",
            "Train step - Step 5840, Loss 0.01757953129708767\n",
            "Train step - Step 5850, Loss 0.017361251637339592\n",
            "Train step - Step 5860, Loss 0.017005018889904022\n",
            "Train step - Step 5870, Loss 0.019630685448646545\n",
            "Train step - Step 5880, Loss 0.016712957993149757\n",
            "Train step - Step 5890, Loss 0.018810542300343513\n",
            "Train step - Step 5900, Loss 0.02037120796740055\n",
            "Train step - Step 5910, Loss 0.01859704777598381\n",
            "Train step - Step 5920, Loss 0.01601240411400795\n",
            "Train step - Step 5930, Loss 0.020081061869859695\n",
            "Train epoch - Accuracy: 0.6838608305274972 Loss: 0.019415699691918295 Corrects: 30466\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 5940, Loss 0.027181295678019524\n",
            "Train step - Step 5950, Loss 0.021656660363078117\n",
            "Train step - Step 5960, Loss 0.02292734757065773\n",
            "Train step - Step 5970, Loss 0.019838929176330566\n",
            "Train step - Step 5980, Loss 0.02448456548154354\n",
            "Train step - Step 5990, Loss 0.01903940550982952\n",
            "Train step - Step 6000, Loss 0.019521895796060562\n",
            "Train step - Step 6010, Loss 0.017898816615343094\n",
            "Train step - Step 6020, Loss 0.01925199292600155\n",
            "Train step - Step 6030, Loss 0.017889805138111115\n",
            "Train step - Step 6040, Loss 0.019391020759940147\n",
            "Train step - Step 6050, Loss 0.022460641339421272\n",
            "Train step - Step 6060, Loss 0.018179379403591156\n",
            "Train step - Step 6070, Loss 0.016966287046670914\n",
            "Train step - Step 6080, Loss 0.020761869847774506\n",
            "Train step - Step 6090, Loss 0.0178088266402483\n",
            "Train step - Step 6100, Loss 0.016659094020724297\n",
            "Train step - Step 6110, Loss 0.020124323666095734\n",
            "Train step - Step 6120, Loss 0.01683180220425129\n",
            "Train step - Step 6130, Loss 0.018228132277727127\n",
            "Train step - Step 6140, Loss 0.017585407942533493\n",
            "Train step - Step 6150, Loss 0.019521525129675865\n",
            "Train step - Step 6160, Loss 0.02089368738234043\n",
            "Train step - Step 6170, Loss 0.023650556802749634\n",
            "Train step - Step 6180, Loss 0.02142818458378315\n",
            "Train step - Step 6190, Loss 0.01830759271979332\n",
            "Train step - Step 6200, Loss 0.017067845910787582\n",
            "Train step - Step 6210, Loss 0.021101146936416626\n",
            "Train step - Step 6220, Loss 0.01750883087515831\n",
            "Train step - Step 6230, Loss 0.0190728846937418\n",
            "Train step - Step 6240, Loss 0.023148953914642334\n",
            "Train step - Step 6250, Loss 0.02064952440559864\n",
            "Train step - Step 6260, Loss 0.01889636740088463\n",
            "Train step - Step 6270, Loss 0.018869750201702118\n",
            "Train step - Step 6280, Loss 0.018797961995005608\n",
            "Train epoch - Accuracy: 0.6761840628507295 Loss: 0.019713293899155895 Corrects: 30124\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 6290, Loss 0.017343319952487946\n",
            "Train step - Step 6300, Loss 0.019279731437563896\n",
            "Train step - Step 6310, Loss 0.018982578068971634\n",
            "Train step - Step 6320, Loss 0.017601657658815384\n",
            "Train step - Step 6330, Loss 0.01952831819653511\n",
            "Train step - Step 6340, Loss 0.015918279066681862\n",
            "Train step - Step 6350, Loss 0.01844443939626217\n",
            "Train step - Step 6360, Loss 0.01797931268811226\n",
            "Train step - Step 6370, Loss 0.021627191454172134\n",
            "Train step - Step 6380, Loss 0.018510282039642334\n",
            "Train step - Step 6390, Loss 0.017444152384996414\n",
            "Train step - Step 6400, Loss 0.01949118822813034\n",
            "Train step - Step 6410, Loss 0.017478078603744507\n",
            "Train step - Step 6420, Loss 0.018158962950110435\n",
            "Train step - Step 6430, Loss 0.01993587240576744\n",
            "Train step - Step 6440, Loss 0.019578097388148308\n",
            "Train step - Step 6450, Loss 0.020741285756230354\n",
            "Train step - Step 6460, Loss 0.023271873593330383\n",
            "Train step - Step 6470, Loss 0.018062004819512367\n",
            "Train step - Step 6480, Loss 0.017193756997585297\n",
            "Train step - Step 6490, Loss 0.0164760984480381\n",
            "Train step - Step 6500, Loss 0.018910853192210197\n",
            "Train step - Step 6510, Loss 0.02142862230539322\n",
            "Train step - Step 6520, Loss 0.02063196524977684\n",
            "Train step - Step 6530, Loss 0.01975652016699314\n",
            "Train step - Step 6540, Loss 0.019059009850025177\n",
            "Train step - Step 6550, Loss 0.016317367553710938\n",
            "Train step - Step 6560, Loss 0.017851796001195908\n",
            "Train step - Step 6570, Loss 0.01984368823468685\n",
            "Train step - Step 6580, Loss 0.01742047257721424\n",
            "Train step - Step 6590, Loss 0.020738884806632996\n",
            "Train step - Step 6600, Loss 0.019239122048020363\n",
            "Train step - Step 6610, Loss 0.01809515431523323\n",
            "Train step - Step 6620, Loss 0.01946433074772358\n",
            "Train step - Step 6630, Loss 0.04940904676914215\n",
            "Train epoch - Accuracy: 0.6863299663299663 Loss: 0.019093111197555104 Corrects: 30576\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 6640, Loss 0.02169322781264782\n",
            "Train step - Step 6650, Loss 0.022988254204392433\n",
            "Train step - Step 6660, Loss 0.0220927931368351\n",
            "Train step - Step 6670, Loss 0.01871144026517868\n",
            "Train step - Step 6680, Loss 0.021236492320895195\n",
            "Train step - Step 6690, Loss 0.019865820184350014\n",
            "Train step - Step 6700, Loss 0.020250696688890457\n",
            "Train step - Step 6710, Loss 0.019145095720887184\n",
            "Train step - Step 6720, Loss 0.017924780026078224\n",
            "Train step - Step 6730, Loss 0.016148585826158524\n",
            "Train step - Step 6740, Loss 0.015367700718343258\n",
            "Train step - Step 6750, Loss 0.02191227860748768\n",
            "Train step - Step 6760, Loss 0.018597997725009918\n",
            "Train step - Step 6770, Loss 0.018696138635277748\n",
            "Train step - Step 6780, Loss 0.0204567089676857\n",
            "Train step - Step 6790, Loss 0.020099129527807236\n",
            "Train step - Step 6800, Loss 0.016771504655480385\n",
            "Train step - Step 6810, Loss 0.020381461828947067\n",
            "Train step - Step 6820, Loss 0.016244616359472275\n",
            "Train step - Step 6830, Loss 0.020543286576867104\n",
            "Train step - Step 6840, Loss 0.01763366162776947\n",
            "Train step - Step 6850, Loss 0.021800443530082703\n",
            "Train step - Step 6860, Loss 0.019601166248321533\n",
            "Train step - Step 6870, Loss 0.02028178796172142\n",
            "Train step - Step 6880, Loss 0.01748979091644287\n",
            "Train step - Step 6890, Loss 0.01788203790783882\n",
            "Train step - Step 6900, Loss 0.023429738357663155\n",
            "Train step - Step 6910, Loss 0.015262344852089882\n",
            "Train step - Step 6920, Loss 0.019919531419873238\n",
            "Train step - Step 6930, Loss 0.017272576689720154\n",
            "Train step - Step 6940, Loss 0.018486060202121735\n",
            "Train step - Step 6950, Loss 0.020907998085021973\n",
            "Train step - Step 6960, Loss 0.01910879835486412\n",
            "Train step - Step 6970, Loss 0.017736701294779778\n",
            "Train epoch - Accuracy: 0.6857463524130191 Loss: 0.019184433947391517 Corrects: 30550\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 6980, Loss 0.01857544295489788\n",
            "Train step - Step 6990, Loss 0.021641183644533157\n",
            "Train step - Step 7000, Loss 0.020223578438162804\n",
            "Train step - Step 7010, Loss 0.019313817843794823\n",
            "Train step - Step 7020, Loss 0.017651338130235672\n",
            "Train step - Step 7030, Loss 0.021005533635616302\n",
            "Train step - Step 7040, Loss 0.020109735429286957\n",
            "Train step - Step 7050, Loss 0.01736871525645256\n",
            "Train step - Step 7060, Loss 0.017734099179506302\n",
            "Train step - Step 7070, Loss 0.01966971345245838\n",
            "Train step - Step 7080, Loss 0.01735972799360752\n",
            "Train step - Step 7090, Loss 0.020843932405114174\n",
            "Train step - Step 7100, Loss 0.018930191174149513\n",
            "Train step - Step 7110, Loss 0.019911102950572968\n",
            "Train step - Step 7120, Loss 0.017381440848112106\n",
            "Train step - Step 7130, Loss 0.018278008326888084\n",
            "Train step - Step 7140, Loss 0.019865896552801132\n",
            "Train step - Step 7150, Loss 0.016740789636969566\n",
            "Train step - Step 7160, Loss 0.019404718652367592\n",
            "Train step - Step 7170, Loss 0.020394545048475266\n",
            "Train step - Step 7180, Loss 0.01999959908425808\n",
            "Train step - Step 7190, Loss 0.022113850340247154\n",
            "Train step - Step 7200, Loss 0.01867985725402832\n",
            "Train step - Step 7210, Loss 0.014855637215077877\n",
            "Train step - Step 7220, Loss 0.018582288175821304\n",
            "Train step - Step 7230, Loss 0.01872381381690502\n",
            "Train step - Step 7240, Loss 0.020549369975924492\n",
            "Train step - Step 7250, Loss 0.016430910676717758\n",
            "Train step - Step 7260, Loss 0.01887502893805504\n",
            "Train step - Step 7270, Loss 0.020083650946617126\n",
            "Train step - Step 7280, Loss 0.01675746776163578\n",
            "Train step - Step 7290, Loss 0.020082449540495872\n",
            "Train step - Step 7300, Loss 0.020154669880867004\n",
            "Train step - Step 7310, Loss 0.01917452923953533\n",
            "Train step - Step 7320, Loss 0.018148943781852722\n",
            "Train epoch - Accuracy: 0.6882379349046016 Loss: 0.019142020878232555 Corrects: 30661\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 7330, Loss 0.024359507486224174\n",
            "Train step - Step 7340, Loss 0.023567667230963707\n",
            "Train step - Step 7350, Loss 0.020917696878314018\n",
            "Train step - Step 7360, Loss 0.018412534147500992\n",
            "Train step - Step 7370, Loss 0.01974574476480484\n",
            "Train step - Step 7380, Loss 0.01945759542286396\n",
            "Train step - Step 7390, Loss 0.02054748684167862\n",
            "Train step - Step 7400, Loss 0.017617689445614815\n",
            "Train step - Step 7410, Loss 0.018457286059856415\n",
            "Train step - Step 7420, Loss 0.01907401718199253\n",
            "Train step - Step 7430, Loss 0.019556008279323578\n",
            "Train step - Step 7440, Loss 0.023066207766532898\n",
            "Train step - Step 7450, Loss 0.01880025863647461\n",
            "Train step - Step 7460, Loss 0.01946203224360943\n",
            "Train step - Step 7470, Loss 0.01843218505382538\n",
            "Train step - Step 7480, Loss 0.016924124211072922\n",
            "Train step - Step 7490, Loss 0.015700705349445343\n",
            "Train step - Step 7500, Loss 0.01870352402329445\n",
            "Train step - Step 7510, Loss 0.02107158489525318\n",
            "Train step - Step 7520, Loss 0.019247760996222496\n",
            "Train step - Step 7530, Loss 0.018439944833517075\n",
            "Train step - Step 7540, Loss 0.016833478584885597\n",
            "Train step - Step 7550, Loss 0.01887340284883976\n",
            "Train step - Step 7560, Loss 0.018450627103447914\n",
            "Train step - Step 7570, Loss 0.01944785751402378\n",
            "Train step - Step 7580, Loss 0.01653902418911457\n",
            "Train step - Step 7590, Loss 0.020910954102873802\n",
            "Train step - Step 7600, Loss 0.020028352737426758\n",
            "Train step - Step 7610, Loss 0.01809149980545044\n",
            "Train step - Step 7620, Loss 0.02090352773666382\n",
            "Train step - Step 7630, Loss 0.01785377785563469\n",
            "Train step - Step 7640, Loss 0.02230468951165676\n",
            "Train step - Step 7650, Loss 0.02067287638783455\n",
            "Train step - Step 7660, Loss 0.019182750955224037\n",
            "Train step - Step 7670, Loss 0.020406268537044525\n",
            "Train epoch - Accuracy: 0.6821997755331088 Loss: 0.01936172342419156 Corrects: 30392\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 7680, Loss 0.02281058207154274\n",
            "Train step - Step 7690, Loss 0.022939449176192284\n",
            "Train step - Step 7700, Loss 0.021287905052304268\n",
            "Train step - Step 7710, Loss 0.018643392249941826\n",
            "Train step - Step 7720, Loss 0.018567588180303574\n",
            "Train step - Step 7730, Loss 0.019088372588157654\n",
            "Train step - Step 7740, Loss 0.01976758986711502\n",
            "Train step - Step 7750, Loss 0.019668836146593094\n",
            "Train step - Step 7760, Loss 0.017468802630901337\n",
            "Train step - Step 7770, Loss 0.014905765652656555\n",
            "Train step - Step 7780, Loss 0.01710321195423603\n",
            "Train step - Step 7790, Loss 0.02043791487812996\n",
            "Train step - Step 7800, Loss 0.017767611891031265\n",
            "Train step - Step 7810, Loss 0.01934468001127243\n",
            "Train step - Step 7820, Loss 0.018201084807515144\n",
            "Train step - Step 7830, Loss 0.0187515951693058\n",
            "Train step - Step 7840, Loss 0.017971940338611603\n",
            "Train step - Step 7850, Loss 0.023867744952440262\n",
            "Train step - Step 7860, Loss 0.019415654242038727\n",
            "Train step - Step 7870, Loss 0.01866942271590233\n",
            "Train step - Step 7880, Loss 0.01690700277686119\n",
            "Train step - Step 7890, Loss 0.017632177099585533\n",
            "Train step - Step 7900, Loss 0.020120272412896156\n",
            "Train step - Step 7910, Loss 0.020068617537617683\n",
            "Train step - Step 7920, Loss 0.01804344914853573\n",
            "Train step - Step 7930, Loss 0.01646798849105835\n",
            "Train step - Step 7940, Loss 0.02127699926495552\n",
            "Train step - Step 7950, Loss 0.020220333710312843\n",
            "Train step - Step 7960, Loss 0.019621556624770164\n",
            "Train step - Step 7970, Loss 0.019269851967692375\n",
            "Train step - Step 7980, Loss 0.01925773359835148\n",
            "Train step - Step 7990, Loss 0.017630470916628838\n",
            "Train step - Step 8000, Loss 0.01810258999466896\n",
            "Train step - Step 8010, Loss 0.016390744596719742\n",
            "Train step - Step 8020, Loss 0.019649436697363853\n",
            "Train epoch - Accuracy: 0.6875196408529742 Loss: 0.019151497893160844 Corrects: 30629\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 8030, Loss 0.024458615109324455\n",
            "Train step - Step 8040, Loss 0.021690761670470238\n",
            "Train step - Step 8050, Loss 0.020334459841251373\n",
            "Train step - Step 8060, Loss 0.01950291357934475\n",
            "Train step - Step 8070, Loss 0.018438901752233505\n",
            "Train step - Step 8080, Loss 0.014693056233227253\n",
            "Train step - Step 8090, Loss 0.019317924976348877\n",
            "Train step - Step 8100, Loss 0.019940683618187904\n",
            "Train step - Step 8110, Loss 0.01666519232094288\n",
            "Train step - Step 8120, Loss 0.019793497398495674\n",
            "Train step - Step 8130, Loss 0.018478041514754295\n",
            "Train step - Step 8140, Loss 0.021036285907030106\n",
            "Train step - Step 8150, Loss 0.01894022896885872\n",
            "Train step - Step 8160, Loss 0.016617508605122566\n",
            "Train step - Step 8170, Loss 0.01683962717652321\n",
            "Train step - Step 8180, Loss 0.016520608216524124\n",
            "Train step - Step 8190, Loss 0.014293456450104713\n",
            "Train step - Step 8200, Loss 0.018387699499726295\n",
            "Train step - Step 8210, Loss 0.019015438854694366\n",
            "Train step - Step 8220, Loss 0.019208455458283424\n",
            "Train step - Step 8230, Loss 0.017514647915959358\n",
            "Train step - Step 8240, Loss 0.016337841749191284\n",
            "Train step - Step 8250, Loss 0.01849997788667679\n",
            "Train step - Step 8260, Loss 0.017465179786086082\n",
            "Train step - Step 8270, Loss 0.021047165617346764\n",
            "Train step - Step 8280, Loss 0.017946818843483925\n",
            "Train step - Step 8290, Loss 0.019077913835644722\n",
            "Train step - Step 8300, Loss 0.01779545098543167\n",
            "Train step - Step 8310, Loss 0.016665292903780937\n",
            "Train step - Step 8320, Loss 0.02065916731953621\n",
            "Train step - Step 8330, Loss 0.01657515950500965\n",
            "Train step - Step 8340, Loss 0.020855680108070374\n",
            "Train step - Step 8350, Loss 0.018376780673861504\n",
            "Train step - Step 8360, Loss 0.02166754938662052\n",
            "Train step - Step 8370, Loss 0.02106226049363613\n",
            "Train epoch - Accuracy: 0.6874523007856341 Loss: 0.019197302235397024 Corrects: 30626\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 8380, Loss 0.02749033086001873\n",
            "Train step - Step 8390, Loss 0.020020604133605957\n",
            "Train step - Step 8400, Loss 0.022675657644867897\n",
            "Train step - Step 8410, Loss 0.018862595781683922\n",
            "Train step - Step 8420, Loss 0.0182839073240757\n",
            "Train step - Step 8430, Loss 0.019023042172193527\n",
            "Train step - Step 8440, Loss 0.020345542579889297\n",
            "Train step - Step 8450, Loss 0.017692267894744873\n",
            "Train step - Step 8460, Loss 0.018342291936278343\n",
            "Train step - Step 8470, Loss 0.019060542806982994\n",
            "Train step - Step 8480, Loss 0.017326898872852325\n",
            "Train step - Step 8490, Loss 0.017090076580643654\n",
            "Train step - Step 8500, Loss 0.02033291384577751\n",
            "Train step - Step 8510, Loss 0.01937922090291977\n",
            "Train step - Step 8520, Loss 0.020250806584954262\n",
            "Train step - Step 8530, Loss 0.017421526834368706\n",
            "Train step - Step 8540, Loss 0.016654765233397484\n",
            "Train step - Step 8550, Loss 0.020337585359811783\n",
            "Train step - Step 8560, Loss 0.016763271763920784\n",
            "Train step - Step 8570, Loss 0.01742534153163433\n",
            "Train step - Step 8580, Loss 0.019412340596318245\n",
            "Train step - Step 8590, Loss 0.020294269546866417\n",
            "Train step - Step 8600, Loss 0.01769619807600975\n",
            "Train step - Step 8610, Loss 0.016335152089595795\n",
            "Train step - Step 8620, Loss 0.018195008859038353\n",
            "Train step - Step 8630, Loss 0.016889767721295357\n",
            "Train step - Step 8640, Loss 0.019944624975323677\n",
            "Train step - Step 8650, Loss 0.01908830925822258\n",
            "Train step - Step 8660, Loss 0.0220546443015337\n",
            "Train step - Step 8670, Loss 0.018162667751312256\n",
            "Train step - Step 8680, Loss 0.020983589813113213\n",
            "Train step - Step 8690, Loss 0.018665745854377747\n",
            "Train step - Step 8700, Loss 0.02141747996211052\n",
            "Train step - Step 8710, Loss 0.02173473685979843\n",
            "Train step - Step 8720, Loss 0.0202469564974308\n",
            "Train epoch - Accuracy: 0.6819304152637486 Loss: 0.019356076681921644 Corrects: 30380\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 8730, Loss 0.024810301139950752\n",
            "Train step - Step 8740, Loss 0.02405894175171852\n",
            "Train step - Step 8750, Loss 0.02559647709131241\n",
            "Train step - Step 8760, Loss 0.019516512751579285\n",
            "Train step - Step 8770, Loss 0.019295038655400276\n",
            "Train step - Step 8780, Loss 0.019617224112153053\n",
            "Train step - Step 8790, Loss 0.021213460713624954\n",
            "Train step - Step 8800, Loss 0.019209396094083786\n",
            "Train step - Step 8810, Loss 0.020687762647867203\n",
            "Train step - Step 8820, Loss 0.021490126848220825\n",
            "Train step - Step 8830, Loss 0.0189233236014843\n",
            "Train step - Step 8840, Loss 0.01935175061225891\n",
            "Train step - Step 8850, Loss 0.018839942291378975\n",
            "Train step - Step 8860, Loss 0.02037934586405754\n",
            "Train step - Step 8870, Loss 0.017078783363103867\n",
            "Train step - Step 8880, Loss 0.016321450471878052\n",
            "Train step - Step 8890, Loss 0.01773190125823021\n",
            "Train step - Step 8900, Loss 0.019262999296188354\n",
            "Train step - Step 8910, Loss 0.019929302856326103\n",
            "Train step - Step 8920, Loss 0.02064509317278862\n",
            "Train step - Step 8930, Loss 0.01769627444446087\n",
            "Train step - Step 8940, Loss 0.015235554426908493\n",
            "Train step - Step 8950, Loss 0.01865588128566742\n",
            "Train step - Step 8960, Loss 0.019775817170739174\n",
            "Train step - Step 8970, Loss 0.019085729494690895\n",
            "Train step - Step 8980, Loss 0.016910625621676445\n",
            "Train step - Step 8990, Loss 0.022735927253961563\n",
            "Train step - Step 9000, Loss 0.020138099789619446\n",
            "Train step - Step 9010, Loss 0.022889813408255577\n",
            "Train step - Step 9020, Loss 0.019560033455491066\n",
            "Train step - Step 9030, Loss 0.021268941462039948\n",
            "Train step - Step 9040, Loss 0.019179536029696465\n",
            "Train step - Step 9050, Loss 0.01929650828242302\n",
            "Train step - Step 9060, Loss 0.01834598369896412\n",
            "Train step - Step 9070, Loss 0.0205110814422369\n",
            "Train epoch - Accuracy: 0.6830751964085298 Loss: 0.01926751390350387 Corrects: 30431\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 9080, Loss 0.0242718867957592\n",
            "Train step - Step 9090, Loss 0.022007867693901062\n",
            "Train step - Step 9100, Loss 0.020320337265729904\n",
            "Train step - Step 9110, Loss 0.020900683477520943\n",
            "Train step - Step 9120, Loss 0.017605537548661232\n",
            "Train step - Step 9130, Loss 0.014760621823370457\n",
            "Train step - Step 9140, Loss 0.01911655254662037\n",
            "Train step - Step 9150, Loss 0.02014256827533245\n",
            "Train step - Step 9160, Loss 0.017188742756843567\n",
            "Train step - Step 9170, Loss 0.019565248861908913\n",
            "Train step - Step 9180, Loss 0.01920858584344387\n",
            "Train step - Step 9190, Loss 0.0177534818649292\n",
            "Train step - Step 9200, Loss 0.01818547025322914\n",
            "Train step - Step 9210, Loss 0.021487422287464142\n",
            "Train step - Step 9220, Loss 0.018445132300257683\n",
            "Train step - Step 9230, Loss 0.017025282606482506\n",
            "Train step - Step 9240, Loss 0.017955636605620384\n",
            "Train step - Step 9250, Loss 0.020709728822112083\n",
            "Train step - Step 9260, Loss 0.018946202471852303\n",
            "Train step - Step 9270, Loss 0.01765255257487297\n",
            "Train step - Step 9280, Loss 0.020417051389813423\n",
            "Train step - Step 9290, Loss 0.020896390080451965\n",
            "Train step - Step 9300, Loss 0.016670113429427147\n",
            "Train step - Step 9310, Loss 0.019122585654258728\n",
            "Train step - Step 9320, Loss 0.017560891807079315\n",
            "Train step - Step 9330, Loss 0.018916433677077293\n",
            "Train step - Step 9340, Loss 0.019293449819087982\n",
            "Train step - Step 9350, Loss 0.018174849450588226\n",
            "Train step - Step 9360, Loss 0.019476724788546562\n",
            "Train step - Step 9370, Loss 0.019355176016688347\n",
            "Train step - Step 9380, Loss 0.01793801784515381\n",
            "Train step - Step 9390, Loss 0.019894564524292946\n",
            "Train step - Step 9400, Loss 0.018160836771130562\n",
            "Train step - Step 9410, Loss 0.019877217710018158\n",
            "Train step - Step 9420, Loss 0.01955241896212101\n",
            "Train epoch - Accuracy: 0.6854769921436588 Loss: 0.019232266862217157 Corrects: 30538\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 9430, Loss 0.025060873478651047\n",
            "Train step - Step 9440, Loss 0.022642405703663826\n",
            "Train step - Step 9450, Loss 0.018921570852398872\n",
            "Train step - Step 9460, Loss 0.017822088673710823\n",
            "Train step - Step 9470, Loss 0.016798531636595726\n",
            "Train step - Step 9480, Loss 0.019333060830831528\n",
            "Train step - Step 9490, Loss 0.015682049095630646\n",
            "Train step - Step 9500, Loss 0.018945597112178802\n",
            "Train step - Step 9510, Loss 0.017250942066311836\n",
            "Train step - Step 9520, Loss 0.016694145277142525\n",
            "Train step - Step 9530, Loss 0.01633591204881668\n",
            "Train step - Step 9540, Loss 0.017123684287071228\n",
            "Train step - Step 9550, Loss 0.017339512705802917\n",
            "Train step - Step 9560, Loss 0.016796842217445374\n",
            "Train step - Step 9570, Loss 0.02000829204916954\n",
            "Train step - Step 9580, Loss 0.017775464802980423\n",
            "Train step - Step 9590, Loss 0.018750153481960297\n",
            "Train step - Step 9600, Loss 0.017327990382909775\n",
            "Train step - Step 9610, Loss 0.017893105745315552\n",
            "Train step - Step 9620, Loss 0.0191577710211277\n",
            "Train step - Step 9630, Loss 0.018480435013771057\n",
            "Train step - Step 9640, Loss 0.018571505323052406\n",
            "Train step - Step 9650, Loss 0.01806878112256527\n",
            "Train step - Step 9660, Loss 0.017706047743558884\n",
            "Train step - Step 9670, Loss 0.01931748166680336\n",
            "Train step - Step 9680, Loss 0.01814522035419941\n",
            "Train step - Step 9690, Loss 0.018587255850434303\n",
            "Train step - Step 9700, Loss 0.016919460147619247\n",
            "Train step - Step 9710, Loss 0.019537892192602158\n",
            "Train step - Step 9720, Loss 0.018528874963521957\n",
            "Train step - Step 9730, Loss 0.019284198060631752\n",
            "Train step - Step 9740, Loss 0.017667926847934723\n",
            "Train step - Step 9750, Loss 0.016690947115421295\n",
            "Train step - Step 9760, Loss 0.021413471549749374\n",
            "Train step - Step 9770, Loss 0.01994870789349079\n",
            "Train epoch - Accuracy: 0.6857463524130191 Loss: 0.019161028511797136 Corrects: 30550\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 9780, Loss 0.024732736870646477\n",
            "Train step - Step 9790, Loss 0.025645531713962555\n",
            "Train step - Step 9800, Loss 0.02085387147963047\n",
            "Train step - Step 9810, Loss 0.021551281213760376\n",
            "Train step - Step 9820, Loss 0.01956959255039692\n",
            "Train step - Step 9830, Loss 0.018258240073919296\n",
            "Train step - Step 9840, Loss 0.023122915998101234\n",
            "Train step - Step 9850, Loss 0.020066989585757256\n",
            "Train step - Step 9860, Loss 0.017499856650829315\n",
            "Train step - Step 9870, Loss 0.01907476782798767\n",
            "Train step - Step 9880, Loss 0.016439739614725113\n",
            "Train step - Step 9890, Loss 0.019642546772956848\n",
            "Train step - Step 9900, Loss 0.020800644531846046\n",
            "Train step - Step 9910, Loss 0.02008723095059395\n",
            "Train step - Step 9920, Loss 0.018858782947063446\n",
            "Train step - Step 9930, Loss 0.01855630613863468\n",
            "Train step - Step 9940, Loss 0.018861612305045128\n",
            "Train step - Step 9950, Loss 0.018973754718899727\n",
            "Train step - Step 9960, Loss 0.014139777980744839\n",
            "Train step - Step 9970, Loss 0.021353553980588913\n",
            "Train step - Step 9980, Loss 0.01863391511142254\n",
            "Train step - Step 9990, Loss 0.01909731887280941\n",
            "Train step - Step 10000, Loss 0.017070475965738297\n",
            "Train step - Step 10010, Loss 0.019523141905665398\n",
            "Train step - Step 10020, Loss 0.0205782949924469\n",
            "Train step - Step 10030, Loss 0.024107350036501884\n",
            "Train step - Step 10040, Loss 0.014746367000043392\n",
            "Train step - Step 10050, Loss 0.019609099254012108\n",
            "Train step - Step 10060, Loss 0.015267828479409218\n",
            "Train step - Step 10070, Loss 0.01950116828083992\n",
            "Train step - Step 10080, Loss 0.019020162522792816\n",
            "Train step - Step 10090, Loss 0.017959199845790863\n",
            "Train step - Step 10100, Loss 0.019121427088975906\n",
            "Train step - Step 10110, Loss 0.018358532339334488\n",
            "Train step - Step 10120, Loss 0.05250249058008194\n",
            "Train epoch - Accuracy: 0.6807182940516274 Loss: 0.019534288239064307 Corrects: 30326\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 10130, Loss 0.018605215474963188\n",
            "Train step - Step 10140, Loss 0.019376156851649284\n",
            "Train step - Step 10150, Loss 0.016688639298081398\n",
            "Train step - Step 10160, Loss 0.017864374443888664\n",
            "Train step - Step 10170, Loss 0.01971358247101307\n",
            "Train step - Step 10180, Loss 0.01627548597753048\n",
            "Train step - Step 10190, Loss 0.018875831738114357\n",
            "Train step - Step 10200, Loss 0.01923501491546631\n",
            "Train step - Step 10210, Loss 0.01606730930507183\n",
            "Train step - Step 10220, Loss 0.018556561321020126\n",
            "Train step - Step 10230, Loss 0.016620706766843796\n",
            "Train step - Step 10240, Loss 0.020466970279812813\n",
            "Train step - Step 10250, Loss 0.017900660634040833\n",
            "Train step - Step 10260, Loss 0.021837210282683372\n",
            "Train step - Step 10270, Loss 0.020868971943855286\n",
            "Train step - Step 10280, Loss 0.0206526517868042\n",
            "Train step - Step 10290, Loss 0.016260746866464615\n",
            "Train step - Step 10300, Loss 0.019150998443365097\n",
            "Train step - Step 10310, Loss 0.018690085038542747\n",
            "Train step - Step 10320, Loss 0.019074754789471626\n",
            "Train step - Step 10330, Loss 0.019515596330165863\n",
            "Train step - Step 10340, Loss 0.016910959035158157\n",
            "Train step - Step 10350, Loss 0.019350973889231682\n",
            "Train step - Step 10360, Loss 0.01772511750459671\n",
            "Train step - Step 10370, Loss 0.018200086429715157\n",
            "Train step - Step 10380, Loss 0.02252165973186493\n",
            "Train step - Step 10390, Loss 0.018290529027581215\n",
            "Train step - Step 10400, Loss 0.020015385001897812\n",
            "Train step - Step 10410, Loss 0.019667547196149826\n",
            "Train step - Step 10420, Loss 0.019999513402581215\n",
            "Train step - Step 10430, Loss 0.020753731951117516\n",
            "Train step - Step 10440, Loss 0.017803089693188667\n",
            "Train step - Step 10450, Loss 0.01953515037894249\n",
            "Train step - Step 10460, Loss 0.020268304273486137\n",
            "Train epoch - Accuracy: 0.6905050505050505 Loss: 0.018981460619019605 Corrects: 30762\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 10470, Loss 0.017606452107429504\n",
            "Train step - Step 10480, Loss 0.02175440639257431\n",
            "Train step - Step 10490, Loss 0.021046679466962814\n",
            "Train step - Step 10500, Loss 0.019001226872205734\n",
            "Train step - Step 10510, Loss 0.018969425931572914\n",
            "Train step - Step 10520, Loss 0.018988238647580147\n",
            "Train step - Step 10530, Loss 0.0186463650316\n",
            "Train step - Step 10540, Loss 0.018464406952261925\n",
            "Train step - Step 10550, Loss 0.020226506516337395\n",
            "Train step - Step 10560, Loss 0.01572667993605137\n",
            "Train step - Step 10570, Loss 0.019137104973196983\n",
            "Train step - Step 10580, Loss 0.016574807465076447\n",
            "Train step - Step 10590, Loss 0.017867540940642357\n",
            "Train step - Step 10600, Loss 0.02023901417851448\n",
            "Train step - Step 10610, Loss 0.01988283544778824\n",
            "Train step - Step 10620, Loss 0.017892666161060333\n",
            "Train step - Step 10630, Loss 0.01887216791510582\n",
            "Train step - Step 10640, Loss 0.02153070829808712\n",
            "Train step - Step 10650, Loss 0.022307423874735832\n",
            "Train step - Step 10660, Loss 0.020153582096099854\n",
            "Train step - Step 10670, Loss 0.017602907493710518\n",
            "Train step - Step 10680, Loss 0.016326753422617912\n",
            "Train step - Step 10690, Loss 0.016491610556840897\n",
            "Train step - Step 10700, Loss 0.021330850198864937\n",
            "Train step - Step 10710, Loss 0.020908132195472717\n",
            "Train step - Step 10720, Loss 0.0166994147002697\n",
            "Train step - Step 10730, Loss 0.020340390503406525\n",
            "Train step - Step 10740, Loss 0.016529390588402748\n",
            "Train step - Step 10750, Loss 0.021294109523296356\n",
            "Train step - Step 10760, Loss 0.019811812788248062\n",
            "Train step - Step 10770, Loss 0.019099200144410133\n",
            "Train step - Step 10780, Loss 0.02174251340329647\n",
            "Train step - Step 10790, Loss 0.018364759162068367\n",
            "Train step - Step 10800, Loss 0.021358206868171692\n",
            "Train step - Step 10810, Loss 0.02007107064127922\n",
            "Train epoch - Accuracy: 0.6896745230078564 Loss: 0.018977238843938718 Corrects: 30725\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 10820, Loss 0.01792619563639164\n",
            "Train step - Step 10830, Loss 0.0193961001932621\n",
            "Train step - Step 10840, Loss 0.01855177991092205\n",
            "Train step - Step 10850, Loss 0.020292092114686966\n",
            "Train step - Step 10860, Loss 0.022095104679465294\n",
            "Train step - Step 10870, Loss 0.019457753747701645\n",
            "Train step - Step 10880, Loss 0.017266495153307915\n",
            "Train step - Step 10890, Loss 0.016176803037524223\n",
            "Train step - Step 10900, Loss 0.018710603937506676\n",
            "Train step - Step 10910, Loss 0.01788335107266903\n",
            "Train step - Step 10920, Loss 0.016374986618757248\n",
            "Train step - Step 10930, Loss 0.01964385248720646\n",
            "Train step - Step 10940, Loss 0.019190168008208275\n",
            "Train step - Step 10950, Loss 0.0168178528547287\n",
            "Train step - Step 10960, Loss 0.016866963356733322\n",
            "Train step - Step 10970, Loss 0.02380707673728466\n",
            "Train step - Step 10980, Loss 0.019137563183903694\n",
            "Train step - Step 10990, Loss 0.020345116034150124\n",
            "Train step - Step 11000, Loss 0.020839914679527283\n",
            "Train step - Step 11010, Loss 0.01954910159111023\n",
            "Train step - Step 11020, Loss 0.018583135679364204\n",
            "Train step - Step 11030, Loss 0.016943033784627914\n",
            "Train step - Step 11040, Loss 0.018331337720155716\n",
            "Train step - Step 11050, Loss 0.01904761604964733\n",
            "Train step - Step 11060, Loss 0.016188176348805428\n",
            "Train step - Step 11070, Loss 0.01837248168885708\n",
            "Train step - Step 11080, Loss 0.01620166003704071\n",
            "Train step - Step 11090, Loss 0.018532568588852882\n",
            "Train step - Step 11100, Loss 0.020538749173283577\n",
            "Train step - Step 11110, Loss 0.01920250616967678\n",
            "Train step - Step 11120, Loss 0.017411600798368454\n",
            "Train step - Step 11130, Loss 0.01843106746673584\n",
            "Train step - Step 11140, Loss 0.0211428701877594\n",
            "Train step - Step 11150, Loss 0.02038724720478058\n",
            "Train step - Step 11160, Loss 0.016269059851765633\n",
            "Train epoch - Accuracy: 0.6902581369248036 Loss: 0.019007945780200187 Corrects: 30751\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 11170, Loss 0.025246234610676765\n",
            "Train step - Step 11180, Loss 0.023296140134334564\n",
            "Train step - Step 11190, Loss 0.021899905055761337\n",
            "Train step - Step 11200, Loss 0.019457362592220306\n",
            "Train step - Step 11210, Loss 0.018761293962597847\n",
            "Train step - Step 11220, Loss 0.0198539849370718\n",
            "Train step - Step 11230, Loss 0.016428785398602486\n",
            "Train step - Step 11240, Loss 0.017609434202313423\n",
            "Train step - Step 11250, Loss 0.016303913667798042\n",
            "Train step - Step 11260, Loss 0.01669466122984886\n",
            "Train step - Step 11270, Loss 0.017707642167806625\n",
            "Train step - Step 11280, Loss 0.019329583272337914\n",
            "Train step - Step 11290, Loss 0.019100399687886238\n",
            "Train step - Step 11300, Loss 0.018366876989603043\n",
            "Train step - Step 11310, Loss 0.018640313297510147\n",
            "Train step - Step 11320, Loss 0.01929582841694355\n",
            "Train step - Step 11330, Loss 0.021013930439949036\n",
            "Train step - Step 11340, Loss 0.018648158758878708\n",
            "Train step - Step 11350, Loss 0.02168894000351429\n",
            "Train step - Step 11360, Loss 0.016987327486276627\n",
            "Train step - Step 11370, Loss 0.018542127683758736\n",
            "Train step - Step 11380, Loss 0.020490948110818863\n",
            "Train step - Step 11390, Loss 0.018986815586686134\n",
            "Train step - Step 11400, Loss 0.019404776394367218\n",
            "Train step - Step 11410, Loss 0.01786225475370884\n",
            "Train step - Step 11420, Loss 0.015685157850384712\n",
            "Train step - Step 11430, Loss 0.018322493880987167\n",
            "Train step - Step 11440, Loss 0.017107347026467323\n",
            "Train step - Step 11450, Loss 0.02115948498249054\n",
            "Train step - Step 11460, Loss 0.016915226355195045\n",
            "Train step - Step 11470, Loss 0.019184749573469162\n",
            "Train step - Step 11480, Loss 0.01763824373483658\n",
            "Train step - Step 11490, Loss 0.017041457816958427\n",
            "Train step - Step 11500, Loss 0.01905183121562004\n",
            "Train step - Step 11510, Loss 0.017404504120349884\n",
            "Train epoch - Accuracy: 0.6837710437710438 Loss: 0.019278862968120643 Corrects: 30462\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 11520, Loss 0.025083621963858604\n",
            "Train step - Step 11530, Loss 0.02229980379343033\n",
            "Train step - Step 11540, Loss 0.01977931335568428\n",
            "Train step - Step 11550, Loss 0.01890690065920353\n",
            "Train step - Step 11560, Loss 0.023317692801356316\n",
            "Train step - Step 11570, Loss 0.019899882376194\n",
            "Train step - Step 11580, Loss 0.016735877841711044\n",
            "Train step - Step 11590, Loss 0.017157284542918205\n",
            "Train step - Step 11600, Loss 0.01916790008544922\n",
            "Train step - Step 11610, Loss 0.015162068419158459\n",
            "Train step - Step 11620, Loss 0.018419548869132996\n",
            "Train step - Step 11630, Loss 0.01757749542593956\n",
            "Train step - Step 11640, Loss 0.019573798403143883\n",
            "Train step - Step 11650, Loss 0.018315130844712257\n",
            "Train step - Step 11660, Loss 0.015736542642116547\n",
            "Train step - Step 11670, Loss 0.015226073563098907\n",
            "Train step - Step 11680, Loss 0.01930599845945835\n",
            "Train step - Step 11690, Loss 0.02044026553630829\n",
            "Train step - Step 11700, Loss 0.018418025225400925\n",
            "Train step - Step 11710, Loss 0.020983025431632996\n",
            "Train step - Step 11720, Loss 0.015503223985433578\n",
            "Train step - Step 11730, Loss 0.017808329313993454\n",
            "Train step - Step 11740, Loss 0.016168149188160896\n",
            "Train step - Step 11750, Loss 0.01748841069638729\n",
            "Train step - Step 11760, Loss 0.019761303439736366\n",
            "Train step - Step 11770, Loss 0.019740698859095573\n",
            "Train step - Step 11780, Loss 0.019021909683942795\n",
            "Train step - Step 11790, Loss 0.019272830337285995\n",
            "Train step - Step 11800, Loss 0.02129542827606201\n",
            "Train step - Step 11810, Loss 0.023411210626363754\n",
            "Train step - Step 11820, Loss 0.015751473605632782\n",
            "Train step - Step 11830, Loss 0.0200309157371521\n",
            "Train step - Step 11840, Loss 0.01770685985684395\n",
            "Train step - Step 11850, Loss 0.01666238158941269\n",
            "Train step - Step 11860, Loss 0.019018804654479027\n",
            "Train epoch - Accuracy: 0.6879685746352413 Loss: 0.019104825672845112 Corrects: 30649\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 11870, Loss 0.024689605459570885\n",
            "Train step - Step 11880, Loss 0.020333461463451385\n",
            "Train step - Step 11890, Loss 0.021113000810146332\n",
            "Train step - Step 11900, Loss 0.019031543284654617\n",
            "Train step - Step 11910, Loss 0.02012232504785061\n",
            "Train step - Step 11920, Loss 0.01788703165948391\n",
            "Train step - Step 11930, Loss 0.019949398934841156\n",
            "Train step - Step 11940, Loss 0.018768135458230972\n",
            "Train step - Step 11950, Loss 0.020239727571606636\n",
            "Train step - Step 11960, Loss 0.017315082252025604\n",
            "Train step - Step 11970, Loss 0.021196791902184486\n",
            "Train step - Step 11980, Loss 0.01690947450697422\n",
            "Train step - Step 11990, Loss 0.01972264237701893\n",
            "Train step - Step 12000, Loss 0.017468485981225967\n",
            "Train step - Step 12010, Loss 0.02125285193324089\n",
            "Train step - Step 12020, Loss 0.015781579539179802\n",
            "Train step - Step 12030, Loss 0.01838875748217106\n",
            "Train step - Step 12040, Loss 0.019701506942510605\n",
            "Train step - Step 12050, Loss 0.016845062375068665\n",
            "Train step - Step 12060, Loss 0.01737350970506668\n",
            "Train step - Step 12070, Loss 0.018099753186106682\n",
            "Train step - Step 12080, Loss 0.018279029056429863\n",
            "Train step - Step 12090, Loss 0.02241622656583786\n",
            "Train step - Step 12100, Loss 0.018001362681388855\n",
            "Train step - Step 12110, Loss 0.02360132522881031\n",
            "Train step - Step 12120, Loss 0.018697917461395264\n",
            "Train step - Step 12130, Loss 0.018339769914746284\n",
            "Train step - Step 12140, Loss 0.0178373996168375\n",
            "Train step - Step 12150, Loss 0.0180340763181448\n",
            "Train step - Step 12160, Loss 0.01961429975926876\n",
            "Train step - Step 12170, Loss 0.017554059624671936\n",
            "Train step - Step 12180, Loss 0.017867013812065125\n",
            "Train step - Step 12190, Loss 0.01801014505326748\n",
            "Train step - Step 12200, Loss 0.017718207091093063\n",
            "Train step - Step 12210, Loss 0.01809856668114662\n",
            "Train epoch - Accuracy: 0.6907519640852974 Loss: 0.018945584971495347 Corrects: 30773\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 12220, Loss 0.028305992484092712\n",
            "Train step - Step 12230, Loss 0.023959392681717873\n",
            "Train step - Step 12240, Loss 0.019906187430024147\n",
            "Train step - Step 12250, Loss 0.022326162084937096\n",
            "Train step - Step 12260, Loss 0.016682330518960953\n",
            "Train step - Step 12270, Loss 0.018796823918819427\n",
            "Train step - Step 12280, Loss 0.020141826942563057\n",
            "Train step - Step 12290, Loss 0.017918189987540245\n",
            "Train step - Step 12300, Loss 0.0205595213919878\n",
            "Train step - Step 12310, Loss 0.01931406557559967\n",
            "Train step - Step 12320, Loss 0.01732802763581276\n",
            "Train step - Step 12330, Loss 0.01846267469227314\n",
            "Train step - Step 12340, Loss 0.02239607833325863\n",
            "Train step - Step 12350, Loss 0.018489249050617218\n",
            "Train step - Step 12360, Loss 0.01994617097079754\n",
            "Train step - Step 12370, Loss 0.016476254910230637\n",
            "Train step - Step 12380, Loss 0.018309399485588074\n",
            "Train step - Step 12390, Loss 0.019022267311811447\n",
            "Train step - Step 12400, Loss 0.019930310547351837\n",
            "Train step - Step 12410, Loss 0.021083610132336617\n",
            "Train step - Step 12420, Loss 0.021282434463500977\n",
            "Train step - Step 12430, Loss 0.018663639202713966\n",
            "Train step - Step 12440, Loss 0.017559407278895378\n",
            "Train step - Step 12450, Loss 0.017037956044077873\n",
            "Train step - Step 12460, Loss 0.019836267456412315\n",
            "Train step - Step 12470, Loss 0.02072443999350071\n",
            "Train step - Step 12480, Loss 0.018377937376499176\n",
            "Train step - Step 12490, Loss 0.02194337546825409\n",
            "Train step - Step 12500, Loss 0.01820557937026024\n",
            "Train step - Step 12510, Loss 0.020720625296235085\n",
            "Train step - Step 12520, Loss 0.020128032192587852\n",
            "Train step - Step 12530, Loss 0.018360426649451256\n",
            "Train step - Step 12540, Loss 0.01881876029074192\n",
            "Train step - Step 12550, Loss 0.01929323747754097\n",
            "Train step - Step 12560, Loss 0.019999226555228233\n",
            "Train epoch - Accuracy: 0.6819977553310886 Loss: 0.019381303964841244 Corrects: 30383\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 12570, Loss 0.02083350531756878\n",
            "Train step - Step 12580, Loss 0.019909407943487167\n",
            "Train step - Step 12590, Loss 0.020589180290699005\n",
            "Train step - Step 12600, Loss 0.0209101103246212\n",
            "Train step - Step 12610, Loss 0.019771575927734375\n",
            "Train step - Step 12620, Loss 0.019368866458535194\n",
            "Train step - Step 12630, Loss 0.01689784787595272\n",
            "Train step - Step 12640, Loss 0.019736096262931824\n",
            "Train step - Step 12650, Loss 0.01695166900753975\n",
            "Train step - Step 12660, Loss 0.01694324240088463\n",
            "Train step - Step 12670, Loss 0.01966686174273491\n",
            "Train step - Step 12680, Loss 0.02002246305346489\n",
            "Train step - Step 12690, Loss 0.02202668786048889\n",
            "Train step - Step 12700, Loss 0.018480610102415085\n",
            "Train step - Step 12710, Loss 0.018490690737962723\n",
            "Train step - Step 12720, Loss 0.018097128719091415\n",
            "Train step - Step 12730, Loss 0.020561400800943375\n",
            "Train step - Step 12740, Loss 0.018068665638566017\n",
            "Train step - Step 12750, Loss 0.018495192751288414\n",
            "Train step - Step 12760, Loss 0.017682349309325218\n",
            "Train step - Step 12770, Loss 0.01650857925415039\n",
            "Train step - Step 12780, Loss 0.018450289964675903\n",
            "Train step - Step 12790, Loss 0.019338542595505714\n",
            "Train step - Step 12800, Loss 0.02006867527961731\n",
            "Train step - Step 12810, Loss 0.01612434908747673\n",
            "Train step - Step 12820, Loss 0.019263368099927902\n",
            "Train step - Step 12830, Loss 0.016592416912317276\n",
            "Train step - Step 12840, Loss 0.020018432289361954\n",
            "Train step - Step 12850, Loss 0.020014729350805283\n",
            "Train step - Step 12860, Loss 0.020936833694577217\n",
            "Train step - Step 12870, Loss 0.021050292998552322\n",
            "Train step - Step 12880, Loss 0.018387431278824806\n",
            "Train step - Step 12890, Loss 0.017107829451560974\n",
            "Train step - Step 12900, Loss 0.019079294055700302\n",
            "Train step - Step 12910, Loss 0.021940071135759354\n",
            "Train epoch - Accuracy: 0.6905050505050505 Loss: 0.01897172225963253 Corrects: 30762\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 12920, Loss 0.019842660054564476\n",
            "Train step - Step 12930, Loss 0.022469479590654373\n",
            "Train step - Step 12940, Loss 0.02150123193860054\n",
            "Train step - Step 12950, Loss 0.016800478100776672\n",
            "Train step - Step 12960, Loss 0.019458366557955742\n",
            "Train step - Step 12970, Loss 0.018870770931243896\n",
            "Train step - Step 12980, Loss 0.01812729798257351\n",
            "Train step - Step 12990, Loss 0.01607341133058071\n",
            "Train step - Step 13000, Loss 0.017240898683667183\n",
            "Train step - Step 13010, Loss 0.02143016643822193\n",
            "Train step - Step 13020, Loss 0.01878369227051735\n",
            "Train step - Step 13030, Loss 0.017455115914344788\n",
            "Train step - Step 13040, Loss 0.016983019188046455\n",
            "Train step - Step 13050, Loss 0.018112415447831154\n",
            "Train step - Step 13060, Loss 0.017843177542090416\n",
            "Train step - Step 13070, Loss 0.021119989454746246\n",
            "Train step - Step 13080, Loss 0.018041396513581276\n",
            "Train step - Step 13090, Loss 0.017839564010500908\n",
            "Train step - Step 13100, Loss 0.01812809705734253\n",
            "Train step - Step 13110, Loss 0.018125854432582855\n",
            "Train step - Step 13120, Loss 0.022310053929686546\n",
            "Train step - Step 13130, Loss 0.017069842666387558\n",
            "Train step - Step 13140, Loss 0.01962124928832054\n",
            "Train step - Step 13150, Loss 0.016078228130936623\n",
            "Train step - Step 13160, Loss 0.0162345003336668\n",
            "Train step - Step 13170, Loss 0.016222752630710602\n",
            "Train step - Step 13180, Loss 0.0179116390645504\n",
            "Train step - Step 13190, Loss 0.015405483543872833\n",
            "Train step - Step 13200, Loss 0.01728801429271698\n",
            "Train step - Step 13210, Loss 0.02028619684278965\n",
            "Train step - Step 13220, Loss 0.01682247780263424\n",
            "Train step - Step 13230, Loss 0.02032262459397316\n",
            "Train step - Step 13240, Loss 0.014635549858212471\n",
            "Train step - Step 13250, Loss 0.015778077766299248\n",
            "Train step - Step 13260, Loss 0.021401796489953995\n",
            "Train epoch - Accuracy: 0.6962514029180696 Loss: 0.018671429401930468 Corrects: 31018\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 13270, Loss 0.022302167490124702\n",
            "Train step - Step 13280, Loss 0.01931934989988804\n",
            "Train step - Step 13290, Loss 0.01918395236134529\n",
            "Train step - Step 13300, Loss 0.020128412172198296\n",
            "Train step - Step 13310, Loss 0.0204042736440897\n",
            "Train step - Step 13320, Loss 0.01769299805164337\n",
            "Train step - Step 13330, Loss 0.01810106821358204\n",
            "Train step - Step 13340, Loss 0.019591784104704857\n",
            "Train step - Step 13350, Loss 0.019331522285938263\n",
            "Train step - Step 13360, Loss 0.017495660111308098\n",
            "Train step - Step 13370, Loss 0.018195709213614464\n",
            "Train step - Step 13380, Loss 0.019347473978996277\n",
            "Train step - Step 13390, Loss 0.02072184905409813\n",
            "Train step - Step 13400, Loss 0.019018929451704025\n",
            "Train step - Step 13410, Loss 0.018041308969259262\n",
            "Train step - Step 13420, Loss 0.01799015700817108\n",
            "Train step - Step 13430, Loss 0.018195457756519318\n",
            "Train step - Step 13440, Loss 0.0193080622702837\n",
            "Train step - Step 13450, Loss 0.01671435870230198\n",
            "Train step - Step 13460, Loss 0.018591277301311493\n",
            "Train step - Step 13470, Loss 0.02043532207608223\n",
            "Train step - Step 13480, Loss 0.017310572788119316\n",
            "Train step - Step 13490, Loss 0.020755240693688393\n",
            "Train step - Step 13500, Loss 0.020234782248735428\n",
            "Train step - Step 13510, Loss 0.018871983513236046\n",
            "Train step - Step 13520, Loss 0.018132371827960014\n",
            "Train step - Step 13530, Loss 0.019727632403373718\n",
            "Train step - Step 13540, Loss 0.018264131620526314\n",
            "Train step - Step 13550, Loss 0.018040679395198822\n",
            "Train step - Step 13560, Loss 0.01642383448779583\n",
            "Train step - Step 13570, Loss 0.018954312428832054\n",
            "Train step - Step 13580, Loss 0.01981329917907715\n",
            "Train step - Step 13590, Loss 0.020428607240319252\n",
            "Train step - Step 13600, Loss 0.017844583839178085\n",
            "Train step - Step 13610, Loss 0.04175082966685295\n",
            "Train epoch - Accuracy: 0.6897643097643098 Loss: 0.019043147034282504 Corrects: 30729\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 13620, Loss 0.02395743317902088\n",
            "Train step - Step 13630, Loss 0.018905451521277428\n",
            "Train step - Step 13640, Loss 0.020983433350920677\n",
            "Train step - Step 13650, Loss 0.01760900393128395\n",
            "Train step - Step 13660, Loss 0.019803021103143692\n",
            "Train step - Step 13670, Loss 0.017105793580412865\n",
            "Train step - Step 13680, Loss 0.01682036556303501\n",
            "Train step - Step 13690, Loss 0.01707472652196884\n",
            "Train step - Step 13700, Loss 0.01730380393564701\n",
            "Train step - Step 13710, Loss 0.017681792378425598\n",
            "Train step - Step 13720, Loss 0.016620684415102005\n",
            "Train step - Step 13730, Loss 0.019690245389938354\n",
            "Train step - Step 13740, Loss 0.01936432160437107\n",
            "Train step - Step 13750, Loss 0.01901937834918499\n",
            "Train step - Step 13760, Loss 0.017253944650292397\n",
            "Train step - Step 13770, Loss 0.01896076463162899\n",
            "Train step - Step 13780, Loss 0.018235743045806885\n",
            "Train step - Step 13790, Loss 0.018905965611338615\n",
            "Train step - Step 13800, Loss 0.01823507994413376\n",
            "Train step - Step 13810, Loss 0.015442514792084694\n",
            "Train step - Step 13820, Loss 0.021015148609876633\n",
            "Train step - Step 13830, Loss 0.018474863842129707\n",
            "Train step - Step 13840, Loss 0.017301039770245552\n",
            "Train step - Step 13850, Loss 0.020873555913567543\n",
            "Train step - Step 13860, Loss 0.018922558054327965\n",
            "Train step - Step 13870, Loss 0.01872345432639122\n",
            "Train step - Step 13880, Loss 0.01956855319440365\n",
            "Train step - Step 13890, Loss 0.018279489129781723\n",
            "Train step - Step 13900, Loss 0.022344326600432396\n",
            "Train step - Step 13910, Loss 0.016769202426075935\n",
            "Train step - Step 13920, Loss 0.01903499849140644\n",
            "Train step - Step 13930, Loss 0.01773327961564064\n",
            "Train step - Step 13940, Loss 0.022294098511338234\n",
            "Train step - Step 13950, Loss 0.017195260152220726\n",
            "Train epoch - Accuracy: 0.6898540965207632 Loss: 0.018962623769988116 Corrects: 30733\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 13960, Loss 0.016831310465931892\n",
            "Train step - Step 13970, Loss 0.024949058890342712\n",
            "Train step - Step 13980, Loss 0.022625496610999107\n",
            "Train step - Step 13990, Loss 0.016307774931192398\n",
            "Train step - Step 14000, Loss 0.01929563656449318\n",
            "Train step - Step 14010, Loss 0.019857214763760567\n",
            "Train step - Step 14020, Loss 0.02074587717652321\n",
            "Train step - Step 14030, Loss 0.018886420875787735\n",
            "Train step - Step 14040, Loss 0.020832598209381104\n",
            "Train step - Step 14050, Loss 0.018007181584835052\n",
            "Train step - Step 14060, Loss 0.0188591405749321\n",
            "Train step - Step 14070, Loss 0.018495986238121986\n",
            "Train step - Step 14080, Loss 0.015689756721258163\n",
            "Train step - Step 14090, Loss 0.018083002418279648\n",
            "Train step - Step 14100, Loss 0.020213332027196884\n",
            "Train step - Step 14110, Loss 0.016260264441370964\n",
            "Train step - Step 14120, Loss 0.0203932523727417\n",
            "Train step - Step 14130, Loss 0.018725108355283737\n",
            "Train step - Step 14140, Loss 0.01877390407025814\n",
            "Train step - Step 14150, Loss 0.01764502003788948\n",
            "Train step - Step 14160, Loss 0.019640054553747177\n",
            "Train step - Step 14170, Loss 0.020628398284316063\n",
            "Train step - Step 14180, Loss 0.01964673586189747\n",
            "Train step - Step 14190, Loss 0.019521642476320267\n",
            "Train step - Step 14200, Loss 0.01898246444761753\n",
            "Train step - Step 14210, Loss 0.02175632119178772\n",
            "Train step - Step 14220, Loss 0.0192729402333498\n",
            "Train step - Step 14230, Loss 0.02037283033132553\n",
            "Train step - Step 14240, Loss 0.017649343237280846\n",
            "Train step - Step 14250, Loss 0.020234229043126106\n",
            "Train step - Step 14260, Loss 0.017466837540268898\n",
            "Train step - Step 14270, Loss 0.018630389124155045\n",
            "Train step - Step 14280, Loss 0.01764693483710289\n",
            "Train step - Step 14290, Loss 0.015600504353642464\n",
            "Train step - Step 14300, Loss 0.01867780275642872\n",
            "Train epoch - Accuracy: 0.6920314253647587 Loss: 0.018905256205435955 Corrects: 30830\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 14310, Loss 0.015180910006165504\n",
            "Train step - Step 14320, Loss 0.025099484249949455\n",
            "Train step - Step 14330, Loss 0.020502561703324318\n",
            "Train step - Step 14340, Loss 0.017542824149131775\n",
            "Train step - Step 14350, Loss 0.018990539014339447\n",
            "Train step - Step 14360, Loss 0.020606929436326027\n",
            "Train step - Step 14370, Loss 0.01743284985423088\n",
            "Train step - Step 14380, Loss 0.019836220890283585\n",
            "Train step - Step 14390, Loss 0.019235335290431976\n",
            "Train step - Step 14400, Loss 0.018801454454660416\n",
            "Train step - Step 14410, Loss 0.017646268010139465\n",
            "Train step - Step 14420, Loss 0.01744554378092289\n",
            "Train step - Step 14430, Loss 0.018486224114894867\n",
            "Train step - Step 14440, Loss 0.018375569954514503\n",
            "Train step - Step 14450, Loss 0.022013410925865173\n",
            "Train step - Step 14460, Loss 0.019629040732979774\n",
            "Train step - Step 14470, Loss 0.018558716401457787\n",
            "Train step - Step 14480, Loss 0.01815175823867321\n",
            "Train step - Step 14490, Loss 0.018445922061800957\n",
            "Train step - Step 14500, Loss 0.017485210672020912\n",
            "Train step - Step 14510, Loss 0.019714001566171646\n",
            "Train step - Step 14520, Loss 0.021693959832191467\n",
            "Train step - Step 14530, Loss 0.017100345343351364\n",
            "Train step - Step 14540, Loss 0.017728686332702637\n",
            "Train step - Step 14550, Loss 0.017983121797442436\n",
            "Train step - Step 14560, Loss 0.019675662741065025\n",
            "Train step - Step 14570, Loss 0.016645681113004684\n",
            "Train step - Step 14580, Loss 0.0184373389929533\n",
            "Train step - Step 14590, Loss 0.019442901015281677\n",
            "Train step - Step 14600, Loss 0.020464066416025162\n",
            "Train step - Step 14610, Loss 0.017618073150515556\n",
            "Train step - Step 14620, Loss 0.021503226831555367\n",
            "Train step - Step 14630, Loss 0.018800627440214157\n",
            "Train step - Step 14640, Loss 0.021853188052773476\n",
            "Train step - Step 14650, Loss 0.02043098211288452\n",
            "Train epoch - Accuracy: 0.6897418630751964 Loss: 0.01896967550085316 Corrects: 30728\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 14660, Loss 0.021000131964683533\n",
            "Train step - Step 14670, Loss 0.01654285378754139\n",
            "Train step - Step 14680, Loss 0.02010038122534752\n",
            "Train step - Step 14690, Loss 0.0200198944658041\n",
            "Train step - Step 14700, Loss 0.019191546365618706\n",
            "Train step - Step 14710, Loss 0.01707770675420761\n",
            "Train step - Step 14720, Loss 0.016458220779895782\n",
            "Train step - Step 14730, Loss 0.017581725493073463\n",
            "Train step - Step 14740, Loss 0.02016269974410534\n",
            "Train step - Step 14750, Loss 0.018598729744553566\n",
            "Train step - Step 14760, Loss 0.01934479922056198\n",
            "Train step - Step 14770, Loss 0.020549554377794266\n",
            "Train step - Step 14780, Loss 0.023249387741088867\n",
            "Train step - Step 14790, Loss 0.01714080385863781\n",
            "Train step - Step 14800, Loss 0.019738489761948586\n",
            "Train step - Step 14810, Loss 0.018803032115101814\n",
            "Train step - Step 14820, Loss 0.018914485350251198\n",
            "Train step - Step 14830, Loss 0.01903265155851841\n",
            "Train step - Step 14840, Loss 0.021622423082590103\n",
            "Train step - Step 14850, Loss 0.016764773055911064\n",
            "Train step - Step 14860, Loss 0.021362148225307465\n",
            "Train step - Step 14870, Loss 0.01879188045859337\n",
            "Train step - Step 14880, Loss 0.01612755097448826\n",
            "Train step - Step 14890, Loss 0.02115941420197487\n",
            "Train step - Step 14900, Loss 0.017705412581562996\n",
            "Train step - Step 14910, Loss 0.017933940514922142\n",
            "Train step - Step 14920, Loss 0.0165858194231987\n",
            "Train step - Step 14930, Loss 0.016673250123858452\n",
            "Train step - Step 14940, Loss 0.022412532940506935\n",
            "Train step - Step 14950, Loss 0.018909139558672905\n",
            "Train step - Step 14960, Loss 0.01738705113530159\n",
            "Train step - Step 14970, Loss 0.018770406022667885\n",
            "Train step - Step 14980, Loss 0.018233390524983406\n",
            "Train step - Step 14990, Loss 0.02039155177772045\n",
            "Train step - Step 15000, Loss 0.019046342000365257\n",
            "Train epoch - Accuracy: 0.6933557800224467 Loss: 0.01880583316706514 Corrects: 30889\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 15010, Loss 0.022137226536870003\n",
            "Train step - Step 15020, Loss 0.020278656855225563\n",
            "Train step - Step 15030, Loss 0.01714581623673439\n",
            "Train step - Step 15040, Loss 0.019793614745140076\n",
            "Train step - Step 15050, Loss 0.022089818492531776\n",
            "Train step - Step 15060, Loss 0.02023657225072384\n",
            "Train step - Step 15070, Loss 0.015069771558046341\n",
            "Train step - Step 15080, Loss 0.019885757938027382\n",
            "Train step - Step 15090, Loss 0.021354801952838898\n",
            "Train step - Step 15100, Loss 0.018380559980869293\n",
            "Train step - Step 15110, Loss 0.016109194606542587\n",
            "Train step - Step 15120, Loss 0.01653350330889225\n",
            "Train step - Step 15130, Loss 0.018511733040213585\n",
            "Train step - Step 15140, Loss 0.018601741641759872\n",
            "Train step - Step 15150, Loss 0.01539057120680809\n",
            "Train step - Step 15160, Loss 0.016968918964266777\n",
            "Train step - Step 15170, Loss 0.017373938113451004\n",
            "Train step - Step 15180, Loss 0.01901070401072502\n",
            "Train step - Step 15190, Loss 0.01680411398410797\n",
            "Train step - Step 15200, Loss 0.019243476912379265\n",
            "Train step - Step 15210, Loss 0.018438585102558136\n",
            "Train step - Step 15220, Loss 0.016530508175492287\n",
            "Train step - Step 15230, Loss 0.019023340195417404\n",
            "Train step - Step 15240, Loss 0.018670402467250824\n",
            "Train step - Step 15250, Loss 0.018601849675178528\n",
            "Train step - Step 15260, Loss 0.017986929044127464\n",
            "Train step - Step 15270, Loss 0.018361952155828476\n",
            "Train step - Step 15280, Loss 0.018410464748740196\n",
            "Train step - Step 15290, Loss 0.018780142068862915\n",
            "Train step - Step 15300, Loss 0.018385427072644234\n",
            "Train step - Step 15310, Loss 0.018315384164452553\n",
            "Train step - Step 15320, Loss 0.018887972459197044\n",
            "Train step - Step 15330, Loss 0.018325917422771454\n",
            "Train step - Step 15340, Loss 0.021138666197657585\n",
            "Train step - Step 15350, Loss 0.019232042133808136\n",
            "Train epoch - Accuracy: 0.6917171717171717 Loss: 0.018836378549653136 Corrects: 30816\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 15360, Loss 0.026061328127980232\n",
            "Train step - Step 15370, Loss 0.021345753222703934\n",
            "Train step - Step 15380, Loss 0.02070726454257965\n",
            "Train step - Step 15390, Loss 0.02077091485261917\n",
            "Train step - Step 15400, Loss 0.017528805881738663\n",
            "Train step - Step 15410, Loss 0.01731804944574833\n",
            "Train step - Step 15420, Loss 0.017878394573926926\n",
            "Train step - Step 15430, Loss 0.02181936614215374\n",
            "Train step - Step 15440, Loss 0.02082032896578312\n",
            "Train step - Step 15450, Loss 0.017244387418031693\n",
            "Train step - Step 15460, Loss 0.015760326758027077\n",
            "Train step - Step 15470, Loss 0.019135434180498123\n",
            "Train step - Step 15480, Loss 0.018024036660790443\n",
            "Train step - Step 15490, Loss 0.01726730912923813\n",
            "Train step - Step 15500, Loss 0.019690006971359253\n",
            "Train step - Step 15510, Loss 0.021019769832491875\n",
            "Train step - Step 15520, Loss 0.019125092774629593\n",
            "Train step - Step 15530, Loss 0.016701867803931236\n",
            "Train step - Step 15540, Loss 0.017775103449821472\n",
            "Train step - Step 15550, Loss 0.01934334635734558\n",
            "Train step - Step 15560, Loss 0.018385548144578934\n",
            "Train step - Step 15570, Loss 0.017450479790568352\n",
            "Train step - Step 15580, Loss 0.021488022059202194\n",
            "Train step - Step 15590, Loss 0.01771785132586956\n",
            "Train step - Step 15600, Loss 0.019407963380217552\n",
            "Train step - Step 15610, Loss 0.020396029576659203\n",
            "Train step - Step 15620, Loss 0.020405685529112816\n",
            "Train step - Step 15630, Loss 0.01510693784803152\n",
            "Train step - Step 15640, Loss 0.019302720203995705\n",
            "Train step - Step 15650, Loss 0.019799282774329185\n",
            "Train step - Step 15660, Loss 0.016977157443761826\n",
            "Train step - Step 15670, Loss 0.019959894940257072\n",
            "Train step - Step 15680, Loss 0.019413935020565987\n",
            "Train step - Step 15690, Loss 0.02003704383969307\n",
            "Train step - Step 15700, Loss 0.01965978927910328\n",
            "Train epoch - Accuracy: 0.6899887766554433 Loss: 0.018942480562578815 Corrects: 30739\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 15710, Loss 0.0254047978669405\n",
            "Train step - Step 15720, Loss 0.021289309486746788\n",
            "Train step - Step 15730, Loss 0.022954244166612625\n",
            "Train step - Step 15740, Loss 0.02090519480407238\n",
            "Train step - Step 15750, Loss 0.016721151769161224\n",
            "Train step - Step 15760, Loss 0.01903388649225235\n",
            "Train step - Step 15770, Loss 0.020172957330942154\n",
            "Train step - Step 15780, Loss 0.02147054113447666\n",
            "Train step - Step 15790, Loss 0.01772581972181797\n",
            "Train step - Step 15800, Loss 0.019578827545046806\n",
            "Train step - Step 15810, Loss 0.01682795211672783\n",
            "Train step - Step 15820, Loss 0.01775697059929371\n",
            "Train step - Step 15830, Loss 0.01796468161046505\n",
            "Train step - Step 15840, Loss 0.01631571166217327\n",
            "Train step - Step 15850, Loss 0.016226109117269516\n",
            "Train step - Step 15860, Loss 0.02067088708281517\n",
            "Train step - Step 15870, Loss 0.02091100998222828\n",
            "Train step - Step 15880, Loss 0.01595301739871502\n",
            "Train step - Step 15890, Loss 0.017800087109208107\n",
            "Train step - Step 15900, Loss 0.016658667474985123\n",
            "Train step - Step 15910, Loss 0.01896784082055092\n",
            "Train step - Step 15920, Loss 0.019329950213432312\n",
            "Train step - Step 15930, Loss 0.015673715621232986\n",
            "Train step - Step 15940, Loss 0.021401401609182358\n",
            "Train step - Step 15950, Loss 0.020433615893125534\n",
            "Train step - Step 15960, Loss 0.018753286451101303\n",
            "Train step - Step 15970, Loss 0.01748271845281124\n",
            "Train step - Step 15980, Loss 0.01830352656543255\n",
            "Train step - Step 15990, Loss 0.01853916421532631\n",
            "Train step - Step 16000, Loss 0.018306437879800797\n",
            "Train step - Step 16010, Loss 0.01692511886358261\n",
            "Train step - Step 16020, Loss 0.019287707284092903\n",
            "Train step - Step 16030, Loss 0.021687109023332596\n",
            "Train step - Step 16040, Loss 0.018511464819312096\n",
            "Train step - Step 16050, Loss 0.018917996436357498\n",
            "Train epoch - Accuracy: 0.6843995510662177 Loss: 0.01916838642004898 Corrects: 30490\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 16060, Loss 0.024284977465867996\n",
            "Train step - Step 16070, Loss 0.022862356156110764\n",
            "Train step - Step 16080, Loss 0.01971195451915264\n",
            "Train step - Step 16090, Loss 0.022923944517970085\n",
            "Train step - Step 16100, Loss 0.017340971156954765\n",
            "Train step - Step 16110, Loss 0.017484135925769806\n",
            "Train step - Step 16120, Loss 0.019312575459480286\n",
            "Train step - Step 16130, Loss 0.02018202655017376\n",
            "Train step - Step 16140, Loss 0.017347203567624092\n",
            "Train step - Step 16150, Loss 0.015934325754642487\n",
            "Train step - Step 16160, Loss 0.019120115786790848\n",
            "Train step - Step 16170, Loss 0.02114805206656456\n",
            "Train step - Step 16180, Loss 0.019233012571930885\n",
            "Train step - Step 16190, Loss 0.018289120867848396\n",
            "Train step - Step 16200, Loss 0.01687280461192131\n",
            "Train step - Step 16210, Loss 0.019918758422136307\n",
            "Train step - Step 16220, Loss 0.018664170056581497\n",
            "Train step - Step 16230, Loss 0.01974094845354557\n",
            "Train step - Step 16240, Loss 0.01777852140367031\n",
            "Train step - Step 16250, Loss 0.01908942498266697\n",
            "Train step - Step 16260, Loss 0.01936325989663601\n",
            "Train step - Step 16270, Loss 0.018855931237339973\n",
            "Train step - Step 16280, Loss 0.020250162109732628\n",
            "Train step - Step 16290, Loss 0.017056675627827644\n",
            "Train step - Step 16300, Loss 0.020334886386990547\n",
            "Train step - Step 16310, Loss 0.01883666031062603\n",
            "Train step - Step 16320, Loss 0.014354528859257698\n",
            "Train step - Step 16330, Loss 0.016464313492178917\n",
            "Train step - Step 16340, Loss 0.022099357098340988\n",
            "Train step - Step 16350, Loss 0.017720913514494896\n",
            "Train step - Step 16360, Loss 0.020617851987481117\n",
            "Train step - Step 16370, Loss 0.0213637575507164\n",
            "Train step - Step 16380, Loss 0.01999242790043354\n",
            "Train step - Step 16390, Loss 0.015292628668248653\n",
            "Train step - Step 16400, Loss 0.021525664255023003\n",
            "Train epoch - Accuracy: 0.6918069584736252 Loss: 0.018889849118712776 Corrects: 30820\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 16410, Loss 0.022349342703819275\n",
            "Train step - Step 16420, Loss 0.021696748211979866\n",
            "Train step - Step 16430, Loss 0.020028244704008102\n",
            "Train step - Step 16440, Loss 0.02013283409178257\n",
            "Train step - Step 16450, Loss 0.019028695300221443\n",
            "Train step - Step 16460, Loss 0.014223286882042885\n",
            "Train step - Step 16470, Loss 0.016961954534053802\n",
            "Train step - Step 16480, Loss 0.02003544382750988\n",
            "Train step - Step 16490, Loss 0.01933177374303341\n",
            "Train step - Step 16500, Loss 0.01869756355881691\n",
            "Train step - Step 16510, Loss 0.01739765889942646\n",
            "Train step - Step 16520, Loss 0.015190371312201023\n",
            "Train step - Step 16530, Loss 0.02128932625055313\n",
            "Train step - Step 16540, Loss 0.019611472263932228\n",
            "Train step - Step 16550, Loss 0.017107082530856133\n",
            "Train step - Step 16560, Loss 0.01845947466790676\n",
            "Train step - Step 16570, Loss 0.01852453127503395\n",
            "Train step - Step 16580, Loss 0.019018355756998062\n",
            "Train step - Step 16590, Loss 0.0183288361877203\n",
            "Train step - Step 16600, Loss 0.019270753487944603\n",
            "Train step - Step 16610, Loss 0.019412806257605553\n",
            "Train step - Step 16620, Loss 0.01839281991124153\n",
            "Train step - Step 16630, Loss 0.02261282317340374\n",
            "Train step - Step 16640, Loss 0.014787692576646805\n",
            "Train step - Step 16650, Loss 0.019924888387322426\n",
            "Train step - Step 16660, Loss 0.019368335604667664\n",
            "Train step - Step 16670, Loss 0.01988060772418976\n",
            "Train step - Step 16680, Loss 0.01597864367067814\n",
            "Train step - Step 16690, Loss 0.01948956586420536\n",
            "Train step - Step 16700, Loss 0.01967824064195156\n",
            "Train step - Step 16710, Loss 0.02173823118209839\n",
            "Train step - Step 16720, Loss 0.018939122557640076\n",
            "Train step - Step 16730, Loss 0.0189504511654377\n",
            "Train step - Step 16740, Loss 0.01864999532699585\n",
            "Train step - Step 16750, Loss 0.021258248016238213\n",
            "Train epoch - Accuracy: 0.6930190796857464 Loss: 0.018788697229558237 Corrects: 30874\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 16760, Loss 0.022842951118946075\n",
            "Train step - Step 16770, Loss 0.025568457320332527\n",
            "Train step - Step 16780, Loss 0.01797843538224697\n",
            "Train step - Step 16790, Loss 0.01825963892042637\n",
            "Train step - Step 16800, Loss 0.01575823314487934\n",
            "Train step - Step 16810, Loss 0.01944885402917862\n",
            "Train step - Step 16820, Loss 0.01806267350912094\n",
            "Train step - Step 16830, Loss 0.02219276688992977\n",
            "Train step - Step 16840, Loss 0.018597887828946114\n",
            "Train step - Step 16850, Loss 0.01798798143863678\n",
            "Train step - Step 16860, Loss 0.016664566472172737\n",
            "Train step - Step 16870, Loss 0.020860638469457626\n",
            "Train step - Step 16880, Loss 0.018555795773863792\n",
            "Train step - Step 16890, Loss 0.02200782112777233\n",
            "Train step - Step 16900, Loss 0.020690586417913437\n",
            "Train step - Step 16910, Loss 0.02080969139933586\n",
            "Train step - Step 16920, Loss 0.019690588116645813\n",
            "Train step - Step 16930, Loss 0.018319638445973396\n",
            "Train step - Step 16940, Loss 0.015834106132388115\n",
            "Train step - Step 16950, Loss 0.018622251227498055\n",
            "Train step - Step 16960, Loss 0.017899436876177788\n",
            "Train step - Step 16970, Loss 0.02206849679350853\n",
            "Train step - Step 16980, Loss 0.018293090164661407\n",
            "Train step - Step 16990, Loss 0.01595151424407959\n",
            "Train step - Step 17000, Loss 0.0194838996976614\n",
            "Train step - Step 17010, Loss 0.0205250047147274\n",
            "Train step - Step 17020, Loss 0.018099619075655937\n",
            "Train step - Step 17030, Loss 0.01764870062470436\n",
            "Train step - Step 17040, Loss 0.017766721546649933\n",
            "Train step - Step 17050, Loss 0.01925225742161274\n",
            "Train step - Step 17060, Loss 0.020711416378617287\n",
            "Train step - Step 17070, Loss 0.020978115499019623\n",
            "Train step - Step 17080, Loss 0.020636307075619698\n",
            "Train step - Step 17090, Loss 0.018927467986941338\n",
            "Train step - Step 17100, Loss 0.04143965616822243\n",
            "Train epoch - Accuracy: 0.6886868686868687 Loss: 0.0190546073688468 Corrects: 30681\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 17110, Loss 0.015545126050710678\n",
            "Train step - Step 17120, Loss 0.016034172847867012\n",
            "Train step - Step 17130, Loss 0.01596888341009617\n",
            "Train step - Step 17140, Loss 0.014180981554090977\n",
            "Train step - Step 17150, Loss 0.018155651167035103\n",
            "Train step - Step 17160, Loss 0.016359269618988037\n",
            "Train step - Step 17170, Loss 0.010979375801980495\n",
            "Train step - Step 17180, Loss 0.016680948436260223\n",
            "Train step - Step 17190, Loss 0.013509152457118034\n",
            "Train step - Step 17200, Loss 0.014395108446478844\n",
            "Train step - Step 17210, Loss 0.013312917202711105\n",
            "Train step - Step 17220, Loss 0.016366036608815193\n",
            "Train step - Step 17230, Loss 0.013705049641430378\n",
            "Train step - Step 17240, Loss 0.014321709051728249\n",
            "Train step - Step 17250, Loss 0.014319686219096184\n",
            "Train step - Step 17260, Loss 0.012837697751820087\n",
            "Train step - Step 17270, Loss 0.016100753098726273\n",
            "Train step - Step 17280, Loss 0.014235327020287514\n",
            "Train step - Step 17290, Loss 0.014879420399665833\n",
            "Train step - Step 17300, Loss 0.015169170685112476\n",
            "Train step - Step 17310, Loss 0.013712207786738873\n",
            "Train step - Step 17320, Loss 0.012464683502912521\n",
            "Train step - Step 17330, Loss 0.014616105705499649\n",
            "Train step - Step 17340, Loss 0.014589500613510609\n",
            "Train step - Step 17350, Loss 0.012541795149445534\n",
            "Train step - Step 17360, Loss 0.014850870706140995\n",
            "Train step - Step 17370, Loss 0.015270620584487915\n",
            "Train step - Step 17380, Loss 0.013036999851465225\n",
            "Train step - Step 17390, Loss 0.012860756367444992\n",
            "Train step - Step 17400, Loss 0.01615194045007229\n",
            "Train step - Step 17410, Loss 0.01600973680615425\n",
            "Train step - Step 17420, Loss 0.013310595415532589\n",
            "Train step - Step 17430, Loss 0.014355093240737915\n",
            "Train step - Step 17440, Loss 0.014590892009437084\n",
            "Train epoch - Accuracy: 0.7755555555555556 Loss: 0.014250455099407805 Corrects: 34551\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 17450, Loss 0.012025970965623856\n",
            "Train step - Step 17460, Loss 0.015686511993408203\n",
            "Train step - Step 17470, Loss 0.012815778143703938\n",
            "Train step - Step 17480, Loss 0.01280315313488245\n",
            "Train step - Step 17490, Loss 0.01197845209389925\n",
            "Train step - Step 17500, Loss 0.012409300543367863\n",
            "Train step - Step 17510, Loss 0.011703455820679665\n",
            "Train step - Step 17520, Loss 0.013797519728541374\n",
            "Train step - Step 17530, Loss 0.01396956481039524\n",
            "Train step - Step 17540, Loss 0.015987249091267586\n",
            "Train step - Step 17550, Loss 0.011467238888144493\n",
            "Train step - Step 17560, Loss 0.013999216258525848\n",
            "Train step - Step 17570, Loss 0.011070570908486843\n",
            "Train step - Step 17580, Loss 0.010156909935176373\n",
            "Train step - Step 17590, Loss 0.014763548970222473\n",
            "Train step - Step 17600, Loss 0.011824662797152996\n",
            "Train step - Step 17610, Loss 0.012941980734467506\n",
            "Train step - Step 17620, Loss 0.011997126042842865\n",
            "Train step - Step 17630, Loss 0.014376260340213776\n",
            "Train step - Step 17640, Loss 0.011607099324464798\n",
            "Train step - Step 17650, Loss 0.012195806950330734\n",
            "Train step - Step 17660, Loss 0.014374073594808578\n",
            "Train step - Step 17670, Loss 0.013997513800859451\n",
            "Train step - Step 17680, Loss 0.014187140390276909\n",
            "Train step - Step 17690, Loss 0.012419033795595169\n",
            "Train step - Step 17700, Loss 0.012265878729522228\n",
            "Train step - Step 17710, Loss 0.01160647626966238\n",
            "Train step - Step 17720, Loss 0.01409097295254469\n",
            "Train step - Step 17730, Loss 0.011276322416961193\n",
            "Train step - Step 17740, Loss 0.013500025495886803\n",
            "Train step - Step 17750, Loss 0.01475893147289753\n",
            "Train step - Step 17760, Loss 0.012928503565490246\n",
            "Train step - Step 17770, Loss 0.015197990462183952\n",
            "Train step - Step 17780, Loss 0.013873391784727573\n",
            "Train step - Step 17790, Loss 0.01127102691680193\n",
            "Train epoch - Accuracy: 0.8008978675645342 Loss: 0.01285942456813573 Corrects: 35680\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 17800, Loss 0.012671203352510929\n",
            "Train step - Step 17810, Loss 0.01191641017794609\n",
            "Train step - Step 17820, Loss 0.015493342652916908\n",
            "Train step - Step 17830, Loss 0.010641739703714848\n",
            "Train step - Step 17840, Loss 0.01512061432003975\n",
            "Train step - Step 17850, Loss 0.01020047441124916\n",
            "Train step - Step 17860, Loss 0.014478307217359543\n",
            "Train step - Step 17870, Loss 0.011985283344984055\n",
            "Train step - Step 17880, Loss 0.01137553434818983\n",
            "Train step - Step 17890, Loss 0.009945927187800407\n",
            "Train step - Step 17900, Loss 0.012100291438400745\n",
            "Train step - Step 17910, Loss 0.014961871318519115\n",
            "Train step - Step 17920, Loss 0.013465137220919132\n",
            "Train step - Step 17930, Loss 0.014744529500603676\n",
            "Train step - Step 17940, Loss 0.01349707506597042\n",
            "Train step - Step 17950, Loss 0.013005701825022697\n",
            "Train step - Step 17960, Loss 0.013349260203540325\n",
            "Train step - Step 17970, Loss 0.011514650657773018\n",
            "Train step - Step 17980, Loss 0.01215358730405569\n",
            "Train step - Step 17990, Loss 0.011830881237983704\n",
            "Train step - Step 18000, Loss 0.01124517060816288\n",
            "Train step - Step 18010, Loss 0.012326223775744438\n",
            "Train step - Step 18020, Loss 0.011142912320792675\n",
            "Train step - Step 18030, Loss 0.011736426502466202\n",
            "Train step - Step 18040, Loss 0.014308201149106026\n",
            "Train step - Step 18050, Loss 0.014750661328434944\n",
            "Train step - Step 18060, Loss 0.01134068425744772\n",
            "Train step - Step 18070, Loss 0.013198687694966793\n",
            "Train step - Step 18080, Loss 0.010064766742289066\n",
            "Train step - Step 18090, Loss 0.010505334474146366\n",
            "Train step - Step 18100, Loss 0.013417358510196209\n",
            "Train step - Step 18110, Loss 0.012907044030725956\n",
            "Train step - Step 18120, Loss 0.01439708936959505\n",
            "Train step - Step 18130, Loss 0.013796808198094368\n",
            "Train step - Step 18140, Loss 0.012990946881473064\n",
            "Train epoch - Accuracy: 0.8101234567901234 Loss: 0.012326023536917202 Corrects: 36091\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 18150, Loss 0.012627330608665943\n",
            "Train step - Step 18160, Loss 0.014051095582544804\n",
            "Train step - Step 18170, Loss 0.012716765515506268\n",
            "Train step - Step 18180, Loss 0.012821224518120289\n",
            "Train step - Step 18190, Loss 0.012566208839416504\n",
            "Train step - Step 18200, Loss 0.011511403135955334\n",
            "Train step - Step 18210, Loss 0.011300466023385525\n",
            "Train step - Step 18220, Loss 0.011262170970439911\n",
            "Train step - Step 18230, Loss 0.011153819970786572\n",
            "Train step - Step 18240, Loss 0.012654065154492855\n",
            "Train step - Step 18250, Loss 0.011140062473714352\n",
            "Train step - Step 18260, Loss 0.011564220301806927\n",
            "Train step - Step 18270, Loss 0.009639267809689045\n",
            "Train step - Step 18280, Loss 0.015392505563795567\n",
            "Train step - Step 18290, Loss 0.011241125874221325\n",
            "Train step - Step 18300, Loss 0.013343868777155876\n",
            "Train step - Step 18310, Loss 0.012858626432716846\n",
            "Train step - Step 18320, Loss 0.00946224108338356\n",
            "Train step - Step 18330, Loss 0.011971824802458286\n",
            "Train step - Step 18340, Loss 0.012866295874118805\n",
            "Train step - Step 18350, Loss 0.012406080961227417\n",
            "Train step - Step 18360, Loss 0.01109820231795311\n",
            "Train step - Step 18370, Loss 0.011673117987811565\n",
            "Train step - Step 18380, Loss 0.008920048363506794\n",
            "Train step - Step 18390, Loss 0.01127094216644764\n",
            "Train step - Step 18400, Loss 0.013061518780887127\n",
            "Train step - Step 18410, Loss 0.012913621962070465\n",
            "Train step - Step 18420, Loss 0.010028474032878876\n",
            "Train step - Step 18430, Loss 0.009999783709645271\n",
            "Train step - Step 18440, Loss 0.012504623271524906\n",
            "Train step - Step 18450, Loss 0.012411421164870262\n",
            "Train step - Step 18460, Loss 0.013126065023243427\n",
            "Train step - Step 18470, Loss 0.014678845182061195\n",
            "Train step - Step 18480, Loss 0.013823223300278187\n",
            "Train step - Step 18490, Loss 0.01471423078328371\n",
            "Train epoch - Accuracy: 0.8175308641975308 Loss: 0.011956451844954998 Corrects: 36421\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 18500, Loss 0.008581169880926609\n",
            "Train step - Step 18510, Loss 0.01129450835287571\n",
            "Train step - Step 18520, Loss 0.011835800483822823\n",
            "Train step - Step 18530, Loss 0.012647860683500767\n",
            "Train step - Step 18540, Loss 0.009645771235227585\n",
            "Train step - Step 18550, Loss 0.013558898121118546\n",
            "Train step - Step 18560, Loss 0.012789885513484478\n",
            "Train step - Step 18570, Loss 0.011017980985343456\n",
            "Train step - Step 18580, Loss 0.011351188644766808\n",
            "Train step - Step 18590, Loss 0.013477341271936893\n",
            "Train step - Step 18600, Loss 0.009482404217123985\n",
            "Train step - Step 18610, Loss 0.011570258066058159\n",
            "Train step - Step 18620, Loss 0.012676091864705086\n",
            "Train step - Step 18630, Loss 0.013156617060303688\n",
            "Train step - Step 18640, Loss 0.010362609289586544\n",
            "Train step - Step 18650, Loss 0.01195784192532301\n",
            "Train step - Step 18660, Loss 0.011572128161787987\n",
            "Train step - Step 18670, Loss 0.008882812224328518\n",
            "Train step - Step 18680, Loss 0.009938481263816357\n",
            "Train step - Step 18690, Loss 0.011801354587078094\n",
            "Train step - Step 18700, Loss 0.00985376164317131\n",
            "Train step - Step 18710, Loss 0.011065883561968803\n",
            "Train step - Step 18720, Loss 0.012484192848205566\n",
            "Train step - Step 18730, Loss 0.011667702347040176\n",
            "Train step - Step 18740, Loss 0.013337097130715847\n",
            "Train step - Step 18750, Loss 0.013700730167329311\n",
            "Train step - Step 18760, Loss 0.015478664077818394\n",
            "Train step - Step 18770, Loss 0.011081821285188198\n",
            "Train step - Step 18780, Loss 0.013051819987595081\n",
            "Train step - Step 18790, Loss 0.010691742412745953\n",
            "Train step - Step 18800, Loss 0.011215952225029469\n",
            "Train step - Step 18810, Loss 0.011205270886421204\n",
            "Train step - Step 18820, Loss 0.012557962909340858\n",
            "Train step - Step 18830, Loss 0.013325718231499195\n",
            "Train step - Step 18840, Loss 0.011193977668881416\n",
            "Train epoch - Accuracy: 0.8199102132435466 Loss: 0.01172778135017146 Corrects: 36527\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 18850, Loss 0.012522215954959393\n",
            "Train step - Step 18860, Loss 0.012142491526901722\n",
            "Train step - Step 18870, Loss 0.012522541917860508\n",
            "Train step - Step 18880, Loss 0.013023373670876026\n",
            "Train step - Step 18890, Loss 0.012053047306835651\n",
            "Train step - Step 18900, Loss 0.010551157407462597\n",
            "Train step - Step 18910, Loss 0.013955463655292988\n",
            "Train step - Step 18920, Loss 0.009845570661127567\n",
            "Train step - Step 18930, Loss 0.01220215205103159\n",
            "Train step - Step 18940, Loss 0.011409538798034191\n",
            "Train step - Step 18950, Loss 0.011990092694759369\n",
            "Train step - Step 18960, Loss 0.011958861723542213\n",
            "Train step - Step 18970, Loss 0.009725858457386494\n",
            "Train step - Step 18980, Loss 0.00950118899345398\n",
            "Train step - Step 18990, Loss 0.011101004667580128\n",
            "Train step - Step 19000, Loss 0.013319948688149452\n",
            "Train step - Step 19010, Loss 0.011839928105473518\n",
            "Train step - Step 19020, Loss 0.015695519745349884\n",
            "Train step - Step 19030, Loss 0.014106323942542076\n",
            "Train step - Step 19040, Loss 0.011645378544926643\n",
            "Train step - Step 19050, Loss 0.011536002159118652\n",
            "Train step - Step 19060, Loss 0.013025644235312939\n",
            "Train step - Step 19070, Loss 0.012952794320881367\n",
            "Train step - Step 19080, Loss 0.010489034466445446\n",
            "Train step - Step 19090, Loss 0.009528448805212975\n",
            "Train step - Step 19100, Loss 0.010540420189499855\n",
            "Train step - Step 19110, Loss 0.012679029256105423\n",
            "Train step - Step 19120, Loss 0.010461141355335712\n",
            "Train step - Step 19130, Loss 0.011621594429016113\n",
            "Train step - Step 19140, Loss 0.01093618106096983\n",
            "Train step - Step 19150, Loss 0.009140473790466785\n",
            "Train step - Step 19160, Loss 0.011670942418277264\n",
            "Train step - Step 19170, Loss 0.015311837196350098\n",
            "Train step - Step 19180, Loss 0.011274107731878757\n",
            "Train step - Step 19190, Loss 0.011192870326340199\n",
            "Train epoch - Accuracy: 0.8236588103254769 Loss: 0.011565730436532586 Corrects: 36694\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 19200, Loss 0.009728671982884407\n",
            "Train step - Step 19210, Loss 0.010121063329279423\n",
            "Train step - Step 19220, Loss 0.009646862745285034\n",
            "Train step - Step 19230, Loss 0.013992955908179283\n",
            "Train step - Step 19240, Loss 0.009966499172151089\n",
            "Train step - Step 19250, Loss 0.011827349662780762\n",
            "Train step - Step 19260, Loss 0.011561663821339607\n",
            "Train step - Step 19270, Loss 0.01082923449575901\n",
            "Train step - Step 19280, Loss 0.011206729337573051\n",
            "Train step - Step 19290, Loss 0.010193520225584507\n",
            "Train step - Step 19300, Loss 0.0103251738473773\n",
            "Train step - Step 19310, Loss 0.009246555157005787\n",
            "Train step - Step 19320, Loss 0.01351640559732914\n",
            "Train step - Step 19330, Loss 0.011695941910147667\n",
            "Train step - Step 19340, Loss 0.011151428334414959\n",
            "Train step - Step 19350, Loss 0.011375228874385357\n",
            "Train step - Step 19360, Loss 0.011156633496284485\n",
            "Train step - Step 19370, Loss 0.011192486621439457\n",
            "Train step - Step 19380, Loss 0.008853274397552013\n",
            "Train step - Step 19390, Loss 0.012662730179727077\n",
            "Train step - Step 19400, Loss 0.010650244541466236\n",
            "Train step - Step 19410, Loss 0.010515579022467136\n",
            "Train step - Step 19420, Loss 0.010135817341506481\n",
            "Train step - Step 19430, Loss 0.0092288414016366\n",
            "Train step - Step 19440, Loss 0.013317558914422989\n",
            "Train step - Step 19450, Loss 0.014125720597803593\n",
            "Train step - Step 19460, Loss 0.00922586303204298\n",
            "Train step - Step 19470, Loss 0.010463542304933071\n",
            "Train step - Step 19480, Loss 0.011369374580681324\n",
            "Train step - Step 19490, Loss 0.01206743624061346\n",
            "Train step - Step 19500, Loss 0.012422560714185238\n",
            "Train step - Step 19510, Loss 0.01474923174828291\n",
            "Train step - Step 19520, Loss 0.010307373479008675\n",
            "Train step - Step 19530, Loss 0.013408301398158073\n",
            "Train step - Step 19540, Loss 0.01289836224168539\n",
            "Train epoch - Accuracy: 0.8259483726150393 Loss: 0.011384803793914659 Corrects: 36796\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 19550, Loss 0.013232054188847542\n",
            "Train step - Step 19560, Loss 0.011143083684146404\n",
            "Train step - Step 19570, Loss 0.009308869950473309\n",
            "Train step - Step 19580, Loss 0.01204671710729599\n",
            "Train step - Step 19590, Loss 0.012490730732679367\n",
            "Train step - Step 19600, Loss 0.01200930867344141\n",
            "Train step - Step 19610, Loss 0.013134767301380634\n",
            "Train step - Step 19620, Loss 0.012180808000266552\n",
            "Train step - Step 19630, Loss 0.01140823494642973\n",
            "Train step - Step 19640, Loss 0.012055328115820885\n",
            "Train step - Step 19650, Loss 0.011976700276136398\n",
            "Train step - Step 19660, Loss 0.010756437666714191\n",
            "Train step - Step 19670, Loss 0.009050752967596054\n",
            "Train step - Step 19680, Loss 0.012192358262836933\n",
            "Train step - Step 19690, Loss 0.010567320510745049\n",
            "Train step - Step 19700, Loss 0.010870753787457943\n",
            "Train step - Step 19710, Loss 0.01025855727493763\n",
            "Train step - Step 19720, Loss 0.01094078365713358\n",
            "Train step - Step 19730, Loss 0.010655022226274014\n",
            "Train step - Step 19740, Loss 0.011178502812981606\n",
            "Train step - Step 19750, Loss 0.012015009298920631\n",
            "Train step - Step 19760, Loss 0.014114249497652054\n",
            "Train step - Step 19770, Loss 0.008309361524879932\n",
            "Train step - Step 19780, Loss 0.011042837984859943\n",
            "Train step - Step 19790, Loss 0.013435602188110352\n",
            "Train step - Step 19800, Loss 0.010534281842410564\n",
            "Train step - Step 19810, Loss 0.010092554613947868\n",
            "Train step - Step 19820, Loss 0.009465369395911694\n",
            "Train step - Step 19830, Loss 0.010614949278533459\n",
            "Train step - Step 19840, Loss 0.011466706171631813\n",
            "Train step - Step 19850, Loss 0.012001844123005867\n",
            "Train step - Step 19860, Loss 0.011172221042215824\n",
            "Train step - Step 19870, Loss 0.010754541493952274\n",
            "Train step - Step 19880, Loss 0.009810243733227253\n",
            "Train step - Step 19890, Loss 0.010370543226599693\n",
            "Train epoch - Accuracy: 0.8285072951739618 Loss: 0.01131295793385618 Corrects: 36910\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 19900, Loss 0.011045360006392002\n",
            "Train step - Step 19910, Loss 0.010254799388349056\n",
            "Train step - Step 19920, Loss 0.01036860328167677\n",
            "Train step - Step 19930, Loss 0.009305734187364578\n",
            "Train step - Step 19940, Loss 0.009443742223083973\n",
            "Train step - Step 19950, Loss 0.00941559486091137\n",
            "Train step - Step 19960, Loss 0.009657397866249084\n",
            "Train step - Step 19970, Loss 0.01006859727203846\n",
            "Train step - Step 19980, Loss 0.012445561587810516\n",
            "Train step - Step 19990, Loss 0.009951980784535408\n",
            "Train step - Step 20000, Loss 0.00885733775794506\n",
            "Train step - Step 20010, Loss 0.010411350056529045\n",
            "Train step - Step 20020, Loss 0.010034826584160328\n",
            "Train step - Step 20030, Loss 0.008589942008256912\n",
            "Train step - Step 20040, Loss 0.008785287849605083\n",
            "Train step - Step 20050, Loss 0.010779166594147682\n",
            "Train step - Step 20060, Loss 0.011783981695771217\n",
            "Train step - Step 20070, Loss 0.01153668574988842\n",
            "Train step - Step 20080, Loss 0.009897965006530285\n",
            "Train step - Step 20090, Loss 0.013735105283558369\n",
            "Train step - Step 20100, Loss 0.011346640065312386\n",
            "Train step - Step 20110, Loss 0.0113976476714015\n",
            "Train step - Step 20120, Loss 0.011478069238364697\n",
            "Train step - Step 20130, Loss 0.01403637882322073\n",
            "Train step - Step 20140, Loss 0.012481101788580418\n",
            "Train step - Step 20150, Loss 0.00893430970609188\n",
            "Train step - Step 20160, Loss 0.010562902316451073\n",
            "Train step - Step 20170, Loss 0.011293950490653515\n",
            "Train step - Step 20180, Loss 0.009646180085837841\n",
            "Train step - Step 20190, Loss 0.009910443797707558\n",
            "Train step - Step 20200, Loss 0.01302391942590475\n",
            "Train step - Step 20210, Loss 0.011518833227455616\n",
            "Train step - Step 20220, Loss 0.011187461204826832\n",
            "Train step - Step 20230, Loss 0.012032507918775082\n",
            "Train step - Step 20240, Loss 0.011702142655849457\n",
            "Train epoch - Accuracy: 0.8303703703703704 Loss: 0.011170300124453508 Corrects: 36993\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 20250, Loss 0.01463415939360857\n",
            "Train step - Step 20260, Loss 0.011707182973623276\n",
            "Train step - Step 20270, Loss 0.011520639061927795\n",
            "Train step - Step 20280, Loss 0.011092082597315311\n",
            "Train step - Step 20290, Loss 0.01160238217562437\n",
            "Train step - Step 20300, Loss 0.012842080555856228\n",
            "Train step - Step 20310, Loss 0.009279456920921803\n",
            "Train step - Step 20320, Loss 0.013108424842357635\n",
            "Train step - Step 20330, Loss 0.01016874797642231\n",
            "Train step - Step 20340, Loss 0.011699010618031025\n",
            "Train step - Step 20350, Loss 0.009394547902047634\n",
            "Train step - Step 20360, Loss 0.010536111891269684\n",
            "Train step - Step 20370, Loss 0.010721948929131031\n",
            "Train step - Step 20380, Loss 0.010138839483261108\n",
            "Train step - Step 20390, Loss 0.010769262909889221\n",
            "Train step - Step 20400, Loss 0.009363221004605293\n",
            "Train step - Step 20410, Loss 0.011646483093500137\n",
            "Train step - Step 20420, Loss 0.011096261441707611\n",
            "Train step - Step 20430, Loss 0.010551498271524906\n",
            "Train step - Step 20440, Loss 0.011897170916199684\n",
            "Train step - Step 20450, Loss 0.013400735333561897\n",
            "Train step - Step 20460, Loss 0.010630236938595772\n",
            "Train step - Step 20470, Loss 0.01122322492301464\n",
            "Train step - Step 20480, Loss 0.013866204768419266\n",
            "Train step - Step 20490, Loss 0.013921599835157394\n",
            "Train step - Step 20500, Loss 0.010485569015145302\n",
            "Train step - Step 20510, Loss 0.011087859980762005\n",
            "Train step - Step 20520, Loss 0.010198251344263554\n",
            "Train step - Step 20530, Loss 0.009334447793662548\n",
            "Train step - Step 20540, Loss 0.010542071424424648\n",
            "Train step - Step 20550, Loss 0.013786030001938343\n",
            "Train step - Step 20560, Loss 0.011959410272538662\n",
            "Train step - Step 20570, Loss 0.0133811691775918\n",
            "Train step - Step 20580, Loss 0.008910885080695152\n",
            "Train step - Step 20590, Loss 0.0368921123445034\n",
            "Train epoch - Accuracy: 0.8328170594837262 Loss: 0.011104872900528539 Corrects: 37102\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 20600, Loss 0.012085027061402798\n",
            "Train step - Step 20610, Loss 0.013789081946015358\n",
            "Train step - Step 20620, Loss 0.01150918286293745\n",
            "Train step - Step 20630, Loss 0.01134240161627531\n",
            "Train step - Step 20640, Loss 0.009509444236755371\n",
            "Train step - Step 20650, Loss 0.011167788878083229\n",
            "Train step - Step 20660, Loss 0.00903916172683239\n",
            "Train step - Step 20670, Loss 0.013898507691919804\n",
            "Train step - Step 20680, Loss 0.011356692761182785\n",
            "Train step - Step 20690, Loss 0.012658705934882164\n",
            "Train step - Step 20700, Loss 0.009540525265038013\n",
            "Train step - Step 20710, Loss 0.012014487758278847\n",
            "Train step - Step 20720, Loss 0.012446284294128418\n",
            "Train step - Step 20730, Loss 0.010290629230439663\n",
            "Train step - Step 20740, Loss 0.011170800775289536\n",
            "Train step - Step 20750, Loss 0.009200670756399632\n",
            "Train step - Step 20760, Loss 0.012403836473822594\n",
            "Train step - Step 20770, Loss 0.010404987260699272\n",
            "Train step - Step 20780, Loss 0.010067343711853027\n",
            "Train step - Step 20790, Loss 0.01092781126499176\n",
            "Train step - Step 20800, Loss 0.010363434441387653\n",
            "Train step - Step 20810, Loss 0.015426522120833397\n",
            "Train step - Step 20820, Loss 0.010142811574041843\n",
            "Train step - Step 20830, Loss 0.011052227579057217\n",
            "Train step - Step 20840, Loss 0.011490056291222572\n",
            "Train step - Step 20850, Loss 0.010625135153532028\n",
            "Train step - Step 20860, Loss 0.012801093980669975\n",
            "Train step - Step 20870, Loss 0.012985234148800373\n",
            "Train step - Step 20880, Loss 0.013323183171451092\n",
            "Train step - Step 20890, Loss 0.01113703940063715\n",
            "Train step - Step 20900, Loss 0.010398387908935547\n",
            "Train step - Step 20910, Loss 0.01017721090465784\n",
            "Train step - Step 20920, Loss 0.010450131259858608\n",
            "Train step - Step 20930, Loss 0.013939429074525833\n",
            "Train epoch - Accuracy: 0.8298765432098766 Loss: 0.011152634052214798 Corrects: 36971\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 20940, Loss 0.010326827876269817\n",
            "Train step - Step 20950, Loss 0.010665970854461193\n",
            "Train step - Step 20960, Loss 0.010433627292513847\n",
            "Train step - Step 20970, Loss 0.011342042125761509\n",
            "Train step - Step 20980, Loss 0.013287246227264404\n",
            "Train step - Step 20990, Loss 0.011335334740579128\n",
            "Train step - Step 21000, Loss 0.010219089686870575\n",
            "Train step - Step 21010, Loss 0.00964269693940878\n",
            "Train step - Step 21020, Loss 0.011145014315843582\n",
            "Train step - Step 21030, Loss 0.013301471248269081\n",
            "Train step - Step 21040, Loss 0.011598849669098854\n",
            "Train step - Step 21050, Loss 0.01032178197056055\n",
            "Train step - Step 21060, Loss 0.009870180860161781\n",
            "Train step - Step 21070, Loss 0.011363636702299118\n",
            "Train step - Step 21080, Loss 0.011375965550541878\n",
            "Train step - Step 21090, Loss 0.011304848827421665\n",
            "Train step - Step 21100, Loss 0.008960714563727379\n",
            "Train step - Step 21110, Loss 0.013522638939321041\n",
            "Train step - Step 21120, Loss 0.01067434810101986\n",
            "Train step - Step 21130, Loss 0.014288870617747307\n",
            "Train step - Step 21140, Loss 0.010907932184636593\n",
            "Train step - Step 21150, Loss 0.01111900806427002\n",
            "Train step - Step 21160, Loss 0.010242205113172531\n",
            "Train step - Step 21170, Loss 0.01158189494162798\n",
            "Train step - Step 21180, Loss 0.01031661219894886\n",
            "Train step - Step 21190, Loss 0.00975033175200224\n",
            "Train step - Step 21200, Loss 0.011730838567018509\n",
            "Train step - Step 21210, Loss 0.011664722114801407\n",
            "Train step - Step 21220, Loss 0.008495066314935684\n",
            "Train step - Step 21230, Loss 0.010153347626328468\n",
            "Train step - Step 21240, Loss 0.011172530241310596\n",
            "Train step - Step 21250, Loss 0.010739441029727459\n",
            "Train step - Step 21260, Loss 0.010433993302285671\n",
            "Train step - Step 21270, Loss 0.009613150730729103\n",
            "Train step - Step 21280, Loss 0.010527885518968105\n",
            "Train epoch - Accuracy: 0.8345005611672278 Loss: 0.010982108170670425 Corrects: 37177\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 21290, Loss 0.011160220019519329\n",
            "Train step - Step 21300, Loss 0.007380522787570953\n",
            "Train step - Step 21310, Loss 0.01061019767075777\n",
            "Train step - Step 21320, Loss 0.009505562484264374\n",
            "Train step - Step 21330, Loss 0.010989771224558353\n",
            "Train step - Step 21340, Loss 0.00936095230281353\n",
            "Train step - Step 21350, Loss 0.010841669514775276\n",
            "Train step - Step 21360, Loss 0.010865680873394012\n",
            "Train step - Step 21370, Loss 0.009207000024616718\n",
            "Train step - Step 21380, Loss 0.012530852109193802\n",
            "Train step - Step 21390, Loss 0.010123238898813725\n",
            "Train step - Step 21400, Loss 0.00955653190612793\n",
            "Train step - Step 21410, Loss 0.009492183104157448\n",
            "Train step - Step 21420, Loss 0.009264260530471802\n",
            "Train step - Step 21430, Loss 0.010347412899136543\n",
            "Train step - Step 21440, Loss 0.011607524938881397\n",
            "Train step - Step 21450, Loss 0.009832188487052917\n",
            "Train step - Step 21460, Loss 0.012128784321248531\n",
            "Train step - Step 21470, Loss 0.01115854736417532\n",
            "Train step - Step 21480, Loss 0.011339730583131313\n",
            "Train step - Step 21490, Loss 0.008550948463380337\n",
            "Train step - Step 21500, Loss 0.0116505715996027\n",
            "Train step - Step 21510, Loss 0.009253282099962234\n",
            "Train step - Step 21520, Loss 0.01085127517580986\n",
            "Train step - Step 21530, Loss 0.01205429807305336\n",
            "Train step - Step 21540, Loss 0.012350543402135372\n",
            "Train step - Step 21550, Loss 0.009380090050399303\n",
            "Train step - Step 21560, Loss 0.010253151878714561\n",
            "Train step - Step 21570, Loss 0.010913693346083164\n",
            "Train step - Step 21580, Loss 0.009247491136193275\n",
            "Train step - Step 21590, Loss 0.010976183228194714\n",
            "Train step - Step 21600, Loss 0.012444011867046356\n",
            "Train step - Step 21610, Loss 0.011921623721718788\n",
            "Train step - Step 21620, Loss 0.009232857264578342\n",
            "Train step - Step 21630, Loss 0.010059695690870285\n",
            "Train epoch - Accuracy: 0.8337373737373738 Loss: 0.010938654271540818 Corrects: 37143\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 21640, Loss 0.010996613651514053\n",
            "Train step - Step 21650, Loss 0.013057791627943516\n",
            "Train step - Step 21660, Loss 0.009316193871200085\n",
            "Train step - Step 21670, Loss 0.011045471765100956\n",
            "Train step - Step 21680, Loss 0.010122931562364101\n",
            "Train step - Step 21690, Loss 0.009426474571228027\n",
            "Train step - Step 21700, Loss 0.011288049630820751\n",
            "Train step - Step 21710, Loss 0.009805910289287567\n",
            "Train step - Step 21720, Loss 0.009575393982231617\n",
            "Train step - Step 21730, Loss 0.009721096605062485\n",
            "Train step - Step 21740, Loss 0.011975529603660107\n",
            "Train step - Step 21750, Loss 0.011168277822434902\n",
            "Train step - Step 21760, Loss 0.01092999055981636\n",
            "Train step - Step 21770, Loss 0.011095921508967876\n",
            "Train step - Step 21780, Loss 0.010822484269738197\n",
            "Train step - Step 21790, Loss 0.010084940120577812\n",
            "Train step - Step 21800, Loss 0.009287104941904545\n",
            "Train step - Step 21810, Loss 0.009188001975417137\n",
            "Train step - Step 21820, Loss 0.010822168551385403\n",
            "Train step - Step 21830, Loss 0.010575965978205204\n",
            "Train step - Step 21840, Loss 0.009807622991502285\n",
            "Train step - Step 21850, Loss 0.01048318576067686\n",
            "Train step - Step 21860, Loss 0.012906331568956375\n",
            "Train step - Step 21870, Loss 0.010615874081850052\n",
            "Train step - Step 21880, Loss 0.011514897458255291\n",
            "Train step - Step 21890, Loss 0.012357780709862709\n",
            "Train step - Step 21900, Loss 0.01261833030730486\n",
            "Train step - Step 21910, Loss 0.010045291855931282\n",
            "Train step - Step 21920, Loss 0.012485485523939133\n",
            "Train step - Step 21930, Loss 0.011434005573391914\n",
            "Train step - Step 21940, Loss 0.009757591411471367\n",
            "Train step - Step 21950, Loss 0.009746061637997627\n",
            "Train step - Step 21960, Loss 0.011755085550248623\n",
            "Train step - Step 21970, Loss 0.012197199277579784\n",
            "Train step - Step 21980, Loss 0.010419945232570171\n",
            "Train epoch - Accuracy: 0.8366778900112234 Loss: 0.010802763128772328 Corrects: 37274\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 21990, Loss 0.010239321738481522\n",
            "Train step - Step 22000, Loss 0.009006164968013763\n",
            "Train step - Step 22010, Loss 0.008985104970633984\n",
            "Train step - Step 22020, Loss 0.010367631912231445\n",
            "Train step - Step 22030, Loss 0.006109623238444328\n",
            "Train step - Step 22040, Loss 0.007473824545741081\n",
            "Train step - Step 22050, Loss 0.01003207080066204\n",
            "Train step - Step 22060, Loss 0.010961920954287052\n",
            "Train step - Step 22070, Loss 0.009131153114140034\n",
            "Train step - Step 22080, Loss 0.00982083473354578\n",
            "Train step - Step 22090, Loss 0.008966895751655102\n",
            "Train step - Step 22100, Loss 0.010089827701449394\n",
            "Train step - Step 22110, Loss 0.007485589943826199\n",
            "Train step - Step 22120, Loss 0.010963530279695988\n",
            "Train step - Step 22130, Loss 0.007595482282340527\n",
            "Train step - Step 22140, Loss 0.010332461446523666\n",
            "Train step - Step 22150, Loss 0.007663944736123085\n",
            "Train step - Step 22160, Loss 0.011157495900988579\n",
            "Train step - Step 22170, Loss 0.009238884784281254\n",
            "Train step - Step 22180, Loss 0.006829726975411177\n",
            "Train step - Step 22190, Loss 0.010598070919513702\n",
            "Train step - Step 22200, Loss 0.010063993744552135\n",
            "Train step - Step 22210, Loss 0.009623476304113865\n",
            "Train step - Step 22220, Loss 0.0063428799621760845\n",
            "Train step - Step 22230, Loss 0.009121013805270195\n",
            "Train step - Step 22240, Loss 0.009460141882300377\n",
            "Train step - Step 22250, Loss 0.009634329006075859\n",
            "Train step - Step 22260, Loss 0.00744635658338666\n",
            "Train step - Step 22270, Loss 0.011119518429040909\n",
            "Train step - Step 22280, Loss 0.008435656316578388\n",
            "Train step - Step 22290, Loss 0.009973028674721718\n",
            "Train step - Step 22300, Loss 0.008885078132152557\n",
            "Train step - Step 22310, Loss 0.009846830740571022\n",
            "Train step - Step 22320, Loss 0.007994293235242367\n",
            "Train step - Step 22330, Loss 0.009797451086342335\n",
            "Train epoch - Accuracy: 0.8664197530864197 Loss: 0.009305679703007977 Corrects: 38599\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 22340, Loss 0.009175639599561691\n",
            "Train step - Step 22350, Loss 0.007451143581420183\n",
            "Train step - Step 22360, Loss 0.008174480870366096\n",
            "Train step - Step 22370, Loss 0.010211387649178505\n",
            "Train step - Step 22380, Loss 0.009326174855232239\n",
            "Train step - Step 22390, Loss 0.008063792251050472\n",
            "Train step - Step 22400, Loss 0.008125962689518929\n",
            "Train step - Step 22410, Loss 0.00965200550854206\n",
            "Train step - Step 22420, Loss 0.007853686809539795\n",
            "Train step - Step 22430, Loss 0.00896520260721445\n",
            "Train step - Step 22440, Loss 0.008656444028019905\n",
            "Train step - Step 22450, Loss 0.009605566039681435\n",
            "Train step - Step 22460, Loss 0.0072757769376039505\n",
            "Train step - Step 22470, Loss 0.010140543803572655\n",
            "Train step - Step 22480, Loss 0.010216731578111649\n",
            "Train step - Step 22490, Loss 0.009140417911112309\n",
            "Train step - Step 22500, Loss 0.008105609565973282\n",
            "Train step - Step 22510, Loss 0.009518861770629883\n",
            "Train step - Step 22520, Loss 0.005984591785818338\n",
            "Train step - Step 22530, Loss 0.009710818529129028\n",
            "Train step - Step 22540, Loss 0.010260544717311859\n",
            "Train step - Step 22550, Loss 0.009580097161233425\n",
            "Train step - Step 22560, Loss 0.007637656759470701\n",
            "Train step - Step 22570, Loss 0.009770499542355537\n",
            "Train step - Step 22580, Loss 0.009455513209104538\n",
            "Train step - Step 22590, Loss 0.008743366226553917\n",
            "Train step - Step 22600, Loss 0.008703974075615406\n",
            "Train step - Step 22610, Loss 0.010481716133654118\n",
            "Train step - Step 22620, Loss 0.00954705011099577\n",
            "Train step - Step 22630, Loss 0.008161394856870174\n",
            "Train step - Step 22640, Loss 0.01005900464951992\n",
            "Train step - Step 22650, Loss 0.009293269366025925\n",
            "Train step - Step 22660, Loss 0.010779580101370811\n",
            "Train step - Step 22670, Loss 0.01053034421056509\n",
            "Train step - Step 22680, Loss 0.011181232519447803\n",
            "Train epoch - Accuracy: 0.8742536475869809 Loss: 0.008858371226390872 Corrects: 38948\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 22690, Loss 0.008338081650435925\n",
            "Train step - Step 22700, Loss 0.007767474744468927\n",
            "Train step - Step 22710, Loss 0.008656930178403854\n",
            "Train step - Step 22720, Loss 0.008493319153785706\n",
            "Train step - Step 22730, Loss 0.007976011373102665\n",
            "Train step - Step 22740, Loss 0.008825586177408695\n",
            "Train step - Step 22750, Loss 0.007186977192759514\n",
            "Train step - Step 22760, Loss 0.009318452328443527\n",
            "Train step - Step 22770, Loss 0.009291070513427258\n",
            "Train step - Step 22780, Loss 0.005464097484946251\n",
            "Train step - Step 22790, Loss 0.00719594256952405\n",
            "Train step - Step 22800, Loss 0.009225316345691681\n",
            "Train step - Step 22810, Loss 0.009030061773955822\n",
            "Train step - Step 22820, Loss 0.00905703566968441\n",
            "Train step - Step 22830, Loss 0.007897259667515755\n",
            "Train step - Step 22840, Loss 0.01061639841645956\n",
            "Train step - Step 22850, Loss 0.006934772711247206\n",
            "Train step - Step 22860, Loss 0.010994267649948597\n",
            "Train step - Step 22870, Loss 0.006677854340523481\n",
            "Train step - Step 22880, Loss 0.008695108816027641\n",
            "Train step - Step 22890, Loss 0.007223533466458321\n",
            "Train step - Step 22900, Loss 0.008375405333936214\n",
            "Train step - Step 22910, Loss 0.00914167519658804\n",
            "Train step - Step 22920, Loss 0.009851900860667229\n",
            "Train step - Step 22930, Loss 0.007664780132472515\n",
            "Train step - Step 22940, Loss 0.008384747430682182\n",
            "Train step - Step 22950, Loss 0.007300985045731068\n",
            "Train step - Step 22960, Loss 0.006856316700577736\n",
            "Train step - Step 22970, Loss 0.008002434857189655\n",
            "Train step - Step 22980, Loss 0.0071723791770637035\n",
            "Train step - Step 22990, Loss 0.007707531098276377\n",
            "Train step - Step 23000, Loss 0.010007800534367561\n",
            "Train step - Step 23010, Loss 0.010085485875606537\n",
            "Train step - Step 23020, Loss 0.006474228110164404\n",
            "Train step - Step 23030, Loss 0.007321478333324194\n",
            "Train epoch - Accuracy: 0.8790796857463524 Loss: 0.00867575161225935 Corrects: 39163\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 23040, Loss 0.008566715754568577\n",
            "Train step - Step 23050, Loss 0.007506031543016434\n",
            "Train step - Step 23060, Loss 0.008136911317706108\n",
            "Train step - Step 23070, Loss 0.009431875310838223\n",
            "Train step - Step 23080, Loss 0.007946910336613655\n",
            "Train step - Step 23090, Loss 0.00782430823892355\n",
            "Train step - Step 23100, Loss 0.007827618159353733\n",
            "Train step - Step 23110, Loss 0.006559048779308796\n",
            "Train step - Step 23120, Loss 0.005666451994329691\n",
            "Train step - Step 23130, Loss 0.009686015546321869\n",
            "Train step - Step 23140, Loss 0.010140775702893734\n",
            "Train step - Step 23150, Loss 0.008854568004608154\n",
            "Train step - Step 23160, Loss 0.007698329631239176\n",
            "Train step - Step 23170, Loss 0.01028477679938078\n",
            "Train step - Step 23180, Loss 0.01057757530361414\n",
            "Train step - Step 23190, Loss 0.010377416387200356\n",
            "Train step - Step 23200, Loss 0.00867414753884077\n",
            "Train step - Step 23210, Loss 0.00814699288457632\n",
            "Train step - Step 23220, Loss 0.007073965389281511\n",
            "Train step - Step 23230, Loss 0.007871923968195915\n",
            "Train step - Step 23240, Loss 0.009678082540631294\n",
            "Train step - Step 23250, Loss 0.009498841129243374\n",
            "Train step - Step 23260, Loss 0.00672056945040822\n",
            "Train step - Step 23270, Loss 0.009511074051260948\n",
            "Train step - Step 23280, Loss 0.007238632533699274\n",
            "Train step - Step 23290, Loss 0.00784301571547985\n",
            "Train step - Step 23300, Loss 0.008282911032438278\n",
            "Train step - Step 23310, Loss 0.008514403365552425\n",
            "Train step - Step 23320, Loss 0.010171745903789997\n",
            "Train step - Step 23330, Loss 0.008397032506763935\n",
            "Train step - Step 23340, Loss 0.01006024144589901\n",
            "Train step - Step 23350, Loss 0.008672026917338371\n",
            "Train step - Step 23360, Loss 0.009998368099331856\n",
            "Train step - Step 23370, Loss 0.009464618749916553\n",
            "Train step - Step 23380, Loss 0.007608998101204634\n",
            "Train epoch - Accuracy: 0.8790347923681257 Loss: 0.008597238417024965 Corrects: 39161\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 23390, Loss 0.008812244050204754\n",
            "Train step - Step 23400, Loss 0.009538785554468632\n",
            "Train step - Step 23410, Loss 0.007260090205818415\n",
            "Train step - Step 23420, Loss 0.007814209908246994\n",
            "Train step - Step 23430, Loss 0.007106006145477295\n",
            "Train step - Step 23440, Loss 0.009955691173672676\n",
            "Train step - Step 23450, Loss 0.008542516268789768\n",
            "Train step - Step 23460, Loss 0.008668304421007633\n",
            "Train step - Step 23470, Loss 0.010537123307585716\n",
            "Train step - Step 23480, Loss 0.007503218483179808\n",
            "Train step - Step 23490, Loss 0.008076470345258713\n",
            "Train step - Step 23500, Loss 0.007031290791928768\n",
            "Train step - Step 23510, Loss 0.007687583565711975\n",
            "Train step - Step 23520, Loss 0.006863143760710955\n",
            "Train step - Step 23530, Loss 0.008994181640446186\n",
            "Train step - Step 23540, Loss 0.009192338213324547\n",
            "Train step - Step 23550, Loss 0.008203244768083096\n",
            "Train step - Step 23560, Loss 0.007701685186475515\n",
            "Train step - Step 23570, Loss 0.008047603070735931\n",
            "Train step - Step 23580, Loss 0.008678649552166462\n",
            "Train step - Step 23590, Loss 0.009631408378481865\n",
            "Train step - Step 23600, Loss 0.009826600551605225\n",
            "Train step - Step 23610, Loss 0.006764837075024843\n",
            "Train step - Step 23620, Loss 0.008275921456515789\n",
            "Train step - Step 23630, Loss 0.0071702804416418076\n",
            "Train step - Step 23640, Loss 0.007456433959305286\n",
            "Train step - Step 23650, Loss 0.0075917900539934635\n",
            "Train step - Step 23660, Loss 0.007350718602538109\n",
            "Train step - Step 23670, Loss 0.009495498612523079\n",
            "Train step - Step 23680, Loss 0.008924192748963833\n",
            "Train step - Step 23690, Loss 0.007907991297543049\n",
            "Train step - Step 23700, Loss 0.00786896888166666\n",
            "Train step - Step 23710, Loss 0.007848040200769901\n",
            "Train step - Step 23720, Loss 0.009600021876394749\n",
            "Train step - Step 23730, Loss 0.009924727492034435\n",
            "Train epoch - Accuracy: 0.8816835016835017 Loss: 0.0084680909124087 Corrects: 39279\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 23740, Loss 0.009836237877607346\n",
            "Train step - Step 23750, Loss 0.008027048781514168\n",
            "Train step - Step 23760, Loss 0.008830776438117027\n",
            "Train step - Step 23770, Loss 0.007951087318360806\n",
            "Train step - Step 23780, Loss 0.006861197296530008\n",
            "Train step - Step 23790, Loss 0.007979515939950943\n",
            "Train step - Step 23800, Loss 0.006813474465161562\n",
            "Train step - Step 23810, Loss 0.008800986222922802\n",
            "Train step - Step 23820, Loss 0.007387228775769472\n",
            "Train step - Step 23830, Loss 0.00770494295284152\n",
            "Train step - Step 23840, Loss 0.008780712261795998\n",
            "Train step - Step 23850, Loss 0.0077882385812699795\n",
            "Train step - Step 23860, Loss 0.010777555406093597\n",
            "Train step - Step 23870, Loss 0.0072152987122535706\n",
            "Train step - Step 23880, Loss 0.009390863589942455\n",
            "Train step - Step 23890, Loss 0.0075826519168913364\n",
            "Train step - Step 23900, Loss 0.010273206047713757\n",
            "Train step - Step 23910, Loss 0.007816161029040813\n",
            "Train step - Step 23920, Loss 0.007491100113838911\n",
            "Train step - Step 23930, Loss 0.01076783798635006\n",
            "Train step - Step 23940, Loss 0.00993198063224554\n",
            "Train step - Step 23950, Loss 0.006590526085346937\n",
            "Train step - Step 23960, Loss 0.006332878489047289\n",
            "Train step - Step 23970, Loss 0.008451391942799091\n",
            "Train step - Step 23980, Loss 0.008383641950786114\n",
            "Train step - Step 23990, Loss 0.01091682817786932\n",
            "Train step - Step 24000, Loss 0.00805652979761362\n",
            "Train step - Step 24010, Loss 0.009374912828207016\n",
            "Train step - Step 24020, Loss 0.009478618390858173\n",
            "Train step - Step 24030, Loss 0.00845058262348175\n",
            "Train step - Step 24040, Loss 0.00834832713007927\n",
            "Train step - Step 24050, Loss 0.009324561804533005\n",
            "Train step - Step 24060, Loss 0.010794668458402157\n",
            "Train step - Step 24070, Loss 0.007826711051166058\n",
            "Train step - Step 24080, Loss 0.030119026079773903\n",
            "Train epoch - Accuracy: 0.8816835016835017 Loss: 0.008418631332139374 Corrects: 39279\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 24090, Loss 0.008384783752262592\n",
            "Train step - Step 24100, Loss 0.007390217389911413\n",
            "Train step - Step 24110, Loss 0.007462976034730673\n",
            "Train step - Step 24120, Loss 0.008028541691601276\n",
            "Train step - Step 24130, Loss 0.01050172746181488\n",
            "Train step - Step 24140, Loss 0.010482182726264\n",
            "Train step - Step 24150, Loss 0.007720606867223978\n",
            "Train step - Step 24160, Loss 0.007049296982586384\n",
            "Train step - Step 24170, Loss 0.00955126527696848\n",
            "Train step - Step 24180, Loss 0.009916813112795353\n",
            "Train step - Step 24190, Loss 0.009721284732222557\n",
            "Train step - Step 24200, Loss 0.008213996887207031\n",
            "Train step - Step 24210, Loss 0.008186455816030502\n",
            "Train step - Step 24220, Loss 0.007281366270035505\n",
            "Train step - Step 24230, Loss 0.009721861220896244\n",
            "Train step - Step 24240, Loss 0.006253607105463743\n",
            "Train step - Step 24250, Loss 0.007677617482841015\n",
            "Train step - Step 24260, Loss 0.0073364800773561\n",
            "Train step - Step 24270, Loss 0.007157281041145325\n",
            "Train step - Step 24280, Loss 0.007002557627856731\n",
            "Train step - Step 24290, Loss 0.007591100875288248\n",
            "Train step - Step 24300, Loss 0.007540868129581213\n",
            "Train step - Step 24310, Loss 0.0074990978464484215\n",
            "Train step - Step 24320, Loss 0.0067085144110023975\n",
            "Train step - Step 24330, Loss 0.008069586008787155\n",
            "Train step - Step 24340, Loss 0.006708675995469093\n",
            "Train step - Step 24350, Loss 0.008087001740932465\n",
            "Train step - Step 24360, Loss 0.007940777577459812\n",
            "Train step - Step 24370, Loss 0.007605638820677996\n",
            "Train step - Step 24380, Loss 0.008008875884115696\n",
            "Train step - Step 24390, Loss 0.006972014904022217\n",
            "Train step - Step 24400, Loss 0.010097857564687729\n",
            "Train step - Step 24410, Loss 0.00875526200979948\n",
            "Train step - Step 24420, Loss 0.007495177444070578\n",
            "Train epoch - Accuracy: 0.88675645342312 Loss: 0.00828996455763058 Corrects: 39505\n",
            "Training finished in 2146.7659919261932 seconds\n",
            "\n",
            "Validation accuracy: 0.68 - Validation loss: 0.020822007209062576\n",
            "\n",
            "\n",
            "Test accuracy: 0.7022222222222222\n",
            "\n",
            "\n",
            "\n",
            "Phase completed in 2151.3767631053925 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Joint phase 10/10\n",
            "\n",
            "\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.09597896039485931\n",
            "Train step - Step 10, Loss 0.0254096407443285\n",
            "Train step - Step 20, Loss 0.025554798543453217\n",
            "Train step - Step 30, Loss 0.027594447135925293\n",
            "Train step - Step 40, Loss 0.03173702582716942\n",
            "Train step - Step 50, Loss 0.03281312808394432\n",
            "Train step - Step 60, Loss 0.028100095689296722\n",
            "Train step - Step 70, Loss 0.027556253597140312\n",
            "Train step - Step 80, Loss 0.02942764200270176\n",
            "Train step - Step 90, Loss 0.02510358765721321\n",
            "Train step - Step 100, Loss 0.021247047930955887\n",
            "Train step - Step 110, Loss 0.02262224815785885\n",
            "Train step - Step 120, Loss 0.02277018502354622\n",
            "Train step - Step 130, Loss 0.02057470753788948\n",
            "Train step - Step 140, Loss 0.020402872934937477\n",
            "Train step - Step 150, Loss 0.02045504003763199\n",
            "Train step - Step 160, Loss 0.02148951031267643\n",
            "Train step - Step 170, Loss 0.022249436005949974\n",
            "Train step - Step 180, Loss 0.023016847670078278\n",
            "Train step - Step 190, Loss 0.018748488277196884\n",
            "Train step - Step 200, Loss 0.02036125771701336\n",
            "Train step - Step 210, Loss 0.01908695138990879\n",
            "Train step - Step 220, Loss 0.018738988786935806\n",
            "Train step - Step 230, Loss 0.022968586534261703\n",
            "Train step - Step 240, Loss 0.02025594189763069\n",
            "Train step - Step 250, Loss 0.019209418445825577\n",
            "Train step - Step 260, Loss 0.021262263879179955\n",
            "Train step - Step 270, Loss 0.01970624178647995\n",
            "Train step - Step 280, Loss 0.020513266324996948\n",
            "Train step - Step 290, Loss 0.01753338985145092\n",
            "Train step - Step 300, Loss 0.02247483655810356\n",
            "Train step - Step 310, Loss 0.01756935939192772\n",
            "Train step - Step 320, Loss 0.020955421030521393\n",
            "Train step - Step 330, Loss 0.019481083378195763\n",
            "Train step - Step 340, Loss 0.021104030311107635\n",
            "Train step - Step 350, Loss 0.01837431639432907\n",
            "Train step - Step 360, Loss 0.019877221435308456\n",
            "Train step - Step 370, Loss 0.019770285114645958\n",
            "Train step - Step 380, Loss 0.02087237313389778\n",
            "Train epoch - Accuracy: 0.6054343434343434 Loss: 0.022679033566454444 Corrects: 29969\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.019889583811163902\n",
            "Train step - Step 400, Loss 0.019396910443902016\n",
            "Train step - Step 410, Loss 0.019258879125118256\n",
            "Train step - Step 420, Loss 0.020383300259709358\n",
            "Train step - Step 430, Loss 0.018921419978141785\n",
            "Train step - Step 440, Loss 0.0158782210201025\n",
            "Train step - Step 450, Loss 0.01987476460635662\n",
            "Train step - Step 460, Loss 0.02055603452026844\n",
            "Train step - Step 470, Loss 0.018338127061724663\n",
            "Train step - Step 480, Loss 0.01562686078250408\n",
            "Train step - Step 490, Loss 0.019728267565369606\n",
            "Train step - Step 500, Loss 0.017150750383734703\n",
            "Train step - Step 510, Loss 0.018795784562826157\n",
            "Train step - Step 520, Loss 0.021513046696782112\n",
            "Train step - Step 530, Loss 0.018281156197190285\n",
            "Train step - Step 540, Loss 0.01869468204677105\n",
            "Train step - Step 550, Loss 0.01987622119486332\n",
            "Train step - Step 560, Loss 0.017314456403255463\n",
            "Train step - Step 570, Loss 0.01735682412981987\n",
            "Train step - Step 580, Loss 0.016809897497296333\n",
            "Train step - Step 590, Loss 0.019672878086566925\n",
            "Train step - Step 600, Loss 0.023367108777165413\n",
            "Train step - Step 610, Loss 0.02174760214984417\n",
            "Train step - Step 620, Loss 0.020262546837329865\n",
            "Train step - Step 630, Loss 0.018701395019888878\n",
            "Train step - Step 640, Loss 0.020740032196044922\n",
            "Train step - Step 650, Loss 0.018530817702412605\n",
            "Train step - Step 660, Loss 0.019702164456248283\n",
            "Train step - Step 670, Loss 0.020913492888212204\n",
            "Train step - Step 680, Loss 0.02035176008939743\n",
            "Train step - Step 690, Loss 0.01923776976764202\n",
            "Train step - Step 700, Loss 0.019016047939658165\n",
            "Train step - Step 710, Loss 0.018185719847679138\n",
            "Train step - Step 720, Loss 0.019360734149813652\n",
            "Train step - Step 730, Loss 0.019075047224760056\n",
            "Train step - Step 740, Loss 0.01780720427632332\n",
            "Train step - Step 750, Loss 0.021722761914134026\n",
            "Train step - Step 760, Loss 0.01932639814913273\n",
            "Train step - Step 770, Loss 0.020755931735038757\n",
            "Train epoch - Accuracy: 0.6435151515151515 Loss: 0.01944533648334368 Corrects: 31854\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.01932627707719803\n",
            "Train step - Step 790, Loss 0.018595438450574875\n",
            "Train step - Step 800, Loss 0.01784578338265419\n",
            "Train step - Step 810, Loss 0.017117561772465706\n",
            "Train step - Step 820, Loss 0.017023371532559395\n",
            "Train step - Step 830, Loss 0.019805362448096275\n",
            "Train step - Step 840, Loss 0.01684540882706642\n",
            "Train step - Step 850, Loss 0.01409070659428835\n",
            "Train step - Step 860, Loss 0.015290530398488045\n",
            "Train step - Step 870, Loss 0.01736488752067089\n",
            "Train step - Step 880, Loss 0.018568191677331924\n",
            "Train step - Step 890, Loss 0.020964479073882103\n",
            "Train step - Step 900, Loss 0.022644853219389915\n",
            "Train step - Step 910, Loss 0.018676085397601128\n",
            "Train step - Step 920, Loss 0.019424017518758774\n",
            "Train step - Step 930, Loss 0.015828996896743774\n",
            "Train step - Step 940, Loss 0.01791798323392868\n",
            "Train step - Step 950, Loss 0.017241260036826134\n",
            "Train step - Step 960, Loss 0.01953509822487831\n",
            "Train step - Step 970, Loss 0.021739792078733444\n",
            "Train step - Step 980, Loss 0.01789895072579384\n",
            "Train step - Step 990, Loss 0.020959200337529182\n",
            "Train step - Step 1000, Loss 0.017140746116638184\n",
            "Train step - Step 1010, Loss 0.01943851262331009\n",
            "Train step - Step 1020, Loss 0.020371565595269203\n",
            "Train step - Step 1030, Loss 0.021227853372693062\n",
            "Train step - Step 1040, Loss 0.022737516090273857\n",
            "Train step - Step 1050, Loss 0.018625110387802124\n",
            "Train step - Step 1060, Loss 0.01984492689371109\n",
            "Train step - Step 1070, Loss 0.019267652183771133\n",
            "Train step - Step 1080, Loss 0.01693372055888176\n",
            "Train step - Step 1090, Loss 0.017489155754446983\n",
            "Train step - Step 1100, Loss 0.018056266009807587\n",
            "Train step - Step 1110, Loss 0.020829176530241966\n",
            "Train step - Step 1120, Loss 0.019402137026190758\n",
            "Train step - Step 1130, Loss 0.02025960572063923\n",
            "Train step - Step 1140, Loss 0.01770489662885666\n",
            "Train step - Step 1150, Loss 0.02133999951183796\n",
            "Train step - Step 1160, Loss 0.022054212167859077\n",
            "Train epoch - Accuracy: 0.6536565656565656 Loss: 0.018945342742885 Corrects: 32356\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.01976626180112362\n",
            "Train step - Step 1180, Loss 0.014524775557219982\n",
            "Train step - Step 1190, Loss 0.01847185008227825\n",
            "Train step - Step 1200, Loss 0.01920962706208229\n",
            "Train step - Step 1210, Loss 0.01613549143075943\n",
            "Train step - Step 1220, Loss 0.017185494303703308\n",
            "Train step - Step 1230, Loss 0.019125832244753838\n",
            "Train step - Step 1240, Loss 0.020768331363797188\n",
            "Train step - Step 1250, Loss 0.015005454421043396\n",
            "Train step - Step 1260, Loss 0.016393035650253296\n",
            "Train step - Step 1270, Loss 0.019458962604403496\n",
            "Train step - Step 1280, Loss 0.01837511546909809\n",
            "Train step - Step 1290, Loss 0.016647648066282272\n",
            "Train step - Step 1300, Loss 0.017339305952191353\n",
            "Train step - Step 1310, Loss 0.017267359420657158\n",
            "Train step - Step 1320, Loss 0.018028004094958305\n",
            "Train step - Step 1330, Loss 0.018514765426516533\n",
            "Train step - Step 1340, Loss 0.02066834457218647\n",
            "Train step - Step 1350, Loss 0.019472753629088402\n",
            "Train step - Step 1360, Loss 0.01655413582921028\n",
            "Train step - Step 1370, Loss 0.016526775434613228\n",
            "Train step - Step 1380, Loss 0.019618932157754898\n",
            "Train step - Step 1390, Loss 0.019595040008425713\n",
            "Train step - Step 1400, Loss 0.018398061394691467\n",
            "Train step - Step 1410, Loss 0.016646243631839752\n",
            "Train step - Step 1420, Loss 0.021175522357225418\n",
            "Train step - Step 1430, Loss 0.020199839025735855\n",
            "Train step - Step 1440, Loss 0.02028195746243\n",
            "Train step - Step 1450, Loss 0.01983613334596157\n",
            "Train step - Step 1460, Loss 0.018027884885668755\n",
            "Train step - Step 1470, Loss 0.016693774610757828\n",
            "Train step - Step 1480, Loss 0.021046867594122887\n",
            "Train step - Step 1490, Loss 0.020018085837364197\n",
            "Train step - Step 1500, Loss 0.01822371408343315\n",
            "Train step - Step 1510, Loss 0.020263802260160446\n",
            "Train step - Step 1520, Loss 0.02081720530986786\n",
            "Train step - Step 1530, Loss 0.019534172490239143\n",
            "Train step - Step 1540, Loss 0.018115460872650146\n",
            "Train epoch - Accuracy: 0.6614343434343435 Loss: 0.01858253572489878 Corrects: 32741\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 1550, Loss 0.016969015821814537\n",
            "Train step - Step 1560, Loss 0.01954660378396511\n",
            "Train step - Step 1570, Loss 0.017847174778580666\n",
            "Train step - Step 1580, Loss 0.016569826751947403\n",
            "Train step - Step 1590, Loss 0.017084268853068352\n",
            "Train step - Step 1600, Loss 0.01895536109805107\n",
            "Train step - Step 1610, Loss 0.018169837072491646\n",
            "Train step - Step 1620, Loss 0.019281363114714622\n",
            "Train step - Step 1630, Loss 0.018545150756835938\n",
            "Train step - Step 1640, Loss 0.016801457852125168\n",
            "Train step - Step 1650, Loss 0.018736621364951134\n",
            "Train step - Step 1660, Loss 0.016917385160923004\n",
            "Train step - Step 1670, Loss 0.016893407329916954\n",
            "Train step - Step 1680, Loss 0.01712188869714737\n",
            "Train step - Step 1690, Loss 0.015028634108603\n",
            "Train step - Step 1700, Loss 0.020064515992999077\n",
            "Train step - Step 1710, Loss 0.017814984545111656\n",
            "Train step - Step 1720, Loss 0.017237601801753044\n",
            "Train step - Step 1730, Loss 0.019174441695213318\n",
            "Train step - Step 1740, Loss 0.015032727271318436\n",
            "Train step - Step 1750, Loss 0.016930783167481422\n",
            "Train step - Step 1760, Loss 0.022443154826760292\n",
            "Train step - Step 1770, Loss 0.019041508436203003\n",
            "Train step - Step 1780, Loss 0.019640635699033737\n",
            "Train step - Step 1790, Loss 0.01906847022473812\n",
            "Train step - Step 1800, Loss 0.01685306616127491\n",
            "Train step - Step 1810, Loss 0.020759081467986107\n",
            "Train step - Step 1820, Loss 0.021048879250884056\n",
            "Train step - Step 1830, Loss 0.019746730104088783\n",
            "Train step - Step 1840, Loss 0.017988521605730057\n",
            "Train step - Step 1850, Loss 0.019381796941161156\n",
            "Train step - Step 1860, Loss 0.017295992001891136\n",
            "Train step - Step 1870, Loss 0.01834261044859886\n",
            "Train step - Step 1880, Loss 0.021687373518943787\n",
            "Train step - Step 1890, Loss 0.017200559377670288\n",
            "Train step - Step 1900, Loss 0.018534468486905098\n",
            "Train step - Step 1910, Loss 0.01748817227780819\n",
            "Train step - Step 1920, Loss 0.018040452152490616\n",
            "Train step - Step 1930, Loss 0.017246654257178307\n",
            "Train epoch - Accuracy: 0.6620202020202021 Loss: 0.018582696780562402 Corrects: 32770\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 1940, Loss 0.018175242468714714\n",
            "Train step - Step 1950, Loss 0.01713995449244976\n",
            "Train step - Step 1960, Loss 0.01899970881640911\n",
            "Train step - Step 1970, Loss 0.015312418341636658\n",
            "Train step - Step 1980, Loss 0.018139563500881195\n",
            "Train step - Step 1990, Loss 0.016458136960864067\n",
            "Train step - Step 2000, Loss 0.015383541584014893\n",
            "Train step - Step 2010, Loss 0.017042305320501328\n",
            "Train step - Step 2020, Loss 0.01662622019648552\n",
            "Train step - Step 2030, Loss 0.01646319217979908\n",
            "Train step - Step 2040, Loss 0.019934292882680893\n",
            "Train step - Step 2050, Loss 0.015973474830389023\n",
            "Train step - Step 2060, Loss 0.017078978940844536\n",
            "Train step - Step 2070, Loss 0.016644177958369255\n",
            "Train step - Step 2080, Loss 0.016156934201717377\n",
            "Train step - Step 2090, Loss 0.01818717084825039\n",
            "Train step - Step 2100, Loss 0.019413406029343605\n",
            "Train step - Step 2110, Loss 0.02272716723382473\n",
            "Train step - Step 2120, Loss 0.017393795773386955\n",
            "Train step - Step 2130, Loss 0.016999518498778343\n",
            "Train step - Step 2140, Loss 0.018464969471096992\n",
            "Train step - Step 2150, Loss 0.01713142916560173\n",
            "Train step - Step 2160, Loss 0.019033214077353477\n",
            "Train step - Step 2170, Loss 0.020405959337949753\n",
            "Train step - Step 2180, Loss 0.017768559977412224\n",
            "Train step - Step 2190, Loss 0.016744885593652725\n",
            "Train step - Step 2200, Loss 0.01982686296105385\n",
            "Train step - Step 2210, Loss 0.017207905650138855\n",
            "Train step - Step 2220, Loss 0.015224721282720566\n",
            "Train step - Step 2230, Loss 0.01823800802230835\n",
            "Train step - Step 2240, Loss 0.018894461914896965\n",
            "Train step - Step 2250, Loss 0.02111838571727276\n",
            "Train step - Step 2260, Loss 0.018251555040478706\n",
            "Train step - Step 2270, Loss 0.018358895555138588\n",
            "Train step - Step 2280, Loss 0.01951964758336544\n",
            "Train step - Step 2290, Loss 0.017848240211606026\n",
            "Train step - Step 2300, Loss 0.018942799419164658\n",
            "Train step - Step 2310, Loss 0.018931418657302856\n",
            "Train step - Step 2320, Loss 0.019329912960529327\n",
            "Train epoch - Accuracy: 0.6647676767676768 Loss: 0.018433348847910612 Corrects: 32906\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 2330, Loss 0.017600663006305695\n",
            "Train step - Step 2340, Loss 0.01690405234694481\n",
            "Train step - Step 2350, Loss 0.015766700729727745\n",
            "Train step - Step 2360, Loss 0.01874326355755329\n",
            "Train step - Step 2370, Loss 0.017114786431193352\n",
            "Train step - Step 2380, Loss 0.01847853697836399\n",
            "Train step - Step 2390, Loss 0.01854078471660614\n",
            "Train step - Step 2400, Loss 0.020268302410840988\n",
            "Train step - Step 2410, Loss 0.018280772492289543\n",
            "Train step - Step 2420, Loss 0.017531780526041985\n",
            "Train step - Step 2430, Loss 0.0194622203707695\n",
            "Train step - Step 2440, Loss 0.01844053715467453\n",
            "Train step - Step 2450, Loss 0.02001194655895233\n",
            "Train step - Step 2460, Loss 0.0199521966278553\n",
            "Train step - Step 2470, Loss 0.020520834252238274\n",
            "Train step - Step 2480, Loss 0.021221179515123367\n",
            "Train step - Step 2490, Loss 0.02027803659439087\n",
            "Train step - Step 2500, Loss 0.019320989027619362\n",
            "Train step - Step 2510, Loss 0.01997326873242855\n",
            "Train step - Step 2520, Loss 0.017941627651453018\n",
            "Train step - Step 2530, Loss 0.01751643233001232\n",
            "Train step - Step 2540, Loss 0.019121214747428894\n",
            "Train step - Step 2550, Loss 0.017374902963638306\n",
            "Train step - Step 2560, Loss 0.018884746357798576\n",
            "Train step - Step 2570, Loss 0.016440410166978836\n",
            "Train step - Step 2580, Loss 0.01906721107661724\n",
            "Train step - Step 2590, Loss 0.018300244584679604\n",
            "Train step - Step 2600, Loss 0.019388126209378242\n",
            "Train step - Step 2610, Loss 0.019678262993693352\n",
            "Train step - Step 2620, Loss 0.0197648536413908\n",
            "Train step - Step 2630, Loss 0.019052155315876007\n",
            "Train step - Step 2640, Loss 0.017934594303369522\n",
            "Train step - Step 2650, Loss 0.018499433994293213\n",
            "Train step - Step 2660, Loss 0.015951009467244148\n",
            "Train step - Step 2670, Loss 0.020347943529486656\n",
            "Train step - Step 2680, Loss 0.01952943578362465\n",
            "Train step - Step 2690, Loss 0.02057768777012825\n",
            "Train step - Step 2700, Loss 0.019894249737262726\n",
            "Train epoch - Accuracy: 0.6662222222222223 Loss: 0.018377842026376965 Corrects: 32978\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 2710, Loss 0.019329514354467392\n",
            "Train step - Step 2720, Loss 0.016768164932727814\n",
            "Train step - Step 2730, Loss 0.01782038062810898\n",
            "Train step - Step 2740, Loss 0.021955927833914757\n",
            "Train step - Step 2750, Loss 0.01833028718829155\n",
            "Train step - Step 2760, Loss 0.015976937487721443\n",
            "Train step - Step 2770, Loss 0.017964445054531097\n",
            "Train step - Step 2780, Loss 0.019224142655730247\n",
            "Train step - Step 2790, Loss 0.017768148332834244\n",
            "Train step - Step 2800, Loss 0.018997233361005783\n",
            "Train step - Step 2810, Loss 0.01732255332171917\n",
            "Train step - Step 2820, Loss 0.01950743980705738\n",
            "Train step - Step 2830, Loss 0.017088327556848526\n",
            "Train step - Step 2840, Loss 0.018926134333014488\n",
            "Train step - Step 2850, Loss 0.01603793352842331\n",
            "Train step - Step 2860, Loss 0.019180651754140854\n",
            "Train step - Step 2870, Loss 0.019195828586816788\n",
            "Train step - Step 2880, Loss 0.01909985952079296\n",
            "Train step - Step 2890, Loss 0.019327232614159584\n",
            "Train step - Step 2900, Loss 0.01943237893283367\n",
            "Train step - Step 2910, Loss 0.017370864748954773\n",
            "Train step - Step 2920, Loss 0.01951776072382927\n",
            "Train step - Step 2930, Loss 0.015303420834243298\n",
            "Train step - Step 2940, Loss 0.02055114135146141\n",
            "Train step - Step 2950, Loss 0.019699137657880783\n",
            "Train step - Step 2960, Loss 0.0175973791629076\n",
            "Train step - Step 2970, Loss 0.019229015335440636\n",
            "Train step - Step 2980, Loss 0.02044767327606678\n",
            "Train step - Step 2990, Loss 0.016519295051693916\n",
            "Train step - Step 3000, Loss 0.01897249184548855\n",
            "Train step - Step 3010, Loss 0.018438372761011124\n",
            "Train step - Step 3020, Loss 0.01865123026072979\n",
            "Train step - Step 3030, Loss 0.018645519390702248\n",
            "Train step - Step 3040, Loss 0.016808316111564636\n",
            "Train step - Step 3050, Loss 0.01867203414440155\n",
            "Train step - Step 3060, Loss 0.01723460853099823\n",
            "Train step - Step 3070, Loss 0.0166852418333292\n",
            "Train step - Step 3080, Loss 0.019476216286420822\n",
            "Train step - Step 3090, Loss 0.018583180382847786\n",
            "Train epoch - Accuracy: 0.6701616161616162 Loss: 0.018287633791114345 Corrects: 33173\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 3100, Loss 0.01641620136797428\n",
            "Train step - Step 3110, Loss 0.01492586825042963\n",
            "Train step - Step 3120, Loss 0.018794391304254532\n",
            "Train step - Step 3130, Loss 0.01667024753987789\n",
            "Train step - Step 3140, Loss 0.01651708595454693\n",
            "Train step - Step 3150, Loss 0.016693949699401855\n",
            "Train step - Step 3160, Loss 0.01904025301337242\n",
            "Train step - Step 3170, Loss 0.020904552191495895\n",
            "Train step - Step 3180, Loss 0.018917078152298927\n",
            "Train step - Step 3190, Loss 0.019985701888799667\n",
            "Train step - Step 3200, Loss 0.01768501289188862\n",
            "Train step - Step 3210, Loss 0.016829822212457657\n",
            "Train step - Step 3220, Loss 0.019353946670889854\n",
            "Train step - Step 3230, Loss 0.016562001779675484\n",
            "Train step - Step 3240, Loss 0.02360461838543415\n",
            "Train step - Step 3250, Loss 0.019457070156931877\n",
            "Train step - Step 3260, Loss 0.017162330448627472\n",
            "Train step - Step 3270, Loss 0.018688006326556206\n",
            "Train step - Step 3280, Loss 0.021592598408460617\n",
            "Train step - Step 3290, Loss 0.01411560270935297\n",
            "Train step - Step 3300, Loss 0.01677367277443409\n",
            "Train step - Step 3310, Loss 0.02048085257411003\n",
            "Train step - Step 3320, Loss 0.01685120351612568\n",
            "Train step - Step 3330, Loss 0.017886901274323463\n",
            "Train step - Step 3340, Loss 0.018364841118454933\n",
            "Train step - Step 3350, Loss 0.018160535022616386\n",
            "Train step - Step 3360, Loss 0.0168735571205616\n",
            "Train step - Step 3370, Loss 0.015225250273942947\n",
            "Train step - Step 3380, Loss 0.0178043395280838\n",
            "Train step - Step 3390, Loss 0.019641291350126266\n",
            "Train step - Step 3400, Loss 0.016806529834866524\n",
            "Train step - Step 3410, Loss 0.018589003011584282\n",
            "Train step - Step 3420, Loss 0.018361546099185944\n",
            "Train step - Step 3430, Loss 0.01898609660565853\n",
            "Train step - Step 3440, Loss 0.017201248556375504\n",
            "Train step - Step 3450, Loss 0.01958523876965046\n",
            "Train step - Step 3460, Loss 0.01632336899638176\n",
            "Train step - Step 3470, Loss 0.016330217942595482\n",
            "Train step - Step 3480, Loss 0.01629321649670601\n",
            "Train epoch - Accuracy: 0.6733131313131313 Loss: 0.01809477558400896 Corrects: 33329\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 3490, Loss 0.014665601775050163\n",
            "Train step - Step 3500, Loss 0.016368350014090538\n",
            "Train step - Step 3510, Loss 0.018333446234464645\n",
            "Train step - Step 3520, Loss 0.01748957298696041\n",
            "Train step - Step 3530, Loss 0.018460413441061974\n",
            "Train step - Step 3540, Loss 0.018862556666135788\n",
            "Train step - Step 3550, Loss 0.02083715796470642\n",
            "Train step - Step 3560, Loss 0.01779022440314293\n",
            "Train step - Step 3570, Loss 0.020259536802768707\n",
            "Train step - Step 3580, Loss 0.018221866339445114\n",
            "Train step - Step 3590, Loss 0.016393518075346947\n",
            "Train step - Step 3600, Loss 0.01544187031686306\n",
            "Train step - Step 3610, Loss 0.016164816915988922\n",
            "Train step - Step 3620, Loss 0.016022982075810432\n",
            "Train step - Step 3630, Loss 0.019697600975632668\n",
            "Train step - Step 3640, Loss 0.02174968644976616\n",
            "Train step - Step 3650, Loss 0.018936509266495705\n",
            "Train step - Step 3660, Loss 0.01732286624610424\n",
            "Train step - Step 3670, Loss 0.01717114821076393\n",
            "Train step - Step 3680, Loss 0.018061786890029907\n",
            "Train step - Step 3690, Loss 0.01481879223138094\n",
            "Train step - Step 3700, Loss 0.020317554473876953\n",
            "Train step - Step 3710, Loss 0.017519790679216385\n",
            "Train step - Step 3720, Loss 0.017973214387893677\n",
            "Train step - Step 3730, Loss 0.018242988735437393\n",
            "Train step - Step 3740, Loss 0.022832464426755905\n",
            "Train step - Step 3750, Loss 0.01792975887656212\n",
            "Train step - Step 3760, Loss 0.016849618405103683\n",
            "Train step - Step 3770, Loss 0.018090765923261642\n",
            "Train step - Step 3780, Loss 0.01695645973086357\n",
            "Train step - Step 3790, Loss 0.016293711960315704\n",
            "Train step - Step 3800, Loss 0.016651000827550888\n",
            "Train step - Step 3810, Loss 0.016353020444512367\n",
            "Train step - Step 3820, Loss 0.01867896504700184\n",
            "Train step - Step 3830, Loss 0.02011871710419655\n",
            "Train step - Step 3840, Loss 0.020481007173657417\n",
            "Train step - Step 3850, Loss 0.018289363011717796\n",
            "Train step - Step 3860, Loss 0.019488109275698662\n",
            "Train epoch - Accuracy: 0.6699191919191919 Loss: 0.018197069941897584 Corrects: 33161\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 3870, Loss 0.01769889146089554\n",
            "Train step - Step 3880, Loss 0.01656842976808548\n",
            "Train step - Step 3890, Loss 0.0168707724660635\n",
            "Train step - Step 3900, Loss 0.016356054693460464\n",
            "Train step - Step 3910, Loss 0.019464142620563507\n",
            "Train step - Step 3920, Loss 0.016432901844382286\n",
            "Train step - Step 3930, Loss 0.015677744522690773\n",
            "Train step - Step 3940, Loss 0.01967659220099449\n",
            "Train step - Step 3950, Loss 0.016867022961378098\n",
            "Train step - Step 3960, Loss 0.018313001841306686\n",
            "Train step - Step 3970, Loss 0.018354466184973717\n",
            "Train step - Step 3980, Loss 0.01950320415198803\n",
            "Train step - Step 3990, Loss 0.020177163183689117\n",
            "Train step - Step 4000, Loss 0.019439617171883583\n",
            "Train step - Step 4010, Loss 0.020942287519574165\n",
            "Train step - Step 4020, Loss 0.019780358299613\n",
            "Train step - Step 4030, Loss 0.018619578331708908\n",
            "Train step - Step 4040, Loss 0.01677677594125271\n",
            "Train step - Step 4050, Loss 0.017421303316950798\n",
            "Train step - Step 4060, Loss 0.017607035115361214\n",
            "Train step - Step 4070, Loss 0.020638950169086456\n",
            "Train step - Step 4080, Loss 0.017862867563962936\n",
            "Train step - Step 4090, Loss 0.01794380694627762\n",
            "Train step - Step 4100, Loss 0.01797931082546711\n",
            "Train step - Step 4110, Loss 0.017176520079374313\n",
            "Train step - Step 4120, Loss 0.01695738546550274\n",
            "Train step - Step 4130, Loss 0.0175675880163908\n",
            "Train step - Step 4140, Loss 0.019365770742297173\n",
            "Train step - Step 4150, Loss 0.020137831568717957\n",
            "Train step - Step 4160, Loss 0.017506124451756477\n",
            "Train step - Step 4170, Loss 0.016680290922522545\n",
            "Train step - Step 4180, Loss 0.0176454558968544\n",
            "Train step - Step 4190, Loss 0.021232085302472115\n",
            "Train step - Step 4200, Loss 0.020806526765227318\n",
            "Train step - Step 4210, Loss 0.019231928512454033\n",
            "Train step - Step 4220, Loss 0.019894395023584366\n",
            "Train step - Step 4230, Loss 0.020421691238880157\n",
            "Train step - Step 4240, Loss 0.023625576868653297\n",
            "Train step - Step 4250, Loss 0.017105767503380775\n",
            "Train epoch - Accuracy: 0.6715353535353535 Loss: 0.018078625009969027 Corrects: 33241\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 4260, Loss 0.017686564475297928\n",
            "Train step - Step 4270, Loss 0.01831703446805477\n",
            "Train step - Step 4280, Loss 0.01747618429362774\n",
            "Train step - Step 4290, Loss 0.016152340918779373\n",
            "Train step - Step 4300, Loss 0.015640033408999443\n",
            "Train step - Step 4310, Loss 0.01590421423316002\n",
            "Train step - Step 4320, Loss 0.01802711933851242\n",
            "Train step - Step 4330, Loss 0.02071172185242176\n",
            "Train step - Step 4340, Loss 0.01818012446165085\n",
            "Train step - Step 4350, Loss 0.01903846487402916\n",
            "Train step - Step 4360, Loss 0.014842536300420761\n",
            "Train step - Step 4370, Loss 0.01904783770442009\n",
            "Train step - Step 4380, Loss 0.019777676090598106\n",
            "Train step - Step 4390, Loss 0.016938770189881325\n",
            "Train step - Step 4400, Loss 0.019955893978476524\n",
            "Train step - Step 4410, Loss 0.016445763409137726\n",
            "Train step - Step 4420, Loss 0.015365605242550373\n",
            "Train step - Step 4430, Loss 0.017740828916430473\n",
            "Train step - Step 4440, Loss 0.01999792270362377\n",
            "Train step - Step 4450, Loss 0.01662135124206543\n",
            "Train step - Step 4460, Loss 0.017570411786437035\n",
            "Train step - Step 4470, Loss 0.019077658653259277\n",
            "Train step - Step 4480, Loss 0.015685856342315674\n",
            "Train step - Step 4490, Loss 0.01910870149731636\n",
            "Train step - Step 4500, Loss 0.01838609017431736\n",
            "Train step - Step 4510, Loss 0.018693964928388596\n",
            "Train step - Step 4520, Loss 0.01802770048379898\n",
            "Train step - Step 4530, Loss 0.021809792146086693\n",
            "Train step - Step 4540, Loss 0.018705759197473526\n",
            "Train step - Step 4550, Loss 0.019956249743700027\n",
            "Train step - Step 4560, Loss 0.01867203414440155\n",
            "Train step - Step 4570, Loss 0.01805211417376995\n",
            "Train step - Step 4580, Loss 0.019052037969231606\n",
            "Train step - Step 4590, Loss 0.019965264946222305\n",
            "Train step - Step 4600, Loss 0.019523300230503082\n",
            "Train step - Step 4610, Loss 0.018800096586346626\n",
            "Train step - Step 4620, Loss 0.017253870144486427\n",
            "Train step - Step 4630, Loss 0.01799824833869934\n",
            "Train step - Step 4640, Loss 0.017659788951277733\n",
            "Train epoch - Accuracy: 0.6710909090909091 Loss: 0.018224372169887176 Corrects: 33219\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 4650, Loss 0.01710534282028675\n",
            "Train step - Step 4660, Loss 0.017930960282683372\n",
            "Train step - Step 4670, Loss 0.020559996366500854\n",
            "Train step - Step 4680, Loss 0.01961909979581833\n",
            "Train step - Step 4690, Loss 0.017507821321487427\n",
            "Train step - Step 4700, Loss 0.018994642421603203\n",
            "Train step - Step 4710, Loss 0.019412800669670105\n",
            "Train step - Step 4720, Loss 0.018841620534658432\n",
            "Train step - Step 4730, Loss 0.019780876114964485\n",
            "Train step - Step 4740, Loss 0.01565604843199253\n",
            "Train step - Step 4750, Loss 0.017094697803258896\n",
            "Train step - Step 4760, Loss 0.017018646001815796\n",
            "Train step - Step 4770, Loss 0.016885949298739433\n",
            "Train step - Step 4780, Loss 0.016408363357186317\n",
            "Train step - Step 4790, Loss 0.018966563045978546\n",
            "Train step - Step 4800, Loss 0.016917306929826736\n",
            "Train step - Step 4810, Loss 0.019417792558670044\n",
            "Train step - Step 4820, Loss 0.016182873398065567\n",
            "Train step - Step 4830, Loss 0.019746698439121246\n",
            "Train step - Step 4840, Loss 0.014982504770159721\n",
            "Train step - Step 4850, Loss 0.01651442050933838\n",
            "Train step - Step 4860, Loss 0.015446045435965061\n",
            "Train step - Step 4870, Loss 0.019667917862534523\n",
            "Train step - Step 4880, Loss 0.01701192557811737\n",
            "Train step - Step 4890, Loss 0.014844721183180809\n",
            "Train step - Step 4900, Loss 0.022625969722867012\n",
            "Train step - Step 4910, Loss 0.017422841861844063\n",
            "Train step - Step 4920, Loss 0.02101326920092106\n",
            "Train step - Step 4930, Loss 0.019967708736658096\n",
            "Train step - Step 4940, Loss 0.01705852895975113\n",
            "Train step - Step 4950, Loss 0.01752455346286297\n",
            "Train step - Step 4960, Loss 0.01753579080104828\n",
            "Train step - Step 4970, Loss 0.020231764763593674\n",
            "Train step - Step 4980, Loss 0.018723610788583755\n",
            "Train step - Step 4990, Loss 0.021049195900559425\n",
            "Train step - Step 5000, Loss 0.015839774161577225\n",
            "Train step - Step 5010, Loss 0.01784544438123703\n",
            "Train step - Step 5020, Loss 0.019222285598516464\n",
            "Train step - Step 5030, Loss 0.018627487123012543\n",
            "Train epoch - Accuracy: 0.6743636363636364 Loss: 0.01802410248614321 Corrects: 33381\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 5040, Loss 0.016545044258236885\n",
            "Train step - Step 5050, Loss 0.01663665473461151\n",
            "Train step - Step 5060, Loss 0.014846584759652615\n",
            "Train step - Step 5070, Loss 0.01582806371152401\n",
            "Train step - Step 5080, Loss 0.018393253907561302\n",
            "Train step - Step 5090, Loss 0.019699297845363617\n",
            "Train step - Step 5100, Loss 0.018108217045664787\n",
            "Train step - Step 5110, Loss 0.019110944122076035\n",
            "Train step - Step 5120, Loss 0.016989856958389282\n",
            "Train step - Step 5130, Loss 0.015079615637660027\n",
            "Train step - Step 5140, Loss 0.017971420660614967\n",
            "Train step - Step 5150, Loss 0.018820732831954956\n",
            "Train step - Step 5160, Loss 0.01792851649224758\n",
            "Train step - Step 5170, Loss 0.018638603389263153\n",
            "Train step - Step 5180, Loss 0.01817191019654274\n",
            "Train step - Step 5190, Loss 0.018006915226578712\n",
            "Train step - Step 5200, Loss 0.01844562031328678\n",
            "Train step - Step 5210, Loss 0.018158085644245148\n",
            "Train step - Step 5220, Loss 0.014979612082242966\n",
            "Train step - Step 5230, Loss 0.016368798911571503\n",
            "Train step - Step 5240, Loss 0.016610072925686836\n",
            "Train step - Step 5250, Loss 0.01738000102341175\n",
            "Train step - Step 5260, Loss 0.017151400446891785\n",
            "Train step - Step 5270, Loss 0.019936902448534966\n",
            "Train step - Step 5280, Loss 0.015261529013514519\n",
            "Train step - Step 5290, Loss 0.016518451273441315\n",
            "Train step - Step 5300, Loss 0.01638605259358883\n",
            "Train step - Step 5310, Loss 0.017352759838104248\n",
            "Train step - Step 5320, Loss 0.018193958327174187\n",
            "Train step - Step 5330, Loss 0.01655115745961666\n",
            "Train step - Step 5340, Loss 0.021358676254749298\n",
            "Train step - Step 5350, Loss 0.020014269277453423\n",
            "Train step - Step 5360, Loss 0.019045772030949593\n",
            "Train step - Step 5370, Loss 0.01876860484480858\n",
            "Train step - Step 5380, Loss 0.019560575485229492\n",
            "Train step - Step 5390, Loss 0.017523420974612236\n",
            "Train step - Step 5400, Loss 0.020047979429364204\n",
            "Train step - Step 5410, Loss 0.01765674166381359\n",
            "Train epoch - Accuracy: 0.674969696969697 Loss: 0.0180535319578467 Corrects: 33411\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 5420, Loss 0.018994372338056564\n",
            "Train step - Step 5430, Loss 0.01846543326973915\n",
            "Train step - Step 5440, Loss 0.015359565615653992\n",
            "Train step - Step 5450, Loss 0.015409125946462154\n",
            "Train step - Step 5460, Loss 0.015839392319321632\n",
            "Train step - Step 5470, Loss 0.016097748652100563\n",
            "Train step - Step 5480, Loss 0.015680084004998207\n",
            "Train step - Step 5490, Loss 0.018197430297732353\n",
            "Train step - Step 5500, Loss 0.014661177061498165\n",
            "Train step - Step 5510, Loss 0.015215582214295864\n",
            "Train step - Step 5520, Loss 0.019394459202885628\n",
            "Train step - Step 5530, Loss 0.019570259377360344\n",
            "Train step - Step 5540, Loss 0.01903652772307396\n",
            "Train step - Step 5550, Loss 0.017061926424503326\n",
            "Train step - Step 5560, Loss 0.016123970970511436\n",
            "Train step - Step 5570, Loss 0.016701815649867058\n",
            "Train step - Step 5580, Loss 0.02149944193661213\n",
            "Train step - Step 5590, Loss 0.01830068975687027\n",
            "Train step - Step 5600, Loss 0.01686825603246689\n",
            "Train step - Step 5610, Loss 0.018062761053442955\n",
            "Train step - Step 5620, Loss 0.01765674538910389\n",
            "Train step - Step 5630, Loss 0.016184963285923004\n",
            "Train step - Step 5640, Loss 0.01657894439995289\n",
            "Train step - Step 5650, Loss 0.019080793485045433\n",
            "Train step - Step 5660, Loss 0.018982062116265297\n",
            "Train step - Step 5670, Loss 0.015115337446331978\n",
            "Train step - Step 5680, Loss 0.020136581733822823\n",
            "Train step - Step 5690, Loss 0.014289996586740017\n",
            "Train step - Step 5700, Loss 0.019802113994956017\n",
            "Train step - Step 5710, Loss 0.02023186720907688\n",
            "Train step - Step 5720, Loss 0.017404435202479362\n",
            "Train step - Step 5730, Loss 0.01742708496749401\n",
            "Train step - Step 5740, Loss 0.017986314371228218\n",
            "Train step - Step 5750, Loss 0.02082945592701435\n",
            "Train step - Step 5760, Loss 0.0181173924356699\n",
            "Train step - Step 5770, Loss 0.019690655171871185\n",
            "Train step - Step 5780, Loss 0.018548818305134773\n",
            "Train step - Step 5790, Loss 0.01898367516696453\n",
            "Train step - Step 5800, Loss 0.017758313566446304\n",
            "Train epoch - Accuracy: 0.6727676767676768 Loss: 0.01799515344593862 Corrects: 33302\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 5810, Loss 0.02075210213661194\n",
            "Train step - Step 5820, Loss 0.020285386592149734\n",
            "Train step - Step 5830, Loss 0.01479320414364338\n",
            "Train step - Step 5840, Loss 0.017503604292869568\n",
            "Train step - Step 5850, Loss 0.015820588916540146\n",
            "Train step - Step 5860, Loss 0.018609557300806046\n",
            "Train step - Step 5870, Loss 0.01641031913459301\n",
            "Train step - Step 5880, Loss 0.018485156819224358\n",
            "Train step - Step 5890, Loss 0.018014153465628624\n",
            "Train step - Step 5900, Loss 0.01844303496181965\n",
            "Train step - Step 5910, Loss 0.01626615971326828\n",
            "Train step - Step 5920, Loss 0.017926974222064018\n",
            "Train step - Step 5930, Loss 0.015563773922622204\n",
            "Train step - Step 5940, Loss 0.017894195392727852\n",
            "Train step - Step 5950, Loss 0.01870686747133732\n",
            "Train step - Step 5960, Loss 0.02132147178053856\n",
            "Train step - Step 5970, Loss 0.016179431229829788\n",
            "Train step - Step 5980, Loss 0.017493871971964836\n",
            "Train step - Step 5990, Loss 0.019023489207029343\n",
            "Train step - Step 6000, Loss 0.01750745251774788\n",
            "Train step - Step 6010, Loss 0.020223915576934814\n",
            "Train step - Step 6020, Loss 0.016487203538417816\n",
            "Train step - Step 6030, Loss 0.020441142842173576\n",
            "Train step - Step 6040, Loss 0.01979559287428856\n",
            "Train step - Step 6050, Loss 0.01788182184100151\n",
            "Train step - Step 6060, Loss 0.01999712362885475\n",
            "Train step - Step 6070, Loss 0.01806735061109066\n",
            "Train step - Step 6080, Loss 0.019713498651981354\n",
            "Train step - Step 6090, Loss 0.0186445415019989\n",
            "Train step - Step 6100, Loss 0.017452197149395943\n",
            "Train step - Step 6110, Loss 0.017063211649656296\n",
            "Train step - Step 6120, Loss 0.01816120557487011\n",
            "Train step - Step 6130, Loss 0.017203496769070625\n",
            "Train step - Step 6140, Loss 0.015966512262821198\n",
            "Train step - Step 6150, Loss 0.016964329406619072\n",
            "Train step - Step 6160, Loss 0.01536513026803732\n",
            "Train step - Step 6170, Loss 0.017742101103067398\n",
            "Train step - Step 6180, Loss 0.01803799904882908\n",
            "Train step - Step 6190, Loss 0.01724165491759777\n",
            "Train epoch - Accuracy: 0.6728484848484848 Loss: 0.0180018691688475 Corrects: 33306\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 6200, Loss 0.01724112406373024\n",
            "Train step - Step 6210, Loss 0.02116411179304123\n",
            "Train step - Step 6220, Loss 0.01919519156217575\n",
            "Train step - Step 6230, Loss 0.019087087363004684\n",
            "Train step - Step 6240, Loss 0.019997436553239822\n",
            "Train step - Step 6250, Loss 0.02027251198887825\n",
            "Train step - Step 6260, Loss 0.017964303493499756\n",
            "Train step - Step 6270, Loss 0.018589122220873833\n",
            "Train step - Step 6280, Loss 0.017259133979678154\n",
            "Train step - Step 6290, Loss 0.019119255244731903\n",
            "Train step - Step 6300, Loss 0.019491123035550117\n",
            "Train step - Step 6310, Loss 0.018389057368040085\n",
            "Train step - Step 6320, Loss 0.01875084638595581\n",
            "Train step - Step 6330, Loss 0.016180669888854027\n",
            "Train step - Step 6340, Loss 0.016681648790836334\n",
            "Train step - Step 6350, Loss 0.018257886171340942\n",
            "Train step - Step 6360, Loss 0.019207878038287163\n",
            "Train step - Step 6370, Loss 0.020750373601913452\n",
            "Train step - Step 6380, Loss 0.016285426914691925\n",
            "Train step - Step 6390, Loss 0.01869245059788227\n",
            "Train step - Step 6400, Loss 0.017283307388424873\n",
            "Train step - Step 6410, Loss 0.019214564934372902\n",
            "Train step - Step 6420, Loss 0.019175827503204346\n",
            "Train step - Step 6430, Loss 0.016301659867167473\n",
            "Train step - Step 6440, Loss 0.01870662160217762\n",
            "Train step - Step 6450, Loss 0.016177190467715263\n",
            "Train step - Step 6460, Loss 0.019145211204886436\n",
            "Train step - Step 6470, Loss 0.01820206083357334\n",
            "Train step - Step 6480, Loss 0.017938600853085518\n",
            "Train step - Step 6490, Loss 0.02051682397723198\n",
            "Train step - Step 6500, Loss 0.018764423206448555\n",
            "Train step - Step 6510, Loss 0.019171414896845818\n",
            "Train step - Step 6520, Loss 0.017561888322234154\n",
            "Train step - Step 6530, Loss 0.01806037314236164\n",
            "Train step - Step 6540, Loss 0.01673719845712185\n",
            "Train step - Step 6550, Loss 0.018434902653098106\n",
            "Train step - Step 6560, Loss 0.015287178568542004\n",
            "Train step - Step 6570, Loss 0.019722959026694298\n",
            "Train epoch - Accuracy: 0.675939393939394 Loss: 0.01793376297165047 Corrects: 33459\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 6580, Loss 0.015393695794045925\n",
            "Train step - Step 6590, Loss 0.01817898638546467\n",
            "Train step - Step 6600, Loss 0.0171603262424469\n",
            "Train step - Step 6610, Loss 0.015314915217459202\n",
            "Train step - Step 6620, Loss 0.01761673577129841\n",
            "Train step - Step 6630, Loss 0.018514445051550865\n",
            "Train step - Step 6640, Loss 0.018382251262664795\n",
            "Train step - Step 6650, Loss 0.019403042271733284\n",
            "Train step - Step 6660, Loss 0.019590862095355988\n",
            "Train step - Step 6670, Loss 0.015916764736175537\n",
            "Train step - Step 6680, Loss 0.017308790236711502\n",
            "Train step - Step 6690, Loss 0.015977827832102776\n",
            "Train step - Step 6700, Loss 0.015863077715039253\n",
            "Train step - Step 6710, Loss 0.018510522320866585\n",
            "Train step - Step 6720, Loss 0.01838066056370735\n",
            "Train step - Step 6730, Loss 0.019180433824658394\n",
            "Train step - Step 6740, Loss 0.01975979469716549\n",
            "Train step - Step 6750, Loss 0.018751274794340134\n",
            "Train step - Step 6760, Loss 0.017545608803629875\n",
            "Train step - Step 6770, Loss 0.01774166151881218\n",
            "Train step - Step 6780, Loss 0.01637418381869793\n",
            "Train step - Step 6790, Loss 0.01804022118449211\n",
            "Train step - Step 6800, Loss 0.014501008205115795\n",
            "Train step - Step 6810, Loss 0.016884373500943184\n",
            "Train step - Step 6820, Loss 0.02008114755153656\n",
            "Train step - Step 6830, Loss 0.01755567267537117\n",
            "Train step - Step 6840, Loss 0.02057456411421299\n",
            "Train step - Step 6850, Loss 0.021000592038035393\n",
            "Train step - Step 6860, Loss 0.018776115030050278\n",
            "Train step - Step 6870, Loss 0.01859533227980137\n",
            "Train step - Step 6880, Loss 0.014615995809435844\n",
            "Train step - Step 6890, Loss 0.02285647764801979\n",
            "Train step - Step 6900, Loss 0.020199622958898544\n",
            "Train step - Step 6910, Loss 0.019628383219242096\n",
            "Train step - Step 6920, Loss 0.019487831741571426\n",
            "Train step - Step 6930, Loss 0.01812160760164261\n",
            "Train step - Step 6940, Loss 0.017759138718247414\n",
            "Train step - Step 6950, Loss 0.019795138388872147\n",
            "Train step - Step 6960, Loss 0.014801876619458199\n",
            "Train epoch - Accuracy: 0.676040404040404 Loss: 0.01789717188161431 Corrects: 33464\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 6970, Loss 0.019294563680887222\n",
            "Train step - Step 6980, Loss 0.016453882679343224\n",
            "Train step - Step 6990, Loss 0.020039081573486328\n",
            "Train step - Step 7000, Loss 0.015383283607661724\n",
            "Train step - Step 7010, Loss 0.01724061369895935\n",
            "Train step - Step 7020, Loss 0.01773860864341259\n",
            "Train step - Step 7030, Loss 0.020643476396799088\n",
            "Train step - Step 7040, Loss 0.019896889105439186\n",
            "Train step - Step 7050, Loss 0.016656504943966866\n",
            "Train step - Step 7060, Loss 0.019137676805257797\n",
            "Train step - Step 7070, Loss 0.018059784546494484\n",
            "Train step - Step 7080, Loss 0.018207764253020287\n",
            "Train step - Step 7090, Loss 0.014732434414327145\n",
            "Train step - Step 7100, Loss 0.018411410972476006\n",
            "Train step - Step 7110, Loss 0.017484625801444054\n",
            "Train step - Step 7120, Loss 0.018666917458176613\n",
            "Train step - Step 7130, Loss 0.01857173442840576\n",
            "Train step - Step 7140, Loss 0.01689128763973713\n",
            "Train step - Step 7150, Loss 0.01753389462828636\n",
            "Train step - Step 7160, Loss 0.018839849159121513\n",
            "Train step - Step 7170, Loss 0.01795370690524578\n",
            "Train step - Step 7180, Loss 0.017838187515735626\n",
            "Train step - Step 7190, Loss 0.01726432517170906\n",
            "Train step - Step 7200, Loss 0.016061704605817795\n",
            "Train step - Step 7210, Loss 0.01864614710211754\n",
            "Train step - Step 7220, Loss 0.021624334156513214\n",
            "Train step - Step 7230, Loss 0.016549263149499893\n",
            "Train step - Step 7240, Loss 0.017375189810991287\n",
            "Train step - Step 7250, Loss 0.016575394198298454\n",
            "Train step - Step 7260, Loss 0.01825379580259323\n",
            "Train step - Step 7270, Loss 0.022534344345331192\n",
            "Train step - Step 7280, Loss 0.020825181156396866\n",
            "Train step - Step 7290, Loss 0.019976185634732246\n",
            "Train step - Step 7300, Loss 0.017376018688082695\n",
            "Train step - Step 7310, Loss 0.017782654613256454\n",
            "Train step - Step 7320, Loss 0.016654811799526215\n",
            "Train step - Step 7330, Loss 0.0213591568171978\n",
            "Train step - Step 7340, Loss 0.016557691618800163\n",
            "Train step - Step 7350, Loss 0.015383359044790268\n",
            "Train epoch - Accuracy: 0.6734949494949495 Loss: 0.018120786539231888 Corrects: 33338\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 7360, Loss 0.017761288210749626\n",
            "Train step - Step 7370, Loss 0.01677350141108036\n",
            "Train step - Step 7380, Loss 0.01728239096701145\n",
            "Train step - Step 7390, Loss 0.018412645906209946\n",
            "Train step - Step 7400, Loss 0.016207871958613396\n",
            "Train step - Step 7410, Loss 0.0185590460896492\n",
            "Train step - Step 7420, Loss 0.017807230353355408\n",
            "Train step - Step 7430, Loss 0.01971292868256569\n",
            "Train step - Step 7440, Loss 0.016391457989811897\n",
            "Train step - Step 7450, Loss 0.018609071150422096\n",
            "Train step - Step 7460, Loss 0.017833000048995018\n",
            "Train step - Step 7470, Loss 0.021601468324661255\n",
            "Train step - Step 7480, Loss 0.018339820206165314\n",
            "Train step - Step 7490, Loss 0.019049637019634247\n",
            "Train step - Step 7500, Loss 0.018813645467162132\n",
            "Train step - Step 7510, Loss 0.018184445798397064\n",
            "Train step - Step 7520, Loss 0.018600966781377792\n",
            "Train step - Step 7530, Loss 0.01765928417444229\n",
            "Train step - Step 7540, Loss 0.0162082239985466\n",
            "Train step - Step 7550, Loss 0.016021886840462685\n",
            "Train step - Step 7560, Loss 0.01912454143166542\n",
            "Train step - Step 7570, Loss 0.01808614656329155\n",
            "Train step - Step 7580, Loss 0.01899365335702896\n",
            "Train step - Step 7590, Loss 0.017569661140441895\n",
            "Train step - Step 7600, Loss 0.01668323576450348\n",
            "Train step - Step 7610, Loss 0.019567275419831276\n",
            "Train step - Step 7620, Loss 0.020570244640111923\n",
            "Train step - Step 7630, Loss 0.019445547834038734\n",
            "Train step - Step 7640, Loss 0.01676676794886589\n",
            "Train step - Step 7650, Loss 0.018737096339464188\n",
            "Train step - Step 7660, Loss 0.01810356229543686\n",
            "Train step - Step 7670, Loss 0.019833402708172798\n",
            "Train step - Step 7680, Loss 0.01985401101410389\n",
            "Train step - Step 7690, Loss 0.019035685807466507\n",
            "Train step - Step 7700, Loss 0.01754007302224636\n",
            "Train step - Step 7710, Loss 0.01910795085132122\n",
            "Train step - Step 7720, Loss 0.015049135312438011\n",
            "Train step - Step 7730, Loss 0.018877433612942696\n",
            "Train epoch - Accuracy: 0.6795555555555556 Loss: 0.017772661944380916 Corrects: 33638\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 7740, Loss 0.01722630485892296\n",
            "Train step - Step 7750, Loss 0.01864989660680294\n",
            "Train step - Step 7760, Loss 0.015904726460576057\n",
            "Train step - Step 7770, Loss 0.014431105926632881\n",
            "Train step - Step 7780, Loss 0.01846238784492016\n",
            "Train step - Step 7790, Loss 0.015545978210866451\n",
            "Train step - Step 7800, Loss 0.01959274522960186\n",
            "Train step - Step 7810, Loss 0.015295712277293205\n",
            "Train step - Step 7820, Loss 0.018133215606212616\n",
            "Train step - Step 7830, Loss 0.014364355243742466\n",
            "Train step - Step 7840, Loss 0.01852470636367798\n",
            "Train step - Step 7850, Loss 0.01645371876657009\n",
            "Train step - Step 7860, Loss 0.017560066655278206\n",
            "Train step - Step 7870, Loss 0.01771133579313755\n",
            "Train step - Step 7880, Loss 0.015422320924699306\n",
            "Train step - Step 7890, Loss 0.01705292984843254\n",
            "Train step - Step 7900, Loss 0.019043540582060814\n",
            "Train step - Step 7910, Loss 0.01589752547442913\n",
            "Train step - Step 7920, Loss 0.01672888733446598\n",
            "Train step - Step 7930, Loss 0.016380202025175095\n",
            "Train step - Step 7940, Loss 0.019400957971811295\n",
            "Train step - Step 7950, Loss 0.01913180761039257\n",
            "Train step - Step 7960, Loss 0.019361587241292\n",
            "Train step - Step 7970, Loss 0.018217362463474274\n",
            "Train step - Step 7980, Loss 0.017432985827326775\n",
            "Train step - Step 7990, Loss 0.018610209226608276\n",
            "Train step - Step 8000, Loss 0.02040504664182663\n",
            "Train step - Step 8010, Loss 0.016095247119665146\n",
            "Train step - Step 8020, Loss 0.017577877268195152\n",
            "Train step - Step 8030, Loss 0.019192060455679893\n",
            "Train step - Step 8040, Loss 0.019231680780649185\n",
            "Train step - Step 8050, Loss 0.015713417902588844\n",
            "Train step - Step 8060, Loss 0.019572502002120018\n",
            "Train step - Step 8070, Loss 0.02223154529929161\n",
            "Train step - Step 8080, Loss 0.01621892862021923\n",
            "Train step - Step 8090, Loss 0.01863056793808937\n",
            "Train step - Step 8100, Loss 0.019380437210202217\n",
            "Train step - Step 8110, Loss 0.017713891342282295\n",
            "Train step - Step 8120, Loss 0.017430616542696953\n",
            "Train epoch - Accuracy: 0.6753939393939394 Loss: 0.017976985475782192 Corrects: 33432\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 8130, Loss 0.01962266117334366\n",
            "Train step - Step 8140, Loss 0.018107911571860313\n",
            "Train step - Step 8150, Loss 0.017315367236733437\n",
            "Train step - Step 8160, Loss 0.016504887491464615\n",
            "Train step - Step 8170, Loss 0.015194064937531948\n",
            "Train step - Step 8180, Loss 0.017336362972855568\n",
            "Train step - Step 8190, Loss 0.0192924402654171\n",
            "Train step - Step 8200, Loss 0.017741452902555466\n",
            "Train step - Step 8210, Loss 0.017065562307834625\n",
            "Train step - Step 8220, Loss 0.013879062607884407\n",
            "Train step - Step 8230, Loss 0.02051018923521042\n",
            "Train step - Step 8240, Loss 0.021316932514309883\n",
            "Train step - Step 8250, Loss 0.01883644610643387\n",
            "Train step - Step 8260, Loss 0.018969111144542694\n",
            "Train step - Step 8270, Loss 0.016737064346671104\n",
            "Train step - Step 8280, Loss 0.01688881404697895\n",
            "Train step - Step 8290, Loss 0.018711695447564125\n",
            "Train step - Step 8300, Loss 0.018110988661646843\n",
            "Train step - Step 8310, Loss 0.019413193687796593\n",
            "Train step - Step 8320, Loss 0.018294792622327805\n",
            "Train step - Step 8330, Loss 0.019844939932227135\n",
            "Train step - Step 8340, Loss 0.018585359677672386\n",
            "Train step - Step 8350, Loss 0.016553141176700592\n",
            "Train step - Step 8360, Loss 0.01797492802143097\n",
            "Train step - Step 8370, Loss 0.019028879702091217\n",
            "Train step - Step 8380, Loss 0.018045267090201378\n",
            "Train step - Step 8390, Loss 0.01749894581735134\n",
            "Train step - Step 8400, Loss 0.016872582957148552\n",
            "Train step - Step 8410, Loss 0.016611373052001\n",
            "Train step - Step 8420, Loss 0.01717963255941868\n",
            "Train step - Step 8430, Loss 0.018797215074300766\n",
            "Train step - Step 8440, Loss 0.017117870971560478\n",
            "Train step - Step 8450, Loss 0.0171937495470047\n",
            "Train step - Step 8460, Loss 0.01713130623102188\n",
            "Train step - Step 8470, Loss 0.01840290054678917\n",
            "Train step - Step 8480, Loss 0.018810173496603966\n",
            "Train step - Step 8490, Loss 0.01729855127632618\n",
            "Train step - Step 8500, Loss 0.020417770370841026\n",
            "Train step - Step 8510, Loss 0.017229454591870308\n",
            "Train epoch - Accuracy: 0.6750101010101011 Loss: 0.017884475161631903 Corrects: 33413\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 8520, Loss 0.016739435493946075\n",
            "Train step - Step 8530, Loss 0.015696793794631958\n",
            "Train step - Step 8540, Loss 0.018714718520641327\n",
            "Train step - Step 8550, Loss 0.018298404291272163\n",
            "Train step - Step 8560, Loss 0.016506079584360123\n",
            "Train step - Step 8570, Loss 0.015214921906590462\n",
            "Train step - Step 8580, Loss 0.019674234092235565\n",
            "Train step - Step 8590, Loss 0.017144404351711273\n",
            "Train step - Step 8600, Loss 0.01503843255341053\n",
            "Train step - Step 8610, Loss 0.01729639060795307\n",
            "Train step - Step 8620, Loss 0.015435627661645412\n",
            "Train step - Step 8630, Loss 0.014705030247569084\n",
            "Train step - Step 8640, Loss 0.01599782146513462\n",
            "Train step - Step 8650, Loss 0.019231488928198814\n",
            "Train step - Step 8660, Loss 0.0159841850399971\n",
            "Train step - Step 8670, Loss 0.01791207678616047\n",
            "Train step - Step 8680, Loss 0.018263665959239006\n",
            "Train step - Step 8690, Loss 0.020306212827563286\n",
            "Train step - Step 8700, Loss 0.01764191873371601\n",
            "Train step - Step 8710, Loss 0.017390785738825798\n",
            "Train step - Step 8720, Loss 0.01926615834236145\n",
            "Train step - Step 8730, Loss 0.021521707996726036\n",
            "Train step - Step 8740, Loss 0.01508394442498684\n",
            "Train step - Step 8750, Loss 0.019519714638590813\n",
            "Train step - Step 8760, Loss 0.020647376775741577\n",
            "Train step - Step 8770, Loss 0.017725035548210144\n",
            "Train step - Step 8780, Loss 0.016559839248657227\n",
            "Train step - Step 8790, Loss 0.018154412508010864\n",
            "Train step - Step 8800, Loss 0.02035103552043438\n",
            "Train step - Step 8810, Loss 0.01549104880541563\n",
            "Train step - Step 8820, Loss 0.015707168728113174\n",
            "Train step - Step 8830, Loss 0.01672343537211418\n",
            "Train step - Step 8840, Loss 0.021210815757513046\n",
            "Train step - Step 8850, Loss 0.01805707812309265\n",
            "Train step - Step 8860, Loss 0.015634572133421898\n",
            "Train step - Step 8870, Loss 0.016782065853476524\n",
            "Train step - Step 8880, Loss 0.0181580763310194\n",
            "Train step - Step 8890, Loss 0.01830955035984516\n",
            "Train step - Step 8900, Loss 0.01945943385362625\n",
            "Train epoch - Accuracy: 0.6786262626262626 Loss: 0.017770471878124007 Corrects: 33592\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 8910, Loss 0.01911615952849388\n",
            "Train step - Step 8920, Loss 0.01747860386967659\n",
            "Train step - Step 8930, Loss 0.01817835494875908\n",
            "Train step - Step 8940, Loss 0.017405375838279724\n",
            "Train step - Step 8950, Loss 0.014727277681231499\n",
            "Train step - Step 8960, Loss 0.015824761241674423\n",
            "Train step - Step 8970, Loss 0.01689767651259899\n",
            "Train step - Step 8980, Loss 0.014426087960600853\n",
            "Train step - Step 8990, Loss 0.014335991814732552\n",
            "Train step - Step 9000, Loss 0.01849822700023651\n",
            "Train step - Step 9010, Loss 0.01733430102467537\n",
            "Train step - Step 9020, Loss 0.01791645959019661\n",
            "Train step - Step 9030, Loss 0.0197914969176054\n",
            "Train step - Step 9040, Loss 0.0205799862742424\n",
            "Train step - Step 9050, Loss 0.019863968715071678\n",
            "Train step - Step 9060, Loss 0.017941730096936226\n",
            "Train step - Step 9070, Loss 0.017972806468605995\n",
            "Train step - Step 9080, Loss 0.01659960299730301\n",
            "Train step - Step 9090, Loss 0.01660744473338127\n",
            "Train step - Step 9100, Loss 0.016358939930796623\n",
            "Train step - Step 9110, Loss 0.016649307683110237\n",
            "Train step - Step 9120, Loss 0.019969983026385307\n",
            "Train step - Step 9130, Loss 0.01713218167424202\n",
            "Train step - Step 9140, Loss 0.019334932789206505\n",
            "Train step - Step 9150, Loss 0.021831097081303596\n",
            "Train step - Step 9160, Loss 0.013848824426531792\n",
            "Train step - Step 9170, Loss 0.01675446704030037\n",
            "Train step - Step 9180, Loss 0.01914035901427269\n",
            "Train step - Step 9190, Loss 0.018019769340753555\n",
            "Train step - Step 9200, Loss 0.018944939598441124\n",
            "Train step - Step 9210, Loss 0.019273092970252037\n",
            "Train step - Step 9220, Loss 0.01931799203157425\n",
            "Train step - Step 9230, Loss 0.020362747833132744\n",
            "Train step - Step 9240, Loss 0.018454061821103096\n",
            "Train step - Step 9250, Loss 0.01758415251970291\n",
            "Train step - Step 9260, Loss 0.013590008951723576\n",
            "Train step - Step 9270, Loss 0.021251432597637177\n",
            "Train step - Step 9280, Loss 0.016420643776655197\n",
            "Train epoch - Accuracy: 0.6741414141414142 Loss: 0.017936445626345547 Corrects: 33370\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 9290, Loss 0.017726069316267967\n",
            "Train step - Step 9300, Loss 0.016155777499079704\n",
            "Train step - Step 9310, Loss 0.016948506236076355\n",
            "Train step - Step 9320, Loss 0.017107853665947914\n",
            "Train step - Step 9330, Loss 0.019108349457383156\n",
            "Train step - Step 9340, Loss 0.019056525081396103\n",
            "Train step - Step 9350, Loss 0.017337888479232788\n",
            "Train step - Step 9360, Loss 0.016859538853168488\n",
            "Train step - Step 9370, Loss 0.01620062068104744\n",
            "Train step - Step 9380, Loss 0.017420737072825432\n",
            "Train step - Step 9390, Loss 0.017218943685293198\n",
            "Train step - Step 9400, Loss 0.017440402880311012\n",
            "Train step - Step 9410, Loss 0.016379904001951218\n",
            "Train step - Step 9420, Loss 0.015329565852880478\n",
            "Train step - Step 9430, Loss 0.021792547777295113\n",
            "Train step - Step 9440, Loss 0.015771280974149704\n",
            "Train step - Step 9450, Loss 0.016513943672180176\n",
            "Train step - Step 9460, Loss 0.018365172669291496\n",
            "Train step - Step 9470, Loss 0.01701316051185131\n",
            "Train step - Step 9480, Loss 0.019420446828007698\n",
            "Train step - Step 9490, Loss 0.020562557503581047\n",
            "Train step - Step 9500, Loss 0.015979601070284843\n",
            "Train step - Step 9510, Loss 0.01941516622900963\n",
            "Train step - Step 9520, Loss 0.016351060941815376\n",
            "Train step - Step 9530, Loss 0.01752478815615177\n",
            "Train step - Step 9540, Loss 0.019944211468100548\n",
            "Train step - Step 9550, Loss 0.017747830599546432\n",
            "Train step - Step 9560, Loss 0.018232839182019234\n",
            "Train step - Step 9570, Loss 0.01736673153936863\n",
            "Train step - Step 9580, Loss 0.021867353469133377\n",
            "Train step - Step 9590, Loss 0.017966337502002716\n",
            "Train step - Step 9600, Loss 0.01739102602005005\n",
            "Train step - Step 9610, Loss 0.019079480320215225\n",
            "Train step - Step 9620, Loss 0.01644294150173664\n",
            "Train step - Step 9630, Loss 0.018848581239581108\n",
            "Train step - Step 9640, Loss 0.01738729141652584\n",
            "Train step - Step 9650, Loss 0.01554816123098135\n",
            "Train step - Step 9660, Loss 0.017661962658166885\n",
            "Train step - Step 9670, Loss 0.016673998907208443\n",
            "Train epoch - Accuracy: 0.6758383838383838 Loss: 0.017872849954198106 Corrects: 33454\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 9680, Loss 0.01810958981513977\n",
            "Train step - Step 9690, Loss 0.01733279600739479\n",
            "Train step - Step 9700, Loss 0.01829867623746395\n",
            "Train step - Step 9710, Loss 0.017785653471946716\n",
            "Train step - Step 9720, Loss 0.01507857721298933\n",
            "Train step - Step 9730, Loss 0.01949414238333702\n",
            "Train step - Step 9740, Loss 0.018003111705183983\n",
            "Train step - Step 9750, Loss 0.016524814069271088\n",
            "Train step - Step 9760, Loss 0.0194244347512722\n",
            "Train step - Step 9770, Loss 0.01633381098508835\n",
            "Train step - Step 9780, Loss 0.017078092321753502\n",
            "Train step - Step 9790, Loss 0.015135297551751137\n",
            "Train step - Step 9800, Loss 0.019220443442463875\n",
            "Train step - Step 9810, Loss 0.016300499439239502\n",
            "Train step - Step 9820, Loss 0.01798747293651104\n",
            "Train step - Step 9830, Loss 0.01699751988053322\n",
            "Train step - Step 9840, Loss 0.017284683883190155\n",
            "Train step - Step 9850, Loss 0.02012820728123188\n",
            "Train step - Step 9860, Loss 0.02030348777770996\n",
            "Train step - Step 9870, Loss 0.017448928207159042\n",
            "Train step - Step 9880, Loss 0.021360255777835846\n",
            "Train step - Step 9890, Loss 0.020215418189764023\n",
            "Train step - Step 9900, Loss 0.016463646665215492\n",
            "Train step - Step 9910, Loss 0.01738743670284748\n",
            "Train step - Step 9920, Loss 0.016173619776964188\n",
            "Train step - Step 9930, Loss 0.016396377235651016\n",
            "Train step - Step 9940, Loss 0.020116114988923073\n",
            "Train step - Step 9950, Loss 0.01637045294046402\n",
            "Train step - Step 9960, Loss 0.015762267634272575\n",
            "Train step - Step 9970, Loss 0.01510713528841734\n",
            "Train step - Step 9980, Loss 0.01879188045859337\n",
            "Train step - Step 9990, Loss 0.016370460391044617\n",
            "Train step - Step 10000, Loss 0.018320243805646896\n",
            "Train step - Step 10010, Loss 0.018578000366687775\n",
            "Train step - Step 10020, Loss 0.019005056470632553\n",
            "Train step - Step 10030, Loss 0.02043953165411949\n",
            "Train step - Step 10040, Loss 0.017485346645116806\n",
            "Train step - Step 10050, Loss 0.017872218042612076\n",
            "Train step - Step 10060, Loss 0.016098469495773315\n",
            "Train epoch - Accuracy: 0.6771919191919192 Loss: 0.01787427299115995 Corrects: 33521\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 10070, Loss 0.018910333514213562\n",
            "Train step - Step 10080, Loss 0.017459707334637642\n",
            "Train step - Step 10090, Loss 0.02159779891371727\n",
            "Train step - Step 10100, Loss 0.01916942000389099\n",
            "Train step - Step 10110, Loss 0.015499605797231197\n",
            "Train step - Step 10120, Loss 0.020203284919261932\n",
            "Train step - Step 10130, Loss 0.018092503771185875\n",
            "Train step - Step 10140, Loss 0.018828874453902245\n",
            "Train step - Step 10150, Loss 0.014909464865922928\n",
            "Train step - Step 10160, Loss 0.02026740461587906\n",
            "Train step - Step 10170, Loss 0.016653655096888542\n",
            "Train step - Step 10180, Loss 0.016283893957734108\n",
            "Train step - Step 10190, Loss 0.019114086404442787\n",
            "Train step - Step 10200, Loss 0.017432911321520805\n",
            "Train step - Step 10210, Loss 0.020091144368052483\n",
            "Train step - Step 10220, Loss 0.018588950857520103\n",
            "Train step - Step 10230, Loss 0.020742418244481087\n",
            "Train step - Step 10240, Loss 0.017285000532865524\n",
            "Train step - Step 10250, Loss 0.018415356054902077\n",
            "Train step - Step 10260, Loss 0.01953713223338127\n",
            "Train step - Step 10270, Loss 0.015739891678094864\n",
            "Train step - Step 10280, Loss 0.0181502103805542\n",
            "Train step - Step 10290, Loss 0.01833394542336464\n",
            "Train step - Step 10300, Loss 0.017920566722750664\n",
            "Train step - Step 10310, Loss 0.01800774596631527\n",
            "Train step - Step 10320, Loss 0.01776641607284546\n",
            "Train step - Step 10330, Loss 0.018506871536374092\n",
            "Train step - Step 10340, Loss 0.015128077939152718\n",
            "Train step - Step 10350, Loss 0.015615957789123058\n",
            "Train step - Step 10360, Loss 0.018785299733281136\n",
            "Train step - Step 10370, Loss 0.015167275443673134\n",
            "Train step - Step 10380, Loss 0.019146360456943512\n",
            "Train step - Step 10390, Loss 0.020898398011922836\n",
            "Train step - Step 10400, Loss 0.02049551159143448\n",
            "Train step - Step 10410, Loss 0.01654454879462719\n",
            "Train step - Step 10420, Loss 0.017016559839248657\n",
            "Train step - Step 10430, Loss 0.024158501997590065\n",
            "Train step - Step 10440, Loss 0.01775669865310192\n",
            "Train epoch - Accuracy: 0.6775959595959596 Loss: 0.01789584883355131 Corrects: 33541\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 10450, Loss 0.017065320163965225\n",
            "Train step - Step 10460, Loss 0.017150115221738815\n",
            "Train step - Step 10470, Loss 0.019923748448491096\n",
            "Train step - Step 10480, Loss 0.016182059422135353\n",
            "Train step - Step 10490, Loss 0.017767827957868576\n",
            "Train step - Step 10500, Loss 0.019192975014448166\n",
            "Train step - Step 10510, Loss 0.01768900267779827\n",
            "Train step - Step 10520, Loss 0.017306428402662277\n",
            "Train step - Step 10530, Loss 0.017008069902658463\n",
            "Train step - Step 10540, Loss 0.016851214691996574\n",
            "Train step - Step 10550, Loss 0.017528977245092392\n",
            "Train step - Step 10560, Loss 0.017557818442583084\n",
            "Train step - Step 10570, Loss 0.017669659107923508\n",
            "Train step - Step 10580, Loss 0.01585453562438488\n",
            "Train step - Step 10590, Loss 0.015688307583332062\n",
            "Train step - Step 10600, Loss 0.018198836594820023\n",
            "Train step - Step 10610, Loss 0.015302924439311028\n",
            "Train step - Step 10620, Loss 0.0185557771474123\n",
            "Train step - Step 10630, Loss 0.020879140123724937\n",
            "Train step - Step 10640, Loss 0.017323730513453484\n",
            "Train step - Step 10650, Loss 0.017609359696507454\n",
            "Train step - Step 10660, Loss 0.019232388585805893\n",
            "Train step - Step 10670, Loss 0.016291258856654167\n",
            "Train step - Step 10680, Loss 0.016847997903823853\n",
            "Train step - Step 10690, Loss 0.0197624359279871\n",
            "Train step - Step 10700, Loss 0.020887009799480438\n",
            "Train step - Step 10710, Loss 0.019075725227594376\n",
            "Train step - Step 10720, Loss 0.018554354086518288\n",
            "Train step - Step 10730, Loss 0.018349457532167435\n",
            "Train step - Step 10740, Loss 0.02220684476196766\n",
            "Train step - Step 10750, Loss 0.01694582961499691\n",
            "Train step - Step 10760, Loss 0.019268542528152466\n",
            "Train step - Step 10770, Loss 0.017652340233325958\n",
            "Train step - Step 10780, Loss 0.021122030913829803\n",
            "Train step - Step 10790, Loss 0.01816485822200775\n",
            "Train step - Step 10800, Loss 0.017111552879214287\n",
            "Train step - Step 10810, Loss 0.017117099836468697\n",
            "Train step - Step 10820, Loss 0.019024329259991646\n",
            "Train step - Step 10830, Loss 0.01855701394379139\n",
            "Train epoch - Accuracy: 0.6794949494949495 Loss: 0.017707317646254193 Corrects: 33635\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 10840, Loss 0.01953348144888878\n",
            "Train step - Step 10850, Loss 0.017546316608786583\n",
            "Train step - Step 10860, Loss 0.017095640301704407\n",
            "Train step - Step 10870, Loss 0.0177691038697958\n",
            "Train step - Step 10880, Loss 0.01650666445493698\n",
            "Train step - Step 10890, Loss 0.017372185364365578\n",
            "Train step - Step 10900, Loss 0.018279943615198135\n",
            "Train step - Step 10910, Loss 0.017459150403738022\n",
            "Train step - Step 10920, Loss 0.01708826795220375\n",
            "Train step - Step 10930, Loss 0.018351580947637558\n",
            "Train step - Step 10940, Loss 0.022383913397789\n",
            "Train step - Step 10950, Loss 0.018322719261050224\n",
            "Train step - Step 10960, Loss 0.01694752834737301\n",
            "Train step - Step 10970, Loss 0.018616288900375366\n",
            "Train step - Step 10980, Loss 0.018505685031414032\n",
            "Train step - Step 10990, Loss 0.018920518457889557\n",
            "Train step - Step 11000, Loss 0.016611967235803604\n",
            "Train step - Step 11010, Loss 0.017027810215950012\n",
            "Train step - Step 11020, Loss 0.019886130467057228\n",
            "Train step - Step 11030, Loss 0.018660545349121094\n",
            "Train step - Step 11040, Loss 0.0224415585398674\n",
            "Train step - Step 11050, Loss 0.01981164887547493\n",
            "Train step - Step 11060, Loss 0.015984954312443733\n",
            "Train step - Step 11070, Loss 0.02051578089594841\n",
            "Train step - Step 11080, Loss 0.01783040352165699\n",
            "Train step - Step 11090, Loss 0.018736276775598526\n",
            "Train step - Step 11100, Loss 0.017215033993124962\n",
            "Train step - Step 11110, Loss 0.016343822702765465\n",
            "Train step - Step 11120, Loss 0.01950681209564209\n",
            "Train step - Step 11130, Loss 0.018084364011883736\n",
            "Train step - Step 11140, Loss 0.017133744433522224\n",
            "Train step - Step 11150, Loss 0.016829216852784157\n",
            "Train step - Step 11160, Loss 0.01831451989710331\n",
            "Train step - Step 11170, Loss 0.019399693235754967\n",
            "Train step - Step 11180, Loss 0.02189861796796322\n",
            "Train step - Step 11190, Loss 0.02124156430363655\n",
            "Train step - Step 11200, Loss 0.018540941178798676\n",
            "Train step - Step 11210, Loss 0.01744896173477173\n",
            "Train step - Step 11220, Loss 0.019435232505202293\n",
            "Train epoch - Accuracy: 0.6797575757575758 Loss: 0.017752566664056346 Corrects: 33648\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 11230, Loss 0.016307847574353218\n",
            "Train step - Step 11240, Loss 0.016175685450434685\n",
            "Train step - Step 11250, Loss 0.017129242420196533\n",
            "Train step - Step 11260, Loss 0.016891105100512505\n",
            "Train step - Step 11270, Loss 0.017630968242883682\n",
            "Train step - Step 11280, Loss 0.017271416261792183\n",
            "Train step - Step 11290, Loss 0.019499342888593674\n",
            "Train step - Step 11300, Loss 0.017490483820438385\n",
            "Train step - Step 11310, Loss 0.016166118904948235\n",
            "Train step - Step 11320, Loss 0.015592854470014572\n",
            "Train step - Step 11330, Loss 0.020071638748049736\n",
            "Train step - Step 11340, Loss 0.016719860956072807\n",
            "Train step - Step 11350, Loss 0.02037152647972107\n",
            "Train step - Step 11360, Loss 0.0200045108795166\n",
            "Train step - Step 11370, Loss 0.019575471058487892\n",
            "Train step - Step 11380, Loss 0.018231553956866264\n",
            "Train step - Step 11390, Loss 0.014942383393645287\n",
            "Train step - Step 11400, Loss 0.02092011459171772\n",
            "Train step - Step 11410, Loss 0.015046341344714165\n",
            "Train step - Step 11420, Loss 0.018020646646618843\n",
            "Train step - Step 11430, Loss 0.017532281577587128\n",
            "Train step - Step 11440, Loss 0.019862446933984756\n",
            "Train step - Step 11450, Loss 0.017598718404769897\n",
            "Train step - Step 11460, Loss 0.019210809841752052\n",
            "Train step - Step 11470, Loss 0.021626083180308342\n",
            "Train step - Step 11480, Loss 0.02049521915614605\n",
            "Train step - Step 11490, Loss 0.017903465777635574\n",
            "Train step - Step 11500, Loss 0.020297616720199585\n",
            "Train step - Step 11510, Loss 0.017401954159140587\n",
            "Train step - Step 11520, Loss 0.017462465912103653\n",
            "Train step - Step 11530, Loss 0.01652652770280838\n",
            "Train step - Step 11540, Loss 0.021985013037919998\n",
            "Train step - Step 11550, Loss 0.018389476463198662\n",
            "Train step - Step 11560, Loss 0.016700854524970055\n",
            "Train step - Step 11570, Loss 0.01915818080306053\n",
            "Train step - Step 11580, Loss 0.018435228615999222\n",
            "Train step - Step 11590, Loss 0.01638844981789589\n",
            "Train step - Step 11600, Loss 0.01885908469557762\n",
            "Train epoch - Accuracy: 0.6767474747474748 Loss: 0.01784683451071532 Corrects: 33499\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 11610, Loss 0.017309732735157013\n",
            "Train step - Step 11620, Loss 0.017204649746418\n",
            "Train step - Step 11630, Loss 0.01582046039402485\n",
            "Train step - Step 11640, Loss 0.017773006111383438\n",
            "Train step - Step 11650, Loss 0.017785251140594482\n",
            "Train step - Step 11660, Loss 0.015504279173910618\n",
            "Train step - Step 11670, Loss 0.014146530069410801\n",
            "Train step - Step 11680, Loss 0.017676910385489464\n",
            "Train step - Step 11690, Loss 0.02057228609919548\n",
            "Train step - Step 11700, Loss 0.019849950447678566\n",
            "Train step - Step 11710, Loss 0.015769733116030693\n",
            "Train step - Step 11720, Loss 0.016770940274000168\n",
            "Train step - Step 11730, Loss 0.019472559913992882\n",
            "Train step - Step 11740, Loss 0.017695097252726555\n",
            "Train step - Step 11750, Loss 0.01778959296643734\n",
            "Train step - Step 11760, Loss 0.01786188781261444\n",
            "Train step - Step 11770, Loss 0.019799701869487762\n",
            "Train step - Step 11780, Loss 0.019893266260623932\n",
            "Train step - Step 11790, Loss 0.015440392307937145\n",
            "Train step - Step 11800, Loss 0.018601497635245323\n",
            "Train step - Step 11810, Loss 0.0162114966660738\n",
            "Train step - Step 11820, Loss 0.01629561185836792\n",
            "Train step - Step 11830, Loss 0.01829538494348526\n",
            "Train step - Step 11840, Loss 0.016420921310782433\n",
            "Train step - Step 11850, Loss 0.01728672720491886\n",
            "Train step - Step 11860, Loss 0.016407685354351997\n",
            "Train step - Step 11870, Loss 0.016755856573581696\n",
            "Train step - Step 11880, Loss 0.018102284520864487\n",
            "Train step - Step 11890, Loss 0.016872966662049294\n",
            "Train step - Step 11900, Loss 0.015512395650148392\n",
            "Train step - Step 11910, Loss 0.01539405807852745\n",
            "Train step - Step 11920, Loss 0.016244549304246902\n",
            "Train step - Step 11930, Loss 0.016903268173336983\n",
            "Train step - Step 11940, Loss 0.019326912239193916\n",
            "Train step - Step 11950, Loss 0.01955176331102848\n",
            "Train step - Step 11960, Loss 0.01544469315558672\n",
            "Train step - Step 11970, Loss 0.01574212685227394\n",
            "Train step - Step 11980, Loss 0.017410481348633766\n",
            "Train step - Step 11990, Loss 0.01892622373998165\n",
            "Train epoch - Accuracy: 0.6785454545454546 Loss: 0.017796328553798223 Corrects: 33588\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 12000, Loss 0.01600729115307331\n",
            "Train step - Step 12010, Loss 0.01943284645676613\n",
            "Train step - Step 12020, Loss 0.01936347968876362\n",
            "Train step - Step 12030, Loss 0.015757501125335693\n",
            "Train step - Step 12040, Loss 0.017868222668766975\n",
            "Train step - Step 12050, Loss 0.016711004078388214\n",
            "Train step - Step 12060, Loss 0.01589134894311428\n",
            "Train step - Step 12070, Loss 0.018422935158014297\n",
            "Train step - Step 12080, Loss 0.01855623349547386\n",
            "Train step - Step 12090, Loss 0.019155200570821762\n",
            "Train step - Step 12100, Loss 0.017344439402222633\n",
            "Train step - Step 12110, Loss 0.018824126571416855\n",
            "Train step - Step 12120, Loss 0.01755085214972496\n",
            "Train step - Step 12130, Loss 0.014298402704298496\n",
            "Train step - Step 12140, Loss 0.01643311232328415\n",
            "Train step - Step 12150, Loss 0.01663879118859768\n",
            "Train step - Step 12160, Loss 0.015364264138042927\n",
            "Train step - Step 12170, Loss 0.021998511627316475\n",
            "Train step - Step 12180, Loss 0.015074876137077808\n",
            "Train step - Step 12190, Loss 0.013495814055204391\n",
            "Train step - Step 12200, Loss 0.01779346913099289\n",
            "Train step - Step 12210, Loss 0.01621069945394993\n",
            "Train step - Step 12220, Loss 0.0161808542907238\n",
            "Train step - Step 12230, Loss 0.017459161579608917\n",
            "Train step - Step 12240, Loss 0.016424953937530518\n",
            "Train step - Step 12250, Loss 0.015538432635366917\n",
            "Train step - Step 12260, Loss 0.018513601273298264\n",
            "Train step - Step 12270, Loss 0.01847999542951584\n",
            "Train step - Step 12280, Loss 0.017751820385456085\n",
            "Train step - Step 12290, Loss 0.019969623535871506\n",
            "Train step - Step 12300, Loss 0.016746025532484055\n",
            "Train step - Step 12310, Loss 0.018726350739598274\n",
            "Train step - Step 12320, Loss 0.0195966474711895\n",
            "Train step - Step 12330, Loss 0.017480533570051193\n",
            "Train step - Step 12340, Loss 0.015060573816299438\n",
            "Train step - Step 12350, Loss 0.017396144568920135\n",
            "Train step - Step 12360, Loss 0.018118662759661674\n",
            "Train step - Step 12370, Loss 0.01765414886176586\n",
            "Train step - Step 12380, Loss 0.020098337903618813\n",
            "Train epoch - Accuracy: 0.6773131313131313 Loss: 0.017843554416539693 Corrects: 33527\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 12390, Loss 0.016979502514004707\n",
            "Train step - Step 12400, Loss 0.015721259638667107\n",
            "Train step - Step 12410, Loss 0.016678081825375557\n",
            "Train step - Step 12420, Loss 0.016331113874912262\n",
            "Train step - Step 12430, Loss 0.018439555540680885\n",
            "Train step - Step 12440, Loss 0.01797362044453621\n",
            "Train step - Step 12450, Loss 0.0179422739893198\n",
            "Train step - Step 12460, Loss 0.015553219243884087\n",
            "Train step - Step 12470, Loss 0.015399942174553871\n",
            "Train step - Step 12480, Loss 0.01749431900680065\n",
            "Train step - Step 12490, Loss 0.021031804382801056\n",
            "Train step - Step 12500, Loss 0.01690061204135418\n",
            "Train step - Step 12510, Loss 0.01771925948560238\n",
            "Train step - Step 12520, Loss 0.019544612616300583\n",
            "Train step - Step 12530, Loss 0.01703316904604435\n",
            "Train step - Step 12540, Loss 0.017153006047010422\n",
            "Train step - Step 12550, Loss 0.020920582115650177\n",
            "Train step - Step 12560, Loss 0.017642125487327576\n",
            "Train step - Step 12570, Loss 0.01635190285742283\n",
            "Train step - Step 12580, Loss 0.018951553851366043\n",
            "Train step - Step 12590, Loss 0.016825340688228607\n",
            "Train step - Step 12600, Loss 0.017169978469610214\n",
            "Train step - Step 12610, Loss 0.01980188861489296\n",
            "Train step - Step 12620, Loss 0.022034253925085068\n",
            "Train step - Step 12630, Loss 0.01947893761098385\n",
            "Train step - Step 12640, Loss 0.021658524870872498\n",
            "Train step - Step 12650, Loss 0.019519925117492676\n",
            "Train step - Step 12660, Loss 0.018408149480819702\n",
            "Train step - Step 12670, Loss 0.0168317724019289\n",
            "Train step - Step 12680, Loss 0.016213029623031616\n",
            "Train step - Step 12690, Loss 0.01667463406920433\n",
            "Train step - Step 12700, Loss 0.020381441339850426\n",
            "Train step - Step 12710, Loss 0.016939524561166763\n",
            "Train step - Step 12720, Loss 0.016516003757715225\n",
            "Train step - Step 12730, Loss 0.022101661190390587\n",
            "Train step - Step 12740, Loss 0.018900105729699135\n",
            "Train step - Step 12750, Loss 0.01943228766322136\n",
            "Train step - Step 12760, Loss 0.017502225935459137\n",
            "Train step - Step 12770, Loss 0.019405391067266464\n",
            "Train epoch - Accuracy: 0.679050505050505 Loss: 0.01776861926311194 Corrects: 33613\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 12780, Loss 0.019079072400927544\n",
            "Train step - Step 12790, Loss 0.01787523180246353\n",
            "Train step - Step 12800, Loss 0.01465857308357954\n",
            "Train step - Step 12810, Loss 0.01590760610997677\n",
            "Train step - Step 12820, Loss 0.01572636142373085\n",
            "Train step - Step 12830, Loss 0.017398083582520485\n",
            "Train step - Step 12840, Loss 0.015050547197461128\n",
            "Train step - Step 12850, Loss 0.018278948962688446\n",
            "Train step - Step 12860, Loss 0.015182620845735073\n",
            "Train step - Step 12870, Loss 0.0173896886408329\n",
            "Train step - Step 12880, Loss 0.018086347728967667\n",
            "Train step - Step 12890, Loss 0.016575219109654427\n",
            "Train step - Step 12900, Loss 0.015628457069396973\n",
            "Train step - Step 12910, Loss 0.0156840942800045\n",
            "Train step - Step 12920, Loss 0.018694676458835602\n",
            "Train step - Step 12930, Loss 0.01796240732073784\n",
            "Train step - Step 12940, Loss 0.017548291012644768\n",
            "Train step - Step 12950, Loss 0.01696459762752056\n",
            "Train step - Step 12960, Loss 0.019022289663553238\n",
            "Train step - Step 12970, Loss 0.018301645293831825\n",
            "Train step - Step 12980, Loss 0.020810402929782867\n",
            "Train step - Step 12990, Loss 0.017059991136193275\n",
            "Train step - Step 13000, Loss 0.01643475517630577\n",
            "Train step - Step 13010, Loss 0.01988060027360916\n",
            "Train step - Step 13020, Loss 0.01688041165471077\n",
            "Train step - Step 13030, Loss 0.01723063364624977\n",
            "Train step - Step 13040, Loss 0.017053892835974693\n",
            "Train step - Step 13050, Loss 0.016753122210502625\n",
            "Train step - Step 13060, Loss 0.016843527555465698\n",
            "Train step - Step 13070, Loss 0.020911164581775665\n",
            "Train step - Step 13080, Loss 0.019044561311602592\n",
            "Train step - Step 13090, Loss 0.01874069683253765\n",
            "Train step - Step 13100, Loss 0.01832147128880024\n",
            "Train step - Step 13110, Loss 0.018512699753046036\n",
            "Train step - Step 13120, Loss 0.018594425171613693\n",
            "Train step - Step 13130, Loss 0.02075597643852234\n",
            "Train step - Step 13140, Loss 0.020605720579624176\n",
            "Train step - Step 13150, Loss 0.018031377345323563\n",
            "Train epoch - Accuracy: 0.6764040404040405 Loss: 0.017800060178745875 Corrects: 33482\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 13160, Loss 0.01708901673555374\n",
            "Train step - Step 13170, Loss 0.015696082264184952\n",
            "Train step - Step 13180, Loss 0.020753540098667145\n",
            "Train step - Step 13190, Loss 0.016529113054275513\n",
            "Train step - Step 13200, Loss 0.018195953220129013\n",
            "Train step - Step 13210, Loss 0.01656895875930786\n",
            "Train step - Step 13220, Loss 0.016697103157639503\n",
            "Train step - Step 13230, Loss 0.01657385192811489\n",
            "Train step - Step 13240, Loss 0.01547240000218153\n",
            "Train step - Step 13250, Loss 0.018316881731152534\n",
            "Train step - Step 13260, Loss 0.019496362656354904\n",
            "Train step - Step 13270, Loss 0.015725359320640564\n",
            "Train step - Step 13280, Loss 0.015424279496073723\n",
            "Train step - Step 13290, Loss 0.017865069210529327\n",
            "Train step - Step 13300, Loss 0.016333695501089096\n",
            "Train step - Step 13310, Loss 0.017344970256090164\n",
            "Train step - Step 13320, Loss 0.01423980575054884\n",
            "Train step - Step 13330, Loss 0.019242294132709503\n",
            "Train step - Step 13340, Loss 0.017944572493433952\n",
            "Train step - Step 13350, Loss 0.018003560602664948\n",
            "Train step - Step 13360, Loss 0.01798189990222454\n",
            "Train step - Step 13370, Loss 0.018833620473742485\n",
            "Train step - Step 13380, Loss 0.01812402717769146\n",
            "Train step - Step 13390, Loss 0.01849503442645073\n",
            "Train step - Step 13400, Loss 0.020104464143514633\n",
            "Train step - Step 13410, Loss 0.020173318684101105\n",
            "Train step - Step 13420, Loss 0.015885399654507637\n",
            "Train step - Step 13430, Loss 0.019422559067606926\n",
            "Train step - Step 13440, Loss 0.0174171831458807\n",
            "Train step - Step 13450, Loss 0.0177531149238348\n",
            "Train step - Step 13460, Loss 0.019914299249649048\n",
            "Train step - Step 13470, Loss 0.014783013612031937\n",
            "Train step - Step 13480, Loss 0.019279832020401955\n",
            "Train step - Step 13490, Loss 0.01493368111550808\n",
            "Train step - Step 13500, Loss 0.01854882948100567\n",
            "Train step - Step 13510, Loss 0.01652250811457634\n",
            "Train step - Step 13520, Loss 0.01888396218419075\n",
            "Train step - Step 13530, Loss 0.016011599451303482\n",
            "Train step - Step 13540, Loss 0.017504017800092697\n",
            "Train epoch - Accuracy: 0.6793333333333333 Loss: 0.01776290511753824 Corrects: 33627\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 13550, Loss 0.017385737970471382\n",
            "Train step - Step 13560, Loss 0.01794610172510147\n",
            "Train step - Step 13570, Loss 0.015776893123984337\n",
            "Train step - Step 13580, Loss 0.015745991840958595\n",
            "Train step - Step 13590, Loss 0.015506327152252197\n",
            "Train step - Step 13600, Loss 0.016155216842889786\n",
            "Train step - Step 13610, Loss 0.019592778757214546\n",
            "Train step - Step 13620, Loss 0.016879793256521225\n",
            "Train step - Step 13630, Loss 0.01466319803148508\n",
            "Train step - Step 13640, Loss 0.01978123188018799\n",
            "Train step - Step 13650, Loss 0.01621384732425213\n",
            "Train step - Step 13660, Loss 0.016612229868769646\n",
            "Train step - Step 13670, Loss 0.01857704669237137\n",
            "Train step - Step 13680, Loss 0.017809437587857246\n",
            "Train step - Step 13690, Loss 0.015132347121834755\n",
            "Train step - Step 13700, Loss 0.014992009848356247\n",
            "Train step - Step 13710, Loss 0.018359892070293427\n",
            "Train step - Step 13720, Loss 0.016550635918974876\n",
            "Train step - Step 13730, Loss 0.019883669912815094\n",
            "Train step - Step 13740, Loss 0.019380582496523857\n",
            "Train step - Step 13750, Loss 0.015171699225902557\n",
            "Train step - Step 13760, Loss 0.01887836679816246\n",
            "Train step - Step 13770, Loss 0.015220137313008308\n",
            "Train step - Step 13780, Loss 0.01836949959397316\n",
            "Train step - Step 13790, Loss 0.016721056774258614\n",
            "Train step - Step 13800, Loss 0.0171025600284338\n",
            "Train step - Step 13810, Loss 0.017516063526272774\n",
            "Train step - Step 13820, Loss 0.01927991770207882\n",
            "Train step - Step 13830, Loss 0.017967509105801582\n",
            "Train step - Step 13840, Loss 0.017837446182966232\n",
            "Train step - Step 13850, Loss 0.018061896786093712\n",
            "Train step - Step 13860, Loss 0.0179201140999794\n",
            "Train step - Step 13870, Loss 0.016926061362028122\n",
            "Train step - Step 13880, Loss 0.02017805352807045\n",
            "Train step - Step 13890, Loss 0.018392542377114296\n",
            "Train step - Step 13900, Loss 0.01923588663339615\n",
            "Train step - Step 13910, Loss 0.01938309334218502\n",
            "Train step - Step 13920, Loss 0.016235316172242165\n",
            "Train step - Step 13930, Loss 0.0202705729752779\n",
            "Train epoch - Accuracy: 0.680040404040404 Loss: 0.017720747678869903 Corrects: 33662\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 13940, Loss 0.019262153655290604\n",
            "Train step - Step 13950, Loss 0.018439944833517075\n",
            "Train step - Step 13960, Loss 0.017677519470453262\n",
            "Train step - Step 13970, Loss 0.018294578418135643\n",
            "Train step - Step 13980, Loss 0.016896530985832214\n",
            "Train step - Step 13990, Loss 0.01953224465250969\n",
            "Train step - Step 14000, Loss 0.01766890101134777\n",
            "Train step - Step 14010, Loss 0.01738760992884636\n",
            "Train step - Step 14020, Loss 0.01800854317843914\n",
            "Train step - Step 14030, Loss 0.01868640072643757\n",
            "Train step - Step 14040, Loss 0.0167376808822155\n",
            "Train step - Step 14050, Loss 0.01871226169168949\n",
            "Train step - Step 14060, Loss 0.016875214874744415\n",
            "Train step - Step 14070, Loss 0.01915169507265091\n",
            "Train step - Step 14080, Loss 0.01452538650482893\n",
            "Train step - Step 14090, Loss 0.019341930747032166\n",
            "Train step - Step 14100, Loss 0.0198364220559597\n",
            "Train step - Step 14110, Loss 0.016347447410225868\n",
            "Train step - Step 14120, Loss 0.018453611060976982\n",
            "Train step - Step 14130, Loss 0.016097426414489746\n",
            "Train step - Step 14140, Loss 0.018711978569626808\n",
            "Train step - Step 14150, Loss 0.01796048693358898\n",
            "Train step - Step 14160, Loss 0.017871716991066933\n",
            "Train step - Step 14170, Loss 0.014522292651236057\n",
            "Train step - Step 14180, Loss 0.01712014153599739\n",
            "Train step - Step 14190, Loss 0.017556307837367058\n",
            "Train step - Step 14200, Loss 0.017592601478099823\n",
            "Train step - Step 14210, Loss 0.01760915294289589\n",
            "Train step - Step 14220, Loss 0.015220852568745613\n",
            "Train step - Step 14230, Loss 0.020473547279834747\n",
            "Train step - Step 14240, Loss 0.018089599907398224\n",
            "Train step - Step 14250, Loss 0.017706675454974174\n",
            "Train step - Step 14260, Loss 0.018576640635728836\n",
            "Train step - Step 14270, Loss 0.01695907860994339\n",
            "Train step - Step 14280, Loss 0.019209399819374084\n",
            "Train step - Step 14290, Loss 0.019522150978446007\n",
            "Train step - Step 14300, Loss 0.016789089888334274\n",
            "Train step - Step 14310, Loss 0.017375454306602478\n",
            "Train epoch - Accuracy: 0.677939393939394 Loss: 0.017681826425772724 Corrects: 33558\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 14320, Loss 0.015170571394264698\n",
            "Train step - Step 14330, Loss 0.015961283817887306\n",
            "Train step - Step 14340, Loss 0.018107999116182327\n",
            "Train step - Step 14350, Loss 0.016396228224039078\n",
            "Train step - Step 14360, Loss 0.013891100883483887\n",
            "Train step - Step 14370, Loss 0.019430629909038544\n",
            "Train step - Step 14380, Loss 0.014799494296312332\n",
            "Train step - Step 14390, Loss 0.018030064180493355\n",
            "Train step - Step 14400, Loss 0.0161337461322546\n",
            "Train step - Step 14410, Loss 0.016875041648745537\n",
            "Train step - Step 14420, Loss 0.017417222261428833\n",
            "Train step - Step 14430, Loss 0.017140690237283707\n",
            "Train step - Step 14440, Loss 0.017648644745349884\n",
            "Train step - Step 14450, Loss 0.015592904761433601\n",
            "Train step - Step 14460, Loss 0.018859440460801125\n",
            "Train step - Step 14470, Loss 0.01605192758142948\n",
            "Train step - Step 14480, Loss 0.017458422109484673\n",
            "Train step - Step 14490, Loss 0.018708335235714912\n",
            "Train step - Step 14500, Loss 0.018234070390462875\n",
            "Train step - Step 14510, Loss 0.018672680482268333\n",
            "Train step - Step 14520, Loss 0.021055521443486214\n",
            "Train step - Step 14530, Loss 0.018075695261359215\n",
            "Train step - Step 14540, Loss 0.01609281823039055\n",
            "Train step - Step 14550, Loss 0.01765506900846958\n",
            "Train step - Step 14560, Loss 0.019757496193051338\n",
            "Train step - Step 14570, Loss 0.018715934827923775\n",
            "Train step - Step 14580, Loss 0.019060267135500908\n",
            "Train step - Step 14590, Loss 0.018003521487116814\n",
            "Train step - Step 14600, Loss 0.01638703979551792\n",
            "Train step - Step 14610, Loss 0.017660360783338547\n",
            "Train step - Step 14620, Loss 0.01635018177330494\n",
            "Train step - Step 14630, Loss 0.015394460409879684\n",
            "Train step - Step 14640, Loss 0.01778176613152027\n",
            "Train step - Step 14650, Loss 0.017675885930657387\n",
            "Train step - Step 14660, Loss 0.0189463309943676\n",
            "Train step - Step 14670, Loss 0.01660495437681675\n",
            "Train step - Step 14680, Loss 0.017088936641812325\n",
            "Train step - Step 14690, Loss 0.016527483239769936\n",
            "Train step - Step 14700, Loss 0.016936805099248886\n",
            "Train epoch - Accuracy: 0.681050505050505 Loss: 0.017676138485471407 Corrects: 33712\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 14710, Loss 0.015065143816173077\n",
            "Train step - Step 14720, Loss 0.014712805859744549\n",
            "Train step - Step 14730, Loss 0.014333176426589489\n",
            "Train step - Step 14740, Loss 0.016803285107016563\n",
            "Train step - Step 14750, Loss 0.01887265220284462\n",
            "Train step - Step 14760, Loss 0.01795104891061783\n",
            "Train step - Step 14770, Loss 0.020380781963467598\n",
            "Train step - Step 14780, Loss 0.015537945553660393\n",
            "Train step - Step 14790, Loss 0.015799129381775856\n",
            "Train step - Step 14800, Loss 0.0183082427829504\n",
            "Train step - Step 14810, Loss 0.01328320149332285\n",
            "Train step - Step 14820, Loss 0.01735820807516575\n",
            "Train step - Step 14830, Loss 0.02013002336025238\n",
            "Train step - Step 14840, Loss 0.01690756343305111\n",
            "Train step - Step 14850, Loss 0.017843538895249367\n",
            "Train step - Step 14860, Loss 0.017045436426997185\n",
            "Train step - Step 14870, Loss 0.017474902793765068\n",
            "Train step - Step 14880, Loss 0.016672829166054726\n",
            "Train step - Step 14890, Loss 0.019596392288804054\n",
            "Train step - Step 14900, Loss 0.01750069670379162\n",
            "Train step - Step 14910, Loss 0.019457722082734108\n",
            "Train step - Step 14920, Loss 0.016902124509215355\n",
            "Train step - Step 14930, Loss 0.018739506602287292\n",
            "Train step - Step 14940, Loss 0.019876517355442047\n",
            "Train step - Step 14950, Loss 0.016116056591272354\n",
            "Train step - Step 14960, Loss 0.017467986792325974\n",
            "Train step - Step 14970, Loss 0.017755363136529922\n",
            "Train step - Step 14980, Loss 0.017107179388403893\n",
            "Train step - Step 14990, Loss 0.01803627610206604\n",
            "Train step - Step 15000, Loss 0.019731873646378517\n",
            "Train step - Step 15010, Loss 0.020578060299158096\n",
            "Train step - Step 15020, Loss 0.01702697202563286\n",
            "Train step - Step 15030, Loss 0.018681121990084648\n",
            "Train step - Step 15040, Loss 0.01985972560942173\n",
            "Train step - Step 15050, Loss 0.01685897633433342\n",
            "Train step - Step 15060, Loss 0.019520394504070282\n",
            "Train step - Step 15070, Loss 0.018102476373314857\n",
            "Train step - Step 15080, Loss 0.018924269825220108\n",
            "Train step - Step 15090, Loss 0.016307802870869637\n",
            "Train epoch - Accuracy: 0.6782222222222222 Loss: 0.0176612925762781 Corrects: 33572\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 15100, Loss 0.015997156500816345\n",
            "Train step - Step 15110, Loss 0.02012527920305729\n",
            "Train step - Step 15120, Loss 0.013081464916467667\n",
            "Train step - Step 15130, Loss 0.01673278771340847\n",
            "Train step - Step 15140, Loss 0.016551144421100616\n",
            "Train step - Step 15150, Loss 0.017047792673110962\n",
            "Train step - Step 15160, Loss 0.016160842031240463\n",
            "Train step - Step 15170, Loss 0.020667893812060356\n",
            "Train step - Step 15180, Loss 0.019841449335217476\n",
            "Train step - Step 15190, Loss 0.018822798505425453\n",
            "Train step - Step 15200, Loss 0.01747702993452549\n",
            "Train step - Step 15210, Loss 0.01626269519329071\n",
            "Train step - Step 15220, Loss 0.02020256035029888\n",
            "Train step - Step 15230, Loss 0.019546445459127426\n",
            "Train step - Step 15240, Loss 0.01629025675356388\n",
            "Train step - Step 15250, Loss 0.017088009044528008\n",
            "Train step - Step 15260, Loss 0.019053643569350243\n",
            "Train step - Step 15270, Loss 0.01964571699500084\n",
            "Train step - Step 15280, Loss 0.01846064254641533\n",
            "Train step - Step 15290, Loss 0.01820843480527401\n",
            "Train step - Step 15300, Loss 0.019951969385147095\n",
            "Train step - Step 15310, Loss 0.01712314411997795\n",
            "Train step - Step 15320, Loss 0.019165659323334694\n",
            "Train step - Step 15330, Loss 0.01977827213704586\n",
            "Train step - Step 15340, Loss 0.019730219617486\n",
            "Train step - Step 15350, Loss 0.02013581432402134\n",
            "Train step - Step 15360, Loss 0.01787780411541462\n",
            "Train step - Step 15370, Loss 0.01866884157061577\n",
            "Train step - Step 15380, Loss 0.020335903391242027\n",
            "Train step - Step 15390, Loss 0.019250817596912384\n",
            "Train step - Step 15400, Loss 0.017345005646348\n",
            "Train step - Step 15410, Loss 0.017099687829613686\n",
            "Train step - Step 15420, Loss 0.019796229898929596\n",
            "Train step - Step 15430, Loss 0.02007428929209709\n",
            "Train step - Step 15440, Loss 0.017157165333628654\n",
            "Train step - Step 15450, Loss 0.019720768555998802\n",
            "Train step - Step 15460, Loss 0.016587112098932266\n",
            "Train step - Step 15470, Loss 0.01725570112466812\n",
            "Train epoch - Accuracy: 0.6776363636363636 Loss: 0.01781631530189153 Corrects: 33543\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 15480, Loss 0.018237708136439323\n",
            "Train step - Step 15490, Loss 0.017490942031145096\n",
            "Train step - Step 15500, Loss 0.017712509259581566\n",
            "Train step - Step 15510, Loss 0.017272332683205605\n",
            "Train step - Step 15520, Loss 0.017787568271160126\n",
            "Train step - Step 15530, Loss 0.02069855108857155\n",
            "Train step - Step 15540, Loss 0.017750369384884834\n",
            "Train step - Step 15550, Loss 0.017934700474143028\n",
            "Train step - Step 15560, Loss 0.017041534185409546\n",
            "Train step - Step 15570, Loss 0.017071526497602463\n",
            "Train step - Step 15580, Loss 0.01732473075389862\n",
            "Train step - Step 15590, Loss 0.017523229122161865\n",
            "Train step - Step 15600, Loss 0.015128831379115582\n",
            "Train step - Step 15610, Loss 0.019937891513109207\n",
            "Train step - Step 15620, Loss 0.02004181779921055\n",
            "Train step - Step 15630, Loss 0.017226992174983025\n",
            "Train step - Step 15640, Loss 0.017321458086371422\n",
            "Train step - Step 15650, Loss 0.0187178123742342\n",
            "Train step - Step 15660, Loss 0.019100500270724297\n",
            "Train step - Step 15670, Loss 0.01850903034210205\n",
            "Train step - Step 15680, Loss 0.014693834818899632\n",
            "Train step - Step 15690, Loss 0.017878707498311996\n",
            "Train step - Step 15700, Loss 0.01604965142905712\n",
            "Train step - Step 15710, Loss 0.014189849607646465\n",
            "Train step - Step 15720, Loss 0.018027037382125854\n",
            "Train step - Step 15730, Loss 0.017687242478132248\n",
            "Train step - Step 15740, Loss 0.01650341972708702\n",
            "Train step - Step 15750, Loss 0.018946664407849312\n",
            "Train step - Step 15760, Loss 0.017393270507454872\n",
            "Train step - Step 15770, Loss 0.01583041623234749\n",
            "Train step - Step 15780, Loss 0.020286619663238525\n",
            "Train step - Step 15790, Loss 0.018359720706939697\n",
            "Train step - Step 15800, Loss 0.015966426581144333\n",
            "Train step - Step 15810, Loss 0.019641049206256866\n",
            "Train step - Step 15820, Loss 0.016676146537065506\n",
            "Train step - Step 15830, Loss 0.01593008264899254\n",
            "Train step - Step 15840, Loss 0.015917731449007988\n",
            "Train step - Step 15850, Loss 0.01959052123129368\n",
            "Train step - Step 15860, Loss 0.019746391102671623\n",
            "Train epoch - Accuracy: 0.6823030303030303 Loss: 0.0175770710941517 Corrects: 33774\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 15870, Loss 0.015553420409560204\n",
            "Train step - Step 15880, Loss 0.019153494387865067\n",
            "Train step - Step 15890, Loss 0.01605156436562538\n",
            "Train step - Step 15900, Loss 0.015288758091628551\n",
            "Train step - Step 15910, Loss 0.015388037078082561\n",
            "Train step - Step 15920, Loss 0.015125338919460773\n",
            "Train step - Step 15930, Loss 0.015739545226097107\n",
            "Train step - Step 15940, Loss 0.015353552997112274\n",
            "Train step - Step 15950, Loss 0.016479870304465294\n",
            "Train step - Step 15960, Loss 0.018330121412873268\n",
            "Train step - Step 15970, Loss 0.016855157911777496\n",
            "Train step - Step 15980, Loss 0.017122618854045868\n",
            "Train step - Step 15990, Loss 0.01596006564795971\n",
            "Train step - Step 16000, Loss 0.017340054735541344\n",
            "Train step - Step 16010, Loss 0.016687866300344467\n",
            "Train step - Step 16020, Loss 0.01722813956439495\n",
            "Train step - Step 16030, Loss 0.01563137210905552\n",
            "Train step - Step 16040, Loss 0.01398471836000681\n",
            "Train step - Step 16050, Loss 0.017094168812036514\n",
            "Train step - Step 16060, Loss 0.019811157137155533\n",
            "Train step - Step 16070, Loss 0.017711365595459938\n",
            "Train step - Step 16080, Loss 0.015360768884420395\n",
            "Train step - Step 16090, Loss 0.019054969772696495\n",
            "Train step - Step 16100, Loss 0.017266713082790375\n",
            "Train step - Step 16110, Loss 0.0189034566283226\n",
            "Train step - Step 16120, Loss 0.017859648913145065\n",
            "Train step - Step 16130, Loss 0.01910676620900631\n",
            "Train step - Step 16140, Loss 0.016175581142306328\n",
            "Train step - Step 16150, Loss 0.018383190035820007\n",
            "Train step - Step 16160, Loss 0.017051782459020615\n",
            "Train step - Step 16170, Loss 0.01587998867034912\n",
            "Train step - Step 16180, Loss 0.020123304799199104\n",
            "Train step - Step 16190, Loss 0.01976577751338482\n",
            "Train step - Step 16200, Loss 0.019143206998705864\n",
            "Train step - Step 16210, Loss 0.018243160098791122\n",
            "Train step - Step 16220, Loss 0.01768074929714203\n",
            "Train step - Step 16230, Loss 0.019324110820889473\n",
            "Train step - Step 16240, Loss 0.01794624701142311\n",
            "Train step - Step 16250, Loss 0.019586438313126564\n",
            "Train epoch - Accuracy: 0.6806060606060607 Loss: 0.017723214423867185 Corrects: 33690\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 16260, Loss 0.01845741458237171\n",
            "Train step - Step 16270, Loss 0.0184970423579216\n",
            "Train step - Step 16280, Loss 0.018225472420454025\n",
            "Train step - Step 16290, Loss 0.015009259805083275\n",
            "Train step - Step 16300, Loss 0.018980754539370537\n",
            "Train step - Step 16310, Loss 0.015942003577947617\n",
            "Train step - Step 16320, Loss 0.020142588764429092\n",
            "Train step - Step 16330, Loss 0.015702277421951294\n",
            "Train step - Step 16340, Loss 0.015114039182662964\n",
            "Train step - Step 16350, Loss 0.015252441167831421\n",
            "Train step - Step 16360, Loss 0.018239323049783707\n",
            "Train step - Step 16370, Loss 0.016864247620105743\n",
            "Train step - Step 16380, Loss 0.016310537233948708\n",
            "Train step - Step 16390, Loss 0.0154410470277071\n",
            "Train step - Step 16400, Loss 0.015637177973985672\n",
            "Train step - Step 16410, Loss 0.017668593674898148\n",
            "Train step - Step 16420, Loss 0.017711928114295006\n",
            "Train step - Step 16430, Loss 0.020561832934617996\n",
            "Train step - Step 16440, Loss 0.016073884442448616\n",
            "Train step - Step 16450, Loss 0.01708226464688778\n",
            "Train step - Step 16460, Loss 0.01649390161037445\n",
            "Train step - Step 16470, Loss 0.01761288195848465\n",
            "Train step - Step 16480, Loss 0.017395922914147377\n",
            "Train step - Step 16490, Loss 0.018822086974978447\n",
            "Train step - Step 16500, Loss 0.01883324608206749\n",
            "Train step - Step 16510, Loss 0.016344202682375908\n",
            "Train step - Step 16520, Loss 0.01680927164852619\n",
            "Train step - Step 16530, Loss 0.015581445768475533\n",
            "Train step - Step 16540, Loss 0.018664883449673653\n",
            "Train step - Step 16550, Loss 0.01821126602590084\n",
            "Train step - Step 16560, Loss 0.014535629190504551\n",
            "Train step - Step 16570, Loss 0.02115183137357235\n",
            "Train step - Step 16580, Loss 0.015890121459960938\n",
            "Train step - Step 16590, Loss 0.019555428996682167\n",
            "Train step - Step 16600, Loss 0.018640730530023575\n",
            "Train step - Step 16610, Loss 0.01740640588104725\n",
            "Train step - Step 16620, Loss 0.018444430083036423\n",
            "Train step - Step 16630, Loss 0.018033871427178383\n",
            "Train step - Step 16640, Loss 0.016746561974287033\n",
            "Train epoch - Accuracy: 0.6778787878787879 Loss: 0.017695711544366798 Corrects: 33555\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 16650, Loss 0.01586073823273182\n",
            "Train step - Step 16660, Loss 0.015178295783698559\n",
            "Train step - Step 16670, Loss 0.018576383590698242\n",
            "Train step - Step 16680, Loss 0.016315674409270287\n",
            "Train step - Step 16690, Loss 0.019249949604272842\n",
            "Train step - Step 16700, Loss 0.01741129904985428\n",
            "Train step - Step 16710, Loss 0.01597668044269085\n",
            "Train step - Step 16720, Loss 0.016074059531092644\n",
            "Train step - Step 16730, Loss 0.01806638203561306\n",
            "Train step - Step 16740, Loss 0.016834095120429993\n",
            "Train step - Step 16750, Loss 0.01725814864039421\n",
            "Train step - Step 16760, Loss 0.016155336052179337\n",
            "Train step - Step 16770, Loss 0.01773690991103649\n",
            "Train step - Step 16780, Loss 0.016937967389822006\n",
            "Train step - Step 16790, Loss 0.015493623912334442\n",
            "Train step - Step 16800, Loss 0.016412261873483658\n",
            "Train step - Step 16810, Loss 0.018118422478437424\n",
            "Train step - Step 16820, Loss 0.01806560531258583\n",
            "Train step - Step 16830, Loss 0.015299198217689991\n",
            "Train step - Step 16840, Loss 0.017677154392004013\n",
            "Train step - Step 16850, Loss 0.01903272047638893\n",
            "Train step - Step 16860, Loss 0.016894860193133354\n",
            "Train step - Step 16870, Loss 0.0187663696706295\n",
            "Train step - Step 16880, Loss 0.018322233110666275\n",
            "Train step - Step 16890, Loss 0.01715984009206295\n",
            "Train step - Step 16900, Loss 0.01721312291920185\n",
            "Train step - Step 16910, Loss 0.01873127743601799\n",
            "Train step - Step 16920, Loss 0.016872109845280647\n",
            "Train step - Step 16930, Loss 0.017209473997354507\n",
            "Train step - Step 16940, Loss 0.01678885705769062\n",
            "Train step - Step 16950, Loss 0.017345815896987915\n",
            "Train step - Step 16960, Loss 0.013648446649312973\n",
            "Train step - Step 16970, Loss 0.01641247421503067\n",
            "Train step - Step 16980, Loss 0.01716693863272667\n",
            "Train step - Step 16990, Loss 0.018763553351163864\n",
            "Train step - Step 17000, Loss 0.018096497282385826\n",
            "Train step - Step 17010, Loss 0.018826045095920563\n",
            "Train step - Step 17020, Loss 0.01800081878900528\n",
            "Train epoch - Accuracy: 0.681030303030303 Loss: 0.017536723015735847 Corrects: 33711\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 17030, Loss 0.01615910418331623\n",
            "Train step - Step 17040, Loss 0.016268068924546242\n",
            "Train step - Step 17050, Loss 0.01750669628381729\n",
            "Train step - Step 17060, Loss 0.01986110210418701\n",
            "Train step - Step 17070, Loss 0.016618341207504272\n",
            "Train step - Step 17080, Loss 0.020508084446191788\n",
            "Train step - Step 17090, Loss 0.015116333961486816\n",
            "Train step - Step 17100, Loss 0.01757420413196087\n",
            "Train step - Step 17110, Loss 0.016046812757849693\n",
            "Train step - Step 17120, Loss 0.017403189092874527\n",
            "Train step - Step 17130, Loss 0.017870722338557243\n",
            "Train step - Step 17140, Loss 0.017550872638821602\n",
            "Train step - Step 17150, Loss 0.015431849285960197\n",
            "Train step - Step 17160, Loss 0.016381436958909035\n",
            "Train step - Step 17170, Loss 0.01920180581510067\n",
            "Train step - Step 17180, Loss 0.015440970659255981\n",
            "Train step - Step 17190, Loss 0.016867201775312424\n",
            "Train step - Step 17200, Loss 0.018617650493979454\n",
            "Train step - Step 17210, Loss 0.016229793429374695\n",
            "Train step - Step 17220, Loss 0.015130776911973953\n",
            "Train step - Step 17230, Loss 0.018072573468089104\n",
            "Train step - Step 17240, Loss 0.018230516463518143\n",
            "Train step - Step 17250, Loss 0.01736927218735218\n",
            "Train step - Step 17260, Loss 0.019089413806796074\n",
            "Train step - Step 17270, Loss 0.01740427501499653\n",
            "Train step - Step 17280, Loss 0.018598493188619614\n",
            "Train step - Step 17290, Loss 0.018612822517752647\n",
            "Train step - Step 17300, Loss 0.02063334733247757\n",
            "Train step - Step 17310, Loss 0.016503093764185905\n",
            "Train step - Step 17320, Loss 0.015967637300491333\n",
            "Train step - Step 17330, Loss 0.01875341311097145\n",
            "Train step - Step 17340, Loss 0.018733631819486618\n",
            "Train step - Step 17350, Loss 0.01818912662565708\n",
            "Train step - Step 17360, Loss 0.016326112672686577\n",
            "Train step - Step 17370, Loss 0.01880738139152527\n",
            "Train step - Step 17380, Loss 0.018620308488607407\n",
            "Train step - Step 17390, Loss 0.019215185195207596\n",
            "Train step - Step 17400, Loss 0.015580988489091396\n",
            "Train step - Step 17410, Loss 0.020671600475907326\n",
            "Train epoch - Accuracy: 0.6801414141414142 Loss: 0.017640455723561422 Corrects: 33667\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 17420, Loss 0.015370368957519531\n",
            "Train step - Step 17430, Loss 0.014494620263576508\n",
            "Train step - Step 17440, Loss 0.01903635263442993\n",
            "Train step - Step 17450, Loss 0.015227839350700378\n",
            "Train step - Step 17460, Loss 0.019064834341406822\n",
            "Train step - Step 17470, Loss 0.019163155928254128\n",
            "Train step - Step 17480, Loss 0.016953444108366966\n",
            "Train step - Step 17490, Loss 0.014718434773385525\n",
            "Train step - Step 17500, Loss 0.018206652253866196\n",
            "Train step - Step 17510, Loss 0.018333982676267624\n",
            "Train step - Step 17520, Loss 0.016532395035028458\n",
            "Train step - Step 17530, Loss 0.01624412275850773\n",
            "Train step - Step 17540, Loss 0.019082874059677124\n",
            "Train step - Step 17550, Loss 0.016284896060824394\n",
            "Train step - Step 17560, Loss 0.015766868367791176\n",
            "Train step - Step 17570, Loss 0.017627859488129616\n",
            "Train step - Step 17580, Loss 0.0159137062728405\n",
            "Train step - Step 17590, Loss 0.01808146946132183\n",
            "Train step - Step 17600, Loss 0.018454784527420998\n",
            "Train step - Step 17610, Loss 0.017940690740942955\n",
            "Train step - Step 17620, Loss 0.019302593544125557\n",
            "Train step - Step 17630, Loss 0.018220024183392525\n",
            "Train step - Step 17640, Loss 0.01896326243877411\n",
            "Train step - Step 17650, Loss 0.01824023760855198\n",
            "Train step - Step 17660, Loss 0.017624543979763985\n",
            "Train step - Step 17670, Loss 0.018453797325491905\n",
            "Train step - Step 17680, Loss 0.021163515746593475\n",
            "Train step - Step 17690, Loss 0.021291514858603477\n",
            "Train step - Step 17700, Loss 0.016571808606386185\n",
            "Train step - Step 17710, Loss 0.01670467108488083\n",
            "Train step - Step 17720, Loss 0.017680037766695023\n",
            "Train step - Step 17730, Loss 0.016417576000094414\n",
            "Train step - Step 17740, Loss 0.0181953813880682\n",
            "Train step - Step 17750, Loss 0.018350856378674507\n",
            "Train step - Step 17760, Loss 0.01714983955025673\n",
            "Train step - Step 17770, Loss 0.017010284587740898\n",
            "Train step - Step 17780, Loss 0.01865280419588089\n",
            "Train step - Step 17790, Loss 0.018278853967785835\n",
            "Train step - Step 17800, Loss 0.01826034113764763\n",
            "Train epoch - Accuracy: 0.6811313131313131 Loss: 0.01754150629555336 Corrects: 33716\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 17810, Loss 0.01705646887421608\n",
            "Train step - Step 17820, Loss 0.017882274463772774\n",
            "Train step - Step 17830, Loss 0.01670876145362854\n",
            "Train step - Step 17840, Loss 0.015797162428498268\n",
            "Train step - Step 17850, Loss 0.01869037374854088\n",
            "Train step - Step 17860, Loss 0.016210315749049187\n",
            "Train step - Step 17870, Loss 0.01685311086475849\n",
            "Train step - Step 17880, Loss 0.015582393854856491\n",
            "Train step - Step 17890, Loss 0.016083791851997375\n",
            "Train step - Step 17900, Loss 0.017349187284708023\n",
            "Train step - Step 17910, Loss 0.018111078068614006\n",
            "Train step - Step 17920, Loss 0.018430188298225403\n",
            "Train step - Step 17930, Loss 0.01759481616318226\n",
            "Train step - Step 17940, Loss 0.015138577669858932\n",
            "Train step - Step 17950, Loss 0.018270181491971016\n",
            "Train step - Step 17960, Loss 0.014837273396551609\n",
            "Train step - Step 17970, Loss 0.016455214470624924\n",
            "Train step - Step 17980, Loss 0.020210957154631615\n",
            "Train step - Step 17990, Loss 0.017100531607866287\n",
            "Train step - Step 18000, Loss 0.017025744542479515\n",
            "Train step - Step 18010, Loss 0.016157865524291992\n",
            "Train step - Step 18020, Loss 0.017046036198735237\n",
            "Train step - Step 18030, Loss 0.017652571201324463\n",
            "Train step - Step 18040, Loss 0.019386742264032364\n",
            "Train step - Step 18050, Loss 0.015582107938826084\n",
            "Train step - Step 18060, Loss 0.01616111770272255\n",
            "Train step - Step 18070, Loss 0.018108408898115158\n",
            "Train step - Step 18080, Loss 0.01619293913245201\n",
            "Train step - Step 18090, Loss 0.01746143028140068\n",
            "Train step - Step 18100, Loss 0.015085233375430107\n",
            "Train step - Step 18110, Loss 0.020108938217163086\n",
            "Train step - Step 18120, Loss 0.020282650366425514\n",
            "Train step - Step 18130, Loss 0.017906302586197853\n",
            "Train step - Step 18140, Loss 0.01756579428911209\n",
            "Train step - Step 18150, Loss 0.018036488443613052\n",
            "Train step - Step 18160, Loss 0.015653390437364578\n",
            "Train step - Step 18170, Loss 0.016233760863542557\n",
            "Train step - Step 18180, Loss 0.02173668146133423\n",
            "Train epoch - Accuracy: 0.6813939393939394 Loss: 0.017601919383111626 Corrects: 33729\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 18190, Loss 0.020152587443590164\n",
            "Train step - Step 18200, Loss 0.01676240563392639\n",
            "Train step - Step 18210, Loss 0.015053260140120983\n",
            "Train step - Step 18220, Loss 0.01612076535820961\n",
            "Train step - Step 18230, Loss 0.015311166644096375\n",
            "Train step - Step 18240, Loss 0.015176752582192421\n",
            "Train step - Step 18250, Loss 0.016100963577628136\n",
            "Train step - Step 18260, Loss 0.01764746569097042\n",
            "Train step - Step 18270, Loss 0.015996523201465607\n",
            "Train step - Step 18280, Loss 0.018496276810765266\n",
            "Train step - Step 18290, Loss 0.020392877981066704\n",
            "Train step - Step 18300, Loss 0.01888580434024334\n",
            "Train step - Step 18310, Loss 0.01933477818965912\n",
            "Train step - Step 18320, Loss 0.018654070794582367\n",
            "Train step - Step 18330, Loss 0.01602519303560257\n",
            "Train step - Step 18340, Loss 0.0174502395093441\n",
            "Train step - Step 18350, Loss 0.019285505637526512\n",
            "Train step - Step 18360, Loss 0.016897734254598618\n",
            "Train step - Step 18370, Loss 0.017480820417404175\n",
            "Train step - Step 18380, Loss 0.019054217264056206\n",
            "Train step - Step 18390, Loss 0.01625530607998371\n",
            "Train step - Step 18400, Loss 0.02263448014855385\n",
            "Train step - Step 18410, Loss 0.01760125532746315\n",
            "Train step - Step 18420, Loss 0.01720181107521057\n",
            "Train step - Step 18430, Loss 0.019037064164876938\n",
            "Train step - Step 18440, Loss 0.01868036389350891\n",
            "Train step - Step 18450, Loss 0.01734306663274765\n",
            "Train step - Step 18460, Loss 0.019178112968802452\n",
            "Train step - Step 18470, Loss 0.017339162528514862\n",
            "Train step - Step 18480, Loss 0.01763753779232502\n",
            "Train step - Step 18490, Loss 0.016644848510622978\n",
            "Train step - Step 18500, Loss 0.01663403958082199\n",
            "Train step - Step 18510, Loss 0.018724707886576653\n",
            "Train step - Step 18520, Loss 0.014823411591351032\n",
            "Train step - Step 18530, Loss 0.01874713785946369\n",
            "Train step - Step 18540, Loss 0.015975138172507286\n",
            "Train step - Step 18550, Loss 0.019079778343439102\n",
            "Train step - Step 18560, Loss 0.017148463055491447\n",
            "Train step - Step 18570, Loss 0.014596352353692055\n",
            "Train epoch - Accuracy: 0.6807070707070707 Loss: 0.017516986448806945 Corrects: 33695\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 18580, Loss 0.01665617898106575\n",
            "Train step - Step 18590, Loss 0.016653599217534065\n",
            "Train step - Step 18600, Loss 0.016715964302420616\n",
            "Train step - Step 18610, Loss 0.016186358407139778\n",
            "Train step - Step 18620, Loss 0.016950754448771477\n",
            "Train step - Step 18630, Loss 0.014733533374965191\n",
            "Train step - Step 18640, Loss 0.016627833247184753\n",
            "Train step - Step 18650, Loss 0.02075687050819397\n",
            "Train step - Step 18660, Loss 0.01580910198390484\n",
            "Train step - Step 18670, Loss 0.017686104401946068\n",
            "Train step - Step 18680, Loss 0.016664648428559303\n",
            "Train step - Step 18690, Loss 0.018778275698423386\n",
            "Train step - Step 18700, Loss 0.015309872105717659\n",
            "Train step - Step 18710, Loss 0.018962115049362183\n",
            "Train step - Step 18720, Loss 0.017715662717819214\n",
            "Train step - Step 18730, Loss 0.016842616721987724\n",
            "Train step - Step 18740, Loss 0.0171644426882267\n",
            "Train step - Step 18750, Loss 0.017626607790589333\n",
            "Train step - Step 18760, Loss 0.017615215852856636\n",
            "Train step - Step 18770, Loss 0.01775866001844406\n",
            "Train step - Step 18780, Loss 0.0196598581969738\n",
            "Train step - Step 18790, Loss 0.01632879301905632\n",
            "Train step - Step 18800, Loss 0.018757982179522514\n",
            "Train step - Step 18810, Loss 0.017735445871949196\n",
            "Train step - Step 18820, Loss 0.016030484810471535\n",
            "Train step - Step 18830, Loss 0.01844608038663864\n",
            "Train step - Step 18840, Loss 0.020151618868112564\n",
            "Train step - Step 18850, Loss 0.016885751858353615\n",
            "Train step - Step 18860, Loss 0.016213582828640938\n",
            "Train step - Step 18870, Loss 0.02136494591832161\n",
            "Train step - Step 18880, Loss 0.02000192180275917\n",
            "Train step - Step 18890, Loss 0.01723313331604004\n",
            "Train step - Step 18900, Loss 0.020067939534783363\n",
            "Train step - Step 18910, Loss 0.01613531820476055\n",
            "Train step - Step 18920, Loss 0.017691804096102715\n",
            "Train step - Step 18930, Loss 0.02029602974653244\n",
            "Train step - Step 18940, Loss 0.019057422876358032\n",
            "Train step - Step 18950, Loss 0.01558078732341528\n",
            "Train step - Step 18960, Loss 0.01585233584046364\n",
            "Train epoch - Accuracy: 0.6783838383838384 Loss: 0.0177529675406639 Corrects: 33580\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 18970, Loss 0.018415402621030807\n",
            "Train step - Step 18980, Loss 0.015489725396037102\n",
            "Train step - Step 18990, Loss 0.01352131087332964\n",
            "Train step - Step 19000, Loss 0.014819726347923279\n",
            "Train step - Step 19010, Loss 0.01339778397232294\n",
            "Train step - Step 19020, Loss 0.01382470689713955\n",
            "Train step - Step 19030, Loss 0.014282731339335442\n",
            "Train step - Step 19040, Loss 0.014662131667137146\n",
            "Train step - Step 19050, Loss 0.01349218375980854\n",
            "Train step - Step 19060, Loss 0.014638259075582027\n",
            "Train step - Step 19070, Loss 0.014840450137853622\n",
            "Train step - Step 19080, Loss 0.01361673604696989\n",
            "Train step - Step 19090, Loss 0.013218864798545837\n",
            "Train step - Step 19100, Loss 0.013423766009509563\n",
            "Train step - Step 19110, Loss 0.013498451560735703\n",
            "Train step - Step 19120, Loss 0.01253495179116726\n",
            "Train step - Step 19130, Loss 0.014355899766087532\n",
            "Train step - Step 19140, Loss 0.012860078364610672\n",
            "Train step - Step 19150, Loss 0.01235803309828043\n",
            "Train step - Step 19160, Loss 0.012173735536634922\n",
            "Train step - Step 19170, Loss 0.010828126221895218\n",
            "Train step - Step 19180, Loss 0.012996511533856392\n",
            "Train step - Step 19190, Loss 0.013431563042104244\n",
            "Train step - Step 19200, Loss 0.012125677429139614\n",
            "Train step - Step 19210, Loss 0.014662402682006359\n",
            "Train step - Step 19220, Loss 0.014532837085425854\n",
            "Train step - Step 19230, Loss 0.012912372127175331\n",
            "Train step - Step 19240, Loss 0.01481267623603344\n",
            "Train step - Step 19250, Loss 0.010964934714138508\n",
            "Train step - Step 19260, Loss 0.0147530073300004\n",
            "Train step - Step 19270, Loss 0.014103550463914871\n",
            "Train step - Step 19280, Loss 0.010114031843841076\n",
            "Train step - Step 19290, Loss 0.013275065459311008\n",
            "Train step - Step 19300, Loss 0.014861187897622585\n",
            "Train step - Step 19310, Loss 0.012641417793929577\n",
            "Train step - Step 19320, Loss 0.012443105690181255\n",
            "Train step - Step 19330, Loss 0.01301914919167757\n",
            "Train step - Step 19340, Loss 0.011380528099834919\n",
            "Train epoch - Accuracy: 0.7669494949494949 Loss: 0.01344921632788398 Corrects: 37964\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 19350, Loss 0.013655750080943108\n",
            "Train step - Step 19360, Loss 0.013294392265379429\n",
            "Train step - Step 19370, Loss 0.014370232820510864\n",
            "Train step - Step 19380, Loss 0.012054409831762314\n",
            "Train step - Step 19390, Loss 0.01161892618983984\n",
            "Train step - Step 19400, Loss 0.011504060588777065\n",
            "Train step - Step 19410, Loss 0.012630314566195011\n",
            "Train step - Step 19420, Loss 0.013576509431004524\n",
            "Train step - Step 19430, Loss 0.012208076193928719\n",
            "Train step - Step 19440, Loss 0.00988259632140398\n",
            "Train step - Step 19450, Loss 0.011178762651979923\n",
            "Train step - Step 19460, Loss 0.012747575528919697\n",
            "Train step - Step 19470, Loss 0.012469276785850525\n",
            "Train step - Step 19480, Loss 0.010928455740213394\n",
            "Train step - Step 19490, Loss 0.012771522626280785\n",
            "Train step - Step 19500, Loss 0.011934978887438774\n",
            "Train step - Step 19510, Loss 0.01034554187208414\n",
            "Train step - Step 19520, Loss 0.011693243868649006\n",
            "Train step - Step 19530, Loss 0.011955742724239826\n",
            "Train step - Step 19540, Loss 0.013758288696408272\n",
            "Train step - Step 19550, Loss 0.012364022433757782\n",
            "Train step - Step 19560, Loss 0.012443901970982552\n",
            "Train step - Step 19570, Loss 0.011573336087167263\n",
            "Train step - Step 19580, Loss 0.01075025461614132\n",
            "Train step - Step 19590, Loss 0.011143103241920471\n",
            "Train step - Step 19600, Loss 0.012080995365977287\n",
            "Train step - Step 19610, Loss 0.009929545223712921\n",
            "Train step - Step 19620, Loss 0.01159026101231575\n",
            "Train step - Step 19630, Loss 0.009826038032770157\n",
            "Train step - Step 19640, Loss 0.011378991417586803\n",
            "Train step - Step 19650, Loss 0.011418743059039116\n",
            "Train step - Step 19660, Loss 0.01185569353401661\n",
            "Train step - Step 19670, Loss 0.013940198346972466\n",
            "Train step - Step 19680, Loss 0.01170969195663929\n",
            "Train step - Step 19690, Loss 0.012604255229234695\n",
            "Train step - Step 19700, Loss 0.011675078421831131\n",
            "Train step - Step 19710, Loss 0.013219106942415237\n",
            "Train step - Step 19720, Loss 0.013902325183153152\n",
            "Train step - Step 19730, Loss 0.013367462903261185\n",
            "Train epoch - Accuracy: 0.7907070707070707 Loss: 0.012232260841612864 Corrects: 39140\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 19740, Loss 0.010412835516035557\n",
            "Train step - Step 19750, Loss 0.011207572184503078\n",
            "Train step - Step 19760, Loss 0.011006410233676434\n",
            "Train step - Step 19770, Loss 0.011124493554234505\n",
            "Train step - Step 19780, Loss 0.010003238916397095\n",
            "Train step - Step 19790, Loss 0.010155227966606617\n",
            "Train step - Step 19800, Loss 0.01105785183608532\n",
            "Train step - Step 19810, Loss 0.012113180011510849\n",
            "Train step - Step 19820, Loss 0.012379667721688747\n",
            "Train step - Step 19830, Loss 0.011747653596103191\n",
            "Train step - Step 19840, Loss 0.011340741999447346\n",
            "Train step - Step 19850, Loss 0.012099521234631538\n",
            "Train step - Step 19860, Loss 0.010071560740470886\n",
            "Train step - Step 19870, Loss 0.010094703175127506\n",
            "Train step - Step 19880, Loss 0.010287046432495117\n",
            "Train step - Step 19890, Loss 0.01051921583712101\n",
            "Train step - Step 19900, Loss 0.01080008689314127\n",
            "Train step - Step 19910, Loss 0.012474645860493183\n",
            "Train step - Step 19920, Loss 0.011469576507806778\n",
            "Train step - Step 19930, Loss 0.012009377591311932\n",
            "Train step - Step 19940, Loss 0.011018075980246067\n",
            "Train step - Step 19950, Loss 0.012729726731777191\n",
            "Train step - Step 19960, Loss 0.011867795139551163\n",
            "Train step - Step 19970, Loss 0.014234732836484909\n",
            "Train step - Step 19980, Loss 0.014049640856683254\n",
            "Train step - Step 19990, Loss 0.011063490994274616\n",
            "Train step - Step 20000, Loss 0.013616776093840599\n",
            "Train step - Step 20010, Loss 0.013145589269697666\n",
            "Train step - Step 20020, Loss 0.012366943061351776\n",
            "Train step - Step 20030, Loss 0.009164241142570972\n",
            "Train step - Step 20040, Loss 0.012420124374330044\n",
            "Train step - Step 20050, Loss 0.013027293607592583\n",
            "Train step - Step 20060, Loss 0.011112294159829617\n",
            "Train step - Step 20070, Loss 0.011538119055330753\n",
            "Train step - Step 20080, Loss 0.014166919514536858\n",
            "Train step - Step 20090, Loss 0.01163033489137888\n",
            "Train step - Step 20100, Loss 0.012239126488566399\n",
            "Train step - Step 20110, Loss 0.012020563706755638\n",
            "Train step - Step 20120, Loss 0.012078682892024517\n",
            "Train epoch - Accuracy: 0.7988080808080809 Loss: 0.011783372765312893 Corrects: 39541\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 20130, Loss 0.011212528683245182\n",
            "Train step - Step 20140, Loss 0.012901809997856617\n",
            "Train step - Step 20150, Loss 0.012363379821181297\n",
            "Train step - Step 20160, Loss 0.010068201459944248\n",
            "Train step - Step 20170, Loss 0.011816252954304218\n",
            "Train step - Step 20180, Loss 0.011934746988117695\n",
            "Train step - Step 20190, Loss 0.009386919438838959\n",
            "Train step - Step 20200, Loss 0.01184071321040392\n",
            "Train step - Step 20210, Loss 0.01203356496989727\n",
            "Train step - Step 20220, Loss 0.012632293626666069\n",
            "Train step - Step 20230, Loss 0.009380620904266834\n",
            "Train step - Step 20240, Loss 0.012852165848016739\n",
            "Train step - Step 20250, Loss 0.009787483140826225\n",
            "Train step - Step 20260, Loss 0.010813266970217228\n",
            "Train step - Step 20270, Loss 0.011142699047923088\n",
            "Train step - Step 20280, Loss 0.015795178711414337\n",
            "Train step - Step 20290, Loss 0.012246852740645409\n",
            "Train step - Step 20300, Loss 0.012701597064733505\n",
            "Train step - Step 20310, Loss 0.013172605074942112\n",
            "Train step - Step 20320, Loss 0.009677388705313206\n",
            "Train step - Step 20330, Loss 0.012417118065059185\n",
            "Train step - Step 20340, Loss 0.01137447077780962\n",
            "Train step - Step 20350, Loss 0.01205382402986288\n",
            "Train step - Step 20360, Loss 0.012752057984471321\n",
            "Train step - Step 20370, Loss 0.009952010586857796\n",
            "Train step - Step 20380, Loss 0.011417233385145664\n",
            "Train step - Step 20390, Loss 0.011563860811293125\n",
            "Train step - Step 20400, Loss 0.013429548591375351\n",
            "Train step - Step 20410, Loss 0.01317124255001545\n",
            "Train step - Step 20420, Loss 0.011489393189549446\n",
            "Train step - Step 20430, Loss 0.010907587595283985\n",
            "Train step - Step 20440, Loss 0.01075222622603178\n",
            "Train step - Step 20450, Loss 0.011355332098901272\n",
            "Train step - Step 20460, Loss 0.012526075355708599\n",
            "Train step - Step 20470, Loss 0.01301426999270916\n",
            "Train step - Step 20480, Loss 0.012891835533082485\n",
            "Train step - Step 20490, Loss 0.009649008512496948\n",
            "Train step - Step 20500, Loss 0.010647714138031006\n",
            "Train step - Step 20510, Loss 0.011344894766807556\n",
            "Train epoch - Accuracy: 0.8058383838383838 Loss: 0.01146769258349833 Corrects: 39889\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 20520, Loss 0.011529899202287197\n",
            "Train step - Step 20530, Loss 0.011272960342466831\n",
            "Train step - Step 20540, Loss 0.010956883430480957\n",
            "Train step - Step 20550, Loss 0.010114836506545544\n",
            "Train step - Step 20560, Loss 0.00958737637847662\n",
            "Train step - Step 20570, Loss 0.01142136286944151\n",
            "Train step - Step 20580, Loss 0.010993254370987415\n",
            "Train step - Step 20590, Loss 0.010686496272683144\n",
            "Train step - Step 20600, Loss 0.01393658947199583\n",
            "Train step - Step 20610, Loss 0.010331372730433941\n",
            "Train step - Step 20620, Loss 0.01172870397567749\n",
            "Train step - Step 20630, Loss 0.009000896476209164\n",
            "Train step - Step 20640, Loss 0.012853693217039108\n",
            "Train step - Step 20650, Loss 0.012163572944700718\n",
            "Train step - Step 20660, Loss 0.011566119268536568\n",
            "Train step - Step 20670, Loss 0.010401432402431965\n",
            "Train step - Step 20680, Loss 0.009607982821762562\n",
            "Train step - Step 20690, Loss 0.010358077473938465\n",
            "Train step - Step 20700, Loss 0.010961317457258701\n",
            "Train step - Step 20710, Loss 0.012734651565551758\n",
            "Train step - Step 20720, Loss 0.01083491463214159\n",
            "Train step - Step 20730, Loss 0.010613284073770046\n",
            "Train step - Step 20740, Loss 0.011089086532592773\n",
            "Train step - Step 20750, Loss 0.00935366377234459\n",
            "Train step - Step 20760, Loss 0.009404292330145836\n",
            "Train step - Step 20770, Loss 0.009986041113734245\n",
            "Train step - Step 20780, Loss 0.010717436671257019\n",
            "Train step - Step 20790, Loss 0.014721219427883625\n",
            "Train step - Step 20800, Loss 0.010311374440789223\n",
            "Train step - Step 20810, Loss 0.010153353214263916\n",
            "Train step - Step 20820, Loss 0.011459124274551868\n",
            "Train step - Step 20830, Loss 0.01251574233174324\n",
            "Train step - Step 20840, Loss 0.010847732424736023\n",
            "Train step - Step 20850, Loss 0.01037566177546978\n",
            "Train step - Step 20860, Loss 0.012193900533020496\n",
            "Train step - Step 20870, Loss 0.010770753026008606\n",
            "Train step - Step 20880, Loss 0.010032465681433678\n",
            "Train step - Step 20890, Loss 0.009164969436824322\n",
            "Train epoch - Accuracy: 0.8081414141414142 Loss: 0.011237086269741106 Corrects: 40003\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 20900, Loss 0.0113543551415205\n",
            "Train step - Step 20910, Loss 0.009757026098668575\n",
            "Train step - Step 20920, Loss 0.01107583288103342\n",
            "Train step - Step 20930, Loss 0.01017445046454668\n",
            "Train step - Step 20940, Loss 0.00936761125922203\n",
            "Train step - Step 20950, Loss 0.010586496442556381\n",
            "Train step - Step 20960, Loss 0.009595578536391258\n",
            "Train step - Step 20970, Loss 0.0112147256731987\n",
            "Train step - Step 20980, Loss 0.012483502738177776\n",
            "Train step - Step 20990, Loss 0.012834648601710796\n",
            "Train step - Step 21000, Loss 0.010130492970347404\n",
            "Train step - Step 21010, Loss 0.01038229651749134\n",
            "Train step - Step 21020, Loss 0.011998075060546398\n",
            "Train step - Step 21030, Loss 0.012065288610756397\n",
            "Train step - Step 21040, Loss 0.011864745058119297\n",
            "Train step - Step 21050, Loss 0.012771215289831161\n",
            "Train step - Step 21060, Loss 0.012765352614223957\n",
            "Train step - Step 21070, Loss 0.010441605933010578\n",
            "Train step - Step 21080, Loss 0.011240052990615368\n",
            "Train step - Step 21090, Loss 0.00788199808448553\n",
            "Train step - Step 21100, Loss 0.009569020941853523\n",
            "Train step - Step 21110, Loss 0.012474147602915764\n",
            "Train step - Step 21120, Loss 0.013665806502103806\n",
            "Train step - Step 21130, Loss 0.012174882926046848\n",
            "Train step - Step 21140, Loss 0.010620465502142906\n",
            "Train step - Step 21150, Loss 0.012982272543013096\n",
            "Train step - Step 21160, Loss 0.011897079646587372\n",
            "Train step - Step 21170, Loss 0.012314355000853539\n",
            "Train step - Step 21180, Loss 0.011549646966159344\n",
            "Train step - Step 21190, Loss 0.011976067908108234\n",
            "Train step - Step 21200, Loss 0.012616230174899101\n",
            "Train step - Step 21210, Loss 0.011306180618703365\n",
            "Train step - Step 21220, Loss 0.010102136060595512\n",
            "Train step - Step 21230, Loss 0.008646713569760323\n",
            "Train step - Step 21240, Loss 0.010813318192958832\n",
            "Train step - Step 21250, Loss 0.010168459266424179\n",
            "Train step - Step 21260, Loss 0.012438579462468624\n",
            "Train step - Step 21270, Loss 0.011832008138298988\n",
            "Train step - Step 21280, Loss 0.01168779470026493\n",
            "Train epoch - Accuracy: 0.8108686868686868 Loss: 0.011087565561888195 Corrects: 40138\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 21290, Loss 0.009481361135840416\n",
            "Train step - Step 21300, Loss 0.010381117463111877\n",
            "Train step - Step 21310, Loss 0.010596628300845623\n",
            "Train step - Step 21320, Loss 0.01097471360117197\n",
            "Train step - Step 21330, Loss 0.011063476093113422\n",
            "Train step - Step 21340, Loss 0.00976651068776846\n",
            "Train step - Step 21350, Loss 0.009759883396327496\n",
            "Train step - Step 21360, Loss 0.009955823421478271\n",
            "Train step - Step 21370, Loss 0.009586174972355366\n",
            "Train step - Step 21380, Loss 0.009361611679196358\n",
            "Train step - Step 21390, Loss 0.011136570014059544\n",
            "Train step - Step 21400, Loss 0.008534413762390614\n",
            "Train step - Step 21410, Loss 0.010851484723389149\n",
            "Train step - Step 21420, Loss 0.009126266464591026\n",
            "Train step - Step 21430, Loss 0.009902500547468662\n",
            "Train step - Step 21440, Loss 0.010938667692244053\n",
            "Train step - Step 21450, Loss 0.010263421572744846\n",
            "Train step - Step 21460, Loss 0.012201813980937004\n",
            "Train step - Step 21470, Loss 0.009788289666175842\n",
            "Train step - Step 21480, Loss 0.012594935484230518\n",
            "Train step - Step 21490, Loss 0.011242042295634747\n",
            "Train step - Step 21500, Loss 0.009930020198225975\n",
            "Train step - Step 21510, Loss 0.009717541746795177\n",
            "Train step - Step 21520, Loss 0.010796797461807728\n",
            "Train step - Step 21530, Loss 0.01165806781500578\n",
            "Train step - Step 21540, Loss 0.01013907603919506\n",
            "Train step - Step 21550, Loss 0.008527626283466816\n",
            "Train step - Step 21560, Loss 0.013246391899883747\n",
            "Train step - Step 21570, Loss 0.01144421100616455\n",
            "Train step - Step 21580, Loss 0.00910723116248846\n",
            "Train step - Step 21590, Loss 0.009783082641661167\n",
            "Train step - Step 21600, Loss 0.012531295418739319\n",
            "Train step - Step 21610, Loss 0.012093965895473957\n",
            "Train step - Step 21620, Loss 0.014183130115270615\n",
            "Train step - Step 21630, Loss 0.010482975281774998\n",
            "Train step - Step 21640, Loss 0.010164367035031319\n",
            "Train step - Step 21650, Loss 0.012101609259843826\n",
            "Train step - Step 21660, Loss 0.010550066828727722\n",
            "Train step - Step 21670, Loss 0.009582314640283585\n",
            "Train epoch - Accuracy: 0.8137575757575758 Loss: 0.010962306444241543 Corrects: 40281\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 21680, Loss 0.012209270149469376\n",
            "Train step - Step 21690, Loss 0.008684419095516205\n",
            "Train step - Step 21700, Loss 0.010482239536941051\n",
            "Train step - Step 21710, Loss 0.014979724772274494\n",
            "Train step - Step 21720, Loss 0.012512177228927612\n",
            "Train step - Step 21730, Loss 0.011129127815365791\n",
            "Train step - Step 21740, Loss 0.012414698489010334\n",
            "Train step - Step 21750, Loss 0.010926613584160805\n",
            "Train step - Step 21760, Loss 0.009889943525195122\n",
            "Train step - Step 21770, Loss 0.00824335403740406\n",
            "Train step - Step 21780, Loss 0.011167630553245544\n",
            "Train step - Step 21790, Loss 0.009595809504389763\n",
            "Train step - Step 21800, Loss 0.009734478779137135\n",
            "Train step - Step 21810, Loss 0.011118916794657707\n",
            "Train step - Step 21820, Loss 0.010201883502304554\n",
            "Train step - Step 21830, Loss 0.011407427489757538\n",
            "Train step - Step 21840, Loss 0.01039168331772089\n",
            "Train step - Step 21850, Loss 0.008927312679588795\n",
            "Train step - Step 21860, Loss 0.011260326020419598\n",
            "Train step - Step 21870, Loss 0.011655953712761402\n",
            "Train step - Step 21880, Loss 0.011655868962407112\n",
            "Train step - Step 21890, Loss 0.012072422541677952\n",
            "Train step - Step 21900, Loss 0.009283684194087982\n",
            "Train step - Step 21910, Loss 0.010429692454636097\n",
            "Train step - Step 21920, Loss 0.01319498848170042\n",
            "Train step - Step 21930, Loss 0.011377381160855293\n",
            "Train step - Step 21940, Loss 0.012786312028765678\n",
            "Train step - Step 21950, Loss 0.010835828259587288\n",
            "Train step - Step 21960, Loss 0.0109766386449337\n",
            "Train step - Step 21970, Loss 0.011104317381978035\n",
            "Train step - Step 21980, Loss 0.010197507217526436\n",
            "Train step - Step 21990, Loss 0.012566263787448406\n",
            "Train step - Step 22000, Loss 0.01328118983656168\n",
            "Train step - Step 22010, Loss 0.012197809293866158\n",
            "Train step - Step 22020, Loss 0.010914638638496399\n",
            "Train step - Step 22030, Loss 0.009855328127741814\n",
            "Train step - Step 22040, Loss 0.011809772811830044\n",
            "Train step - Step 22050, Loss 0.010989493690431118\n",
            "Train epoch - Accuracy: 0.8149090909090909 Loss: 0.010842464202205943 Corrects: 40338\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 22060, Loss 0.008729100227355957\n",
            "Train step - Step 22070, Loss 0.009406927973031998\n",
            "Train step - Step 22080, Loss 0.010546592995524406\n",
            "Train step - Step 22090, Loss 0.011174776591360569\n",
            "Train step - Step 22100, Loss 0.008355601690709591\n",
            "Train step - Step 22110, Loss 0.010241321288049221\n",
            "Train step - Step 22120, Loss 0.01081851590424776\n",
            "Train step - Step 22130, Loss 0.011083032004535198\n",
            "Train step - Step 22140, Loss 0.009523910470306873\n",
            "Train step - Step 22150, Loss 0.00873614102602005\n",
            "Train step - Step 22160, Loss 0.012311961501836777\n",
            "Train step - Step 22170, Loss 0.011445675045251846\n",
            "Train step - Step 22180, Loss 0.015264706686139107\n",
            "Train step - Step 22190, Loss 0.007820222526788712\n",
            "Train step - Step 22200, Loss 0.011375674977898598\n",
            "Train step - Step 22210, Loss 0.01104589644819498\n",
            "Train step - Step 22220, Loss 0.012169054709374905\n",
            "Train step - Step 22230, Loss 0.011418644338846207\n",
            "Train step - Step 22240, Loss 0.009907498955726624\n",
            "Train step - Step 22250, Loss 0.013628450222313404\n",
            "Train step - Step 22260, Loss 0.011140265502035618\n",
            "Train step - Step 22270, Loss 0.010944749228656292\n",
            "Train step - Step 22280, Loss 0.01043910626322031\n",
            "Train step - Step 22290, Loss 0.01187959872186184\n",
            "Train step - Step 22300, Loss 0.010905266739428043\n",
            "Train step - Step 22310, Loss 0.013426613062620163\n",
            "Train step - Step 22320, Loss 0.012163043022155762\n",
            "Train step - Step 22330, Loss 0.00972966942936182\n",
            "Train step - Step 22340, Loss 0.010425654239952564\n",
            "Train step - Step 22350, Loss 0.012858273461461067\n",
            "Train step - Step 22360, Loss 0.009997672401368618\n",
            "Train step - Step 22370, Loss 0.011812503449618816\n",
            "Train step - Step 22380, Loss 0.010599472559988499\n",
            "Train step - Step 22390, Loss 0.012182080186903477\n",
            "Train step - Step 22400, Loss 0.011872329749166965\n",
            "Train step - Step 22410, Loss 0.012837810441851616\n",
            "Train step - Step 22420, Loss 0.011978652328252792\n",
            "Train step - Step 22430, Loss 0.012286071665585041\n",
            "Train step - Step 22440, Loss 0.01105202455073595\n",
            "Train epoch - Accuracy: 0.8194747474747475 Loss: 0.010722814583191366 Corrects: 40564\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 22450, Loss 0.00815234798938036\n",
            "Train step - Step 22460, Loss 0.014803695492446423\n",
            "Train step - Step 22470, Loss 0.01279805414378643\n",
            "Train step - Step 22480, Loss 0.00931478664278984\n",
            "Train step - Step 22490, Loss 0.011102596297860146\n",
            "Train step - Step 22500, Loss 0.011006629094481468\n",
            "Train step - Step 22510, Loss 0.011264287866652012\n",
            "Train step - Step 22520, Loss 0.009095591492950916\n",
            "Train step - Step 22530, Loss 0.007756618317216635\n",
            "Train step - Step 22540, Loss 0.008595488034188747\n",
            "Train step - Step 22550, Loss 0.009776907972991467\n",
            "Train step - Step 22560, Loss 0.009570388123393059\n",
            "Train step - Step 22570, Loss 0.009194588288664818\n",
            "Train step - Step 22580, Loss 0.009908013977110386\n",
            "Train step - Step 22590, Loss 0.009932450950145721\n",
            "Train step - Step 22600, Loss 0.009993452578783035\n",
            "Train step - Step 22610, Loss 0.01103388611227274\n",
            "Train step - Step 22620, Loss 0.010230404324829578\n",
            "Train step - Step 22630, Loss 0.01291501522064209\n",
            "Train step - Step 22640, Loss 0.009123356081545353\n",
            "Train step - Step 22650, Loss 0.009936745278537273\n",
            "Train step - Step 22660, Loss 0.012074651196599007\n",
            "Train step - Step 22670, Loss 0.01091831922531128\n",
            "Train step - Step 22680, Loss 0.010837611742317677\n",
            "Train step - Step 22690, Loss 0.008411272428929806\n",
            "Train step - Step 22700, Loss 0.010182463563978672\n",
            "Train step - Step 22710, Loss 0.011050162836909294\n",
            "Train step - Step 22720, Loss 0.009134466759860516\n",
            "Train step - Step 22730, Loss 0.009802456945180893\n",
            "Train step - Step 22740, Loss 0.009630241431295872\n",
            "Train step - Step 22750, Loss 0.011984617449343204\n",
            "Train step - Step 22760, Loss 0.012271811254322529\n",
            "Train step - Step 22770, Loss 0.010257548652589321\n",
            "Train step - Step 22780, Loss 0.011301437392830849\n",
            "Train step - Step 22790, Loss 0.01219521276652813\n",
            "Train step - Step 22800, Loss 0.010879109613597393\n",
            "Train step - Step 22810, Loss 0.009334404021501541\n",
            "Train step - Step 22820, Loss 0.011640300042927265\n",
            "Train step - Step 22830, Loss 0.013050553388893604\n",
            "Train epoch - Accuracy: 0.8211313131313132 Loss: 0.010646605648025118 Corrects: 40646\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 22840, Loss 0.008455997332930565\n",
            "Train step - Step 22850, Loss 0.010439109988510609\n",
            "Train step - Step 22860, Loss 0.011624605394899845\n",
            "Train step - Step 22870, Loss 0.009637279435992241\n",
            "Train step - Step 22880, Loss 0.009095534682273865\n",
            "Train step - Step 22890, Loss 0.01267959363758564\n",
            "Train step - Step 22900, Loss 0.009429369121789932\n",
            "Train step - Step 22910, Loss 0.010240064933896065\n",
            "Train step - Step 22920, Loss 0.010441550053656101\n",
            "Train step - Step 22930, Loss 0.009637346491217613\n",
            "Train step - Step 22940, Loss 0.010013768449425697\n",
            "Train step - Step 22950, Loss 0.008611157536506653\n",
            "Train step - Step 22960, Loss 0.011543919332325459\n",
            "Train step - Step 22970, Loss 0.008805730380117893\n",
            "Train step - Step 22980, Loss 0.012295867316424847\n",
            "Train step - Step 22990, Loss 0.01081889122724533\n",
            "Train step - Step 23000, Loss 0.00851602852344513\n",
            "Train step - Step 23010, Loss 0.0095945093780756\n",
            "Train step - Step 23020, Loss 0.013642542995512486\n",
            "Train step - Step 23030, Loss 0.010876900516450405\n",
            "Train step - Step 23040, Loss 0.011988908983767033\n",
            "Train step - Step 23050, Loss 0.009795745834708214\n",
            "Train step - Step 23060, Loss 0.0133385444059968\n",
            "Train step - Step 23070, Loss 0.009716961532831192\n",
            "Train step - Step 23080, Loss 0.011602256447076797\n",
            "Train step - Step 23090, Loss 0.011194338090717793\n",
            "Train step - Step 23100, Loss 0.011088745668530464\n",
            "Train step - Step 23110, Loss 0.011765588074922562\n",
            "Train step - Step 23120, Loss 0.012868042103946209\n",
            "Train step - Step 23130, Loss 0.012884433381259441\n",
            "Train step - Step 23140, Loss 0.009873892180621624\n",
            "Train step - Step 23150, Loss 0.00981916207820177\n",
            "Train step - Step 23160, Loss 0.009507435373961926\n",
            "Train step - Step 23170, Loss 0.012422091327607632\n",
            "Train step - Step 23180, Loss 0.011351315304636955\n",
            "Train step - Step 23190, Loss 0.009815116412937641\n",
            "Train step - Step 23200, Loss 0.011798049323260784\n",
            "Train step - Step 23210, Loss 0.010509835556149483\n",
            "Train epoch - Accuracy: 0.820929292929293 Loss: 0.010602972833721927 Corrects: 40636\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 23220, Loss 0.00997213739901781\n",
            "Train step - Step 23230, Loss 0.010127929970622063\n",
            "Train step - Step 23240, Loss 0.010567794553935528\n",
            "Train step - Step 23250, Loss 0.011913620866835117\n",
            "Train step - Step 23260, Loss 0.008346750400960445\n",
            "Train step - Step 23270, Loss 0.010016635060310364\n",
            "Train step - Step 23280, Loss 0.009541396051645279\n",
            "Train step - Step 23290, Loss 0.011534602381289005\n",
            "Train step - Step 23300, Loss 0.009476360864937305\n",
            "Train step - Step 23310, Loss 0.010977473109960556\n",
            "Train step - Step 23320, Loss 0.011520798318088055\n",
            "Train step - Step 23330, Loss 0.00903244037181139\n",
            "Train step - Step 23340, Loss 0.01276893075555563\n",
            "Train step - Step 23350, Loss 0.0102759450674057\n",
            "Train step - Step 23360, Loss 0.012816895730793476\n",
            "Train step - Step 23370, Loss 0.009177488274872303\n",
            "Train step - Step 23380, Loss 0.00791832897812128\n",
            "Train step - Step 23390, Loss 0.010666265152394772\n",
            "Train step - Step 23400, Loss 0.012682495638728142\n",
            "Train step - Step 23410, Loss 0.010584158822894096\n",
            "Train step - Step 23420, Loss 0.01015800703316927\n",
            "Train step - Step 23430, Loss 0.013899319805204868\n",
            "Train step - Step 23440, Loss 0.009101239033043385\n",
            "Train step - Step 23450, Loss 0.009558205492794514\n",
            "Train step - Step 23460, Loss 0.011466238647699356\n",
            "Train step - Step 23470, Loss 0.013882412575185299\n",
            "Train step - Step 23480, Loss 0.011025476269423962\n",
            "Train step - Step 23490, Loss 0.01232124213129282\n",
            "Train step - Step 23500, Loss 0.009611973538994789\n",
            "Train step - Step 23510, Loss 0.013150778599083424\n",
            "Train step - Step 23520, Loss 0.011951157823204994\n",
            "Train step - Step 23530, Loss 0.008748045191168785\n",
            "Train step - Step 23540, Loss 0.010743381455540657\n",
            "Train step - Step 23550, Loss 0.009974570944905281\n",
            "Train step - Step 23560, Loss 0.009994530119001865\n",
            "Train step - Step 23570, Loss 0.011937414295971394\n",
            "Train step - Step 23580, Loss 0.010711628943681717\n",
            "Train step - Step 23590, Loss 0.012630118988454342\n",
            "Train step - Step 23600, Loss 0.0118803009390831\n",
            "Train epoch - Accuracy: 0.8174747474747475 Loss: 0.010664121094300892 Corrects: 40465\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 23610, Loss 0.008283190429210663\n",
            "Train step - Step 23620, Loss 0.011157326400279999\n",
            "Train step - Step 23630, Loss 0.008559283800423145\n",
            "Train step - Step 23640, Loss 0.008121799677610397\n",
            "Train step - Step 23650, Loss 0.00812615267932415\n",
            "Train step - Step 23660, Loss 0.0094540324062109\n",
            "Train step - Step 23670, Loss 0.009127872064709663\n",
            "Train step - Step 23680, Loss 0.012457436881959438\n",
            "Train step - Step 23690, Loss 0.009043063037097454\n",
            "Train step - Step 23700, Loss 0.009124867618083954\n",
            "Train step - Step 23710, Loss 0.010705454275012016\n",
            "Train step - Step 23720, Loss 0.007387162651866674\n",
            "Train step - Step 23730, Loss 0.011675029993057251\n",
            "Train step - Step 23740, Loss 0.00859155971556902\n",
            "Train step - Step 23750, Loss 0.009356134571135044\n",
            "Train step - Step 23760, Loss 0.010096808895468712\n",
            "Train step - Step 23770, Loss 0.012749516405165195\n",
            "Train step - Step 23780, Loss 0.01261017844080925\n",
            "Train step - Step 23790, Loss 0.009608921594917774\n",
            "Train step - Step 23800, Loss 0.011511372402310371\n",
            "Train step - Step 23810, Loss 0.011085344478487968\n",
            "Train step - Step 23820, Loss 0.013409360311925411\n",
            "Train step - Step 23830, Loss 0.008795357309281826\n",
            "Train step - Step 23840, Loss 0.009557674638926983\n",
            "Train step - Step 23850, Loss 0.011082906275987625\n",
            "Train step - Step 23860, Loss 0.011474397033452988\n",
            "Train step - Step 23870, Loss 0.011076834052801132\n",
            "Train step - Step 23880, Loss 0.01073796022683382\n",
            "Train step - Step 23890, Loss 0.01328518521040678\n",
            "Train step - Step 23900, Loss 0.00921229925006628\n",
            "Train step - Step 23910, Loss 0.012840536423027515\n",
            "Train step - Step 23920, Loss 0.01051551103591919\n",
            "Train step - Step 23930, Loss 0.009674794040620327\n",
            "Train step - Step 23940, Loss 0.01397661678493023\n",
            "Train step - Step 23950, Loss 0.011509865522384644\n",
            "Train step - Step 23960, Loss 0.011356470175087452\n",
            "Train step - Step 23970, Loss 0.011849203146994114\n",
            "Train step - Step 23980, Loss 0.010636625811457634\n",
            "Train step - Step 23990, Loss 0.010076927952468395\n",
            "Train epoch - Accuracy: 0.8222828282828283 Loss: 0.010608001631995042 Corrects: 40703\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 24000, Loss 0.00905769132077694\n",
            "Train step - Step 24010, Loss 0.011051583103835583\n",
            "Train step - Step 24020, Loss 0.009422765113413334\n",
            "Train step - Step 24030, Loss 0.010536002926528454\n",
            "Train step - Step 24040, Loss 0.010938000865280628\n",
            "Train step - Step 24050, Loss 0.009603725746273994\n",
            "Train step - Step 24060, Loss 0.011435589753091335\n",
            "Train step - Step 24070, Loss 0.01038116030395031\n",
            "Train step - Step 24080, Loss 0.011241002008318901\n",
            "Train step - Step 24090, Loss 0.010443371720612049\n",
            "Train step - Step 24100, Loss 0.009338711388409138\n",
            "Train step - Step 24110, Loss 0.010080577805638313\n",
            "Train step - Step 24120, Loss 0.009335102513432503\n",
            "Train step - Step 24130, Loss 0.008386070840060711\n",
            "Train step - Step 24140, Loss 0.010097645223140717\n",
            "Train step - Step 24150, Loss 0.01382896862924099\n",
            "Train step - Step 24160, Loss 0.012391015887260437\n",
            "Train step - Step 24170, Loss 0.010902113281190395\n",
            "Train step - Step 24180, Loss 0.010796774178743362\n",
            "Train step - Step 24190, Loss 0.010779157280921936\n",
            "Train step - Step 24200, Loss 0.009300554171204567\n",
            "Train step - Step 24210, Loss 0.011311017908155918\n",
            "Train step - Step 24220, Loss 0.01086458284407854\n",
            "Train step - Step 24230, Loss 0.010997393168509007\n",
            "Train step - Step 24240, Loss 0.012177295051515102\n",
            "Train step - Step 24250, Loss 0.011701171286404133\n",
            "Train step - Step 24260, Loss 0.011777935549616814\n",
            "Train step - Step 24270, Loss 0.009650319814682007\n",
            "Train step - Step 24280, Loss 0.011045734398066998\n",
            "Train step - Step 24290, Loss 0.010239711031317711\n",
            "Train step - Step 24300, Loss 0.010128450579941273\n",
            "Train step - Step 24310, Loss 0.009197145700454712\n",
            "Train step - Step 24320, Loss 0.008631146512925625\n",
            "Train step - Step 24330, Loss 0.01089984830468893\n",
            "Train step - Step 24340, Loss 0.011884281411767006\n",
            "Train step - Step 24350, Loss 0.011610686779022217\n",
            "Train step - Step 24360, Loss 0.00938983540982008\n",
            "Train step - Step 24370, Loss 0.011871788650751114\n",
            "Train step - Step 24380, Loss 0.010670348070561886\n",
            "Train epoch - Accuracy: 0.8216969696969697 Loss: 0.010503918613523545 Corrects: 40674\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 24390, Loss 0.010795659385621548\n",
            "Train step - Step 24400, Loss 0.010257123038172722\n",
            "Train step - Step 24410, Loss 0.010449056513607502\n",
            "Train step - Step 24420, Loss 0.01083358097821474\n",
            "Train step - Step 24430, Loss 0.008551139384508133\n",
            "Train step - Step 24440, Loss 0.009811305440962315\n",
            "Train step - Step 24450, Loss 0.009649856016039848\n",
            "Train step - Step 24460, Loss 0.00866938941180706\n",
            "Train step - Step 24470, Loss 0.010357990860939026\n",
            "Train step - Step 24480, Loss 0.009920229203999043\n",
            "Train step - Step 24490, Loss 0.007724795024842024\n",
            "Train step - Step 24500, Loss 0.009638280607759953\n",
            "Train step - Step 24510, Loss 0.010470123030245304\n",
            "Train step - Step 24520, Loss 0.008841416798532009\n",
            "Train step - Step 24530, Loss 0.00637327553704381\n",
            "Train step - Step 24540, Loss 0.008846386335790157\n",
            "Train step - Step 24550, Loss 0.006252272054553032\n",
            "Train step - Step 24560, Loss 0.009986026212573051\n",
            "Train step - Step 24570, Loss 0.009860609658062458\n",
            "Train step - Step 24580, Loss 0.008983554318547249\n",
            "Train step - Step 24590, Loss 0.009281441569328308\n",
            "Train step - Step 24600, Loss 0.0077619170770049095\n",
            "Train step - Step 24610, Loss 0.008519122377038002\n",
            "Train step - Step 24620, Loss 0.00735183572396636\n",
            "Train step - Step 24630, Loss 0.007965500466525555\n",
            "Train step - Step 24640, Loss 0.008092506788671017\n",
            "Train step - Step 24650, Loss 0.010228903032839298\n",
            "Train step - Step 24660, Loss 0.00820530392229557\n",
            "Train step - Step 24670, Loss 0.009310049936175346\n",
            "Train step - Step 24680, Loss 0.009801719337701797\n",
            "Train step - Step 24690, Loss 0.008415821939706802\n",
            "Train step - Step 24700, Loss 0.008798058144748211\n",
            "Train step - Step 24710, Loss 0.008595016784965992\n",
            "Train step - Step 24720, Loss 0.008077066391706467\n",
            "Train step - Step 24730, Loss 0.008841877803206444\n",
            "Train step - Step 24740, Loss 0.00808947067707777\n",
            "Train step - Step 24750, Loss 0.009473149664700031\n",
            "Train step - Step 24760, Loss 0.00827589351683855\n",
            "Train epoch - Accuracy: 0.8517575757575757 Loss: 0.009166158300231804 Corrects: 42162\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 24770, Loss 0.00982838124036789\n",
            "Train step - Step 24780, Loss 0.011889745481312275\n",
            "Train step - Step 24790, Loss 0.008817552588880062\n",
            "Train step - Step 24800, Loss 0.007317537907510996\n",
            "Train step - Step 24810, Loss 0.00832073763012886\n",
            "Train step - Step 24820, Loss 0.010509065352380276\n",
            "Train step - Step 24830, Loss 0.0093154888600111\n",
            "Train step - Step 24840, Loss 0.008390642702579498\n",
            "Train step - Step 24850, Loss 0.008708791807293892\n",
            "Train step - Step 24860, Loss 0.00989359337836504\n",
            "Train step - Step 24870, Loss 0.006623363122344017\n",
            "Train step - Step 24880, Loss 0.007458873093128204\n",
            "Train step - Step 24890, Loss 0.007359455805271864\n",
            "Train step - Step 24900, Loss 0.008005185052752495\n",
            "Train step - Step 24910, Loss 0.009363548830151558\n",
            "Train step - Step 24920, Loss 0.010477921925485134\n",
            "Train step - Step 24930, Loss 0.007692150771617889\n",
            "Train step - Step 24940, Loss 0.007349770050495863\n",
            "Train step - Step 24950, Loss 0.009378110058605671\n",
            "Train step - Step 24960, Loss 0.00713214511051774\n",
            "Train step - Step 24970, Loss 0.007136117201298475\n",
            "Train step - Step 24980, Loss 0.00852297991514206\n",
            "Train step - Step 24990, Loss 0.007358591537922621\n",
            "Train step - Step 25000, Loss 0.008672411553561687\n",
            "Train step - Step 25010, Loss 0.012394633144140244\n",
            "Train step - Step 25020, Loss 0.007534924428910017\n",
            "Train step - Step 25030, Loss 0.010252130217850208\n",
            "Train step - Step 25040, Loss 0.008687020279467106\n",
            "Train step - Step 25050, Loss 0.010428223758935928\n",
            "Train step - Step 25060, Loss 0.009622296318411827\n",
            "Train step - Step 25070, Loss 0.009070074185729027\n",
            "Train step - Step 25080, Loss 0.008181223645806313\n",
            "Train step - Step 25090, Loss 0.007052041590213776\n",
            "Train step - Step 25100, Loss 0.009489981457591057\n",
            "Train step - Step 25110, Loss 0.010080760344862938\n",
            "Train step - Step 25120, Loss 0.009966745041310787\n",
            "Train step - Step 25130, Loss 0.008391967043280602\n",
            "Train step - Step 25140, Loss 0.01012430153787136\n",
            "Train step - Step 25150, Loss 0.007240447215735912\n",
            "Train epoch - Accuracy: 0.8596161616161616 Loss: 0.008738985494456508 Corrects: 42551\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 25160, Loss 0.008877072483301163\n",
            "Train step - Step 25170, Loss 0.008844203315675259\n",
            "Train step - Step 25180, Loss 0.01031591184437275\n",
            "Train step - Step 25190, Loss 0.006885673850774765\n",
            "Train step - Step 25200, Loss 0.00914367102086544\n",
            "Train step - Step 25210, Loss 0.008588017895817757\n",
            "Train step - Step 25220, Loss 0.010215560905635357\n",
            "Train step - Step 25230, Loss 0.007948534563183784\n",
            "Train step - Step 25240, Loss 0.006625909823924303\n",
            "Train step - Step 25250, Loss 0.007999470457434654\n",
            "Train step - Step 25260, Loss 0.006053950637578964\n",
            "Train step - Step 25270, Loss 0.008135482668876648\n",
            "Train step - Step 25280, Loss 0.008145817555487156\n",
            "Train step - Step 25290, Loss 0.0076471189968287945\n",
            "Train step - Step 25300, Loss 0.010592381469905376\n",
            "Train step - Step 25310, Loss 0.008099411614239216\n",
            "Train step - Step 25320, Loss 0.00869397260248661\n",
            "Train step - Step 25330, Loss 0.00948399119079113\n",
            "Train step - Step 25340, Loss 0.009116657078266144\n",
            "Train step - Step 25350, Loss 0.008211284875869751\n",
            "Train step - Step 25360, Loss 0.008082322776317596\n",
            "Train step - Step 25370, Loss 0.00813857652246952\n",
            "Train step - Step 25380, Loss 0.009980550967156887\n",
            "Train step - Step 25390, Loss 0.009692971594631672\n",
            "Train step - Step 25400, Loss 0.008667003363370895\n",
            "Train step - Step 25410, Loss 0.009254248812794685\n",
            "Train step - Step 25420, Loss 0.009605782106518745\n",
            "Train step - Step 25430, Loss 0.009240931831300259\n",
            "Train step - Step 25440, Loss 0.008659751154482365\n",
            "Train step - Step 25450, Loss 0.009367999620735645\n",
            "Train step - Step 25460, Loss 0.0100612947717309\n",
            "Train step - Step 25470, Loss 0.009446674957871437\n",
            "Train step - Step 25480, Loss 0.007346461992710829\n",
            "Train step - Step 25490, Loss 0.00698493979871273\n",
            "Train step - Step 25500, Loss 0.007758440915495157\n",
            "Train step - Step 25510, Loss 0.00840720720589161\n",
            "Train step - Step 25520, Loss 0.0074935792945325375\n",
            "Train step - Step 25530, Loss 0.008672405034303665\n",
            "Train step - Step 25540, Loss 0.008715184405446053\n",
            "Train epoch - Accuracy: 0.8649494949494949 Loss: 0.008531931159848516 Corrects: 42815\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 25550, Loss 0.007685864809900522\n",
            "Train step - Step 25560, Loss 0.009250202216207981\n",
            "Train step - Step 25570, Loss 0.007340674754232168\n",
            "Train step - Step 25580, Loss 0.005911847110837698\n",
            "Train step - Step 25590, Loss 0.007723360322415829\n",
            "Train step - Step 25600, Loss 0.010124113410711288\n",
            "Train step - Step 25610, Loss 0.006839606445282698\n",
            "Train step - Step 25620, Loss 0.008402465842664242\n",
            "Train step - Step 25630, Loss 0.008394758217036724\n",
            "Train step - Step 25640, Loss 0.007407741155475378\n",
            "Train step - Step 25650, Loss 0.009110418148338795\n",
            "Train step - Step 25660, Loss 0.007917664013803005\n",
            "Train step - Step 25670, Loss 0.008045526221394539\n",
            "Train step - Step 25680, Loss 0.009294826537370682\n",
            "Train step - Step 25690, Loss 0.006563746836036444\n",
            "Train step - Step 25700, Loss 0.008043069392442703\n",
            "Train step - Step 25710, Loss 0.011805071495473385\n",
            "Train step - Step 25720, Loss 0.007977779023349285\n",
            "Train step - Step 25730, Loss 0.006654088385403156\n",
            "Train step - Step 25740, Loss 0.007974379695951939\n",
            "Train step - Step 25750, Loss 0.007458108011633158\n",
            "Train step - Step 25760, Loss 0.007429680787026882\n",
            "Train step - Step 25770, Loss 0.009505282156169415\n",
            "Train step - Step 25780, Loss 0.0071553997695446014\n",
            "Train step - Step 25790, Loss 0.008420673198997974\n",
            "Train step - Step 25800, Loss 0.010953285731375217\n",
            "Train step - Step 25810, Loss 0.009309174492955208\n",
            "Train step - Step 25820, Loss 0.008479614742100239\n",
            "Train step - Step 25830, Loss 0.009163320995867252\n",
            "Train step - Step 25840, Loss 0.008410348556935787\n",
            "Train step - Step 25850, Loss 0.008291024714708328\n",
            "Train step - Step 25860, Loss 0.010985388420522213\n",
            "Train step - Step 25870, Loss 0.009074526838958263\n",
            "Train step - Step 25880, Loss 0.009028617292642593\n",
            "Train step - Step 25890, Loss 0.006783848628401756\n",
            "Train step - Step 25900, Loss 0.007193576078861952\n",
            "Train step - Step 25910, Loss 0.006047010887414217\n",
            "Train step - Step 25920, Loss 0.008201679214835167\n",
            "Train epoch - Accuracy: 0.8677979797979798 Loss: 0.008394983493544237 Corrects: 42956\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 25930, Loss 0.008697488345205784\n",
            "Train step - Step 25940, Loss 0.010249334387481213\n",
            "Train step - Step 25950, Loss 0.006588391959667206\n",
            "Train step - Step 25960, Loss 0.006211560219526291\n",
            "Train step - Step 25970, Loss 0.007874778471887112\n",
            "Train step - Step 25980, Loss 0.00728081027045846\n",
            "Train step - Step 25990, Loss 0.00876222550868988\n",
            "Train step - Step 26000, Loss 0.008164424449205399\n",
            "Train step - Step 26010, Loss 0.007306133862584829\n",
            "Train step - Step 26020, Loss 0.00784982554614544\n",
            "Train step - Step 26030, Loss 0.00823375303298235\n",
            "Train step - Step 26040, Loss 0.006138512399047613\n",
            "Train step - Step 26050, Loss 0.00818028673529625\n",
            "Train step - Step 26060, Loss 0.01017079222947359\n",
            "Train step - Step 26070, Loss 0.007514668628573418\n",
            "Train step - Step 26080, Loss 0.008018627762794495\n",
            "Train step - Step 26090, Loss 0.009346435777842999\n",
            "Train step - Step 26100, Loss 0.009695080108940601\n",
            "Train step - Step 26110, Loss 0.008366111665964127\n",
            "Train step - Step 26120, Loss 0.009116651490330696\n",
            "Train step - Step 26130, Loss 0.008821606636047363\n",
            "Train step - Step 26140, Loss 0.007340095471590757\n",
            "Train step - Step 26150, Loss 0.006769916042685509\n",
            "Train step - Step 26160, Loss 0.008438747376203537\n",
            "Train step - Step 26170, Loss 0.007899128831923008\n",
            "Train step - Step 26180, Loss 0.007988542318344116\n",
            "Train step - Step 26190, Loss 0.0070567140355706215\n",
            "Train step - Step 26200, Loss 0.007264718879014254\n",
            "Train step - Step 26210, Loss 0.00931495614349842\n",
            "Train step - Step 26220, Loss 0.006082930602133274\n",
            "Train step - Step 26230, Loss 0.008435259573161602\n",
            "Train step - Step 26240, Loss 0.008540602400898933\n",
            "Train step - Step 26250, Loss 0.008939709514379501\n",
            "Train step - Step 26260, Loss 0.008190580643713474\n",
            "Train step - Step 26270, Loss 0.008379118517041206\n",
            "Train step - Step 26280, Loss 0.007594048045575619\n",
            "Train step - Step 26290, Loss 0.009190394543111324\n",
            "Train step - Step 26300, Loss 0.007185276597738266\n",
            "Train step - Step 26310, Loss 0.008410312235355377\n",
            "Train epoch - Accuracy: 0.8707676767676767 Loss: 0.008282605374551782 Corrects: 43103\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 26320, Loss 0.006835995241999626\n",
            "Train step - Step 26330, Loss 0.009854299947619438\n",
            "Train step - Step 26340, Loss 0.008645053021609783\n",
            "Train step - Step 26350, Loss 0.010033540427684784\n",
            "Train step - Step 26360, Loss 0.009534768760204315\n",
            "Train step - Step 26370, Loss 0.009372010827064514\n",
            "Train step - Step 26380, Loss 0.0072028241120278835\n",
            "Train step - Step 26390, Loss 0.007321499288082123\n",
            "Train step - Step 26400, Loss 0.007786753587424755\n",
            "Train step - Step 26410, Loss 0.007427482400089502\n",
            "Train step - Step 26420, Loss 0.008820912800729275\n",
            "Train step - Step 26430, Loss 0.008235758170485497\n",
            "Train step - Step 26440, Loss 0.006692696828395128\n",
            "Train step - Step 26450, Loss 0.0078562768176198\n",
            "Train step - Step 26460, Loss 0.009301712736487389\n",
            "Train step - Step 26470, Loss 0.007788854651153088\n",
            "Train step - Step 26480, Loss 0.0076079582795500755\n",
            "Train step - Step 26490, Loss 0.009875541552901268\n",
            "Train step - Step 26500, Loss 0.008225677534937859\n",
            "Train step - Step 26510, Loss 0.007779595907777548\n",
            "Train step - Step 26520, Loss 0.008163096383213997\n",
            "Train step - Step 26530, Loss 0.0077360388822853565\n",
            "Train step - Step 26540, Loss 0.009807828813791275\n",
            "Train step - Step 26550, Loss 0.009300237521529198\n",
            "Train step - Step 26560, Loss 0.009150891564786434\n",
            "Train step - Step 26570, Loss 0.010441119782626629\n",
            "Train step - Step 26580, Loss 0.00925358198583126\n",
            "Train step - Step 26590, Loss 0.007417712826281786\n",
            "Train step - Step 26600, Loss 0.0062953815795481205\n",
            "Train step - Step 26610, Loss 0.00721388915553689\n",
            "Train step - Step 26620, Loss 0.009076413698494434\n",
            "Train step - Step 26630, Loss 0.008183171972632408\n",
            "Train step - Step 26640, Loss 0.008039859123528004\n",
            "Train step - Step 26650, Loss 0.00949749257415533\n",
            "Train step - Step 26660, Loss 0.009465123526751995\n",
            "Train step - Step 26670, Loss 0.006008555646985769\n",
            "Train step - Step 26680, Loss 0.009491723962128162\n",
            "Train step - Step 26690, Loss 0.0075226472690701485\n",
            "Train step - Step 26700, Loss 0.006712094880640507\n",
            "Train epoch - Accuracy: 0.8707474747474747 Loss: 0.008305606234254258 Corrects: 43102\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 26710, Loss 0.006630228832364082\n",
            "Train step - Step 26720, Loss 0.008147181943058968\n",
            "Train step - Step 26730, Loss 0.006601589731872082\n",
            "Train step - Step 26740, Loss 0.007497516926378012\n",
            "Train step - Step 26750, Loss 0.00931481085717678\n",
            "Train step - Step 26760, Loss 0.009246627800166607\n",
            "Train step - Step 26770, Loss 0.00671760831028223\n",
            "Train step - Step 26780, Loss 0.006849906872957945\n",
            "Train step - Step 26790, Loss 0.007350185886025429\n",
            "Train step - Step 26800, Loss 0.010454349219799042\n",
            "Train step - Step 26810, Loss 0.007315272931009531\n",
            "Train step - Step 26820, Loss 0.0076400479301810265\n",
            "Train step - Step 26830, Loss 0.0076629528775811195\n",
            "Train step - Step 26840, Loss 0.00843180250376463\n",
            "Train step - Step 26850, Loss 0.006808615755289793\n",
            "Train step - Step 26860, Loss 0.008255496621131897\n",
            "Train step - Step 26870, Loss 0.008099463768303394\n",
            "Train step - Step 26880, Loss 0.00814124010503292\n",
            "Train step - Step 26890, Loss 0.009163649752736092\n",
            "Train step - Step 26900, Loss 0.012115498073399067\n",
            "Train step - Step 26910, Loss 0.006670505274087191\n",
            "Train step - Step 26920, Loss 0.008744684047996998\n",
            "Train step - Step 26930, Loss 0.00863632932305336\n",
            "Train step - Step 26940, Loss 0.008130368776619434\n",
            "Train step - Step 26950, Loss 0.008957619778811932\n",
            "Train step - Step 26960, Loss 0.007856016978621483\n",
            "Train step - Step 26970, Loss 0.009804823435842991\n",
            "Train step - Step 26980, Loss 0.0076946672052145\n",
            "Train step - Step 26990, Loss 0.008750636130571365\n",
            "Train step - Step 27000, Loss 0.007856178097426891\n",
            "Train step - Step 27010, Loss 0.008981487713754177\n",
            "Train step - Step 27020, Loss 0.008398450911045074\n",
            "Train step - Step 27030, Loss 0.00792787130922079\n",
            "Train step - Step 27040, Loss 0.009827928617596626\n",
            "Train step - Step 27050, Loss 0.01011614315211773\n",
            "Train step - Step 27060, Loss 0.007664517033845186\n",
            "Train step - Step 27070, Loss 0.008938879705965519\n",
            "Train step - Step 27080, Loss 0.007069108542054892\n",
            "Train epoch - Accuracy: 0.8725252525252525 Loss: 0.008155869203911285 Corrects: 43190\n",
            "Training finished in 2393.1273233890533 seconds\n",
            "\n",
            "Validation accuracy: 0.76 - Validation loss: 0.01630561053752899\n",
            "\n",
            "\n",
            "Test accuracy: 0.7005\n",
            "\n",
            "\n",
            "\n",
            "Phase completed in 2398.1064348220825 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Joint-training finished in 13033.40284371376 seconds\n",
            "metrics jointtraining for seed 42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c3e08a856d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# write down json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusionMatrixData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# [DEBUG]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pts78KY42gXj",
        "colab_type": "text"
      },
      "source": [
        "**Fine tuning (catastrophic forgetting)**<br>\n",
        "In this section of the homework the aim is to demonstrate how, without ad-hoc methodologies, our CNN is unable to learn without dramatically forgetting what it has already been learnt.<br>\n",
        "Operatively, what we do is to perform a training again divided into (ten) steps but without exploiting previous data as before (joint training).\n",
        "What we should observe is a dramatic drop in the perfomances of the network.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrA3WhUzuK67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Fine tuning\n",
        "def sequentialLearning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    #confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb",
        "colab_type": "code",
        "outputId": "d4e375ff-1709-4446-cb51-f8eda1546f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "Starting epoch 1/70, LR = [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.6901078820228577\n",
            "Train step - Step 10, Loss 0.3247760236263275\n",
            "Train step - Step 20, Loss 0.2987397015094757\n",
            "Train step - Step 30, Loss 0.30344995856285095\n",
            "Train epoch - Accuracy: 0.16121212121212122 Loss: 0.3912074251488002 Corrects: 798\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.30295270681381226\n",
            "Train step - Step 50, Loss 0.2963450849056244\n",
            "Train step - Step 60, Loss 0.2957838475704193\n",
            "Train step - Step 70, Loss 0.3007523715496063\n",
            "Train epoch - Accuracy: 0.18484848484848485 Loss: 0.29860427785401394 Corrects: 915\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.29217034578323364\n",
            "Train step - Step 90, Loss 0.30655863881111145\n",
            "Train step - Step 100, Loss 0.30829039216041565\n",
            "Train step - Step 110, Loss 0.30797630548477173\n",
            "Train epoch - Accuracy: 0.19494949494949496 Loss: 0.2986088549007069 Corrects: 965\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.3140912652015686\n",
            "Train step - Step 130, Loss 0.2932884097099304\n",
            "Train step - Step 140, Loss 0.29770171642303467\n",
            "Train step - Step 150, Loss 0.28470897674560547\n",
            "Train epoch - Accuracy: 0.22363636363636363 Loss: 0.29485977222221066 Corrects: 1107\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.2905299663543701\n",
            "Train step - Step 170, Loss 0.27265414595603943\n",
            "Train step - Step 180, Loss 0.27559974789619446\n",
            "Train step - Step 190, Loss 0.2821387052536011\n",
            "Train epoch - Accuracy: 0.25414141414141417 Loss: 0.2824004531629158 Corrects: 1258\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.26950764656066895\n",
            "Train step - Step 210, Loss 0.2510541081428528\n",
            "Train step - Step 220, Loss 0.26384496688842773\n",
            "Train step - Step 230, Loss 0.25922998785972595\n",
            "Train epoch - Accuracy: 0.3191919191919192 Loss: 0.26614451651621346 Corrects: 1580\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.24871687591075897\n",
            "Train step - Step 250, Loss 0.24074554443359375\n",
            "Train step - Step 260, Loss 0.248219296336174\n",
            "Train step - Step 270, Loss 0.2575720548629761\n",
            "Train epoch - Accuracy: 0.4018181818181818 Loss: 0.24585399430207533 Corrects: 1989\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.2312520295381546\n",
            "Train step - Step 290, Loss 0.25699055194854736\n",
            "Train step - Step 300, Loss 0.2190731018781662\n",
            "Train step - Step 310, Loss 0.22500324249267578\n",
            "Train epoch - Accuracy: 0.43212121212121213 Loss: 0.2322071938743495 Corrects: 2139\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.2241048365831375\n",
            "Train step - Step 330, Loss 0.23162841796875\n",
            "Train step - Step 340, Loss 0.21151648461818695\n",
            "Train step - Step 350, Loss 0.21710649132728577\n",
            "Train epoch - Accuracy: 0.4672727272727273 Loss: 0.22447970350583393 Corrects: 2313\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.22115802764892578\n",
            "Train step - Step 370, Loss 0.2110581398010254\n",
            "Train step - Step 380, Loss 0.2128748893737793\n",
            "Train epoch - Accuracy: 0.4818181818181818 Loss: 0.21671947188449628 Corrects: 2385\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.21181975305080414\n",
            "Train step - Step 400, Loss 0.1980506181716919\n",
            "Train step - Step 410, Loss 0.21058058738708496\n",
            "Train step - Step 420, Loss 0.20589803159236908\n",
            "Train epoch - Accuracy: 0.5038383838383839 Loss: 0.20938549623344885 Corrects: 2494\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.19858253002166748\n",
            "Train step - Step 440, Loss 0.22053375840187073\n",
            "Train step - Step 450, Loss 0.2081248015165329\n",
            "Train step - Step 460, Loss 0.21572640538215637\n",
            "Train epoch - Accuracy: 0.5111111111111111 Loss: 0.20833375936204737 Corrects: 2530\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.20275166630744934\n",
            "Train step - Step 480, Loss 0.1999359279870987\n",
            "Train step - Step 490, Loss 0.21364589035511017\n",
            "Train step - Step 500, Loss 0.1937791407108307\n",
            "Train epoch - Accuracy: 0.5305050505050505 Loss: 0.20161331842644045 Corrects: 2626\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.19234316051006317\n",
            "Train step - Step 520, Loss 0.19526706635951996\n",
            "Train step - Step 530, Loss 0.1955813765525818\n",
            "Train step - Step 540, Loss 0.17865432798862457\n",
            "Train epoch - Accuracy: 0.5424242424242425 Loss: 0.19546172712186372 Corrects: 2685\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.17553436756134033\n",
            "Train step - Step 560, Loss 0.1878637820482254\n",
            "Train step - Step 570, Loss 0.16954346001148224\n",
            "Train step - Step 580, Loss 0.18576310575008392\n",
            "Train epoch - Accuracy: 0.5634343434343434 Loss: 0.1883637442974129 Corrects: 2789\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.18622279167175293\n",
            "Train step - Step 600, Loss 0.19491635262966156\n",
            "Train step - Step 610, Loss 0.18377788364887238\n",
            "Train step - Step 620, Loss 0.19408130645751953\n",
            "Train epoch - Accuracy: 0.5715151515151515 Loss: 0.18570700237245272 Corrects: 2829\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.18937914073467255\n",
            "Train step - Step 640, Loss 0.1932188719511032\n",
            "Train step - Step 650, Loss 0.19486887753009796\n",
            "Train step - Step 660, Loss 0.18944770097732544\n",
            "Train epoch - Accuracy: 0.5822222222222222 Loss: 0.18424124017508342 Corrects: 2882\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.18966703116893768\n",
            "Train step - Step 680, Loss 0.15178106725215912\n",
            "Train step - Step 690, Loss 0.18656866252422333\n",
            "Train step - Step 700, Loss 0.163358673453331\n",
            "Train epoch - Accuracy: 0.573939393939394 Loss: 0.1837520956993103 Corrects: 2841\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.17936034500598907\n",
            "Train step - Step 720, Loss 0.1632305383682251\n",
            "Train step - Step 730, Loss 0.2159961313009262\n",
            "Train step - Step 740, Loss 0.1692410111427307\n",
            "Train epoch - Accuracy: 0.5951515151515151 Loss: 0.17671286214481702 Corrects: 2946\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.16915953159332275\n",
            "Train step - Step 760, Loss 0.1887507289648056\n",
            "Train step - Step 770, Loss 0.18885980546474457\n",
            "Train epoch - Accuracy: 0.5971717171717171 Loss: 0.17792140142484145 Corrects: 2956\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.1796293705701828\n",
            "Train step - Step 790, Loss 0.15668144822120667\n",
            "Train step - Step 800, Loss 0.19705413281917572\n",
            "Train step - Step 810, Loss 0.18155932426452637\n",
            "Train epoch - Accuracy: 0.6050505050505051 Loss: 0.17502308002023986 Corrects: 2995\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.17253349721431732\n",
            "Train step - Step 830, Loss 0.16964830458164215\n",
            "Train step - Step 840, Loss 0.1735209971666336\n",
            "Train step - Step 850, Loss 0.19208894670009613\n",
            "Train epoch - Accuracy: 0.6135353535353535 Loss: 0.1691733884690988 Corrects: 3037\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.16746294498443604\n",
            "Train step - Step 870, Loss 0.17184777557849884\n",
            "Train step - Step 880, Loss 0.1724710911512375\n",
            "Train step - Step 890, Loss 0.17334316670894623\n",
            "Train epoch - Accuracy: 0.6208080808080808 Loss: 0.1697686023844613 Corrects: 3073\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.15959720313549042\n",
            "Train step - Step 910, Loss 0.2035789042711258\n",
            "Train step - Step 920, Loss 0.16213785111904144\n",
            "Train step - Step 930, Loss 0.19265393912792206\n",
            "Train epoch - Accuracy: 0.6191919191919192 Loss: 0.16988704905365454 Corrects: 3065\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.16756455600261688\n",
            "Train step - Step 950, Loss 0.1546563357114792\n",
            "Train step - Step 960, Loss 0.2000211775302887\n",
            "Train step - Step 970, Loss 0.16144441068172455\n",
            "Train epoch - Accuracy: 0.6325252525252525 Loss: 0.16487869427059637 Corrects: 3131\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.1522998809814453\n",
            "Train step - Step 990, Loss 0.16139595210552216\n",
            "Train step - Step 1000, Loss 0.1476876139640808\n",
            "Train step - Step 1010, Loss 0.19299577176570892\n",
            "Train epoch - Accuracy: 0.6432323232323233 Loss: 0.16222547381815283 Corrects: 3184\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.16852818429470062\n",
            "Train step - Step 1030, Loss 0.15513724088668823\n",
            "Train step - Step 1040, Loss 0.1801801174879074\n",
            "Train step - Step 1050, Loss 0.15107880532741547\n",
            "Train epoch - Accuracy: 0.6505050505050505 Loss: 0.16036565840244293 Corrects: 3220\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.16082195937633514\n",
            "Train step - Step 1070, Loss 0.1433466523885727\n",
            "Train step - Step 1080, Loss 0.15410013496875763\n",
            "Train step - Step 1090, Loss 0.1730615347623825\n",
            "Train epoch - Accuracy: 0.6466666666666666 Loss: 0.15817576998412006 Corrects: 3201\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.15759482979774475\n",
            "Train step - Step 1110, Loss 0.14425499737262726\n",
            "Train step - Step 1120, Loss 0.1488225758075714\n",
            "Train step - Step 1130, Loss 0.14714056253433228\n",
            "Train epoch - Accuracy: 0.6662626262626262 Loss: 0.1542401823130521 Corrects: 3298\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.1534873992204666\n",
            "Train step - Step 1150, Loss 0.1578260213136673\n",
            "Train step - Step 1160, Loss 0.1421336978673935\n",
            "Train epoch - Accuracy: 0.6690909090909091 Loss: 0.151212920522449 Corrects: 3312\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.1586669236421585\n",
            "Train step - Step 1180, Loss 0.16323547065258026\n",
            "Train step - Step 1190, Loss 0.1496584266424179\n",
            "Train step - Step 1200, Loss 0.1437714397907257\n",
            "Train epoch - Accuracy: 0.6719191919191919 Loss: 0.15191645680653929 Corrects: 3326\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.16267822682857513\n",
            "Train step - Step 1220, Loss 0.14302152395248413\n",
            "Train step - Step 1230, Loss 0.14368656277656555\n",
            "Train step - Step 1240, Loss 0.18481400609016418\n",
            "Train epoch - Accuracy: 0.6767676767676768 Loss: 0.1520385874461646 Corrects: 3350\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.14695993065834045\n",
            "Train step - Step 1260, Loss 0.13147182762622833\n",
            "Train step - Step 1270, Loss 0.13468877971172333\n",
            "Train step - Step 1280, Loss 0.1445833295583725\n",
            "Train epoch - Accuracy: 0.6737373737373737 Loss: 0.15109791051859808 Corrects: 3335\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.16779756546020508\n",
            "Train step - Step 1300, Loss 0.11713699251413345\n",
            "Train step - Step 1310, Loss 0.17373645305633545\n",
            "Train step - Step 1320, Loss 0.18266670405864716\n",
            "Train epoch - Accuracy: 0.6941414141414142 Loss: 0.14382400507878776 Corrects: 3436\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.13012893497943878\n",
            "Train step - Step 1340, Loss 0.13366244733333588\n",
            "Train step - Step 1350, Loss 0.15465150773525238\n",
            "Train step - Step 1360, Loss 0.15379993617534637\n",
            "Train epoch - Accuracy: 0.6995959595959595 Loss: 0.14607291753845986 Corrects: 3463\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.16448937356472015\n",
            "Train step - Step 1380, Loss 0.13546375930309296\n",
            "Train step - Step 1390, Loss 0.1379089653491974\n",
            "Train step - Step 1400, Loss 0.12373208999633789\n",
            "Train epoch - Accuracy: 0.7034343434343434 Loss: 0.14174613234972713 Corrects: 3482\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.14479656517505646\n",
            "Train step - Step 1420, Loss 0.1327618658542633\n",
            "Train step - Step 1430, Loss 0.12997858226299286\n",
            "Train step - Step 1440, Loss 0.14337444305419922\n",
            "Train epoch - Accuracy: 0.7002020202020202 Loss: 0.14116126676400503 Corrects: 3466\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.13889315724372864\n",
            "Train step - Step 1460, Loss 0.1466086357831955\n",
            "Train step - Step 1470, Loss 0.14870773255825043\n",
            "Train step - Step 1480, Loss 0.14485983550548553\n",
            "Train epoch - Accuracy: 0.6983838383838383 Loss: 0.14199699774535016 Corrects: 3457\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.159211665391922\n",
            "Train step - Step 1500, Loss 0.12480495125055313\n",
            "Train step - Step 1510, Loss 0.13620996475219727\n",
            "Train step - Step 1520, Loss 0.14062964916229248\n",
            "Train epoch - Accuracy: 0.7008080808080808 Loss: 0.14148251104836512 Corrects: 3469\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.12447476387023926\n",
            "Train step - Step 1540, Loss 0.13696913421154022\n",
            "Train step - Step 1550, Loss 0.13570237159729004\n",
            "Train epoch - Accuracy: 0.7232323232323232 Loss: 0.13485934225597768 Corrects: 3580\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.15386514365673065\n",
            "Train step - Step 1570, Loss 0.13167865574359894\n",
            "Train step - Step 1580, Loss 0.10861688107252121\n",
            "Train step - Step 1590, Loss 0.11644666641950607\n",
            "Train epoch - Accuracy: 0.7252525252525253 Loss: 0.1333844464716285 Corrects: 3590\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.14021314680576324\n",
            "Train step - Step 1610, Loss 0.13801497220993042\n",
            "Train step - Step 1620, Loss 0.12932847440242767\n",
            "Train step - Step 1630, Loss 0.13638313114643097\n",
            "Train epoch - Accuracy: 0.722020202020202 Loss: 0.13033047111949536 Corrects: 3574\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.14206068217754364\n",
            "Train step - Step 1650, Loss 0.13858386874198914\n",
            "Train step - Step 1660, Loss 0.12054290622472763\n",
            "Train step - Step 1670, Loss 0.13844351470470428\n",
            "Train epoch - Accuracy: 0.7173737373737373 Loss: 0.13195284579739427 Corrects: 3551\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.11154361814260483\n",
            "Train step - Step 1690, Loss 0.11724617332220078\n",
            "Train step - Step 1700, Loss 0.13521789014339447\n",
            "Train step - Step 1710, Loss 0.10117312520742416\n",
            "Train epoch - Accuracy: 0.7369696969696969 Loss: 0.1264944218114169 Corrects: 3648\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.1333567351102829\n",
            "Train step - Step 1730, Loss 0.12334175407886505\n",
            "Train step - Step 1740, Loss 0.10877414047718048\n",
            "Train step - Step 1750, Loss 0.13031506538391113\n",
            "Train epoch - Accuracy: 0.7492929292929293 Loss: 0.12201914978147757 Corrects: 3709\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.13099628686904907\n",
            "Train step - Step 1770, Loss 0.10733123123645782\n",
            "Train step - Step 1780, Loss 0.12915711104869843\n",
            "Train step - Step 1790, Loss 0.1358059197664261\n",
            "Train epoch - Accuracy: 0.7468686868686869 Loss: 0.1228895594104372 Corrects: 3697\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.09393034875392914\n",
            "Train step - Step 1810, Loss 0.12679457664489746\n",
            "Train step - Step 1820, Loss 0.12852643430233002\n",
            "Train step - Step 1830, Loss 0.10484113544225693\n",
            "Train epoch - Accuracy: 0.7468686868686869 Loss: 0.12289822089852709 Corrects: 3697\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.1367531269788742\n",
            "Train step - Step 1850, Loss 0.11800310760736465\n",
            "Train step - Step 1860, Loss 0.12923073768615723\n",
            "Train step - Step 1870, Loss 0.10751869529485703\n",
            "Train epoch - Accuracy: 0.7525252525252525 Loss: 0.1192450451579961 Corrects: 3725\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.12905795872211456\n",
            "Train step - Step 1890, Loss 0.11194753646850586\n",
            "Train step - Step 1900, Loss 0.1315135806798935\n",
            "Train step - Step 1910, Loss 0.1116330698132515\n",
            "Train epoch - Accuracy: 0.761010101010101 Loss: 0.11688380986452103 Corrects: 3767\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.11541698127985\n",
            "Train step - Step 1930, Loss 0.10274423658847809\n",
            "Train step - Step 1940, Loss 0.10647566616535187\n",
            "Train epoch - Accuracy: 0.7826262626262627 Loss: 0.10497140234166925 Corrects: 3874\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.10782575607299805\n",
            "Train step - Step 1960, Loss 0.0904649943113327\n",
            "Train step - Step 1970, Loss 0.09647219628095627\n",
            "Train step - Step 1980, Loss 0.09028778225183487\n",
            "Train epoch - Accuracy: 0.8078787878787879 Loss: 0.09532141376926441 Corrects: 3999\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.09024786949157715\n",
            "Train step - Step 2000, Loss 0.08068373054265976\n",
            "Train step - Step 2010, Loss 0.0947253555059433\n",
            "Train step - Step 2020, Loss 0.07569487392902374\n",
            "Train epoch - Accuracy: 0.8086868686868687 Loss: 0.09561182382732931 Corrects: 4003\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.10815327614545822\n",
            "Train step - Step 2040, Loss 0.07946032285690308\n",
            "Train step - Step 2050, Loss 0.10199729353189468\n",
            "Train step - Step 2060, Loss 0.08753698319196701\n",
            "Train epoch - Accuracy: 0.812929292929293 Loss: 0.09374040264673908 Corrects: 4024\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.07384135574102402\n",
            "Train step - Step 2080, Loss 0.10184741020202637\n",
            "Train step - Step 2090, Loss 0.0748792439699173\n",
            "Train step - Step 2100, Loss 0.0945902094244957\n",
            "Train epoch - Accuracy: 0.8268686868686869 Loss: 0.08917460025259943 Corrects: 4093\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.083185113966465\n",
            "Train step - Step 2120, Loss 0.08823948353528976\n",
            "Train step - Step 2130, Loss 0.06945449858903885\n",
            "Train step - Step 2140, Loss 0.10341067612171173\n",
            "Train epoch - Accuracy: 0.8248484848484848 Loss: 0.0878452530412963 Corrects: 4083\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.08749665319919586\n",
            "Train step - Step 2160, Loss 0.09760095924139023\n",
            "Train step - Step 2170, Loss 0.08471717685461044\n",
            "Train step - Step 2180, Loss 0.09470228105783463\n",
            "Train epoch - Accuracy: 0.8228282828282828 Loss: 0.08864714569816685 Corrects: 4073\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.082990363240242\n",
            "Train step - Step 2200, Loss 0.09213564544916153\n",
            "Train step - Step 2210, Loss 0.10384859144687653\n",
            "Train step - Step 2220, Loss 0.09071431308984756\n",
            "Train epoch - Accuracy: 0.8323232323232324 Loss: 0.08548866361379623 Corrects: 4120\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.08748797327280045\n",
            "Train step - Step 2240, Loss 0.10180266946554184\n",
            "Train step - Step 2250, Loss 0.1054980531334877\n",
            "Train step - Step 2260, Loss 0.07575754821300507\n",
            "Train epoch - Accuracy: 0.8375757575757575 Loss: 0.08410221116711394 Corrects: 4146\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.09036427736282349\n",
            "Train step - Step 2280, Loss 0.07571760565042496\n",
            "Train step - Step 2290, Loss 0.09542329609394073\n",
            "Train step - Step 2300, Loss 0.07594280689954758\n",
            "Train epoch - Accuracy: 0.8294949494949495 Loss: 0.08494963312690908 Corrects: 4106\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.07912111282348633\n",
            "Train step - Step 2320, Loss 0.08348213881254196\n",
            "Train step - Step 2330, Loss 0.08137064427137375\n",
            "Train epoch - Accuracy: 0.8371717171717171 Loss: 0.083963634582481 Corrects: 4144\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.06810619682073593\n",
            "Train step - Step 2350, Loss 0.07274267077445984\n",
            "Train step - Step 2360, Loss 0.07628851383924484\n",
            "Train step - Step 2370, Loss 0.07551579922437668\n",
            "Train epoch - Accuracy: 0.8418181818181818 Loss: 0.08128994381789005 Corrects: 4167\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.06961183995008469\n",
            "Train step - Step 2390, Loss 0.07230933755636215\n",
            "Train step - Step 2400, Loss 0.06981374323368073\n",
            "Train step - Step 2410, Loss 0.0893198624253273\n",
            "Train epoch - Accuracy: 0.8480808080808081 Loss: 0.07855069335662958 Corrects: 4198\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0889735147356987\n",
            "Train step - Step 2430, Loss 0.08181793987751007\n",
            "Train step - Step 2440, Loss 0.07784955948591232\n",
            "Train step - Step 2450, Loss 0.0680379718542099\n",
            "Train epoch - Accuracy: 0.8470707070707071 Loss: 0.07870526665991003 Corrects: 4193\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.07662618905305862\n",
            "Train step - Step 2470, Loss 0.06161161884665489\n",
            "Train step - Step 2480, Loss 0.08194234222173691\n",
            "Train step - Step 2490, Loss 0.08622640371322632\n",
            "Train epoch - Accuracy: 0.8632323232323232 Loss: 0.07310711064724007 Corrects: 4273\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0611485131084919\n",
            "Train step - Step 2510, Loss 0.08395203202962875\n",
            "Train step - Step 2520, Loss 0.07122525572776794\n",
            "Train step - Step 2530, Loss 0.07509396970272064\n",
            "Train epoch - Accuracy: 0.8692929292929293 Loss: 0.07040403602701245 Corrects: 4303\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.06886455416679382\n",
            "Train step - Step 2550, Loss 0.07279904931783676\n",
            "Train step - Step 2560, Loss 0.0725124403834343\n",
            "Train step - Step 2570, Loss 0.0666952133178711\n",
            "Train epoch - Accuracy: 0.86989898989899 Loss: 0.06812021930410404 Corrects: 4306\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.08335327357053757\n",
            "Train step - Step 2590, Loss 0.06581691652536392\n",
            "Train step - Step 2600, Loss 0.06052113696932793\n",
            "Train step - Step 2610, Loss 0.08052919059991837\n",
            "Train epoch - Accuracy: 0.86989898989899 Loss: 0.06811947051924888 Corrects: 4306\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.06291001290082932\n",
            "Train step - Step 2630, Loss 0.06940282881259918\n",
            "Train step - Step 2640, Loss 0.07969838380813599\n",
            "Train step - Step 2650, Loss 0.0678260549902916\n",
            "Train epoch - Accuracy: 0.8707070707070707 Loss: 0.06787054492969706 Corrects: 4310\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.056063711643218994\n",
            "Train step - Step 2670, Loss 0.07340153306722641\n",
            "Train step - Step 2680, Loss 0.06595098972320557\n",
            "Train step - Step 2690, Loss 0.05372442305088043\n",
            "Train epoch - Accuracy: 0.8676767676767677 Loss: 0.0671614236723293 Corrects: 4295\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0521400049328804\n",
            "Train step - Step 2710, Loss 0.0791592225432396\n",
            "Train step - Step 2720, Loss 0.0570225715637207\n",
            "Train epoch - Accuracy: 0.8719191919191919 Loss: 0.06723011649618245 Corrects: 4316\n",
            "Training finished in 238.9890968799591 seconds\n",
            "EVALUATION:  0.74 0.13105522096157074\n",
            "TEST GROUP:  0.781\n",
            "TEST ALL:  0.781\n",
            "GROUP:  2\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.44926175475120544\n",
            "Train step - Step 10, Loss 0.21208377182483673\n",
            "Train step - Step 20, Loss 0.15658564865589142\n",
            "Train step - Step 30, Loss 0.12831299006938934\n",
            "Train epoch - Accuracy: 0.31555555555555553 Loss: 0.1679661063714461 Corrects: 1562\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.11187869310379028\n",
            "Train step - Step 50, Loss 0.09292241930961609\n",
            "Train step - Step 60, Loss 0.1024218201637268\n",
            "Train step - Step 70, Loss 0.08956458419561386\n",
            "Train epoch - Accuracy: 0.5751515151515152 Loss: 0.09502511889344514 Corrects: 2847\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.08192827552556992\n",
            "Train step - Step 90, Loss 0.07927487045526505\n",
            "Train step - Step 100, Loss 0.08467675000429153\n",
            "Train step - Step 110, Loss 0.083372101187706\n",
            "Train epoch - Accuracy: 0.6662626262626262 Loss: 0.07935776242102036 Corrects: 3298\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.0725802332162857\n",
            "Train step - Step 130, Loss 0.071249820291996\n",
            "Train step - Step 140, Loss 0.076332226395607\n",
            "Train step - Step 150, Loss 0.07042566686868668\n",
            "Train epoch - Accuracy: 0.7034343434343434 Loss: 0.07162841699942193 Corrects: 3482\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.05724652484059334\n",
            "Train step - Step 170, Loss 0.06463823467493057\n",
            "Train step - Step 180, Loss 0.07552681118249893\n",
            "Train step - Step 190, Loss 0.06827908009290695\n",
            "Train epoch - Accuracy: 0.7385858585858586 Loss: 0.06555442334726604 Corrects: 3656\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.06176885962486267\n",
            "Train step - Step 210, Loss 0.055333252996206284\n",
            "Train step - Step 220, Loss 0.059058405458927155\n",
            "Train step - Step 230, Loss 0.05637132003903389\n",
            "Train epoch - Accuracy: 0.7642424242424243 Loss: 0.05958365604732976 Corrects: 3783\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.05317750200629234\n",
            "Train step - Step 250, Loss 0.05866730213165283\n",
            "Train step - Step 260, Loss 0.051244474947452545\n",
            "Train step - Step 270, Loss 0.04796231910586357\n",
            "Train epoch - Accuracy: 0.7741414141414141 Loss: 0.056422552747858894 Corrects: 3832\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.04872675985097885\n",
            "Train step - Step 290, Loss 0.0485052764415741\n",
            "Train step - Step 300, Loss 0.06932950764894485\n",
            "Train step - Step 310, Loss 0.06646733731031418\n",
            "Train epoch - Accuracy: 0.7917171717171717 Loss: 0.05361395946656815 Corrects: 3919\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.05152243375778198\n",
            "Train step - Step 330, Loss 0.04717309772968292\n",
            "Train step - Step 340, Loss 0.04236210510134697\n",
            "Train step - Step 350, Loss 0.05719456821680069\n",
            "Train epoch - Accuracy: 0.8121212121212121 Loss: 0.048432052301035984 Corrects: 4020\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.04235883429646492\n",
            "Train step - Step 370, Loss 0.03732331842184067\n",
            "Train step - Step 380, Loss 0.041605472564697266\n",
            "Train epoch - Accuracy: 0.8214141414141414 Loss: 0.04576842960083123 Corrects: 4066\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0357951857149601\n",
            "Train step - Step 400, Loss 0.03160123899579048\n",
            "Train step - Step 410, Loss 0.04146101698279381\n",
            "Train step - Step 420, Loss 0.04378598555922508\n",
            "Train epoch - Accuracy: 0.8327272727272728 Loss: 0.04446840670373705 Corrects: 4122\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.043889302760362625\n",
            "Train step - Step 440, Loss 0.03827795013785362\n",
            "Train step - Step 450, Loss 0.04375752806663513\n",
            "Train step - Step 460, Loss 0.04801900312304497\n",
            "Train epoch - Accuracy: 0.8331313131313132 Loss: 0.04386353048260766 Corrects: 4124\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.027514105662703514\n",
            "Train step - Step 480, Loss 0.05294063314795494\n",
            "Train step - Step 490, Loss 0.041738707572221756\n",
            "Train step - Step 500, Loss 0.04259436950087547\n",
            "Train epoch - Accuracy: 0.8454545454545455 Loss: 0.04145410155407106 Corrects: 4185\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.04132836312055588\n",
            "Train step - Step 520, Loss 0.03728892654180527\n",
            "Train step - Step 530, Loss 0.041488587856292725\n",
            "Train step - Step 540, Loss 0.04221540316939354\n",
            "Train epoch - Accuracy: 0.8452525252525253 Loss: 0.041444436180772204 Corrects: 4184\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.026568938046693802\n",
            "Train step - Step 560, Loss 0.03598810359835625\n",
            "Train step - Step 570, Loss 0.03379831835627556\n",
            "Train step - Step 580, Loss 0.04134569689631462\n",
            "Train epoch - Accuracy: 0.8602020202020202 Loss: 0.03722419210004084 Corrects: 4258\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.04135540872812271\n",
            "Train step - Step 600, Loss 0.02932046912610531\n",
            "Train step - Step 610, Loss 0.04890858754515648\n",
            "Train step - Step 620, Loss 0.04923743009567261\n",
            "Train epoch - Accuracy: 0.8636363636363636 Loss: 0.037137974771586334 Corrects: 4275\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.0420881025493145\n",
            "Train step - Step 640, Loss 0.03767993673682213\n",
            "Train step - Step 650, Loss 0.04210406541824341\n",
            "Train step - Step 660, Loss 0.024966081604361534\n",
            "Train epoch - Accuracy: 0.8707070707070707 Loss: 0.03392590497629811 Corrects: 4310\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.030267834663391113\n",
            "Train step - Step 680, Loss 0.031950999051332474\n",
            "Train step - Step 690, Loss 0.025835314765572548\n",
            "Train step - Step 700, Loss 0.03304162248969078\n",
            "Train epoch - Accuracy: 0.8840404040404041 Loss: 0.03267300652133094 Corrects: 4376\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.032580066472291946\n",
            "Train step - Step 720, Loss 0.0357922725379467\n",
            "Train step - Step 730, Loss 0.02770090103149414\n",
            "Train step - Step 740, Loss 0.029594786465168\n",
            "Train epoch - Accuracy: 0.882020202020202 Loss: 0.031214052821048582 Corrects: 4366\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.0351414792239666\n",
            "Train step - Step 760, Loss 0.024730851873755455\n",
            "Train step - Step 770, Loss 0.03770241513848305\n",
            "Train epoch - Accuracy: 0.8846464646464647 Loss: 0.030787131047309048 Corrects: 4379\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.023715723305940628\n",
            "Train step - Step 790, Loss 0.03639836236834526\n",
            "Train step - Step 800, Loss 0.02334176003932953\n",
            "Train step - Step 810, Loss 0.028967324644327164\n",
            "Train epoch - Accuracy: 0.896969696969697 Loss: 0.028365586835025536 Corrects: 4440\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.023195913061499596\n",
            "Train step - Step 830, Loss 0.02378014475107193\n",
            "Train step - Step 840, Loss 0.024088995531201363\n",
            "Train step - Step 850, Loss 0.021391790360212326\n",
            "Train epoch - Accuracy: 0.9026262626262627 Loss: 0.026124937817303823 Corrects: 4468\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.01856101118028164\n",
            "Train step - Step 870, Loss 0.024375302717089653\n",
            "Train step - Step 880, Loss 0.03308088704943657\n",
            "Train step - Step 890, Loss 0.01983400620520115\n",
            "Train epoch - Accuracy: 0.9042424242424243 Loss: 0.026451481828334355 Corrects: 4476\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.025143301114439964\n",
            "Train step - Step 910, Loss 0.027873778715729713\n",
            "Train step - Step 920, Loss 0.03099416010081768\n",
            "Train step - Step 930, Loss 0.0373285710811615\n",
            "Train epoch - Accuracy: 0.8983838383838384 Loss: 0.02771046556532383 Corrects: 4447\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.023261578753590584\n",
            "Train step - Step 950, Loss 0.028853625059127808\n",
            "Train step - Step 960, Loss 0.027272088453173637\n",
            "Train step - Step 970, Loss 0.02372906170785427\n",
            "Train epoch - Accuracy: 0.9165656565656566 Loss: 0.023114669885900285 Corrects: 4537\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.017558658495545387\n",
            "Train step - Step 990, Loss 0.02285546064376831\n",
            "Train step - Step 1000, Loss 0.029187163338065147\n",
            "Train step - Step 1010, Loss 0.032465483993291855\n",
            "Train epoch - Accuracy: 0.9145454545454546 Loss: 0.0247252621930657 Corrects: 4527\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.032112251967191696\n",
            "Train step - Step 1030, Loss 0.0448802225291729\n",
            "Train step - Step 1040, Loss 0.022639883682131767\n",
            "Train step - Step 1050, Loss 0.020646488294005394\n",
            "Train epoch - Accuracy: 0.9096969696969697 Loss: 0.026054488348238397 Corrects: 4503\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.028143150731921196\n",
            "Train step - Step 1070, Loss 0.020476695150136948\n",
            "Train step - Step 1080, Loss 0.023537952452898026\n",
            "Train step - Step 1090, Loss 0.022286033257842064\n",
            "Train epoch - Accuracy: 0.9175757575757576 Loss: 0.023925498034616913 Corrects: 4542\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.019333211705088615\n",
            "Train step - Step 1110, Loss 0.0185347069054842\n",
            "Train step - Step 1120, Loss 0.017906449735164642\n",
            "Train step - Step 1130, Loss 0.024564845487475395\n",
            "Train epoch - Accuracy: 0.9195959595959596 Loss: 0.0215553172647652 Corrects: 4552\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.012501455843448639\n",
            "Train step - Step 1150, Loss 0.018644703552126884\n",
            "Train step - Step 1160, Loss 0.038765400648117065\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.022127697556608854 Corrects: 4555\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.02156870998442173\n",
            "Train step - Step 1180, Loss 0.029782865196466446\n",
            "Train step - Step 1190, Loss 0.020478568971157074\n",
            "Train step - Step 1200, Loss 0.02044183574616909\n",
            "Train epoch - Accuracy: 0.9264646464646464 Loss: 0.020887510865324675 Corrects: 4586\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.017640370875597\n",
            "Train step - Step 1220, Loss 0.01519112940877676\n",
            "Train step - Step 1230, Loss 0.020447317510843277\n",
            "Train step - Step 1240, Loss 0.02117655985057354\n",
            "Train epoch - Accuracy: 0.9296969696969697 Loss: 0.020437232266471844 Corrects: 4602\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.013175101950764656\n",
            "Train step - Step 1260, Loss 0.026179015636444092\n",
            "Train step - Step 1270, Loss 0.024511214345693588\n",
            "Train step - Step 1280, Loss 0.02083088830113411\n",
            "Train epoch - Accuracy: 0.9290909090909091 Loss: 0.020291619933765343 Corrects: 4599\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.019303498789668083\n",
            "Train step - Step 1300, Loss 0.019120560958981514\n",
            "Train step - Step 1310, Loss 0.02391248568892479\n",
            "Train step - Step 1320, Loss 0.02668469026684761\n",
            "Train epoch - Accuracy: 0.9331313131313131 Loss: 0.018957807641438763 Corrects: 4619\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.014481872320175171\n",
            "Train step - Step 1340, Loss 0.016678759828209877\n",
            "Train step - Step 1350, Loss 0.018816670402884483\n",
            "Train step - Step 1360, Loss 0.0258122980594635\n",
            "Train epoch - Accuracy: 0.935959595959596 Loss: 0.017675246044692366 Corrects: 4633\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.01478028018027544\n",
            "Train step - Step 1380, Loss 0.013731421902775764\n",
            "Train step - Step 1390, Loss 0.016747159883379936\n",
            "Train step - Step 1400, Loss 0.02427443116903305\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.015650548219229236 Corrects: 4698\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.00808781012892723\n",
            "Train step - Step 1420, Loss 0.017357109114527702\n",
            "Train step - Step 1430, Loss 0.01278647780418396\n",
            "Train step - Step 1440, Loss 0.01844829134643078\n",
            "Train epoch - Accuracy: 0.9488888888888889 Loss: 0.015356817624785683 Corrects: 4697\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.013281079940497875\n",
            "Train step - Step 1460, Loss 0.01949872449040413\n",
            "Train step - Step 1470, Loss 0.017194969579577446\n",
            "Train step - Step 1480, Loss 0.02254166267812252\n",
            "Train epoch - Accuracy: 0.9393939393939394 Loss: 0.017823989850403083 Corrects: 4650\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.014679007232189178\n",
            "Train step - Step 1500, Loss 0.02266036719083786\n",
            "Train step - Step 1510, Loss 0.019889604300260544\n",
            "Train step - Step 1520, Loss 0.02568870782852173\n",
            "Train epoch - Accuracy: 0.9387878787878788 Loss: 0.017549658592301186 Corrects: 4647\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.015819374471902847\n",
            "Train step - Step 1540, Loss 0.011802471242845058\n",
            "Train step - Step 1550, Loss 0.015942668542265892\n",
            "Train epoch - Accuracy: 0.9406060606060606 Loss: 0.017300053576778884 Corrects: 4656\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.021033454686403275\n",
            "Train step - Step 1570, Loss 0.024300431832671165\n",
            "Train step - Step 1580, Loss 0.01384078711271286\n",
            "Train step - Step 1590, Loss 0.019919132813811302\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.016350794606136553 Corrects: 4678\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.014819549396634102\n",
            "Train step - Step 1610, Loss 0.024843422695994377\n",
            "Train step - Step 1620, Loss 0.015722444280982018\n",
            "Train step - Step 1630, Loss 0.01505217980593443\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.017527938931804113 Corrects: 4652\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.014867129735648632\n",
            "Train step - Step 1650, Loss 0.021516917273402214\n",
            "Train step - Step 1660, Loss 0.01770995929837227\n",
            "Train step - Step 1670, Loss 0.013624787330627441\n",
            "Train epoch - Accuracy: 0.9478787878787879 Loss: 0.015483809546614536 Corrects: 4692\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.018143972381949425\n",
            "Train step - Step 1690, Loss 0.02162383683025837\n",
            "Train step - Step 1700, Loss 0.01757490448653698\n",
            "Train step - Step 1710, Loss 0.015344438143074512\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.015189111977815629 Corrects: 4698\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.007666230201721191\n",
            "Train step - Step 1730, Loss 0.01736009493470192\n",
            "Train step - Step 1740, Loss 0.011558524332940578\n",
            "Train step - Step 1750, Loss 0.017239529639482498\n",
            "Train epoch - Accuracy: 0.9563636363636364 Loss: 0.013248789104623626 Corrects: 4734\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.01022892165929079\n",
            "Train step - Step 1770, Loss 0.009540293365716934\n",
            "Train step - Step 1780, Loss 0.013485184870660305\n",
            "Train step - Step 1790, Loss 0.011183932423591614\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.012049272221447242 Corrects: 4760\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.01010022684931755\n",
            "Train step - Step 1810, Loss 0.009086198173463345\n",
            "Train step - Step 1820, Loss 0.015506001189351082\n",
            "Train step - Step 1830, Loss 0.023418128490447998\n",
            "Train epoch - Accuracy: 0.9551515151515152 Loss: 0.013376012718436693 Corrects: 4728\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.01680557057261467\n",
            "Train step - Step 1850, Loss 0.014889664016664028\n",
            "Train step - Step 1860, Loss 0.015497389249503613\n",
            "Train step - Step 1870, Loss 0.014566403813660145\n",
            "Train epoch - Accuracy: 0.9535353535353536 Loss: 0.013517454555164081 Corrects: 4720\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.011819752864539623\n",
            "Train step - Step 1890, Loss 0.022377990186214447\n",
            "Train step - Step 1900, Loss 0.01049520168453455\n",
            "Train step - Step 1910, Loss 0.013532388024032116\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.011507322084196287 Corrects: 4760\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.006791840773075819\n",
            "Train step - Step 1930, Loss 0.0095451008528471\n",
            "Train step - Step 1940, Loss 0.008827206678688526\n",
            "Train epoch - Accuracy: 0.9755555555555555 Loss: 0.008028851075831688 Corrects: 4829\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.007073176093399525\n",
            "Train step - Step 1960, Loss 0.006795933935791254\n",
            "Train step - Step 1970, Loss 0.0029295976273715496\n",
            "Train step - Step 1980, Loss 0.00397137925028801\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0051574071082803935 Corrects: 4886\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0020746930968016386\n",
            "Train step - Step 2000, Loss 0.004675812087953091\n",
            "Train step - Step 2010, Loss 0.004129158798605204\n",
            "Train step - Step 2020, Loss 0.0020101608242839575\n",
            "Train epoch - Accuracy: 0.9907070707070708 Loss: 0.004509224096934001 Corrects: 4904\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.005343184340745211\n",
            "Train step - Step 2040, Loss 0.0034179016947746277\n",
            "Train step - Step 2050, Loss 0.0033114522229880095\n",
            "Train step - Step 2060, Loss 0.004101991653442383\n",
            "Train epoch - Accuracy: 0.9929292929292929 Loss: 0.003719129509885203 Corrects: 4915\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0033312754239887\n",
            "Train step - Step 2080, Loss 0.0027728667482733727\n",
            "Train step - Step 2090, Loss 0.0037113360594958067\n",
            "Train step - Step 2100, Loss 0.00291301473043859\n",
            "Train epoch - Accuracy: 0.9935353535353535 Loss: 0.0032649862789784117 Corrects: 4918\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0033123090397566557\n",
            "Train step - Step 2120, Loss 0.0029229503124952316\n",
            "Train step - Step 2130, Loss 0.0028362555895000696\n",
            "Train step - Step 2140, Loss 0.003235605778172612\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.002992225770622191 Corrects: 4916\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0011962909484282136\n",
            "Train step - Step 2160, Loss 0.0016897820169106126\n",
            "Train step - Step 2170, Loss 0.0045096916146576405\n",
            "Train step - Step 2180, Loss 0.0018949101213365793\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0030345635883735887 Corrects: 4917\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0010861203772947192\n",
            "Train step - Step 2200, Loss 0.0017409181455150247\n",
            "Train step - Step 2210, Loss 0.0031818305142223835\n",
            "Train step - Step 2220, Loss 0.0015252860030159354\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0026593839337654187 Corrects: 4928\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0018489258363842964\n",
            "Train step - Step 2240, Loss 0.0028527043759822845\n",
            "Train step - Step 2250, Loss 0.0022786378394812346\n",
            "Train step - Step 2260, Loss 0.0041412971913814545\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0026536779432096568 Corrects: 4931\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.002491225255653262\n",
            "Train step - Step 2280, Loss 0.00601120013743639\n",
            "Train step - Step 2290, Loss 0.0009791076881811023\n",
            "Train step - Step 2300, Loss 0.0015384641010314226\n",
            "Train epoch - Accuracy: 0.9945454545454545 Loss: 0.0025958261276698776 Corrects: 4923\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0032241553999483585\n",
            "Train step - Step 2320, Loss 0.0022152760066092014\n",
            "Train step - Step 2330, Loss 0.001095076440833509\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.002613022836640176 Corrects: 4927\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0016358006978407502\n",
            "Train step - Step 2350, Loss 0.0018020587740465999\n",
            "Train step - Step 2360, Loss 0.0036082379519939423\n",
            "Train step - Step 2370, Loss 0.0034735880326479673\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.002279772367892843 Corrects: 4928\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.002115060808137059\n",
            "Train step - Step 2390, Loss 0.0025131830479949713\n",
            "Train step - Step 2400, Loss 0.0017137108370661736\n",
            "Train step - Step 2410, Loss 0.0006777787930332124\n",
            "Train epoch - Accuracy: 0.9949494949494949 Loss: 0.002501799571516011 Corrects: 4925\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0008403122774325311\n",
            "Train step - Step 2430, Loss 0.0034238339867442846\n",
            "Train step - Step 2440, Loss 0.002096658805385232\n",
            "Train step - Step 2450, Loss 0.0023903220426291227\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0020998982274246336 Corrects: 4932\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.002481449395418167\n",
            "Train step - Step 2470, Loss 0.0020621519070118666\n",
            "Train step - Step 2480, Loss 0.0013686290476471186\n",
            "Train step - Step 2490, Loss 0.0007478948100470006\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0019679322617711745 Corrects: 4936\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0023236614651978016\n",
            "Train step - Step 2510, Loss 0.0013172811595723033\n",
            "Train step - Step 2520, Loss 0.0007305156905204058\n",
            "Train step - Step 2530, Loss 0.0010554223554208875\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0016239832177983992 Corrects: 4941\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.002799209440127015\n",
            "Train step - Step 2550, Loss 0.002209654077887535\n",
            "Train step - Step 2560, Loss 0.0012681320076808333\n",
            "Train step - Step 2570, Loss 0.0014954856596887112\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0018766054748604545 Corrects: 4932\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0027280745562165976\n",
            "Train step - Step 2590, Loss 0.0014606040203943849\n",
            "Train step - Step 2600, Loss 0.00042514430242590606\n",
            "Train step - Step 2610, Loss 0.0032364309299737215\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0017725236219062349 Corrects: 4936\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0029375816229730844\n",
            "Train step - Step 2630, Loss 0.0019352121744304895\n",
            "Train step - Step 2640, Loss 0.001391450292430818\n",
            "Train step - Step 2650, Loss 0.0011095835361629725\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.001678588863702096 Corrects: 4938\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0021721688099205494\n",
            "Train step - Step 2670, Loss 0.0013870698167011142\n",
            "Train step - Step 2680, Loss 0.001707612769678235\n",
            "Train step - Step 2690, Loss 0.0020923472475260496\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0016536056770557405 Corrects: 4941\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0016741823637858033\n",
            "Train step - Step 2710, Loss 0.0025728028267621994\n",
            "Train step - Step 2720, Loss 0.0006759032257832587\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0016315372920397556 Corrects: 4938\n",
            "Training finished in 235.03005194664001 seconds\n",
            "EVALUATION:  0.92 0.018819263204932213\n",
            "TEST GROUP:  0.902\n",
            "TEST ALL:  0.451\n",
            "GROUP:  3\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.3555186092853546\n",
            "Train step - Step 10, Loss 0.13807383179664612\n",
            "Train step - Step 20, Loss 0.08994452655315399\n",
            "Train step - Step 30, Loss 0.08158458024263382\n",
            "Train epoch - Accuracy: 0.32141414141414143 Loss: 0.11351540774106979 Corrects: 1591\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.06757519394159317\n",
            "Train step - Step 50, Loss 0.07000746577978134\n",
            "Train step - Step 60, Loss 0.0686064288020134\n",
            "Train step - Step 70, Loss 0.05558517947793007\n",
            "Train epoch - Accuracy: 0.5773737373737374 Loss: 0.0646030104340929 Corrects: 2858\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.06036753207445145\n",
            "Train step - Step 90, Loss 0.04896504431962967\n",
            "Train step - Step 100, Loss 0.059279102832078934\n",
            "Train step - Step 110, Loss 0.04927011579275131\n",
            "Train epoch - Accuracy: 0.6703030303030303 Loss: 0.05331820080677668 Corrects: 3318\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.0442122146487236\n",
            "Train step - Step 130, Loss 0.0467909574508667\n",
            "Train step - Step 140, Loss 0.05103297159075737\n",
            "Train step - Step 150, Loss 0.041026387363672256\n",
            "Train epoch - Accuracy: 0.7165656565656565 Loss: 0.04663011774420738 Corrects: 3547\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.04847795516252518\n",
            "Train step - Step 170, Loss 0.03887825459241867\n",
            "Train step - Step 180, Loss 0.03613832965493202\n",
            "Train step - Step 190, Loss 0.039732713252305984\n",
            "Train epoch - Accuracy: 0.7486868686868687 Loss: 0.04175336756941044 Corrects: 3706\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.039034925401210785\n",
            "Train step - Step 210, Loss 0.0385700948536396\n",
            "Train step - Step 220, Loss 0.0412088967859745\n",
            "Train step - Step 230, Loss 0.03232405334711075\n",
            "Train epoch - Accuracy: 0.7719191919191919 Loss: 0.039101977200821196 Corrects: 3821\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.03889624401926994\n",
            "Train step - Step 250, Loss 0.030584096908569336\n",
            "Train step - Step 260, Loss 0.03363112732768059\n",
            "Train step - Step 270, Loss 0.03446023911237717\n",
            "Train epoch - Accuracy: 0.7929292929292929 Loss: 0.03586319041071516 Corrects: 3925\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.03704817593097687\n",
            "Train step - Step 290, Loss 0.028530968353152275\n",
            "Train step - Step 300, Loss 0.027129625901579857\n",
            "Train step - Step 310, Loss 0.034489020705223083\n",
            "Train epoch - Accuracy: 0.821010101010101 Loss: 0.031713969952831364 Corrects: 4064\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.027808601036667824\n",
            "Train step - Step 330, Loss 0.03922199457883835\n",
            "Train step - Step 340, Loss 0.029453560709953308\n",
            "Train step - Step 350, Loss 0.039082661271095276\n",
            "Train epoch - Accuracy: 0.824040404040404 Loss: 0.030465151486974772 Corrects: 4079\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.02541627176105976\n",
            "Train step - Step 370, Loss 0.02612961083650589\n",
            "Train step - Step 380, Loss 0.028828376904129982\n",
            "Train epoch - Accuracy: 0.8468686868686869 Loss: 0.027918789346109738 Corrects: 4192\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.025730296969413757\n",
            "Train step - Step 400, Loss 0.03507932275533676\n",
            "Train step - Step 410, Loss 0.02493170276284218\n",
            "Train step - Step 420, Loss 0.023081965744495392\n",
            "Train epoch - Accuracy: 0.8511111111111112 Loss: 0.027231975075120877 Corrects: 4213\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.025606069713830948\n",
            "Train step - Step 440, Loss 0.023079531267285347\n",
            "Train step - Step 450, Loss 0.030807089060544968\n",
            "Train step - Step 460, Loss 0.024728739634156227\n",
            "Train epoch - Accuracy: 0.8543434343434343 Loss: 0.026283016366639524 Corrects: 4229\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.02127799019217491\n",
            "Train step - Step 480, Loss 0.02769698016345501\n",
            "Train step - Step 490, Loss 0.023447521030902863\n",
            "Train step - Step 500, Loss 0.0250734593719244\n",
            "Train epoch - Accuracy: 0.8626262626262626 Loss: 0.024853454266834742 Corrects: 4270\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.024048281833529472\n",
            "Train step - Step 520, Loss 0.021938234567642212\n",
            "Train step - Step 530, Loss 0.019270356744527817\n",
            "Train step - Step 540, Loss 0.024755246937274933\n",
            "Train epoch - Accuracy: 0.8759595959595959 Loss: 0.022471074765228263 Corrects: 4336\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.02021164447069168\n",
            "Train step - Step 560, Loss 0.022562257945537567\n",
            "Train step - Step 570, Loss 0.017470164224505424\n",
            "Train step - Step 580, Loss 0.0214157123118639\n",
            "Train epoch - Accuracy: 0.8816161616161616 Loss: 0.021205252332217765 Corrects: 4364\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.02008752152323723\n",
            "Train step - Step 600, Loss 0.022427592426538467\n",
            "Train step - Step 610, Loss 0.02568136528134346\n",
            "Train step - Step 620, Loss 0.015330619178712368\n",
            "Train epoch - Accuracy: 0.8723232323232323 Loss: 0.02211696759393119 Corrects: 4318\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.019737733528017998\n",
            "Train step - Step 640, Loss 0.01992947794497013\n",
            "Train step - Step 650, Loss 0.01830730400979519\n",
            "Train step - Step 660, Loss 0.03359118476510048\n",
            "Train epoch - Accuracy: 0.8749494949494949 Loss: 0.022907000498639214 Corrects: 4331\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.015756040811538696\n",
            "Train step - Step 680, Loss 0.020961981266736984\n",
            "Train step - Step 690, Loss 0.018773552030324936\n",
            "Train step - Step 700, Loss 0.021390410140156746\n",
            "Train epoch - Accuracy: 0.8878787878787879 Loss: 0.020973056134099912 Corrects: 4395\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.021482182666659355\n",
            "Train step - Step 720, Loss 0.024600878357887268\n",
            "Train step - Step 730, Loss 0.017167016863822937\n",
            "Train step - Step 740, Loss 0.018450146540999413\n",
            "Train epoch - Accuracy: 0.8997979797979798 Loss: 0.019120898681006047 Corrects: 4454\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.016115320846438408\n",
            "Train step - Step 760, Loss 0.019983794540166855\n",
            "Train step - Step 770, Loss 0.01718633621931076\n",
            "Train epoch - Accuracy: 0.8993939393939394 Loss: 0.018088510597896096 Corrects: 4452\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.019714148715138435\n",
            "Train step - Step 790, Loss 0.013829891569912434\n",
            "Train step - Step 800, Loss 0.019126007333397865\n",
            "Train step - Step 810, Loss 0.013774590566754341\n",
            "Train epoch - Accuracy: 0.902020202020202 Loss: 0.01799333507289188 Corrects: 4465\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.011993343010544777\n",
            "Train step - Step 830, Loss 0.015107056125998497\n",
            "Train step - Step 840, Loss 0.016209959983825684\n",
            "Train step - Step 850, Loss 0.013824434019625187\n",
            "Train epoch - Accuracy: 0.9155555555555556 Loss: 0.015970896885852622 Corrects: 4532\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.013900474645197392\n",
            "Train step - Step 870, Loss 0.019781332463026047\n",
            "Train step - Step 880, Loss 0.01938113011419773\n",
            "Train step - Step 890, Loss 0.012856468558311462\n",
            "Train epoch - Accuracy: 0.9088888888888889 Loss: 0.01664455056416266 Corrects: 4499\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.01967361755669117\n",
            "Train step - Step 910, Loss 0.014159336686134338\n",
            "Train step - Step 920, Loss 0.012048103846609592\n",
            "Train step - Step 930, Loss 0.019499830901622772\n",
            "Train epoch - Accuracy: 0.9113131313131313 Loss: 0.01628042836494819 Corrects: 4511\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.014298702590167522\n",
            "Train step - Step 950, Loss 0.008357821963727474\n",
            "Train step - Step 960, Loss 0.01703745126724243\n",
            "Train step - Step 970, Loss 0.00940883718430996\n",
            "Train epoch - Accuracy: 0.9244444444444444 Loss: 0.014270578118963073 Corrects: 4576\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.011817843653261662\n",
            "Train step - Step 990, Loss 0.0164661668241024\n",
            "Train step - Step 1000, Loss 0.014719306491315365\n",
            "Train step - Step 1010, Loss 0.018951889127492905\n",
            "Train epoch - Accuracy: 0.9222222222222223 Loss: 0.014729670820136865 Corrects: 4565\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.01553906686604023\n",
            "Train step - Step 1030, Loss 0.014055977575480938\n",
            "Train step - Step 1040, Loss 0.018117737025022507\n",
            "Train step - Step 1050, Loss 0.00868421234190464\n",
            "Train epoch - Accuracy: 0.9301010101010101 Loss: 0.013751095286523452 Corrects: 4604\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.012697766534984112\n",
            "Train step - Step 1070, Loss 0.011415496468544006\n",
            "Train step - Step 1080, Loss 0.010023954324424267\n",
            "Train step - Step 1090, Loss 0.010563642717897892\n",
            "Train epoch - Accuracy: 0.933939393939394 Loss: 0.013079253674080275 Corrects: 4623\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.01578468456864357\n",
            "Train step - Step 1110, Loss 0.01775846630334854\n",
            "Train step - Step 1120, Loss 0.010322426445782185\n",
            "Train step - Step 1130, Loss 0.026716403663158417\n",
            "Train epoch - Accuracy: 0.9276767676767677 Loss: 0.014488607359052908 Corrects: 4592\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.012010732665657997\n",
            "Train step - Step 1150, Loss 0.012585889548063278\n",
            "Train step - Step 1160, Loss 0.01672498695552349\n",
            "Train epoch - Accuracy: 0.933939393939394 Loss: 0.01296848807371024 Corrects: 4623\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.011767971329391003\n",
            "Train step - Step 1180, Loss 0.012905866838991642\n",
            "Train step - Step 1190, Loss 0.01079693902283907\n",
            "Train step - Step 1200, Loss 0.016270849853754044\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.012423853975429078 Corrects: 4621\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.007470369804650545\n",
            "Train step - Step 1220, Loss 0.00818832777440548\n",
            "Train step - Step 1230, Loss 0.009712942875921726\n",
            "Train step - Step 1240, Loss 0.008492577821016312\n",
            "Train epoch - Accuracy: 0.9442424242424242 Loss: 0.010891829858900923 Corrects: 4674\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.007298607844859362\n",
            "Train step - Step 1260, Loss 0.006414880510419607\n",
            "Train step - Step 1270, Loss 0.01192050613462925\n",
            "Train step - Step 1280, Loss 0.010521442629396915\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.009575462159559582 Corrects: 4711\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.00582609698176384\n",
            "Train step - Step 1300, Loss 0.01685129851102829\n",
            "Train step - Step 1310, Loss 0.010730288922786713\n",
            "Train step - Step 1320, Loss 0.008110581897199154\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.010504264097773667 Corrects: 4690\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.00794412475079298\n",
            "Train step - Step 1340, Loss 0.01222253032028675\n",
            "Train step - Step 1350, Loss 0.007869260385632515\n",
            "Train step - Step 1360, Loss 0.008070607669651508\n",
            "Train epoch - Accuracy: 0.9448484848484848 Loss: 0.0111518626780522 Corrects: 4677\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.007503743749111891\n",
            "Train step - Step 1380, Loss 0.011719413101673126\n",
            "Train step - Step 1390, Loss 0.009867655113339424\n",
            "Train step - Step 1400, Loss 0.012349860742688179\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.010304949936090093 Corrects: 4695\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.010061175562441349\n",
            "Train step - Step 1420, Loss 0.014309915713965893\n",
            "Train step - Step 1430, Loss 0.008020509034395218\n",
            "Train step - Step 1440, Loss 0.008741825819015503\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.010434941837959217 Corrects: 4670\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.01163343247026205\n",
            "Train step - Step 1460, Loss 0.013339389115571976\n",
            "Train step - Step 1470, Loss 0.009055684320628643\n",
            "Train step - Step 1480, Loss 0.025516746565699577\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.010078746029599146 Corrects: 4711\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.014397060498595238\n",
            "Train step - Step 1500, Loss 0.00858133565634489\n",
            "Train step - Step 1510, Loss 0.013535112142562866\n",
            "Train step - Step 1520, Loss 0.00526203541085124\n",
            "Train epoch - Accuracy: 0.9408080808080808 Loss: 0.011247067140848046 Corrects: 4657\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.014191992580890656\n",
            "Train step - Step 1540, Loss 0.009735922329127789\n",
            "Train step - Step 1550, Loss 0.007510497234761715\n",
            "Train epoch - Accuracy: 0.9357575757575758 Loss: 0.012117712837879104 Corrects: 4632\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.009783940389752388\n",
            "Train step - Step 1570, Loss 0.016291573643684387\n",
            "Train step - Step 1580, Loss 0.006337478756904602\n",
            "Train step - Step 1590, Loss 0.012322395108640194\n",
            "Train epoch - Accuracy: 0.9385858585858586 Loss: 0.01199264966779285 Corrects: 4646\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.01071875635534525\n",
            "Train step - Step 1610, Loss 0.012790068052709103\n",
            "Train step - Step 1620, Loss 0.012168394401669502\n",
            "Train step - Step 1630, Loss 0.013597258366644382\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.010239794073682843 Corrects: 4690\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.006243881769478321\n",
            "Train step - Step 1650, Loss 0.005246956367045641\n",
            "Train step - Step 1660, Loss 0.012309818528592587\n",
            "Train step - Step 1670, Loss 0.00810710433870554\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.009585660750215703 Corrects: 4708\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0063878921791911125\n",
            "Train step - Step 1690, Loss 0.009669310413300991\n",
            "Train step - Step 1700, Loss 0.009221657179296017\n",
            "Train step - Step 1710, Loss 0.01012992300093174\n",
            "Train epoch - Accuracy: 0.9573737373737373 Loss: 0.008611265429756557 Corrects: 4739\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.008855138905346394\n",
            "Train step - Step 1730, Loss 0.008220859803259373\n",
            "Train step - Step 1740, Loss 0.007423887029290199\n",
            "Train step - Step 1750, Loss 0.00626417575404048\n",
            "Train epoch - Accuracy: 0.9593939393939394 Loss: 0.00865581958582907 Corrects: 4749\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.009494362398982048\n",
            "Train step - Step 1770, Loss 0.003914559260010719\n",
            "Train step - Step 1780, Loss 0.007972038350999355\n",
            "Train step - Step 1790, Loss 0.007141836918890476\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.007405902548420309 Corrects: 4766\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.012473712675273418\n",
            "Train step - Step 1810, Loss 0.009485620073974133\n",
            "Train step - Step 1820, Loss 0.009191065095365047\n",
            "Train step - Step 1830, Loss 0.0103900833055377\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.008218698215040595 Corrects: 4760\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0074341678991913795\n",
            "Train step - Step 1850, Loss 0.005085096228867769\n",
            "Train step - Step 1860, Loss 0.008336273953318596\n",
            "Train step - Step 1870, Loss 0.004730642307549715\n",
            "Train epoch - Accuracy: 0.9670707070707071 Loss: 0.007104313291910321 Corrects: 4787\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.008064313791692257\n",
            "Train step - Step 1890, Loss 0.006075065582990646\n",
            "Train step - Step 1900, Loss 0.010672328993678093\n",
            "Train step - Step 1910, Loss 0.009451163932681084\n",
            "Train epoch - Accuracy: 0.9660606060606061 Loss: 0.00682802546280201 Corrects: 4782\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.003237366210669279\n",
            "Train step - Step 1930, Loss 0.0035252156667411327\n",
            "Train step - Step 1940, Loss 0.0029564935248345137\n",
            "Train epoch - Accuracy: 0.9854545454545455 Loss: 0.004003853678392867 Corrects: 4878\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.004446463193744421\n",
            "Train step - Step 1960, Loss 0.003691684454679489\n",
            "Train step - Step 1970, Loss 0.0012509117368608713\n",
            "Train step - Step 1980, Loss 0.002147868275642395\n",
            "Train epoch - Accuracy: 0.9925252525252525 Loss: 0.0025506019825586165 Corrects: 4913\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0018592706182971597\n",
            "Train step - Step 2000, Loss 0.0029052384197711945\n",
            "Train step - Step 2010, Loss 0.0018523236503824592\n",
            "Train step - Step 2020, Loss 0.0026211580261588097\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.002013923025341949 Corrects: 4927\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0017728981329128146\n",
            "Train step - Step 2040, Loss 0.0014596671098843217\n",
            "Train step - Step 2050, Loss 0.0013280365383252501\n",
            "Train step - Step 2060, Loss 0.0014725028304383159\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0019195064848684 Corrects: 4927\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0012506330385804176\n",
            "Train step - Step 2080, Loss 0.0015325137646868825\n",
            "Train step - Step 2090, Loss 0.0011364989914000034\n",
            "Train step - Step 2100, Loss 0.0016198853263631463\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0016359408080314445 Corrects: 4938\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0006853505619801581\n",
            "Train step - Step 2120, Loss 0.0010414420394226909\n",
            "Train step - Step 2130, Loss 0.0024703473318368196\n",
            "Train step - Step 2140, Loss 0.0015556163853034377\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0014412730950109586 Corrects: 4937\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.000892091600690037\n",
            "Train step - Step 2160, Loss 0.001153292367234826\n",
            "Train step - Step 2170, Loss 0.0010687927715480328\n",
            "Train step - Step 2180, Loss 0.003326383652165532\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0014001762317117266 Corrects: 4935\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0016188232693821192\n",
            "Train step - Step 2200, Loss 0.0018827716121450067\n",
            "Train step - Step 2210, Loss 0.0012563263298943639\n",
            "Train step - Step 2220, Loss 0.0008911420009098947\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00130191611920982 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0016094526508823037\n",
            "Train step - Step 2240, Loss 0.0009184537339024246\n",
            "Train step - Step 2250, Loss 0.001157658756710589\n",
            "Train step - Step 2260, Loss 0.0017590358620509505\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0012275714467213763 Corrects: 4944\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0008194163092412055\n",
            "Train step - Step 2280, Loss 0.001082942239008844\n",
            "Train step - Step 2290, Loss 0.001101260189898312\n",
            "Train step - Step 2300, Loss 0.0007414467982016504\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0011664296546715755 Corrects: 4945\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0016693046782165766\n",
            "Train step - Step 2320, Loss 0.0006614190642721951\n",
            "Train step - Step 2330, Loss 0.0006882003508508205\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0011294756302694705 Corrects: 4939\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.001070672064088285\n",
            "Train step - Step 2350, Loss 0.0010410966351628304\n",
            "Train step - Step 2360, Loss 0.0015990867977961898\n",
            "Train step - Step 2370, Loss 0.0010569423902779818\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.0010163471933849382 Corrects: 4948\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0006868172786198556\n",
            "Train step - Step 2390, Loss 0.0011108937906101346\n",
            "Train step - Step 2400, Loss 0.000691945489961654\n",
            "Train step - Step 2410, Loss 0.0005935572553426027\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0012232403409187542 Corrects: 4937\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0003931266546715051\n",
            "Train step - Step 2430, Loss 0.0008551943465135992\n",
            "Train step - Step 2440, Loss 0.0012241746298968792\n",
            "Train step - Step 2450, Loss 0.0008154027746059\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0009538054619586528 Corrects: 4944\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0009302667458541691\n",
            "Train step - Step 2470, Loss 0.0007205409929156303\n",
            "Train step - Step 2480, Loss 0.0012981301406398416\n",
            "Train step - Step 2490, Loss 0.0006699316436424851\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0009186279785941647 Corrects: 4943\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0005134809180162847\n",
            "Train step - Step 2510, Loss 0.000568496820051223\n",
            "Train step - Step 2520, Loss 0.00072794797597453\n",
            "Train step - Step 2530, Loss 0.0009529467206448317\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0010191850065056122 Corrects: 4943\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0005486824084073305\n",
            "Train step - Step 2550, Loss 0.0019385687774047256\n",
            "Train step - Step 2560, Loss 0.001243201899342239\n",
            "Train step - Step 2570, Loss 0.0005436119390651584\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0008547515878359778 Corrects: 4943\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0012926447670906782\n",
            "Train step - Step 2590, Loss 0.0007650424377061427\n",
            "Train step - Step 2600, Loss 0.0007099412614479661\n",
            "Train step - Step 2610, Loss 0.0006073093973100185\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0009283523978148069 Corrects: 4942\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0012879305286332965\n",
            "Train step - Step 2630, Loss 0.0013330139918252826\n",
            "Train step - Step 2640, Loss 0.0012429156340658665\n",
            "Train step - Step 2650, Loss 0.000725742953363806\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0009100556676981575 Corrects: 4945\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0007891715504229069\n",
            "Train step - Step 2670, Loss 0.0008942326530814171\n",
            "Train step - Step 2680, Loss 0.000618028047028929\n",
            "Train step - Step 2690, Loss 0.0007787922513671219\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0007872032479270164 Corrects: 4947\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0014607266057282686\n",
            "Train step - Step 2710, Loss 0.0003983874630648643\n",
            "Train step - Step 2720, Loss 0.0006555306608788669\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0008044405239210887 Corrects: 4945\n",
            "Training finished in 240.43073439598083 seconds\n",
            "EVALUATION:  0.9 0.020734135061502457\n",
            "TEST GROUP:  0.865\n",
            "TEST ALL:  0.28833333333333333\n",
            "GROUP:  4\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.2608965039253235\n",
            "Train step - Step 10, Loss 0.11323349922895432\n",
            "Train step - Step 20, Loss 0.07478510588407516\n",
            "Train step - Step 30, Loss 0.06295721232891083\n",
            "Train epoch - Accuracy: 0.3094949494949495 Loss: 0.08927936794179858 Corrects: 1532\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.05036624148488045\n",
            "Train step - Step 50, Loss 0.0479847751557827\n",
            "Train step - Step 60, Loss 0.03435495123267174\n",
            "Train step - Step 70, Loss 0.039935458451509476\n",
            "Train epoch - Accuracy: 0.618989898989899 Loss: 0.04472326577010781 Corrects: 3064\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.03397543355822563\n",
            "Train step - Step 90, Loss 0.03304199501872063\n",
            "Train step - Step 100, Loss 0.033174362033605576\n",
            "Train step - Step 110, Loss 0.02836412750184536\n",
            "Train epoch - Accuracy: 0.7234343434343434 Loss: 0.03427485047340995 Corrects: 3581\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.034957654774188995\n",
            "Train step - Step 130, Loss 0.030921125784516335\n",
            "Train step - Step 140, Loss 0.02635740302503109\n",
            "Train step - Step 150, Loss 0.024259930476546288\n",
            "Train epoch - Accuracy: 0.7682828282828282 Loss: 0.028668072419335142 Corrects: 3803\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.023718008771538734\n",
            "Train step - Step 170, Loss 0.023873165249824524\n",
            "Train step - Step 180, Loss 0.023034268990159035\n",
            "Train step - Step 190, Loss 0.025444984436035156\n",
            "Train epoch - Accuracy: 0.7977777777777778 Loss: 0.02552565746235125 Corrects: 3949\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.018369076773524284\n",
            "Train step - Step 210, Loss 0.022210344672203064\n",
            "Train step - Step 220, Loss 0.01955718733370304\n",
            "Train step - Step 230, Loss 0.02147703804075718\n",
            "Train epoch - Accuracy: 0.8331313131313132 Loss: 0.02218519365847713 Corrects: 4124\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.019556362181901932\n",
            "Train step - Step 250, Loss 0.020209020003676414\n",
            "Train step - Step 260, Loss 0.019816605374217033\n",
            "Train step - Step 270, Loss 0.020153749734163284\n",
            "Train epoch - Accuracy: 0.8438383838383838 Loss: 0.0203280003767724 Corrects: 4177\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.021901393309235573\n",
            "Train step - Step 290, Loss 0.014749469235539436\n",
            "Train step - Step 300, Loss 0.01953924261033535\n",
            "Train step - Step 310, Loss 0.01992098055779934\n",
            "Train epoch - Accuracy: 0.8654545454545455 Loss: 0.018722387130061784 Corrects: 4284\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.02118932455778122\n",
            "Train step - Step 330, Loss 0.014942044392228127\n",
            "Train step - Step 340, Loss 0.019795751199126244\n",
            "Train step - Step 350, Loss 0.01851249672472477\n",
            "Train epoch - Accuracy: 0.8638383838383838 Loss: 0.018396659492693767 Corrects: 4276\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.013353508897125721\n",
            "Train step - Step 370, Loss 0.018446240574121475\n",
            "Train step - Step 380, Loss 0.01241292804479599\n",
            "Train epoch - Accuracy: 0.8848484848484849 Loss: 0.015257193543242686 Corrects: 4380\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.011201036162674427\n",
            "Train step - Step 400, Loss 0.01613299921154976\n",
            "Train step - Step 410, Loss 0.014399182982742786\n",
            "Train step - Step 420, Loss 0.011504321359097958\n",
            "Train epoch - Accuracy: 0.8884848484848484 Loss: 0.01548889578291864 Corrects: 4398\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.013529203832149506\n",
            "Train step - Step 440, Loss 0.01681278459727764\n",
            "Train step - Step 450, Loss 0.013322300277650356\n",
            "Train step - Step 460, Loss 0.011270204558968544\n",
            "Train epoch - Accuracy: 0.8933333333333333 Loss: 0.014079739157900666 Corrects: 4422\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.015307602472603321\n",
            "Train step - Step 480, Loss 0.016052937135100365\n",
            "Train step - Step 490, Loss 0.015141278505325317\n",
            "Train step - Step 500, Loss 0.012144889682531357\n",
            "Train epoch - Accuracy: 0.9066666666666666 Loss: 0.013405819767051273 Corrects: 4488\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.011847074143588543\n",
            "Train step - Step 520, Loss 0.010828266851603985\n",
            "Train step - Step 530, Loss 0.01202948298305273\n",
            "Train step - Step 540, Loss 0.014459818601608276\n",
            "Train epoch - Accuracy: 0.9074747474747474 Loss: 0.01243385183615516 Corrects: 4492\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.010052031837403774\n",
            "Train step - Step 560, Loss 0.011541876010596752\n",
            "Train step - Step 570, Loss 0.011389066465198994\n",
            "Train step - Step 580, Loss 0.011708550155162811\n",
            "Train epoch - Accuracy: 0.9119191919191919 Loss: 0.011762543772958746 Corrects: 4514\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.0102999834343791\n",
            "Train step - Step 600, Loss 0.008458539843559265\n",
            "Train step - Step 610, Loss 0.012982179410755634\n",
            "Train step - Step 620, Loss 0.009127876721322536\n",
            "Train epoch - Accuracy: 0.9185858585858586 Loss: 0.011294984157112511 Corrects: 4547\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.01175291370600462\n",
            "Train step - Step 640, Loss 0.012595045380294323\n",
            "Train step - Step 650, Loss 0.010398471727967262\n",
            "Train step - Step 660, Loss 0.012406385503709316\n",
            "Train epoch - Accuracy: 0.92 Loss: 0.011057575041371764 Corrects: 4554\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.009308177046477795\n",
            "Train step - Step 680, Loss 0.008219094015657902\n",
            "Train step - Step 690, Loss 0.012105653993785381\n",
            "Train step - Step 700, Loss 0.011446203105151653\n",
            "Train epoch - Accuracy: 0.9288888888888889 Loss: 0.01041822936762162 Corrects: 4598\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.010742620564997196\n",
            "Train step - Step 720, Loss 0.006402296479791403\n",
            "Train step - Step 730, Loss 0.010893262922763824\n",
            "Train step - Step 740, Loss 0.01812790520489216\n",
            "Train epoch - Accuracy: 0.9288888888888889 Loss: 0.010369042846741098 Corrects: 4598\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.010808916762471199\n",
            "Train step - Step 760, Loss 0.015058154240250587\n",
            "Train step - Step 770, Loss 0.008984968066215515\n",
            "Train epoch - Accuracy: 0.9284848484848485 Loss: 0.010045208888071956 Corrects: 4596\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.005992574151605368\n",
            "Train step - Step 790, Loss 0.006992465350776911\n",
            "Train step - Step 800, Loss 0.006672290153801441\n",
            "Train step - Step 810, Loss 0.007107994984835386\n",
            "Train epoch - Accuracy: 0.9329292929292929 Loss: 0.009625575941319417 Corrects: 4618\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.004828899633139372\n",
            "Train step - Step 830, Loss 0.005121932830661535\n",
            "Train step - Step 840, Loss 0.011747349984943867\n",
            "Train step - Step 850, Loss 0.007773953024297953\n",
            "Train epoch - Accuracy: 0.943030303030303 Loss: 0.0085656242341631 Corrects: 4668\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.007656367961317301\n",
            "Train step - Step 870, Loss 0.007111002691090107\n",
            "Train step - Step 880, Loss 0.0075165145099163055\n",
            "Train step - Step 890, Loss 0.007675379514694214\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.00845603532938644 Corrects: 4658\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.007954330183565617\n",
            "Train step - Step 910, Loss 0.005736727733165026\n",
            "Train step - Step 920, Loss 0.007793729193508625\n",
            "Train step - Step 930, Loss 0.007314410991966724\n",
            "Train epoch - Accuracy: 0.9341414141414142 Loss: 0.009206758596830898 Corrects: 4624\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.007743183057755232\n",
            "Train step - Step 950, Loss 0.009839995764195919\n",
            "Train step - Step 960, Loss 0.007347284350544214\n",
            "Train step - Step 970, Loss 0.010088570415973663\n",
            "Train epoch - Accuracy: 0.9406060606060606 Loss: 0.00888329887894368 Corrects: 4656\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.008021824061870575\n",
            "Train step - Step 990, Loss 0.008365794084966183\n",
            "Train step - Step 1000, Loss 0.007972453720867634\n",
            "Train step - Step 1010, Loss 0.009212044067680836\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.0077789302181565404 Corrects: 4695\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.006672473158687353\n",
            "Train step - Step 1030, Loss 0.01246829517185688\n",
            "Train step - Step 1040, Loss 0.007615936454385519\n",
            "Train step - Step 1050, Loss 0.005615465342998505\n",
            "Train epoch - Accuracy: 0.9533333333333334 Loss: 0.007210030029857099 Corrects: 4719\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0062868245877325535\n",
            "Train step - Step 1070, Loss 0.005330601241439581\n",
            "Train step - Step 1080, Loss 0.00810398068279028\n",
            "Train step - Step 1090, Loss 0.007531724404543638\n",
            "Train epoch - Accuracy: 0.9513131313131313 Loss: 0.0069244715183822796 Corrects: 4709\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.007453809957951307\n",
            "Train step - Step 1110, Loss 0.0076520973816514015\n",
            "Train step - Step 1120, Loss 0.004542123526334763\n",
            "Train step - Step 1130, Loss 0.01445210911333561\n",
            "Train epoch - Accuracy: 0.9503030303030303 Loss: 0.007477735159824593 Corrects: 4704\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.008496413007378578\n",
            "Train step - Step 1150, Loss 0.007103502284735441\n",
            "Train step - Step 1160, Loss 0.007597610354423523\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.00687381652005092 Corrects: 4724\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.006952914875000715\n",
            "Train step - Step 1180, Loss 0.004760746378451586\n",
            "Train step - Step 1190, Loss 0.0033277024049311876\n",
            "Train step - Step 1200, Loss 0.007591610308736563\n",
            "Train epoch - Accuracy: 0.9505050505050505 Loss: 0.007438179479554446 Corrects: 4705\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0052152457647025585\n",
            "Train step - Step 1220, Loss 0.004899855703115463\n",
            "Train step - Step 1230, Loss 0.00811404176056385\n",
            "Train step - Step 1240, Loss 0.006058677565306425\n",
            "Train epoch - Accuracy: 0.9521212121212121 Loss: 0.006934344230802974 Corrects: 4713\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.004414945840835571\n",
            "Train step - Step 1260, Loss 0.006965510081499815\n",
            "Train step - Step 1270, Loss 0.0027814216446131468\n",
            "Train step - Step 1280, Loss 0.0050401147454977036\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.007015523849939457 Corrects: 4711\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.006952121388167143\n",
            "Train step - Step 1300, Loss 0.009972876869142056\n",
            "Train step - Step 1310, Loss 0.004975836258381605\n",
            "Train step - Step 1320, Loss 0.008891156874597073\n",
            "Train epoch - Accuracy: 0.9541414141414142 Loss: 0.006927026158405675 Corrects: 4723\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.006976579315960407\n",
            "Train step - Step 1340, Loss 0.005080002825707197\n",
            "Train step - Step 1350, Loss 0.005469608120620251\n",
            "Train step - Step 1360, Loss 0.005638397764414549\n",
            "Train epoch - Accuracy: 0.9674747474747475 Loss: 0.005363840780061002 Corrects: 4789\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004707049578428268\n",
            "Train step - Step 1380, Loss 0.002626679604873061\n",
            "Train step - Step 1390, Loss 0.005522281862795353\n",
            "Train step - Step 1400, Loss 0.0034244582056999207\n",
            "Train epoch - Accuracy: 0.972929292929293 Loss: 0.004574870222125842 Corrects: 4816\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0050721550360322\n",
            "Train step - Step 1420, Loss 0.007697220891714096\n",
            "Train step - Step 1430, Loss 0.004537809174507856\n",
            "Train step - Step 1440, Loss 0.0032013796735554934\n",
            "Train epoch - Accuracy: 0.9678787878787879 Loss: 0.005259284362798989 Corrects: 4791\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0038328790105879307\n",
            "Train step - Step 1460, Loss 0.004453297704458237\n",
            "Train step - Step 1470, Loss 0.0035528279840946198\n",
            "Train step - Step 1480, Loss 0.005085522774606943\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.005381739459593187 Corrects: 4790\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0028519651386886835\n",
            "Train step - Step 1500, Loss 0.003778858808800578\n",
            "Train step - Step 1510, Loss 0.005003062542527914\n",
            "Train step - Step 1520, Loss 0.00516884122043848\n",
            "Train epoch - Accuracy: 0.9642424242424242 Loss: 0.005576677621539795 Corrects: 4773\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.004743614699691534\n",
            "Train step - Step 1540, Loss 0.01006790529936552\n",
            "Train step - Step 1550, Loss 0.0032222368754446507\n",
            "Train epoch - Accuracy: 0.9642424242424242 Loss: 0.00564547264402864 Corrects: 4773\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.006656603422015905\n",
            "Train step - Step 1570, Loss 0.00425175903365016\n",
            "Train step - Step 1580, Loss 0.0018960386514663696\n",
            "Train step - Step 1590, Loss 0.00414906395599246\n",
            "Train epoch - Accuracy: 0.9711111111111111 Loss: 0.004735731568488509 Corrects: 4807\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0052078342996537685\n",
            "Train step - Step 1610, Loss 0.0035047479905188084\n",
            "Train step - Step 1620, Loss 0.00676788529381156\n",
            "Train step - Step 1630, Loss 0.007347141392529011\n",
            "Train epoch - Accuracy: 0.9696969696969697 Loss: 0.004897158956813692 Corrects: 4800\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.005603571888059378\n",
            "Train step - Step 1650, Loss 0.0035450446885079145\n",
            "Train step - Step 1660, Loss 0.006295026279985905\n",
            "Train step - Step 1670, Loss 0.006087278015911579\n",
            "Train epoch - Accuracy: 0.9678787878787879 Loss: 0.005044644464635187 Corrects: 4791\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.002498085843399167\n",
            "Train step - Step 1690, Loss 0.004225403070449829\n",
            "Train step - Step 1700, Loss 0.006292040925472975\n",
            "Train step - Step 1710, Loss 0.0056896149180829525\n",
            "Train epoch - Accuracy: 0.9711111111111111 Loss: 0.004866474128205969 Corrects: 4807\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.004401708021759987\n",
            "Train step - Step 1730, Loss 0.00451762555167079\n",
            "Train step - Step 1740, Loss 0.005051370244473219\n",
            "Train step - Step 1750, Loss 0.002984944498166442\n",
            "Train epoch - Accuracy: 0.963030303030303 Loss: 0.0056240068921687624 Corrects: 4767\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.0069117057137191296\n",
            "Train step - Step 1770, Loss 0.005117302294820547\n",
            "Train step - Step 1780, Loss 0.004844212904572487\n",
            "Train step - Step 1790, Loss 0.0034650079905986786\n",
            "Train epoch - Accuracy: 0.9652525252525253 Loss: 0.005164290089160204 Corrects: 4778\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.002972711343318224\n",
            "Train step - Step 1810, Loss 0.00291449879296124\n",
            "Train step - Step 1820, Loss 0.010651372373104095\n",
            "Train step - Step 1830, Loss 0.00605078274384141\n",
            "Train epoch - Accuracy: 0.9686868686868687 Loss: 0.005187298480910484 Corrects: 4795\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.00476006418466568\n",
            "Train step - Step 1850, Loss 0.003180264262482524\n",
            "Train step - Step 1860, Loss 0.0030033213552087545\n",
            "Train step - Step 1870, Loss 0.0060191391967237\n",
            "Train epoch - Accuracy: 0.9717171717171718 Loss: 0.004745974968178104 Corrects: 4810\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.014372250996530056\n",
            "Train step - Step 1890, Loss 0.00445741368457675\n",
            "Train step - Step 1900, Loss 0.007744640111923218\n",
            "Train step - Step 1910, Loss 0.005036347545683384\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.005540503023775539 Corrects: 4758\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.002386016771197319\n",
            "Train step - Step 1930, Loss 0.0026932626497000456\n",
            "Train step - Step 1940, Loss 0.00506429560482502\n",
            "Train epoch - Accuracy: 0.9850505050505051 Loss: 0.0031604355216176823 Corrects: 4876\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.00529279513284564\n",
            "Train step - Step 1960, Loss 0.0011151405051350594\n",
            "Train step - Step 1970, Loss 0.00351539789699018\n",
            "Train step - Step 1980, Loss 0.0012356172082945704\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0016459413749081166 Corrects: 4921\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0017066985601559281\n",
            "Train step - Step 2000, Loss 0.0007929481798782945\n",
            "Train step - Step 2010, Loss 0.001097985776141286\n",
            "Train step - Step 2020, Loss 0.002480743220075965\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0013471978078737404 Corrects: 4927\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0019103024387732148\n",
            "Train step - Step 2040, Loss 0.0014502013800665736\n",
            "Train step - Step 2050, Loss 0.0008033111807890236\n",
            "Train step - Step 2060, Loss 0.0011139194248244166\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0011897774439568471 Corrects: 4931\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0009343604906462133\n",
            "Train step - Step 2080, Loss 0.0006626758840866387\n",
            "Train step - Step 2090, Loss 0.0016423013294115663\n",
            "Train step - Step 2100, Loss 0.0013299387646839023\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0009050319603446758 Corrects: 4941\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0003376725653652102\n",
            "Train step - Step 2120, Loss 0.000615521683357656\n",
            "Train step - Step 2130, Loss 0.002046097768470645\n",
            "Train step - Step 2140, Loss 0.000833813683129847\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.000919715900519731 Corrects: 4938\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0009876637486740947\n",
            "Train step - Step 2160, Loss 0.001049597980454564\n",
            "Train step - Step 2170, Loss 0.0005096737877465785\n",
            "Train step - Step 2180, Loss 0.0006691670860163867\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0009039188108308185 Corrects: 4937\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0010505690006539226\n",
            "Train step - Step 2200, Loss 0.0005771767464466393\n",
            "Train step - Step 2210, Loss 0.0007505806279368699\n",
            "Train step - Step 2220, Loss 0.0008975224918685853\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0008448703926423508 Corrects: 4942\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.000612537085544318\n",
            "Train step - Step 2240, Loss 0.0007061329088173807\n",
            "Train step - Step 2250, Loss 0.0003502879699226469\n",
            "Train step - Step 2260, Loss 0.0014884386910125613\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0008226446405457653 Corrects: 4939\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0013513339217752218\n",
            "Train step - Step 2280, Loss 0.0013219492975622416\n",
            "Train step - Step 2290, Loss 0.0006012312951497734\n",
            "Train step - Step 2300, Loss 0.0006668299320153892\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0007309057928781693 Corrects: 4942\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.00039019566611386836\n",
            "Train step - Step 2320, Loss 0.0006795083172619343\n",
            "Train step - Step 2330, Loss 0.00027316814521327615\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0006663754704229609 Corrects: 4947\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0003410693316254765\n",
            "Train step - Step 2350, Loss 0.0002876959915738553\n",
            "Train step - Step 2360, Loss 0.0005870380555279553\n",
            "Train step - Step 2370, Loss 0.0006280461675487459\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00062666941970361 Corrects: 4945\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0014510279288515449\n",
            "Train step - Step 2390, Loss 0.0024758928921073675\n",
            "Train step - Step 2400, Loss 0.0006368189351633191\n",
            "Train step - Step 2410, Loss 0.00037234817864373326\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0007069087069072394 Corrects: 4943\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00040630900184623897\n",
            "Train step - Step 2430, Loss 0.00071669090539217\n",
            "Train step - Step 2440, Loss 0.0007874352158978581\n",
            "Train step - Step 2450, Loss 0.0005909243482165039\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.000677040280113373 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0003413996601011604\n",
            "Train step - Step 2470, Loss 0.0009270988521166146\n",
            "Train step - Step 2480, Loss 0.0004750474472530186\n",
            "Train step - Step 2490, Loss 0.0007391613908112049\n",
            "Train epoch - Accuracy: 0.9997979797979798 Loss: 0.0005469372787635134 Corrects: 4949\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00042977911652997136\n",
            "Train step - Step 2510, Loss 0.00027659436454996467\n",
            "Train step - Step 2520, Loss 0.0006447960622608662\n",
            "Train step - Step 2530, Loss 0.000627334404271096\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0005989563636801611 Corrects: 4943\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0005036396905779839\n",
            "Train step - Step 2550, Loss 0.0005826945998705924\n",
            "Train step - Step 2560, Loss 0.0003132782003376633\n",
            "Train step - Step 2570, Loss 0.00035935049527324736\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0005637743737021781 Corrects: 4945\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0005403906106948853\n",
            "Train step - Step 2590, Loss 0.001936478540301323\n",
            "Train step - Step 2600, Loss 0.0003971871919929981\n",
            "Train step - Step 2610, Loss 0.0003485076013021171\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.000597543420300659 Corrects: 4947\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0005088350153528154\n",
            "Train step - Step 2630, Loss 0.00034085052902810276\n",
            "Train step - Step 2640, Loss 0.0008997283293865621\n",
            "Train step - Step 2650, Loss 0.0002805460535455495\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0004956090609740579 Corrects: 4946\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0004561564128380269\n",
            "Train step - Step 2670, Loss 0.0006328043527901173\n",
            "Train step - Step 2680, Loss 0.0008699645404703915\n",
            "Train step - Step 2690, Loss 0.0004475967143662274\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0005478465716787285 Corrects: 4946\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0008208476938307285\n",
            "Train step - Step 2710, Loss 0.0003086607903242111\n",
            "Train step - Step 2720, Loss 0.001152730779722333\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0005768792788531029 Corrects: 4945\n",
            "Training finished in 240.50345420837402 seconds\n",
            "EVALUATION:  0.82 0.03526134043931961\n",
            "TEST GROUP:  0.886\n",
            "TEST ALL:  0.2215\n",
            "GROUP:  5\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.24346879124641418\n",
            "Train step - Step 10, Loss 0.09500650316476822\n",
            "Train step - Step 20, Loss 0.05601593852043152\n",
            "Train step - Step 30, Loss 0.04809928685426712\n",
            "Train epoch - Accuracy: 0.2862626262626263 Loss: 0.0752354212255791 Corrects: 1417\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.04185672849416733\n",
            "Train step - Step 50, Loss 0.04051906615495682\n",
            "Train step - Step 60, Loss 0.036282844841480255\n",
            "Train step - Step 70, Loss 0.040908556431531906\n",
            "Train epoch - Accuracy: 0.5458585858585858 Loss: 0.04001551156995272 Corrects: 2702\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.0326821468770504\n",
            "Train step - Step 90, Loss 0.030330628156661987\n",
            "Train step - Step 100, Loss 0.031168684363365173\n",
            "Train step - Step 110, Loss 0.031231578439474106\n",
            "Train epoch - Accuracy: 0.6329292929292929 Loss: 0.033550595048100054 Corrects: 3133\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.03269214928150177\n",
            "Train step - Step 130, Loss 0.029445605352520943\n",
            "Train step - Step 140, Loss 0.030261952430009842\n",
            "Train step - Step 150, Loss 0.030511146411299706\n",
            "Train epoch - Accuracy: 0.6888888888888889 Loss: 0.02981308450000455 Corrects: 3410\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.028041452169418335\n",
            "Train step - Step 170, Loss 0.02398909442126751\n",
            "Train step - Step 180, Loss 0.029998043552041054\n",
            "Train step - Step 190, Loss 0.02669750340282917\n",
            "Train epoch - Accuracy: 0.7173737373737373 Loss: 0.027094048958535146 Corrects: 3551\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.021244434639811516\n",
            "Train step - Step 210, Loss 0.03027522750198841\n",
            "Train step - Step 220, Loss 0.023656319826841354\n",
            "Train step - Step 230, Loss 0.0291342344135046\n",
            "Train epoch - Accuracy: 0.7325252525252526 Loss: 0.0257337450567219 Corrects: 3626\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.019030403345823288\n",
            "Train step - Step 250, Loss 0.023654405027627945\n",
            "Train step - Step 260, Loss 0.023965761065483093\n",
            "Train step - Step 270, Loss 0.0274380911141634\n",
            "Train epoch - Accuracy: 0.7612121212121212 Loss: 0.023432305486816348 Corrects: 3768\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.025074584409594536\n",
            "Train step - Step 290, Loss 0.019710540771484375\n",
            "Train step - Step 300, Loss 0.022349238395690918\n",
            "Train step - Step 310, Loss 0.016778720542788506\n",
            "Train epoch - Accuracy: 0.7886868686868687 Loss: 0.021410377970097042 Corrects: 3904\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.02248762734234333\n",
            "Train step - Step 330, Loss 0.022700846195220947\n",
            "Train step - Step 340, Loss 0.021479301154613495\n",
            "Train step - Step 350, Loss 0.02221429906785488\n",
            "Train epoch - Accuracy: 0.781010101010101 Loss: 0.021555086146249916 Corrects: 3866\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.02075035311281681\n",
            "Train step - Step 370, Loss 0.028228048235177994\n",
            "Train step - Step 380, Loss 0.026020247489213943\n",
            "Train epoch - Accuracy: 0.7981818181818182 Loss: 0.02003405183403179 Corrects: 3951\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.019159777089953423\n",
            "Train step - Step 400, Loss 0.020492715761065483\n",
            "Train step - Step 410, Loss 0.021470895037055016\n",
            "Train step - Step 420, Loss 0.01808609999716282\n",
            "Train epoch - Accuracy: 0.8173737373737374 Loss: 0.018579013462018484 Corrects: 4046\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.015014155767858028\n",
            "Train step - Step 440, Loss 0.017541255801916122\n",
            "Train step - Step 450, Loss 0.015502681024372578\n",
            "Train step - Step 460, Loss 0.01791602373123169\n",
            "Train epoch - Accuracy: 0.8274747474747475 Loss: 0.01784054155452083 Corrects: 4096\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.021496228873729706\n",
            "Train step - Step 480, Loss 0.01323656551539898\n",
            "Train step - Step 490, Loss 0.01461044792085886\n",
            "Train step - Step 500, Loss 0.018137024715542793\n",
            "Train epoch - Accuracy: 0.8309090909090909 Loss: 0.017030742185735942 Corrects: 4113\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.01415189728140831\n",
            "Train step - Step 520, Loss 0.015586723573505878\n",
            "Train step - Step 530, Loss 0.017879322171211243\n",
            "Train step - Step 540, Loss 0.016762783750891685\n",
            "Train epoch - Accuracy: 0.84 Loss: 0.016253357687682816 Corrects: 4158\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.016439590603113174\n",
            "Train step - Step 560, Loss 0.011674460954964161\n",
            "Train step - Step 570, Loss 0.01716739311814308\n",
            "Train step - Step 580, Loss 0.01955266483128071\n",
            "Train epoch - Accuracy: 0.8482828282828283 Loss: 0.01584932420891945 Corrects: 4199\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.016718881204724312\n",
            "Train step - Step 600, Loss 0.01382600236684084\n",
            "Train step - Step 610, Loss 0.013209815137088299\n",
            "Train step - Step 620, Loss 0.014438563026487827\n",
            "Train epoch - Accuracy: 0.8656565656565657 Loss: 0.014451545984155 Corrects: 4285\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.01538056693971157\n",
            "Train step - Step 640, Loss 0.011908630840480328\n",
            "Train step - Step 650, Loss 0.016555313020944595\n",
            "Train step - Step 660, Loss 0.012573771178722382\n",
            "Train epoch - Accuracy: 0.8591919191919192 Loss: 0.014702593027943313 Corrects: 4253\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.010592219419777393\n",
            "Train step - Step 680, Loss 0.011376704089343548\n",
            "Train step - Step 690, Loss 0.01602151431143284\n",
            "Train step - Step 700, Loss 0.01661851815879345\n",
            "Train epoch - Accuracy: 0.8593939393939394 Loss: 0.014830903688615019 Corrects: 4254\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.015342564322054386\n",
            "Train step - Step 720, Loss 0.011525877751410007\n",
            "Train step - Step 730, Loss 0.01036868803203106\n",
            "Train step - Step 740, Loss 0.013221831992268562\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.013522910249203143 Corrects: 4326\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.011125920340418816\n",
            "Train step - Step 760, Loss 0.014972777105867863\n",
            "Train step - Step 770, Loss 0.009613433852791786\n",
            "Train epoch - Accuracy: 0.8870707070707071 Loss: 0.012528662599924236 Corrects: 4391\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.00930423941463232\n",
            "Train step - Step 790, Loss 0.014264973811805248\n",
            "Train step - Step 800, Loss 0.014510031789541245\n",
            "Train step - Step 810, Loss 0.013725606724619865\n",
            "Train epoch - Accuracy: 0.8868686868686869 Loss: 0.012328159524635835 Corrects: 4390\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.008453688584268093\n",
            "Train step - Step 830, Loss 0.011782501824200153\n",
            "Train step - Step 840, Loss 0.010043608956038952\n",
            "Train step - Step 850, Loss 0.013062022626399994\n",
            "Train epoch - Accuracy: 0.8929292929292929 Loss: 0.011652517248735283 Corrects: 4420\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.009720764122903347\n",
            "Train step - Step 870, Loss 0.010599516332149506\n",
            "Train step - Step 880, Loss 0.012875963002443314\n",
            "Train step - Step 890, Loss 0.015688616782426834\n",
            "Train epoch - Accuracy: 0.8840404040404041 Loss: 0.012614218917007399 Corrects: 4376\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.011122406460344791\n",
            "Train step - Step 910, Loss 0.011466402560472488\n",
            "Train step - Step 920, Loss 0.012168421410024166\n",
            "Train step - Step 930, Loss 0.01407710276544094\n",
            "Train epoch - Accuracy: 0.8854545454545455 Loss: 0.012123138433454013 Corrects: 4383\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.01496755238622427\n",
            "Train step - Step 950, Loss 0.010474327951669693\n",
            "Train step - Step 960, Loss 0.010839138180017471\n",
            "Train step - Step 970, Loss 0.01314262393862009\n",
            "Train epoch - Accuracy: 0.8993939393939394 Loss: 0.011418450781793306 Corrects: 4452\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.011208610609173775\n",
            "Train step - Step 990, Loss 0.006318144034594297\n",
            "Train step - Step 1000, Loss 0.007245477754622698\n",
            "Train step - Step 1010, Loss 0.010655398480594158\n",
            "Train epoch - Accuracy: 0.9074747474747474 Loss: 0.010370019881638012 Corrects: 4492\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.008000917732715607\n",
            "Train step - Step 1030, Loss 0.009410611353814602\n",
            "Train step - Step 1040, Loss 0.010120784863829613\n",
            "Train step - Step 1050, Loss 0.009277423843741417\n",
            "Train epoch - Accuracy: 0.9115151515151515 Loss: 0.010149479981022651 Corrects: 4512\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.010067880153656006\n",
            "Train step - Step 1070, Loss 0.00979244988411665\n",
            "Train step - Step 1080, Loss 0.00881761871278286\n",
            "Train step - Step 1090, Loss 0.011555864475667477\n",
            "Train epoch - Accuracy: 0.9042424242424243 Loss: 0.009945302906662526 Corrects: 4476\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.012799439020454884\n",
            "Train step - Step 1110, Loss 0.02006818726658821\n",
            "Train step - Step 1120, Loss 0.014151552692055702\n",
            "Train step - Step 1130, Loss 0.012326451018452644\n",
            "Train epoch - Accuracy: 0.8949494949494949 Loss: 0.011503086218779737 Corrects: 4430\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.009306665509939194\n",
            "Train step - Step 1150, Loss 0.009883514605462551\n",
            "Train step - Step 1160, Loss 0.007083328906446695\n",
            "Train epoch - Accuracy: 0.9086868686868687 Loss: 0.010299769103376552 Corrects: 4498\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.009225436486303806\n",
            "Train step - Step 1180, Loss 0.007681877352297306\n",
            "Train step - Step 1190, Loss 0.01015485543757677\n",
            "Train step - Step 1200, Loss 0.01209558267146349\n",
            "Train epoch - Accuracy: 0.9218181818181819 Loss: 0.009443831738423218 Corrects: 4563\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.006196699570864439\n",
            "Train step - Step 1220, Loss 0.007644440978765488\n",
            "Train step - Step 1230, Loss 0.011815223842859268\n",
            "Train step - Step 1240, Loss 0.012504150159657001\n",
            "Train epoch - Accuracy: 0.9185858585858586 Loss: 0.00911314148606375 Corrects: 4547\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.006452958565205336\n",
            "Train step - Step 1260, Loss 0.008260098285973072\n",
            "Train step - Step 1270, Loss 0.00889797043055296\n",
            "Train step - Step 1280, Loss 0.008512328378856182\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.008811932647544327 Corrects: 4555\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.00767941027879715\n",
            "Train step - Step 1300, Loss 0.017571939155459404\n",
            "Train step - Step 1310, Loss 0.012211914174258709\n",
            "Train step - Step 1320, Loss 0.00880940817296505\n",
            "Train epoch - Accuracy: 0.906060606060606 Loss: 0.010238977472363698 Corrects: 4485\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.009783080779016018\n",
            "Train step - Step 1340, Loss 0.012497675605118275\n",
            "Train step - Step 1350, Loss 0.007590543013066053\n",
            "Train step - Step 1360, Loss 0.009753855876624584\n",
            "Train epoch - Accuracy: 0.9321212121212121 Loss: 0.008360909341712191 Corrects: 4614\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004421229939907789\n",
            "Train step - Step 1380, Loss 0.005734867881983519\n",
            "Train step - Step 1390, Loss 0.006961696781218052\n",
            "Train step - Step 1400, Loss 0.004566482733935118\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.007389644079211385 Corrects: 4652\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.004946400411427021\n",
            "Train step - Step 1420, Loss 0.008882428519427776\n",
            "Train step - Step 1430, Loss 0.010023853741586208\n",
            "Train step - Step 1440, Loss 0.008850899524986744\n",
            "Train epoch - Accuracy: 0.9286868686868687 Loss: 0.007886111836391266 Corrects: 4597\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.007030413020402193\n",
            "Train step - Step 1460, Loss 0.007313818670809269\n",
            "Train step - Step 1470, Loss 0.006022936664521694\n",
            "Train step - Step 1480, Loss 0.007756122387945652\n",
            "Train epoch - Accuracy: 0.936969696969697 Loss: 0.007179160601450036 Corrects: 4638\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.007950259372591972\n",
            "Train step - Step 1500, Loss 0.005878607276827097\n",
            "Train step - Step 1510, Loss 0.004901852924376726\n",
            "Train step - Step 1520, Loss 0.008908177725970745\n",
            "Train epoch - Accuracy: 0.9444444444444444 Loss: 0.006626040673993453 Corrects: 4675\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.007629668340086937\n",
            "Train step - Step 1540, Loss 0.00962307769805193\n",
            "Train step - Step 1550, Loss 0.006176813505589962\n",
            "Train epoch - Accuracy: 0.936969696969697 Loss: 0.007642456179465911 Corrects: 4638\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.006099835969507694\n",
            "Train step - Step 1570, Loss 0.008617664687335491\n",
            "Train step - Step 1580, Loss 0.009193037636578083\n",
            "Train step - Step 1590, Loss 0.012486794032156467\n",
            "Train epoch - Accuracy: 0.9072727272727272 Loss: 0.010057819480396281 Corrects: 4491\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.009574844501912594\n",
            "Train step - Step 1610, Loss 0.005666179582476616\n",
            "Train step - Step 1620, Loss 0.009572708979249\n",
            "Train step - Step 1630, Loss 0.009902802295982838\n",
            "Train epoch - Accuracy: 0.927070707070707 Loss: 0.00825098738902145 Corrects: 4589\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.005981911905109882\n",
            "Train step - Step 1650, Loss 0.008572731167078018\n",
            "Train step - Step 1660, Loss 0.007527533452957869\n",
            "Train step - Step 1670, Loss 0.006242492236196995\n",
            "Train epoch - Accuracy: 0.9365656565656566 Loss: 0.007627361844472512 Corrects: 4636\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.005287107080221176\n",
            "Train step - Step 1690, Loss 0.005317969247698784\n",
            "Train step - Step 1700, Loss 0.008325382135808468\n",
            "Train step - Step 1710, Loss 0.00729983439669013\n",
            "Train epoch - Accuracy: 0.94 Loss: 0.007006262234515614 Corrects: 4653\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.011587527580559254\n",
            "Train step - Step 1730, Loss 0.005624506156891584\n",
            "Train step - Step 1740, Loss 0.0054560815915465355\n",
            "Train step - Step 1750, Loss 0.007577481213957071\n",
            "Train epoch - Accuracy: 0.9351515151515152 Loss: 0.007454485479328367 Corrects: 4629\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.009111878462135792\n",
            "Train step - Step 1770, Loss 0.006029487121850252\n",
            "Train step - Step 1780, Loss 0.006963391788303852\n",
            "Train step - Step 1790, Loss 0.00442893011495471\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.006745103712786328 Corrects: 4670\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.007462714333087206\n",
            "Train step - Step 1810, Loss 0.00561577919870615\n",
            "Train step - Step 1820, Loss 0.00856475718319416\n",
            "Train step - Step 1830, Loss 0.007534979376941919\n",
            "Train epoch - Accuracy: 0.9442424242424242 Loss: 0.006532737970201656 Corrects: 4674\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.005540394224226475\n",
            "Train step - Step 1850, Loss 0.006619706749916077\n",
            "Train step - Step 1860, Loss 0.004684052430093288\n",
            "Train step - Step 1870, Loss 0.004720683209598064\n",
            "Train epoch - Accuracy: 0.9553535353535354 Loss: 0.005657164452954977 Corrects: 4729\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.006875856313854456\n",
            "Train step - Step 1890, Loss 0.008879100903868675\n",
            "Train step - Step 1900, Loss 0.003974215593189001\n",
            "Train step - Step 1910, Loss 0.00615736236795783\n",
            "Train epoch - Accuracy: 0.9480808080808081 Loss: 0.0061251916158756225 Corrects: 4693\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.005170452408492565\n",
            "Train step - Step 1930, Loss 0.003218540223315358\n",
            "Train step - Step 1940, Loss 0.0048247515223920345\n",
            "Train epoch - Accuracy: 0.9725252525252526 Loss: 0.0038270507658822368 Corrects: 4814\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0028007172513753176\n",
            "Train step - Step 1960, Loss 0.00309816375374794\n",
            "Train step - Step 1970, Loss 0.001474746153689921\n",
            "Train step - Step 1980, Loss 0.0012815027730539441\n",
            "Train epoch - Accuracy: 0.9888888888888889 Loss: 0.0022310172685073935 Corrects: 4895\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.00214620353654027\n",
            "Train step - Step 2000, Loss 0.0013937830226495862\n",
            "Train step - Step 2010, Loss 0.0037906644865870476\n",
            "Train step - Step 2020, Loss 0.002324128756299615\n",
            "Train epoch - Accuracy: 0.9915151515151515 Loss: 0.0019174574743580036 Corrects: 4908\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0015587926609441638\n",
            "Train step - Step 2040, Loss 0.002265797695145011\n",
            "Train step - Step 2050, Loss 0.0013043088838458061\n",
            "Train step - Step 2060, Loss 0.0019791871309280396\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0017396238470694634 Corrects: 4916\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0012606080854311585\n",
            "Train step - Step 2080, Loss 0.0014026390854269266\n",
            "Train step - Step 2090, Loss 0.0017681119497865438\n",
            "Train step - Step 2100, Loss 0.0011780665954574943\n",
            "Train epoch - Accuracy: 0.9949494949494949 Loss: 0.0014260224077963467 Corrects: 4925\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0012839409755542874\n",
            "Train step - Step 2120, Loss 0.001779344049282372\n",
            "Train step - Step 2130, Loss 0.0010959262726828456\n",
            "Train step - Step 2140, Loss 0.0007824936183169484\n",
            "Train epoch - Accuracy: 0.9951515151515151 Loss: 0.0013591671269857371 Corrects: 4926\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0006623392691835761\n",
            "Train step - Step 2160, Loss 0.001422565896064043\n",
            "Train step - Step 2170, Loss 0.0008860171656124294\n",
            "Train step - Step 2180, Loss 0.0008219829760491848\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.001271826235525724 Corrects: 4927\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0014515010407194495\n",
            "Train step - Step 2200, Loss 0.0014653750695288181\n",
            "Train step - Step 2210, Loss 0.0020645095501095057\n",
            "Train step - Step 2220, Loss 0.002139293123036623\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0012080019939634385 Corrects: 4927\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0010943009983748198\n",
            "Train step - Step 2240, Loss 0.0010303116869181395\n",
            "Train step - Step 2250, Loss 0.0011991866631433368\n",
            "Train step - Step 2260, Loss 0.002042581792920828\n",
            "Train epoch - Accuracy: 0.9945454545454545 Loss: 0.0012524216462190103 Corrects: 4923\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0012430851347744465\n",
            "Train step - Step 2280, Loss 0.0006073637050576508\n",
            "Train step - Step 2290, Loss 0.000646251137368381\n",
            "Train step - Step 2300, Loss 0.0009828121401369572\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0011032960140569643 Corrects: 4927\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0012768082087859511\n",
            "Train step - Step 2320, Loss 0.0006487834034487605\n",
            "Train step - Step 2330, Loss 0.0009812744101509452\n",
            "Train epoch - Accuracy: 0.9959595959595959 Loss: 0.0010874818881616147 Corrects: 4930\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0007073166780173779\n",
            "Train step - Step 2350, Loss 0.0008817158523015678\n",
            "Train step - Step 2360, Loss 0.0006350481417030096\n",
            "Train step - Step 2370, Loss 0.0005764490342698991\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0009710649328395687 Corrects: 4935\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0006326268194243312\n",
            "Train step - Step 2390, Loss 0.0010038417531177402\n",
            "Train step - Step 2400, Loss 0.0004839583416469395\n",
            "Train step - Step 2410, Loss 0.0010217728558927774\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0009762001968920231 Corrects: 4936\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0007695955573581159\n",
            "Train step - Step 2430, Loss 0.0005958191468380392\n",
            "Train step - Step 2440, Loss 0.001671177102252841\n",
            "Train step - Step 2450, Loss 0.0003799102851189673\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0010925446368396433 Corrects: 4928\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0004268662305548787\n",
            "Train step - Step 2470, Loss 0.0008561645518057048\n",
            "Train step - Step 2480, Loss 0.0006128755630925298\n",
            "Train step - Step 2490, Loss 0.0009691641898825765\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.000922242529793746 Corrects: 4932\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0006725828279741108\n",
            "Train step - Step 2510, Loss 0.0006831549690105021\n",
            "Train step - Step 2520, Loss 0.000993276247754693\n",
            "Train step - Step 2530, Loss 0.000932842493057251\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0009636232967610763 Corrects: 4939\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0004748816427309066\n",
            "Train step - Step 2550, Loss 0.0016801763558760285\n",
            "Train step - Step 2560, Loss 0.0007654793444089592\n",
            "Train step - Step 2570, Loss 0.0010355866979807615\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0009798245243916306 Corrects: 4932\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0006603103829547763\n",
            "Train step - Step 2590, Loss 0.000871410476975143\n",
            "Train step - Step 2600, Loss 0.0005484889261424541\n",
            "Train step - Step 2610, Loss 0.0011640394804999232\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0008735978602422307 Corrects: 4939\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0007329517393372953\n",
            "Train step - Step 2630, Loss 0.0006579892942681909\n",
            "Train step - Step 2640, Loss 0.0005637254798784852\n",
            "Train step - Step 2650, Loss 0.0010636486113071442\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0007800554805858569 Corrects: 4938\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0006142997299320996\n",
            "Train step - Step 2670, Loss 0.0005240323371253908\n",
            "Train step - Step 2680, Loss 0.0007213249919004738\n",
            "Train step - Step 2690, Loss 0.0004763207398355007\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0008139822724265883 Corrects: 4938\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0005521021666936576\n",
            "Train step - Step 2710, Loss 0.0006356863304972649\n",
            "Train step - Step 2720, Loss 0.0006314599304459989\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0007952065658614491 Corrects: 4942\n",
            "Training finished in 238.4515950679779 seconds\n",
            "EVALUATION:  0.84 0.014452937059104443\n",
            "TEST GROUP:  0.828\n",
            "TEST ALL:  0.1656\n",
            "GROUP:  6\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.1684623807668686\n",
            "Train step - Step 10, Loss 0.07661537826061249\n",
            "Train step - Step 20, Loss 0.05264335125684738\n",
            "Train step - Step 30, Loss 0.04122552275657654\n",
            "Train epoch - Accuracy: 0.2991919191919192 Loss: 0.05925572524919654 Corrects: 1481\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.03215416148304939\n",
            "Train step - Step 50, Loss 0.03365394100546837\n",
            "Train step - Step 60, Loss 0.029930250719189644\n",
            "Train step - Step 70, Loss 0.03127005323767662\n",
            "Train epoch - Accuracy: 0.5985858585858586 Loss: 0.030627426444882096 Corrects: 2963\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.023004373535513878\n",
            "Train step - Step 90, Loss 0.024162672460079193\n",
            "Train step - Step 100, Loss 0.024804236367344856\n",
            "Train step - Step 110, Loss 0.022619176656007767\n",
            "Train epoch - Accuracy: 0.7105050505050505 Loss: 0.024009367368287512 Corrects: 3517\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.020805971696972847\n",
            "Train step - Step 130, Loss 0.0188364889472723\n",
            "Train step - Step 140, Loss 0.016519254073500633\n",
            "Train step - Step 150, Loss 0.017055703327059746\n",
            "Train epoch - Accuracy: 0.7814141414141414 Loss: 0.01934781945376384 Corrects: 3868\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.01624245010316372\n",
            "Train step - Step 170, Loss 0.019761057570576668\n",
            "Train step - Step 180, Loss 0.014738697558641434\n",
            "Train step - Step 190, Loss 0.015162779949605465\n",
            "Train epoch - Accuracy: 0.8135353535353536 Loss: 0.016864732167109698 Corrects: 4027\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.011838363483548164\n",
            "Train step - Step 210, Loss 0.016400642693042755\n",
            "Train step - Step 220, Loss 0.015378380194306374\n",
            "Train step - Step 230, Loss 0.017010800540447235\n",
            "Train epoch - Accuracy: 0.8337373737373738 Loss: 0.014600771965101511 Corrects: 4127\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.011150008998811245\n",
            "Train step - Step 250, Loss 0.010638076812028885\n",
            "Train step - Step 260, Loss 0.015293287113308907\n",
            "Train step - Step 270, Loss 0.012779326178133488\n",
            "Train epoch - Accuracy: 0.8563636363636363 Loss: 0.012857114900317457 Corrects: 4239\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.010002977214753628\n",
            "Train step - Step 290, Loss 0.009697530418634415\n",
            "Train step - Step 300, Loss 0.014745733700692654\n",
            "Train step - Step 310, Loss 0.014086266979575157\n",
            "Train epoch - Accuracy: 0.8684848484848485 Loss: 0.012197882719714233 Corrects: 4299\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.010345467366278172\n",
            "Train step - Step 330, Loss 0.008357667364180088\n",
            "Train step - Step 340, Loss 0.013855040073394775\n",
            "Train step - Step 350, Loss 0.012683034874498844\n",
            "Train epoch - Accuracy: 0.8733333333333333 Loss: 0.011303007739285628 Corrects: 4323\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.00939587689936161\n",
            "Train step - Step 370, Loss 0.011221736669540405\n",
            "Train step - Step 380, Loss 0.012928035110235214\n",
            "Train epoch - Accuracy: 0.8696969696969697 Loss: 0.011615614108364992 Corrects: 4305\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.013281691819429398\n",
            "Train step - Step 400, Loss 0.010307759046554565\n",
            "Train step - Step 410, Loss 0.009477037936449051\n",
            "Train step - Step 420, Loss 0.008773564361035824\n",
            "Train epoch - Accuracy: 0.8852525252525253 Loss: 0.010440958511799273 Corrects: 4382\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.010115028358995914\n",
            "Train step - Step 440, Loss 0.010592209175229073\n",
            "Train step - Step 450, Loss 0.009055791422724724\n",
            "Train step - Step 460, Loss 0.01043718308210373\n",
            "Train epoch - Accuracy: 0.8884848484848484 Loss: 0.009781428150682137 Corrects: 4398\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.00849848985671997\n",
            "Train step - Step 480, Loss 0.010869390331208706\n",
            "Train step - Step 490, Loss 0.009731805883347988\n",
            "Train step - Step 500, Loss 0.011259432882070541\n",
            "Train epoch - Accuracy: 0.8923232323232323 Loss: 0.009489704836348091 Corrects: 4417\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.00981084629893303\n",
            "Train step - Step 520, Loss 0.006470039952546358\n",
            "Train step - Step 530, Loss 0.009663911536335945\n",
            "Train step - Step 540, Loss 0.011203770525753498\n",
            "Train epoch - Accuracy: 0.9022222222222223 Loss: 0.0092406097265205 Corrects: 4466\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.0058666132390499115\n",
            "Train step - Step 560, Loss 0.00862165167927742\n",
            "Train step - Step 570, Loss 0.008935388177633286\n",
            "Train step - Step 580, Loss 0.00866607204079628\n",
            "Train epoch - Accuracy: 0.9167676767676768 Loss: 0.008074027197905863 Corrects: 4538\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.008058153092861176\n",
            "Train step - Step 600, Loss 0.007902120240032673\n",
            "Train step - Step 610, Loss 0.008368108421564102\n",
            "Train step - Step 620, Loss 0.007381466683000326\n",
            "Train epoch - Accuracy: 0.914949494949495 Loss: 0.007963704726461207 Corrects: 4529\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.006936478894203901\n",
            "Train step - Step 640, Loss 0.005757045932114124\n",
            "Train step - Step 650, Loss 0.004852918442338705\n",
            "Train step - Step 660, Loss 0.008182676509022713\n",
            "Train epoch - Accuracy: 0.924040404040404 Loss: 0.007477714001492719 Corrects: 4574\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.01131630502641201\n",
            "Train step - Step 680, Loss 0.005536940880119801\n",
            "Train step - Step 690, Loss 0.004797021858394146\n",
            "Train step - Step 700, Loss 0.007130446378141642\n",
            "Train epoch - Accuracy: 0.9181818181818182 Loss: 0.007703677022622691 Corrects: 4545\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.00631181662902236\n",
            "Train step - Step 720, Loss 0.005505361594259739\n",
            "Train step - Step 730, Loss 0.007535090669989586\n",
            "Train step - Step 740, Loss 0.008288647048175335\n",
            "Train epoch - Accuracy: 0.924040404040404 Loss: 0.00708362990294141 Corrects: 4574\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.006753689609467983\n",
            "Train step - Step 760, Loss 0.005340477917343378\n",
            "Train step - Step 770, Loss 0.008408725261688232\n",
            "Train epoch - Accuracy: 0.9327272727272727 Loss: 0.00659933847779728 Corrects: 4617\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.004081620369106531\n",
            "Train step - Step 790, Loss 0.008528081700205803\n",
            "Train step - Step 800, Loss 0.005161612294614315\n",
            "Train step - Step 810, Loss 0.006702912040054798\n",
            "Train epoch - Accuracy: 0.9337373737373738 Loss: 0.006580441273523099 Corrects: 4622\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.005145119968801737\n",
            "Train step - Step 830, Loss 0.006842718925327063\n",
            "Train step - Step 840, Loss 0.0062181539833545685\n",
            "Train step - Step 850, Loss 0.004585241433233023\n",
            "Train epoch - Accuracy: 0.9383838383838384 Loss: 0.00607142186864759 Corrects: 4645\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.003515040036290884\n",
            "Train step - Step 870, Loss 0.009950883686542511\n",
            "Train step - Step 880, Loss 0.0069207395426929\n",
            "Train step - Step 890, Loss 0.003980171401053667\n",
            "Train epoch - Accuracy: 0.9321212121212121 Loss: 0.006370855557045551 Corrects: 4614\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.007616872899234295\n",
            "Train step - Step 910, Loss 0.003455281723290682\n",
            "Train step - Step 920, Loss 0.005166863091289997\n",
            "Train step - Step 930, Loss 0.008778143674135208\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.005790485422493833 Corrects: 4658\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.005287380889058113\n",
            "Train step - Step 950, Loss 0.00455269031226635\n",
            "Train step - Step 960, Loss 0.0033769698347896338\n",
            "Train step - Step 970, Loss 0.006836956366896629\n",
            "Train epoch - Accuracy: 0.9476767676767677 Loss: 0.00512320746978124 Corrects: 4691\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.006633953657001257\n",
            "Train step - Step 990, Loss 0.0021018011029809713\n",
            "Train step - Step 1000, Loss 0.004500658251345158\n",
            "Train step - Step 1010, Loss 0.006726494058966637\n",
            "Train epoch - Accuracy: 0.944040404040404 Loss: 0.005575587891531412 Corrects: 4673\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.007286660373210907\n",
            "Train step - Step 1030, Loss 0.005432202480733395\n",
            "Train step - Step 1040, Loss 0.0032692207023501396\n",
            "Train step - Step 1050, Loss 0.004240481182932854\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.005314059105391304 Corrects: 4690\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.008208739571273327\n",
            "Train step - Step 1070, Loss 0.0068520051427185535\n",
            "Train step - Step 1080, Loss 0.007939956150949001\n",
            "Train step - Step 1090, Loss 0.007933261804282665\n",
            "Train epoch - Accuracy: 0.9367676767676768 Loss: 0.00631176634418844 Corrects: 4637\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.006723683327436447\n",
            "Train step - Step 1110, Loss 0.005683714058250189\n",
            "Train step - Step 1120, Loss 0.004983908496797085\n",
            "Train step - Step 1130, Loss 0.0029345182701945305\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.006216587177807032 Corrects: 4621\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.00564737431704998\n",
            "Train step - Step 1150, Loss 0.004388721194118261\n",
            "Train step - Step 1160, Loss 0.004741201177239418\n",
            "Train epoch - Accuracy: 0.955959595959596 Loss: 0.004590154070821073 Corrects: 4732\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.005265211220830679\n",
            "Train step - Step 1180, Loss 0.0030460632406175137\n",
            "Train step - Step 1190, Loss 0.004890416748821735\n",
            "Train step - Step 1200, Loss 0.0033371211029589176\n",
            "Train epoch - Accuracy: 0.9531313131313132 Loss: 0.004589928460467343 Corrects: 4718\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.006108345929533243\n",
            "Train step - Step 1220, Loss 0.004446431994438171\n",
            "Train step - Step 1230, Loss 0.005794290918856859\n",
            "Train step - Step 1240, Loss 0.0031753545626997948\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.004925631128176294 Corrects: 4706\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.005093304440379143\n",
            "Train step - Step 1260, Loss 0.0049111866392195225\n",
            "Train step - Step 1270, Loss 0.004304856061935425\n",
            "Train step - Step 1280, Loss 0.006853287573903799\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.0049614067294757175 Corrects: 4708\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.004122429993003607\n",
            "Train step - Step 1300, Loss 0.00463942950591445\n",
            "Train step - Step 1310, Loss 0.0047606551088392735\n",
            "Train step - Step 1320, Loss 0.0023935919161885977\n",
            "Train epoch - Accuracy: 0.9638383838383838 Loss: 0.004012775312582351 Corrects: 4771\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.003295422997325659\n",
            "Train step - Step 1340, Loss 0.004967028275132179\n",
            "Train step - Step 1350, Loss 0.005649734754115343\n",
            "Train step - Step 1360, Loss 0.004214740823954344\n",
            "Train epoch - Accuracy: 0.9541414141414142 Loss: 0.00458169827764534 Corrects: 4723\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004659314174205065\n",
            "Train step - Step 1380, Loss 0.004421117249876261\n",
            "Train step - Step 1390, Loss 0.003080108668655157\n",
            "Train step - Step 1400, Loss 0.004024517722427845\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.004251347281734901 Corrects: 4738\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0026135093066841364\n",
            "Train step - Step 1420, Loss 0.0028312173672020435\n",
            "Train step - Step 1430, Loss 0.005048057995736599\n",
            "Train step - Step 1440, Loss 0.005246778484433889\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.004020078215146004 Corrects: 4772\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0031949994154274464\n",
            "Train step - Step 1460, Loss 0.003305075690150261\n",
            "Train step - Step 1470, Loss 0.002573310863226652\n",
            "Train step - Step 1480, Loss 0.006028519012033939\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.0039315201300713755 Corrects: 4758\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.004104582592844963\n",
            "Train step - Step 1500, Loss 0.004556572530418634\n",
            "Train step - Step 1510, Loss 0.004212253727018833\n",
            "Train step - Step 1520, Loss 0.007429973222315311\n",
            "Train epoch - Accuracy: 0.9523232323232323 Loss: 0.004481399954494202 Corrects: 4714\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.004983981139957905\n",
            "Train step - Step 1540, Loss 0.0025987299159169197\n",
            "Train step - Step 1550, Loss 0.003508086549118161\n",
            "Train epoch - Accuracy: 0.9622222222222222 Loss: 0.004006624132996858 Corrects: 4763\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0039064111188054085\n",
            "Train step - Step 1570, Loss 0.005713318940252066\n",
            "Train step - Step 1580, Loss 0.002953173825517297\n",
            "Train step - Step 1590, Loss 0.004107961896806955\n",
            "Train epoch - Accuracy: 0.9583838383838383 Loss: 0.0041447467276017474 Corrects: 4744\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0019125856924802065\n",
            "Train step - Step 1610, Loss 0.005493929143995047\n",
            "Train step - Step 1620, Loss 0.004566035699099302\n",
            "Train step - Step 1630, Loss 0.002726576756685972\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.003724321372468363 Corrects: 4769\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0013577506178990006\n",
            "Train step - Step 1650, Loss 0.00404726155102253\n",
            "Train step - Step 1660, Loss 0.005392864812165499\n",
            "Train step - Step 1670, Loss 0.0047163330018520355\n",
            "Train epoch - Accuracy: 0.9723232323232324 Loss: 0.003320134838459769 Corrects: 4813\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.002381274476647377\n",
            "Train step - Step 1690, Loss 0.004552466794848442\n",
            "Train step - Step 1700, Loss 0.0032296020071953535\n",
            "Train step - Step 1710, Loss 0.003974109888076782\n",
            "Train epoch - Accuracy: 0.9652525252525253 Loss: 0.0034211288164887163 Corrects: 4778\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0037553799338638783\n",
            "Train step - Step 1730, Loss 0.004868552554398775\n",
            "Train step - Step 1740, Loss 0.0015635652234777808\n",
            "Train step - Step 1750, Loss 0.005381214432418346\n",
            "Train epoch - Accuracy: 0.9626262626262626 Loss: 0.004070693950328713 Corrects: 4765\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.004333291668444872\n",
            "Train step - Step 1770, Loss 0.003239238867536187\n",
            "Train step - Step 1780, Loss 0.002515304135158658\n",
            "Train step - Step 1790, Loss 0.005501079838722944\n",
            "Train epoch - Accuracy: 0.9642424242424242 Loss: 0.0037358253893226083 Corrects: 4773\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.002841126173734665\n",
            "Train step - Step 1810, Loss 0.002153958659619093\n",
            "Train step - Step 1820, Loss 0.002594235586002469\n",
            "Train step - Step 1830, Loss 0.0037500744219869375\n",
            "Train epoch - Accuracy: 0.9664646464646465 Loss: 0.0034642773536457255 Corrects: 4784\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.004734286107122898\n",
            "Train step - Step 1850, Loss 0.0011830837465822697\n",
            "Train step - Step 1860, Loss 0.003930778242647648\n",
            "Train step - Step 1870, Loss 0.006956483703106642\n",
            "Train epoch - Accuracy: 0.9765656565656565 Loss: 0.0026973378623017306 Corrects: 4834\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0018688786076381803\n",
            "Train step - Step 1890, Loss 0.002893306314945221\n",
            "Train step - Step 1900, Loss 0.0016093561425805092\n",
            "Train step - Step 1910, Loss 0.0010094644967466593\n",
            "Train epoch - Accuracy: 0.9793939393939394 Loss: 0.0023675650669581663 Corrects: 4848\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.001234720228239894\n",
            "Train step - Step 1930, Loss 0.001195377204567194\n",
            "Train step - Step 1940, Loss 0.0010632309131324291\n",
            "Train epoch - Accuracy: 0.9868686868686869 Loss: 0.0016989694096411418 Corrects: 4885\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0012844059383496642\n",
            "Train step - Step 1960, Loss 0.002177432645112276\n",
            "Train step - Step 1970, Loss 0.002147552091628313\n",
            "Train step - Step 1980, Loss 0.0016089435666799545\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0010172498330116423 Corrects: 4921\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0007123589748516679\n",
            "Train step - Step 2000, Loss 0.0007405393989756703\n",
            "Train step - Step 2010, Loss 0.0011144065065309405\n",
            "Train step - Step 2020, Loss 0.0003022929304279387\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0008151822508726682 Corrects: 4931\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0006497841677628458\n",
            "Train step - Step 2040, Loss 0.0009659007773734629\n",
            "Train step - Step 2050, Loss 0.0007801676401868463\n",
            "Train step - Step 2060, Loss 0.0004683879087679088\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0007829567092715415 Corrects: 4932\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0006771090556867421\n",
            "Train step - Step 2080, Loss 0.0005455329082906246\n",
            "Train step - Step 2090, Loss 0.0008116490207612514\n",
            "Train step - Step 2100, Loss 0.0003334435459692031\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0007019112498094939 Corrects: 4933\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0009339709067717195\n",
            "Train step - Step 2120, Loss 0.0003745188005268574\n",
            "Train step - Step 2130, Loss 0.0009615636663511395\n",
            "Train step - Step 2140, Loss 0.0011245625792071223\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0006721442663745785 Corrects: 4935\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.00041567409061826766\n",
            "Train step - Step 2160, Loss 0.0006814302178099751\n",
            "Train step - Step 2170, Loss 0.0009673676686361432\n",
            "Train step - Step 2180, Loss 0.0007708905031904578\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0006436324982452348 Corrects: 4936\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.000981986173428595\n",
            "Train step - Step 2200, Loss 0.0004542125971056521\n",
            "Train step - Step 2210, Loss 0.0004618655366357416\n",
            "Train step - Step 2220, Loss 0.0002814665494952351\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0005618227293921841 Corrects: 4943\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0004738573916256428\n",
            "Train step - Step 2240, Loss 0.000461763673229143\n",
            "Train step - Step 2250, Loss 0.0006155786104500294\n",
            "Train step - Step 2260, Loss 0.0010213913628831506\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0005221614276877407 Corrects: 4942\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0004661149869207293\n",
            "Train step - Step 2280, Loss 0.0005462205735966563\n",
            "Train step - Step 2290, Loss 0.00045090654748491943\n",
            "Train step - Step 2300, Loss 0.00040230114245787263\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0004834831077746595 Corrects: 4945\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0002253303537145257\n",
            "Train step - Step 2320, Loss 0.0004551866149995476\n",
            "Train step - Step 2330, Loss 0.000549387710634619\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00041541390367924716 Corrects: 4948\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00045476792729459703\n",
            "Train step - Step 2350, Loss 0.00037961077759973705\n",
            "Train step - Step 2360, Loss 0.00038838916225358844\n",
            "Train step - Step 2370, Loss 0.00040279122185893357\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0004168982839804481 Corrects: 4947\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00022223179985303432\n",
            "Train step - Step 2390, Loss 0.00034379021963104606\n",
            "Train step - Step 2400, Loss 0.0006078990991227329\n",
            "Train step - Step 2410, Loss 0.00030324069666676223\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00042882852656108263 Corrects: 4944\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00024449214106425643\n",
            "Train step - Step 2430, Loss 0.00028404645854607224\n",
            "Train step - Step 2440, Loss 0.0006354042561724782\n",
            "Train step - Step 2450, Loss 0.0002880192769225687\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00043976493360888626 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0005287143867462873\n",
            "Train step - Step 2470, Loss 0.0002032746997429058\n",
            "Train step - Step 2480, Loss 0.00044823120697401464\n",
            "Train step - Step 2490, Loss 0.0001667991018621251\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0003500230214676133 Corrects: 4947\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0003102758782915771\n",
            "Train step - Step 2510, Loss 0.0002680294564925134\n",
            "Train step - Step 2520, Loss 0.0008093435899354517\n",
            "Train step - Step 2530, Loss 0.00033550531952641904\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0004032620320724549 Corrects: 4946\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00028618433861993253\n",
            "Train step - Step 2550, Loss 0.0003993607242591679\n",
            "Train step - Step 2560, Loss 0.00036524212919175625\n",
            "Train step - Step 2570, Loss 0.0005916913505643606\n",
            "Train epoch - Accuracy: 1.0 Loss: 0.0003535025734325043 Corrects: 4950\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002957393298856914\n",
            "Train step - Step 2590, Loss 0.0002826194104272872\n",
            "Train step - Step 2600, Loss 0.00021726715203840286\n",
            "Train step - Step 2610, Loss 0.000373530900105834\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.000381132788142434 Corrects: 4948\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00036703149089589715\n",
            "Train step - Step 2630, Loss 0.0003189400886185467\n",
            "Train step - Step 2640, Loss 0.00040698712109588087\n",
            "Train step - Step 2650, Loss 0.001244267332367599\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.000405867742339262 Corrects: 4946\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00027950172079727054\n",
            "Train step - Step 2670, Loss 0.0002406125422567129\n",
            "Train step - Step 2680, Loss 0.0003881195734720677\n",
            "Train step - Step 2690, Loss 0.00029925868147984147\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0003845124184436193 Corrects: 4946\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0002503312425687909\n",
            "Train step - Step 2710, Loss 0.0004993024631403387\n",
            "Train step - Step 2720, Loss 0.0002723905781749636\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00036488210584267487 Corrects: 4948\n",
            "Training finished in 236.90812301635742 seconds\n",
            "EVALUATION:  0.86 0.01205222774296999\n",
            "TEST GROUP:  0.889\n",
            "TEST ALL:  0.14816666666666667\n",
            "GROUP:  7\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.19210156798362732\n",
            "Train step - Step 10, Loss 0.07300921529531479\n",
            "Train step - Step 20, Loss 0.04102465137839317\n",
            "Train step - Step 30, Loss 0.03832554817199707\n",
            "Train epoch - Accuracy: 0.2397979797979798 Loss: 0.05705710027555023 Corrects: 1187\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.034117694944143295\n",
            "Train step - Step 50, Loss 0.02937178686261177\n",
            "Train step - Step 60, Loss 0.025757720693945885\n",
            "Train step - Step 70, Loss 0.025108588859438896\n",
            "Train epoch - Accuracy: 0.5535353535353535 Loss: 0.028456836505369707 Corrects: 2740\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.022209979593753815\n",
            "Train step - Step 90, Loss 0.021760378032922745\n",
            "Train step - Step 100, Loss 0.015431281179189682\n",
            "Train step - Step 110, Loss 0.02113148756325245\n",
            "Train epoch - Accuracy: 0.6894949494949495 Loss: 0.019856735482962445 Corrects: 3413\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.019945135340094566\n",
            "Train step - Step 130, Loss 0.01675332710146904\n",
            "Train step - Step 140, Loss 0.015169636346399784\n",
            "Train step - Step 150, Loss 0.017135262489318848\n",
            "Train epoch - Accuracy: 0.7359595959595959 Loss: 0.01679589886933264 Corrects: 3643\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.017123375087976456\n",
            "Train step - Step 170, Loss 0.01462564803659916\n",
            "Train step - Step 180, Loss 0.013538029044866562\n",
            "Train step - Step 190, Loss 0.012395326048135757\n",
            "Train epoch - Accuracy: 0.7638383838383839 Loss: 0.015569798842524038 Corrects: 3781\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.015538735315203667\n",
            "Train step - Step 210, Loss 0.014173916541039944\n",
            "Train step - Step 220, Loss 0.011470864526927471\n",
            "Train step - Step 230, Loss 0.014818048104643822\n",
            "Train epoch - Accuracy: 0.786060606060606 Loss: 0.014244688855051393 Corrects: 3891\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.01292947307229042\n",
            "Train step - Step 250, Loss 0.012535219080746174\n",
            "Train step - Step 260, Loss 0.011967962607741356\n",
            "Train step - Step 270, Loss 0.01111604180186987\n",
            "Train epoch - Accuracy: 0.8195959595959595 Loss: 0.0124536539173939 Corrects: 4057\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.011831577867269516\n",
            "Train step - Step 290, Loss 0.014171293936669827\n",
            "Train step - Step 300, Loss 0.01353652123361826\n",
            "Train step - Step 310, Loss 0.013453638181090355\n",
            "Train epoch - Accuracy: 0.842020202020202 Loss: 0.011338728788976718 Corrects: 4168\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.008421888574957848\n",
            "Train step - Step 330, Loss 0.009840117767453194\n",
            "Train step - Step 340, Loss 0.010838551446795464\n",
            "Train step - Step 350, Loss 0.010109961032867432\n",
            "Train epoch - Accuracy: 0.8498989898989899 Loss: 0.010592837574506046 Corrects: 4207\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.007350889965891838\n",
            "Train step - Step 370, Loss 0.007975982502102852\n",
            "Train step - Step 380, Loss 0.00805975217372179\n",
            "Train epoch - Accuracy: 0.8561616161616161 Loss: 0.010077920279117546 Corrects: 4238\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.009280861355364323\n",
            "Train step - Step 400, Loss 0.011890750378370285\n",
            "Train step - Step 410, Loss 0.008590562269091606\n",
            "Train step - Step 420, Loss 0.010212752036750317\n",
            "Train epoch - Accuracy: 0.8757575757575757 Loss: 0.009273687526583672 Corrects: 4335\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.007576901465654373\n",
            "Train step - Step 440, Loss 0.007945745252072811\n",
            "Train step - Step 450, Loss 0.011116545647382736\n",
            "Train step - Step 460, Loss 0.010238918475806713\n",
            "Train epoch - Accuracy: 0.86989898989899 Loss: 0.009275178640253014 Corrects: 4306\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.007836764678359032\n",
            "Train step - Step 480, Loss 0.010564968921244144\n",
            "Train step - Step 490, Loss 0.00801767036318779\n",
            "Train step - Step 500, Loss 0.006729462184011936\n",
            "Train epoch - Accuracy: 0.881010101010101 Loss: 0.008717022938183461 Corrects: 4361\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.006688591558486223\n",
            "Train step - Step 520, Loss 0.011755657382309437\n",
            "Train step - Step 530, Loss 0.0061634378507733345\n",
            "Train step - Step 540, Loss 0.007202585227787495\n",
            "Train epoch - Accuracy: 0.8896969696969697 Loss: 0.008379418832259346 Corrects: 4404\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.008413242176175117\n",
            "Train step - Step 560, Loss 0.007991067133843899\n",
            "Train step - Step 570, Loss 0.008769530802965164\n",
            "Train step - Step 580, Loss 0.00886556226760149\n",
            "Train epoch - Accuracy: 0.8832323232323233 Loss: 0.008464464635936298 Corrects: 4372\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.006010348908603191\n",
            "Train step - Step 600, Loss 0.007925755344331264\n",
            "Train step - Step 610, Loss 0.006786607671529055\n",
            "Train step - Step 620, Loss 0.006158995442092419\n",
            "Train epoch - Accuracy: 0.9038383838383839 Loss: 0.007291182784194296 Corrects: 4474\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.008132756687700748\n",
            "Train step - Step 640, Loss 0.005772977136075497\n",
            "Train step - Step 650, Loss 0.008065301924943924\n",
            "Train step - Step 660, Loss 0.010164586827158928\n",
            "Train epoch - Accuracy: 0.895959595959596 Loss: 0.007699052008113476 Corrects: 4435\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.009097944013774395\n",
            "Train step - Step 680, Loss 0.005539994221180677\n",
            "Train step - Step 690, Loss 0.007804900407791138\n",
            "Train step - Step 700, Loss 0.005996147636324167\n",
            "Train epoch - Accuracy: 0.9084848484848485 Loss: 0.007093473941162981 Corrects: 4497\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.008686746470630169\n",
            "Train step - Step 720, Loss 0.006023692898452282\n",
            "Train step - Step 730, Loss 0.008625374175608158\n",
            "Train step - Step 740, Loss 0.008636035025119781\n",
            "Train epoch - Accuracy: 0.9129292929292929 Loss: 0.0066908735488400315 Corrects: 4519\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.005175075959414244\n",
            "Train step - Step 760, Loss 0.007111407816410065\n",
            "Train step - Step 770, Loss 0.007005448918789625\n",
            "Train epoch - Accuracy: 0.9143434343434343 Loss: 0.00669684787704186 Corrects: 4526\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.006482348777353764\n",
            "Train step - Step 790, Loss 0.006932229734957218\n",
            "Train step - Step 800, Loss 0.006884322036057711\n",
            "Train step - Step 810, Loss 0.0064946673810482025\n",
            "Train epoch - Accuracy: 0.9157575757575758 Loss: 0.006471724893822513 Corrects: 4533\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.006006421986967325\n",
            "Train step - Step 830, Loss 0.0051763891242444515\n",
            "Train step - Step 840, Loss 0.007625309284776449\n",
            "Train step - Step 850, Loss 0.006292537320405245\n",
            "Train epoch - Accuracy: 0.918989898989899 Loss: 0.006302509145303206 Corrects: 4549\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.0057603297755122185\n",
            "Train step - Step 870, Loss 0.006502203643321991\n",
            "Train step - Step 880, Loss 0.005894097499549389\n",
            "Train step - Step 890, Loss 0.007762742228806019\n",
            "Train epoch - Accuracy: 0.924040404040404 Loss: 0.005835356654392348 Corrects: 4574\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.009847601875662804\n",
            "Train step - Step 910, Loss 0.004835821222513914\n",
            "Train step - Step 920, Loss 0.007426715921610594\n",
            "Train step - Step 930, Loss 0.006409232039004564\n",
            "Train epoch - Accuracy: 0.9222222222222223 Loss: 0.006072739845122954 Corrects: 4565\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.0048867142759263515\n",
            "Train step - Step 950, Loss 0.005463422276079655\n",
            "Train step - Step 960, Loss 0.004709422588348389\n",
            "Train step - Step 970, Loss 0.00468048732727766\n",
            "Train epoch - Accuracy: 0.927070707070707 Loss: 0.005809165042157125 Corrects: 4589\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0043853153474628925\n",
            "Train step - Step 990, Loss 0.005914856214076281\n",
            "Train step - Step 1000, Loss 0.005814577918499708\n",
            "Train step - Step 1010, Loss 0.004391242749989033\n",
            "Train epoch - Accuracy: 0.9280808080808081 Loss: 0.0054739453831706385 Corrects: 4594\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0059026088565588\n",
            "Train step - Step 1030, Loss 0.005041694268584251\n",
            "Train step - Step 1040, Loss 0.005407134536653757\n",
            "Train step - Step 1050, Loss 0.0037255806382745504\n",
            "Train epoch - Accuracy: 0.9327272727272727 Loss: 0.005372395498696903 Corrects: 4617\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0032640951685607433\n",
            "Train step - Step 1070, Loss 0.0046543278731405735\n",
            "Train step - Step 1080, Loss 0.004641085863113403\n",
            "Train step - Step 1090, Loss 0.0050421892665326595\n",
            "Train epoch - Accuracy: 0.9301010101010101 Loss: 0.005606330775025517 Corrects: 4604\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.005678065586835146\n",
            "Train step - Step 1110, Loss 0.004972909111529589\n",
            "Train step - Step 1120, Loss 0.007894839160144329\n",
            "Train step - Step 1130, Loss 0.006392414681613445\n",
            "Train epoch - Accuracy: 0.925050505050505 Loss: 0.005804045029135063 Corrects: 4579\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.006625812966376543\n",
            "Train step - Step 1150, Loss 0.003133039688691497\n",
            "Train step - Step 1160, Loss 0.0032772591803222895\n",
            "Train epoch - Accuracy: 0.942020202020202 Loss: 0.004787194915303979 Corrects: 4663\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.004925761837512255\n",
            "Train step - Step 1180, Loss 0.005677504930645227\n",
            "Train step - Step 1190, Loss 0.004463524091988802\n",
            "Train step - Step 1200, Loss 0.004495078697800636\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.004603615673352973 Corrects: 4670\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.004380133468657732\n",
            "Train step - Step 1220, Loss 0.0038646177854388952\n",
            "Train step - Step 1230, Loss 0.004564193543046713\n",
            "Train step - Step 1240, Loss 0.00320733105763793\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.0040812809140694266 Corrects: 4706\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0037682014517486095\n",
            "Train step - Step 1260, Loss 0.003115255618467927\n",
            "Train step - Step 1270, Loss 0.004644824657589197\n",
            "Train step - Step 1280, Loss 0.00510433642193675\n",
            "Train epoch - Accuracy: 0.938989898989899 Loss: 0.004696682587341227 Corrects: 4648\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.007781958673149347\n",
            "Train step - Step 1300, Loss 0.003382885130122304\n",
            "Train step - Step 1310, Loss 0.0039778053760528564\n",
            "Train step - Step 1320, Loss 0.0030379733070731163\n",
            "Train epoch - Accuracy: 0.9464646464646465 Loss: 0.004440411844413088 Corrects: 4685\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0042914231307804585\n",
            "Train step - Step 1340, Loss 0.004947292152792215\n",
            "Train step - Step 1350, Loss 0.004736623726785183\n",
            "Train step - Step 1360, Loss 0.005172508768737316\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.0043474589720970454 Corrects: 4690\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0057098763063549995\n",
            "Train step - Step 1380, Loss 0.004003917798399925\n",
            "Train step - Step 1390, Loss 0.004624946508556604\n",
            "Train step - Step 1400, Loss 0.0031852833926677704\n",
            "Train epoch - Accuracy: 0.9505050505050505 Loss: 0.004103973014938711 Corrects: 4705\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002514416817575693\n",
            "Train step - Step 1420, Loss 0.0039503625594079494\n",
            "Train step - Step 1430, Loss 0.004108837805688381\n",
            "Train step - Step 1440, Loss 0.004666339140385389\n",
            "Train epoch - Accuracy: 0.9494949494949495 Loss: 0.003954954543009852 Corrects: 4700\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.003412902355194092\n",
            "Train step - Step 1460, Loss 0.0044813938438892365\n",
            "Train step - Step 1470, Loss 0.003798939986154437\n",
            "Train step - Step 1480, Loss 0.003090611891821027\n",
            "Train epoch - Accuracy: 0.9585858585858585 Loss: 0.003611747771877833 Corrects: 4745\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0025000236928462982\n",
            "Train step - Step 1500, Loss 0.00316044595092535\n",
            "Train step - Step 1510, Loss 0.002032452030107379\n",
            "Train step - Step 1520, Loss 0.00714458804577589\n",
            "Train epoch - Accuracy: 0.9569696969696969 Loss: 0.003503469819146575 Corrects: 4737\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.006214768625795841\n",
            "Train step - Step 1540, Loss 0.005948908627033234\n",
            "Train step - Step 1550, Loss 0.005550246685743332\n",
            "Train epoch - Accuracy: 0.9533333333333334 Loss: 0.004024224435026296 Corrects: 4719\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.003861393313854933\n",
            "Train step - Step 1570, Loss 0.004360876977443695\n",
            "Train step - Step 1580, Loss 0.0028021589387208223\n",
            "Train step - Step 1590, Loss 0.0031172530725598335\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.004104548663352475 Corrects: 4695\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.003811209462583065\n",
            "Train step - Step 1610, Loss 0.005158091429620981\n",
            "Train step - Step 1620, Loss 0.005141228437423706\n",
            "Train step - Step 1630, Loss 0.0057846917770802975\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.003721777165703701 Corrects: 4724\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.004037585575133562\n",
            "Train step - Step 1650, Loss 0.005053344648331404\n",
            "Train step - Step 1660, Loss 0.0037337355315685272\n",
            "Train step - Step 1670, Loss 0.004006045404821634\n",
            "Train epoch - Accuracy: 0.96 Loss: 0.003386537641324479 Corrects: 4752\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.002652835100889206\n",
            "Train step - Step 1690, Loss 0.004015746526420116\n",
            "Train step - Step 1700, Loss 0.002438213676214218\n",
            "Train step - Step 1710, Loss 0.002661788370460272\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.0031623805745156727 Corrects: 4760\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0022798841819167137\n",
            "Train step - Step 1730, Loss 0.004230746533721685\n",
            "Train step - Step 1740, Loss 0.004113790113478899\n",
            "Train step - Step 1750, Loss 0.0024808053858578205\n",
            "Train epoch - Accuracy: 0.9632323232323232 Loss: 0.003135083464886805 Corrects: 4768\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002964147599413991\n",
            "Train step - Step 1770, Loss 0.0032845463138073683\n",
            "Train step - Step 1780, Loss 0.00236469111405313\n",
            "Train step - Step 1790, Loss 0.003034010296687484\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.0033257719748324218 Corrects: 4760\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.007231669966131449\n",
            "Train step - Step 1810, Loss 0.0037047015503048897\n",
            "Train step - Step 1820, Loss 0.0041825780645012856\n",
            "Train step - Step 1830, Loss 0.0030838127713650465\n",
            "Train epoch - Accuracy: 0.9531313131313132 Loss: 0.003898870444320368 Corrects: 4718\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0033168925438076258\n",
            "Train step - Step 1850, Loss 0.0019634480122476816\n",
            "Train step - Step 1860, Loss 0.001790288370102644\n",
            "Train step - Step 1870, Loss 0.002197293797507882\n",
            "Train epoch - Accuracy: 0.9583838383838383 Loss: 0.0034564482428208745 Corrects: 4744\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.002650356385856867\n",
            "Train step - Step 1890, Loss 0.0021040798164904118\n",
            "Train step - Step 1900, Loss 0.0025715543888509274\n",
            "Train step - Step 1910, Loss 0.004627462476491928\n",
            "Train epoch - Accuracy: 0.9557575757575758 Loss: 0.003610307334950476 Corrects: 4731\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0015019831480458379\n",
            "Train step - Step 1930, Loss 0.002548921387642622\n",
            "Train step - Step 1940, Loss 0.0016097172629088163\n",
            "Train epoch - Accuracy: 0.9806060606060606 Loss: 0.0020361508591796714 Corrects: 4854\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0021250545978546143\n",
            "Train step - Step 1960, Loss 0.0012689318973571062\n",
            "Train step - Step 1970, Loss 0.0008966806926764548\n",
            "Train step - Step 1980, Loss 0.0013313018716871738\n",
            "Train epoch - Accuracy: 0.9894949494949495 Loss: 0.001297397722650056 Corrects: 4898\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.000743397104088217\n",
            "Train step - Step 2000, Loss 0.0010423521744087338\n",
            "Train step - Step 2010, Loss 0.0009369660983793437\n",
            "Train step - Step 2020, Loss 0.0005828032735735178\n",
            "Train epoch - Accuracy: 0.9939393939393939 Loss: 0.0009301990775786566 Corrects: 4920\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0007274702657014132\n",
            "Train step - Step 2040, Loss 0.000795823463704437\n",
            "Train step - Step 2050, Loss 0.0011569233611226082\n",
            "Train step - Step 2060, Loss 0.0005513843498192728\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0007584895685108172 Corrects: 4935\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0010385274654254317\n",
            "Train step - Step 2080, Loss 0.001168358139693737\n",
            "Train step - Step 2090, Loss 0.0003342566196806729\n",
            "Train step - Step 2100, Loss 0.0005821675877086818\n",
            "Train epoch - Accuracy: 0.9951515151515151 Loss: 0.0007520440339952745 Corrects: 4926\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.000463691569166258\n",
            "Train step - Step 2120, Loss 0.00047090506996028125\n",
            "Train step - Step 2130, Loss 0.0004329824587330222\n",
            "Train step - Step 2140, Loss 0.0005395045736804605\n",
            "Train epoch - Accuracy: 0.9957575757575757 Loss: 0.0007274963233074305 Corrects: 4929\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0003594800364226103\n",
            "Train step - Step 2160, Loss 0.0004407983797136694\n",
            "Train step - Step 2170, Loss 0.0008896773215383291\n",
            "Train step - Step 2180, Loss 0.0007984499097801745\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0006302361854474351 Corrects: 4937\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0005360037321224809\n",
            "Train step - Step 2200, Loss 0.0007694361265748739\n",
            "Train step - Step 2210, Loss 0.0003589654224924743\n",
            "Train step - Step 2220, Loss 0.0004231563361827284\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0005813742993220762 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.00042274087900295854\n",
            "Train step - Step 2240, Loss 0.0006239533540792763\n",
            "Train step - Step 2250, Loss 0.000324604770867154\n",
            "Train step - Step 2260, Loss 0.0008699289173819125\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0006049351423809474 Corrects: 4933\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0006006649928167462\n",
            "Train step - Step 2280, Loss 0.00047749749501235783\n",
            "Train step - Step 2290, Loss 0.0003159939660690725\n",
            "Train step - Step 2300, Loss 0.0006617981707677245\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0005117387362671169 Corrects: 4939\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0004769079387187958\n",
            "Train step - Step 2320, Loss 0.0004525650874711573\n",
            "Train step - Step 2330, Loss 0.00040692565380595624\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.000559571931053969 Corrects: 4936\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00027144025079905987\n",
            "Train step - Step 2350, Loss 0.00019922891806345433\n",
            "Train step - Step 2360, Loss 0.00023402510851155967\n",
            "Train step - Step 2370, Loss 0.0007677432731725276\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0004375878448546347 Corrects: 4941\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00044315450941212475\n",
            "Train step - Step 2390, Loss 0.0004194337234366685\n",
            "Train step - Step 2400, Loss 0.0008167112828232348\n",
            "Train step - Step 2410, Loss 0.0003268665459472686\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0005139531029124904 Corrects: 4937\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0004549262812361121\n",
            "Train step - Step 2430, Loss 0.00029663596069440246\n",
            "Train step - Step 2440, Loss 0.00028129396378062665\n",
            "Train step - Step 2450, Loss 0.0003270531306043267\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00038899119385997906 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00021563866175711155\n",
            "Train step - Step 2470, Loss 0.00017395005852449685\n",
            "Train step - Step 2480, Loss 0.00040651229210197926\n",
            "Train step - Step 2490, Loss 0.0002712093701120466\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0004363826365031377 Corrects: 4941\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00020646015764214098\n",
            "Train step - Step 2510, Loss 0.00017752630810718983\n",
            "Train step - Step 2520, Loss 0.00027435884112492204\n",
            "Train step - Step 2530, Loss 0.0009357628296129405\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00043290722272076615 Corrects: 4940\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0003002654993906617\n",
            "Train step - Step 2550, Loss 0.00028540732455439866\n",
            "Train step - Step 2560, Loss 0.0003009890206158161\n",
            "Train step - Step 2570, Loss 0.00038888672133907676\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.00036164276885113333 Corrects: 4946\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002512607607059181\n",
            "Train step - Step 2590, Loss 0.00023540365509688854\n",
            "Train step - Step 2600, Loss 0.000584084598813206\n",
            "Train step - Step 2610, Loss 0.000292893877485767\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00041404124125932353 Corrects: 4942\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00015720499504823238\n",
            "Train step - Step 2630, Loss 0.00025921614724211395\n",
            "Train step - Step 2640, Loss 0.00047082756645977497\n",
            "Train step - Step 2650, Loss 0.0003283766855020076\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00035024093835605213 Corrects: 4947\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.000910756119992584\n",
            "Train step - Step 2670, Loss 0.00017600769933778793\n",
            "Train step - Step 2680, Loss 0.0002987806801684201\n",
            "Train step - Step 2690, Loss 0.00028129940619692206\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0003363133731034744 Corrects: 4944\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00029686465859413147\n",
            "Train step - Step 2710, Loss 0.000667656131554395\n",
            "Train step - Step 2720, Loss 0.00021877909603063017\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0003447849042313832 Corrects: 4946\n",
            "Training finished in 234.72998571395874 seconds\n",
            "EVALUATION:  0.84 0.018496444448828697\n",
            "TEST GROUP:  0.882\n",
            "TEST ALL:  0.126\n",
            "GROUP:  8\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.15287235379219055\n",
            "Train step - Step 10, Loss 0.06099393591284752\n",
            "Train step - Step 20, Loss 0.03482365235686302\n",
            "Train step - Step 30, Loss 0.030614301562309265\n",
            "Train epoch - Accuracy: 0.301010101010101 Loss: 0.04718249968582332 Corrects: 1490\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.0237742867320776\n",
            "Train step - Step 50, Loss 0.024505237117409706\n",
            "Train step - Step 60, Loss 0.01904546655714512\n",
            "Train step - Step 70, Loss 0.017568496987223625\n",
            "Train epoch - Accuracy: 0.675959595959596 Loss: 0.02044189751750291 Corrects: 3346\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.015190544538199902\n",
            "Train step - Step 90, Loss 0.014196410775184631\n",
            "Train step - Step 100, Loss 0.013653161935508251\n",
            "Train step - Step 110, Loss 0.010625320486724377\n",
            "Train epoch - Accuracy: 0.7903030303030303 Loss: 0.01427641904376673 Corrects: 3912\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.014517015777528286\n",
            "Train step - Step 130, Loss 0.01566370762884617\n",
            "Train step - Step 140, Loss 0.008592667058110237\n",
            "Train step - Step 150, Loss 0.009106074459850788\n",
            "Train epoch - Accuracy: 0.8301010101010101 Loss: 0.011654751771552996 Corrects: 4109\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.011471739038825035\n",
            "Train step - Step 170, Loss 0.01266789622604847\n",
            "Train step - Step 180, Loss 0.01059616357088089\n",
            "Train step - Step 190, Loss 0.011984797194600105\n",
            "Train epoch - Accuracy: 0.8549494949494949 Loss: 0.009999560332960553 Corrects: 4232\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.009217659942805767\n",
            "Train step - Step 210, Loss 0.008429561741650105\n",
            "Train step - Step 220, Loss 0.01194543857127428\n",
            "Train step - Step 230, Loss 0.007977784611284733\n",
            "Train epoch - Accuracy: 0.8705050505050506 Loss: 0.008762380074182846 Corrects: 4309\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00785566121339798\n",
            "Train step - Step 250, Loss 0.008600175380706787\n",
            "Train step - Step 260, Loss 0.006283040624111891\n",
            "Train step - Step 270, Loss 0.008382178843021393\n",
            "Train epoch - Accuracy: 0.8838383838383839 Loss: 0.007895968230535285 Corrects: 4375\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.010903234593570232\n",
            "Train step - Step 290, Loss 0.00834383349865675\n",
            "Train step - Step 300, Loss 0.008333878591656685\n",
            "Train step - Step 310, Loss 0.007384873926639557\n",
            "Train epoch - Accuracy: 0.8909090909090909 Loss: 0.00761792802900979 Corrects: 4410\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.008423247374594212\n",
            "Train step - Step 330, Loss 0.005598131567239761\n",
            "Train step - Step 340, Loss 0.00806940346956253\n",
            "Train step - Step 350, Loss 0.0055251410230994225\n",
            "Train epoch - Accuracy: 0.9040404040404041 Loss: 0.006750369296606743 Corrects: 4475\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.010776246897876263\n",
            "Train step - Step 370, Loss 0.0058189439587295055\n",
            "Train step - Step 380, Loss 0.005688570439815521\n",
            "Train epoch - Accuracy: 0.9076767676767676 Loss: 0.006525868000556725 Corrects: 4493\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.005125769879668951\n",
            "Train step - Step 400, Loss 0.004036699887365103\n",
            "Train step - Step 410, Loss 0.004836235195398331\n",
            "Train step - Step 420, Loss 0.004537707660347223\n",
            "Train epoch - Accuracy: 0.9119191919191919 Loss: 0.0060590483050680525 Corrects: 4514\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.003593454835936427\n",
            "Train step - Step 440, Loss 0.0053554982878267765\n",
            "Train step - Step 450, Loss 0.004208590369671583\n",
            "Train step - Step 460, Loss 0.0050436886958777905\n",
            "Train epoch - Accuracy: 0.925050505050505 Loss: 0.005419580970110014 Corrects: 4579\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.003959041088819504\n",
            "Train step - Step 480, Loss 0.005574698094278574\n",
            "Train step - Step 490, Loss 0.003607428865507245\n",
            "Train step - Step 500, Loss 0.006026438903063536\n",
            "Train epoch - Accuracy: 0.92 Loss: 0.005736440328899959 Corrects: 4554\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.003848848631605506\n",
            "Train step - Step 520, Loss 0.005557899363338947\n",
            "Train step - Step 530, Loss 0.0030983334872871637\n",
            "Train step - Step 540, Loss 0.005908515769988298\n",
            "Train epoch - Accuracy: 0.933939393939394 Loss: 0.00502742389969603 Corrects: 4623\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.004902686458081007\n",
            "Train step - Step 560, Loss 0.0038218952249735594\n",
            "Train step - Step 570, Loss 0.003930594772100449\n",
            "Train step - Step 580, Loss 0.0053487503901124\n",
            "Train epoch - Accuracy: 0.9309090909090909 Loss: 0.004868214339902154 Corrects: 4608\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.004624083172529936\n",
            "Train step - Step 600, Loss 0.005696508567780256\n",
            "Train step - Step 610, Loss 0.0036447462625801563\n",
            "Train step - Step 620, Loss 0.0036501921713352203\n",
            "Train epoch - Accuracy: 0.9363636363636364 Loss: 0.004765144345548117 Corrects: 4635\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.0032670118380337954\n",
            "Train step - Step 640, Loss 0.0025917289312928915\n",
            "Train step - Step 650, Loss 0.004777586553245783\n",
            "Train step - Step 660, Loss 0.0037670712918043137\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.003710511697625572 Corrects: 4696\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.0038944350089877844\n",
            "Train step - Step 680, Loss 0.0038758006412535906\n",
            "Train step - Step 690, Loss 0.003926763776689768\n",
            "Train step - Step 700, Loss 0.0037927806843072176\n",
            "Train epoch - Accuracy: 0.9454545454545454 Loss: 0.004084102157315221 Corrects: 4680\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.0032652930822223425\n",
            "Train step - Step 720, Loss 0.007038432639092207\n",
            "Train step - Step 730, Loss 0.005027072969824076\n",
            "Train step - Step 740, Loss 0.0041990079917013645\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.0038243719798070615 Corrects: 4687\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.00355354486964643\n",
            "Train step - Step 760, Loss 0.004621411673724651\n",
            "Train step - Step 770, Loss 0.004139667376875877\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.004071541398650769 Corrects: 4678\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.0037319455295801163\n",
            "Train step - Step 790, Loss 0.0031669330783188343\n",
            "Train step - Step 800, Loss 0.00324164517223835\n",
            "Train step - Step 810, Loss 0.004470379091799259\n",
            "Train epoch - Accuracy: 0.9458585858585858 Loss: 0.003897485067653987 Corrects: 4682\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.0031787471380084753\n",
            "Train step - Step 830, Loss 0.0034049847163259983\n",
            "Train step - Step 840, Loss 0.0034024789929389954\n",
            "Train step - Step 850, Loss 0.004022581037133932\n",
            "Train epoch - Accuracy: 0.9480808080808081 Loss: 0.003949228360345869 Corrects: 4693\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.0025540764909237623\n",
            "Train step - Step 870, Loss 0.0031520482152700424\n",
            "Train step - Step 880, Loss 0.004506799392402172\n",
            "Train step - Step 890, Loss 0.004367444198578596\n",
            "Train epoch - Accuracy: 0.9569696969696969 Loss: 0.0031734848325375956 Corrects: 4737\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.003971584141254425\n",
            "Train step - Step 910, Loss 0.00242160283960402\n",
            "Train step - Step 920, Loss 0.0028080642223358154\n",
            "Train step - Step 930, Loss 0.0034495890140533447\n",
            "Train epoch - Accuracy: 0.9579797979797979 Loss: 0.0031025703850606776 Corrects: 4742\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.0021849223412573338\n",
            "Train step - Step 950, Loss 0.002493001287803054\n",
            "Train step - Step 960, Loss 0.002508930629119277\n",
            "Train step - Step 970, Loss 0.0028758221305906773\n",
            "Train epoch - Accuracy: 0.9581818181818181 Loss: 0.003067584872772597 Corrects: 4743\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.002267373027279973\n",
            "Train step - Step 990, Loss 0.003009539796039462\n",
            "Train step - Step 1000, Loss 0.004176025278866291\n",
            "Train step - Step 1010, Loss 0.0023235396947711706\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.003084560422734781 Corrects: 4738\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0016724109882488847\n",
            "Train step - Step 1030, Loss 0.00111490860581398\n",
            "Train step - Step 1040, Loss 0.0013796428684145212\n",
            "Train step - Step 1050, Loss 0.0018774804193526506\n",
            "Train epoch - Accuracy: 0.9656565656565657 Loss: 0.0027181883132781346 Corrects: 4780\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0023765077348798513\n",
            "Train step - Step 1070, Loss 0.0031792912632226944\n",
            "Train step - Step 1080, Loss 0.005152581259608269\n",
            "Train step - Step 1090, Loss 0.0025637440849095583\n",
            "Train epoch - Accuracy: 0.9579797979797979 Loss: 0.0030244098294225307 Corrects: 4742\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.002658079843968153\n",
            "Train step - Step 1110, Loss 0.0015946573112159967\n",
            "Train step - Step 1120, Loss 0.0017286468064412475\n",
            "Train step - Step 1130, Loss 0.0029596821404993534\n",
            "Train epoch - Accuracy: 0.9660606060606061 Loss: 0.0024988637772398164 Corrects: 4782\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.003009974490851164\n",
            "Train step - Step 1150, Loss 0.00439070351421833\n",
            "Train step - Step 1160, Loss 0.0016331812366843224\n",
            "Train epoch - Accuracy: 0.9668686868686869 Loss: 0.0025037241192779154 Corrects: 4786\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0013175877975299954\n",
            "Train step - Step 1180, Loss 0.0030265876557677984\n",
            "Train step - Step 1190, Loss 0.001885027508251369\n",
            "Train step - Step 1200, Loss 0.002207809826359153\n",
            "Train epoch - Accuracy: 0.9680808080808081 Loss: 0.002603121368741297 Corrects: 4792\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0034627579152584076\n",
            "Train step - Step 1220, Loss 0.0030968363862484694\n",
            "Train step - Step 1230, Loss 0.00281234341673553\n",
            "Train step - Step 1240, Loss 0.0030279955826699734\n",
            "Train epoch - Accuracy: 0.9604040404040404 Loss: 0.0030331694746785092 Corrects: 4754\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0012295531341806054\n",
            "Train step - Step 1260, Loss 0.0022563335951417685\n",
            "Train step - Step 1270, Loss 0.0016894128639250994\n",
            "Train step - Step 1280, Loss 0.0029907887801527977\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.0025773255139438793 Corrects: 4769\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.002935628639534116\n",
            "Train step - Step 1300, Loss 0.0026383136864751577\n",
            "Train step - Step 1310, Loss 0.0018686869880184531\n",
            "Train step - Step 1320, Loss 0.0041503612883389\n",
            "Train epoch - Accuracy: 0.9626262626262626 Loss: 0.002702142202173068 Corrects: 4765\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0027535229455679655\n",
            "Train step - Step 1340, Loss 0.004005958791822195\n",
            "Train step - Step 1350, Loss 0.0032618322875350714\n",
            "Train step - Step 1360, Loss 0.004591536242514849\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.002858467922461304 Corrects: 4766\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0035823385696858168\n",
            "Train step - Step 1380, Loss 0.0025747125037014484\n",
            "Train step - Step 1390, Loss 0.003119882894679904\n",
            "Train step - Step 1400, Loss 0.004019235260784626\n",
            "Train epoch - Accuracy: 0.9698989898989899 Loss: 0.0025757520579065035 Corrects: 4801\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.004708901979029179\n",
            "Train step - Step 1420, Loss 0.0014880754752084613\n",
            "Train step - Step 1430, Loss 0.0030200944747775793\n",
            "Train step - Step 1440, Loss 0.0028805523179471493\n",
            "Train epoch - Accuracy: 0.9622222222222222 Loss: 0.0028440051523009034 Corrects: 4763\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0021549207158386707\n",
            "Train step - Step 1460, Loss 0.003021782962605357\n",
            "Train step - Step 1470, Loss 0.0038497212808579206\n",
            "Train step - Step 1480, Loss 0.0027285378891974688\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.0028097946771580462 Corrects: 4758\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.001752882613800466\n",
            "Train step - Step 1500, Loss 0.0024711843580007553\n",
            "Train step - Step 1510, Loss 0.003562367055565119\n",
            "Train step - Step 1520, Loss 0.002949964487925172\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.0027593551797209064 Corrects: 4766\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.0022419504821300507\n",
            "Train step - Step 1540, Loss 0.001964929746463895\n",
            "Train step - Step 1550, Loss 0.0019740965217351913\n",
            "Train epoch - Accuracy: 0.9749494949494949 Loss: 0.0019931422295801416 Corrects: 4826\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0012185516534373164\n",
            "Train step - Step 1570, Loss 0.002353393705561757\n",
            "Train step - Step 1580, Loss 0.001996074104681611\n",
            "Train step - Step 1590, Loss 0.0015713233733549714\n",
            "Train epoch - Accuracy: 0.9763636363636363 Loss: 0.0018594523211658905 Corrects: 4833\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0018889611819759011\n",
            "Train step - Step 1610, Loss 0.0024186258669942617\n",
            "Train step - Step 1620, Loss 0.001210240414366126\n",
            "Train step - Step 1630, Loss 0.0028021582402288914\n",
            "Train epoch - Accuracy: 0.9751515151515151 Loss: 0.001928584487882979 Corrects: 4827\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0006687596323899925\n",
            "Train step - Step 1650, Loss 0.0016684308648109436\n",
            "Train step - Step 1660, Loss 0.0016817189753055573\n",
            "Train step - Step 1670, Loss 0.0018961317837238312\n",
            "Train epoch - Accuracy: 0.9737373737373738 Loss: 0.002006470959991066 Corrects: 4820\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0018673116574063897\n",
            "Train step - Step 1690, Loss 0.0023977842647582293\n",
            "Train step - Step 1700, Loss 0.0021893265657126904\n",
            "Train step - Step 1710, Loss 0.0018300444353371859\n",
            "Train epoch - Accuracy: 0.9723232323232324 Loss: 0.00205230216599173 Corrects: 4813\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.003331247018650174\n",
            "Train step - Step 1730, Loss 0.00216515245847404\n",
            "Train step - Step 1740, Loss 0.0028650148306041956\n",
            "Train step - Step 1750, Loss 0.003459267783910036\n",
            "Train epoch - Accuracy: 0.9692929292929293 Loss: 0.002354055257664636 Corrects: 4798\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002644659485667944\n",
            "Train step - Step 1770, Loss 0.0033775854390114546\n",
            "Train step - Step 1780, Loss 0.0014346957905218005\n",
            "Train step - Step 1790, Loss 0.0017972014611586928\n",
            "Train epoch - Accuracy: 0.9715151515151516 Loss: 0.0022451907200644714 Corrects: 4809\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0008372798911295831\n",
            "Train step - Step 1810, Loss 0.003673345549032092\n",
            "Train step - Step 1820, Loss 0.0016424946952611208\n",
            "Train step - Step 1830, Loss 0.001805650070309639\n",
            "Train epoch - Accuracy: 0.9735353535353536 Loss: 0.002004649615517319 Corrects: 4819\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.003216681769117713\n",
            "Train step - Step 1850, Loss 0.0025341545697301626\n",
            "Train step - Step 1860, Loss 0.0014683095505461097\n",
            "Train step - Step 1870, Loss 0.0014660506276413798\n",
            "Train epoch - Accuracy: 0.9793939393939394 Loss: 0.0017917001426144682 Corrects: 4848\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0018019855488091707\n",
            "Train step - Step 1890, Loss 0.0013014235300943255\n",
            "Train step - Step 1900, Loss 0.0016722086584195495\n",
            "Train step - Step 1910, Loss 0.0026196895632892847\n",
            "Train epoch - Accuracy: 0.9751515151515151 Loss: 0.0020201532771302894 Corrects: 4827\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0010956068290397525\n",
            "Train step - Step 1930, Loss 0.0013641270343214273\n",
            "Train step - Step 1940, Loss 0.0010952567681670189\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0012237361506229698 Corrects: 4886\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.000774425221607089\n",
            "Train step - Step 1960, Loss 0.0005076783709228039\n",
            "Train step - Step 1970, Loss 0.0007858442259021103\n",
            "Train step - Step 1980, Loss 0.0003598957846406847\n",
            "Train epoch - Accuracy: 0.9943434343434343 Loss: 0.0006842628756368702 Corrects: 4922\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0005553549854084849\n",
            "Train step - Step 2000, Loss 0.0006813904037699103\n",
            "Train step - Step 2010, Loss 0.000487588724354282\n",
            "Train step - Step 2020, Loss 0.00038673364906571805\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0005262824360544634 Corrects: 4932\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0004180177056696266\n",
            "Train step - Step 2040, Loss 0.0006779280374757946\n",
            "Train step - Step 2050, Loss 0.0013224398717284203\n",
            "Train step - Step 2060, Loss 0.00039586410275660455\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0004599604367118592 Corrects: 4937\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0008352877921424806\n",
            "Train step - Step 2080, Loss 0.0003326180449221283\n",
            "Train step - Step 2090, Loss 0.0007634996436536312\n",
            "Train step - Step 2100, Loss 0.0003850230132229626\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00041803402052439676 Corrects: 4938\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0002621857274789363\n",
            "Train step - Step 2120, Loss 0.00028353926609270275\n",
            "Train step - Step 2130, Loss 0.00021523782925214618\n",
            "Train step - Step 2140, Loss 0.0005725621012970805\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00041526471713858873 Corrects: 4939\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0004723961465060711\n",
            "Train step - Step 2160, Loss 0.0002265906223328784\n",
            "Train step - Step 2170, Loss 0.00025070318952202797\n",
            "Train step - Step 2180, Loss 0.00016731249343138188\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00032782279631132354 Corrects: 4945\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00020853569731116295\n",
            "Train step - Step 2200, Loss 0.00047084802645258605\n",
            "Train step - Step 2210, Loss 0.00048614965635351837\n",
            "Train step - Step 2220, Loss 0.00038292130921036005\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.000325432670599019 Corrects: 4941\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0003046675701625645\n",
            "Train step - Step 2240, Loss 0.00024016258248593658\n",
            "Train step - Step 2250, Loss 0.00020172835502307862\n",
            "Train step - Step 2260, Loss 0.000287004018900916\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0003163799560379538 Corrects: 4943\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0009846690809354186\n",
            "Train step - Step 2280, Loss 0.00019588382565416396\n",
            "Train step - Step 2290, Loss 0.00024238396144937724\n",
            "Train step - Step 2300, Loss 0.00022659987735096365\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0003518731048920973 Corrects: 4939\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0003089676611125469\n",
            "Train step - Step 2320, Loss 0.0005311873974278569\n",
            "Train step - Step 2330, Loss 0.00013712543295696378\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002855675341326254 Corrects: 4946\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00019365077605471015\n",
            "Train step - Step 2350, Loss 0.0001870504202088341\n",
            "Train step - Step 2360, Loss 0.00026367383543401957\n",
            "Train step - Step 2370, Loss 0.0005090802442282438\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00027267140186993836 Corrects: 4944\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00022381372400559485\n",
            "Train step - Step 2390, Loss 0.0002138722047675401\n",
            "Train step - Step 2400, Loss 0.0004259651177562773\n",
            "Train step - Step 2410, Loss 0.0002449628373142332\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0002568036965400244 Corrects: 4944\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00039145510527305305\n",
            "Train step - Step 2430, Loss 0.00022371379600372165\n",
            "Train step - Step 2440, Loss 0.00023790002160239965\n",
            "Train step - Step 2450, Loss 0.00017406766710337251\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002604111398551425 Corrects: 4946\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00015312960022129118\n",
            "Train step - Step 2470, Loss 0.0006333217024803162\n",
            "Train step - Step 2480, Loss 0.0001609109458513558\n",
            "Train step - Step 2490, Loss 0.0002720736665651202\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0002746944193436642 Corrects: 4945\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00018593603454064578\n",
            "Train step - Step 2510, Loss 0.0001408289826940745\n",
            "Train step - Step 2520, Loss 0.0002446494472678751\n",
            "Train step - Step 2530, Loss 0.00023436204355675727\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00023708296358829946 Corrects: 4945\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00017526361625641584\n",
            "Train step - Step 2550, Loss 0.0002613484102766961\n",
            "Train step - Step 2560, Loss 0.00016933998267631978\n",
            "Train step - Step 2570, Loss 0.00027770621818490326\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00023719049356360402 Corrects: 4948\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.00020675701671279967\n",
            "Train step - Step 2590, Loss 0.0001306314516114071\n",
            "Train step - Step 2600, Loss 0.0003504631749819964\n",
            "Train step - Step 2610, Loss 0.00017034128541126847\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00021704299981009704 Corrects: 4948\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.000441134674474597\n",
            "Train step - Step 2630, Loss 0.00022185943089425564\n",
            "Train step - Step 2640, Loss 0.00013391264656092972\n",
            "Train step - Step 2650, Loss 0.00019970005087088794\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002743727560954714 Corrects: 4946\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00028405687771737576\n",
            "Train step - Step 2670, Loss 0.000166264406288974\n",
            "Train step - Step 2680, Loss 0.0002058808458968997\n",
            "Train step - Step 2690, Loss 0.00015084419283084571\n",
            "Train epoch - Accuracy: 1.0 Loss: 0.00023925709562855912 Corrects: 4950\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0001702414738247171\n",
            "Train step - Step 2710, Loss 0.00014125586312729865\n",
            "Train step - Step 2720, Loss 0.00017080202815122902\n",
            "Train epoch - Accuracy: 1.0 Loss: 0.00020445379323909304 Corrects: 4950\n",
            "Training finished in 237.8252911567688 seconds\n",
            "EVALUATION:  0.86 0.008703310042619705\n",
            "TEST GROUP:  0.909\n",
            "TEST ALL:  0.113625\n",
            "GROUP:  9\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.12499027699232101\n",
            "Train step - Step 10, Loss 0.049289967864751816\n",
            "Train step - Step 20, Loss 0.031144320964813232\n",
            "Train step - Step 30, Loss 0.024399450048804283\n",
            "Train epoch - Accuracy: 0.3109090909090909 Loss: 0.039004727235496646 Corrects: 1539\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.021379925310611725\n",
            "Train step - Step 50, Loss 0.019566822797060013\n",
            "Train step - Step 60, Loss 0.01730971783399582\n",
            "Train step - Step 70, Loss 0.016166456043720245\n",
            "Train epoch - Accuracy: 0.6462626262626263 Loss: 0.018174265001458353 Corrects: 3199\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.016407260671257973\n",
            "Train step - Step 90, Loss 0.012745354324579239\n",
            "Train step - Step 100, Loss 0.014179307967424393\n",
            "Train step - Step 110, Loss 0.013095098547637463\n",
            "Train epoch - Accuracy: 0.7327272727272728 Loss: 0.014364661882546814 Corrects: 3627\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.012768274173140526\n",
            "Train step - Step 130, Loss 0.012878172099590302\n",
            "Train step - Step 140, Loss 0.011765106581151485\n",
            "Train step - Step 150, Loss 0.011654170230031013\n",
            "Train epoch - Accuracy: 0.7941414141414141 Loss: 0.011817710050052464 Corrects: 3931\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.0098880585283041\n",
            "Train step - Step 170, Loss 0.013190418481826782\n",
            "Train step - Step 180, Loss 0.009760596789419651\n",
            "Train step - Step 190, Loss 0.007556477561593056\n",
            "Train epoch - Accuracy: 0.8171717171717172 Loss: 0.010510219657661938 Corrects: 4045\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.008350073359906673\n",
            "Train step - Step 210, Loss 0.00966149102896452\n",
            "Train step - Step 220, Loss 0.008540757931768894\n",
            "Train step - Step 230, Loss 0.009366648271679878\n",
            "Train epoch - Accuracy: 0.8432323232323232 Loss: 0.009326693763711837 Corrects: 4174\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00939270667731762\n",
            "Train step - Step 250, Loss 0.010601235553622246\n",
            "Train step - Step 260, Loss 0.008470986969769001\n",
            "Train step - Step 270, Loss 0.011752751655876637\n",
            "Train epoch - Accuracy: 0.8464646464646465 Loss: 0.00889761092912669 Corrects: 4190\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.009168417192995548\n",
            "Train step - Step 290, Loss 0.008452925831079483\n",
            "Train step - Step 300, Loss 0.007460222113877535\n",
            "Train step - Step 310, Loss 0.007048029452562332\n",
            "Train epoch - Accuracy: 0.8622222222222222 Loss: 0.008025799049346735 Corrects: 4268\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.007316826842725277\n",
            "Train step - Step 330, Loss 0.003765013301745057\n",
            "Train step - Step 340, Loss 0.00659256661310792\n",
            "Train step - Step 350, Loss 0.006960741244256496\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.007404746448226048 Corrects: 4326\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.006034411955624819\n",
            "Train step - Step 370, Loss 0.007335227448493242\n",
            "Train step - Step 380, Loss 0.007791799958795309\n",
            "Train epoch - Accuracy: 0.8777777777777778 Loss: 0.0073929732785833 Corrects: 4345\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0064524514600634575\n",
            "Train step - Step 400, Loss 0.007575794123113155\n",
            "Train step - Step 410, Loss 0.00692939106374979\n",
            "Train step - Step 420, Loss 0.0070231007412076\n",
            "Train epoch - Accuracy: 0.8816161616161616 Loss: 0.007034612915883161 Corrects: 4364\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.007438029162585735\n",
            "Train step - Step 440, Loss 0.0060809520073235035\n",
            "Train step - Step 450, Loss 0.007532939780503511\n",
            "Train step - Step 460, Loss 0.007647937163710594\n",
            "Train epoch - Accuracy: 0.9008080808080808 Loss: 0.00610117725821005 Corrects: 4459\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.00442828144878149\n",
            "Train step - Step 480, Loss 0.00359207671135664\n",
            "Train step - Step 490, Loss 0.0064259860664606094\n",
            "Train step - Step 500, Loss 0.005694315303117037\n",
            "Train epoch - Accuracy: 0.9040404040404041 Loss: 0.005891400441301591 Corrects: 4475\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.00572613999247551\n",
            "Train step - Step 520, Loss 0.0038645085878670216\n",
            "Train step - Step 530, Loss 0.007536806631833315\n",
            "Train step - Step 540, Loss 0.007544344291090965\n",
            "Train epoch - Accuracy: 0.897979797979798 Loss: 0.006341119343508976 Corrects: 4445\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.006449379026889801\n",
            "Train step - Step 560, Loss 0.004267864394932985\n",
            "Train step - Step 570, Loss 0.005708664655685425\n",
            "Train step - Step 580, Loss 0.004738964606076479\n",
            "Train epoch - Accuracy: 0.9062626262626262 Loss: 0.0057030850948032105 Corrects: 4486\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.003194694872945547\n",
            "Train step - Step 600, Loss 0.0038720397278666496\n",
            "Train step - Step 610, Loss 0.0036039615515619516\n",
            "Train step - Step 620, Loss 0.0037540618795901537\n",
            "Train epoch - Accuracy: 0.9248484848484848 Loss: 0.0048992105631741 Corrects: 4578\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.005805222317576408\n",
            "Train step - Step 640, Loss 0.005305573344230652\n",
            "Train step - Step 650, Loss 0.003629975952208042\n",
            "Train step - Step 660, Loss 0.005663860589265823\n",
            "Train epoch - Accuracy: 0.9228282828282828 Loss: 0.004873702321389709 Corrects: 4568\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.004072798881679773\n",
            "Train step - Step 680, Loss 0.00535992905497551\n",
            "Train step - Step 690, Loss 0.004847415257245302\n",
            "Train step - Step 700, Loss 0.004285489674657583\n",
            "Train epoch - Accuracy: 0.9157575757575758 Loss: 0.005103893278335983 Corrects: 4533\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.00447709858417511\n",
            "Train step - Step 720, Loss 0.0071805305778980255\n",
            "Train step - Step 730, Loss 0.004960217978805304\n",
            "Train step - Step 740, Loss 0.004346081987023354\n",
            "Train epoch - Accuracy: 0.9226262626262626 Loss: 0.0048424675601600395 Corrects: 4567\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.004752031993120909\n",
            "Train step - Step 760, Loss 0.002949187997728586\n",
            "Train step - Step 770, Loss 0.003363068215548992\n",
            "Train epoch - Accuracy: 0.9262626262626262 Loss: 0.004529666246827504 Corrects: 4585\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.002047027228400111\n",
            "Train step - Step 790, Loss 0.003509129397571087\n",
            "Train step - Step 800, Loss 0.0043539563193917274\n",
            "Train step - Step 810, Loss 0.0038856735918670893\n",
            "Train epoch - Accuracy: 0.9315151515151515 Loss: 0.0044377556326563915 Corrects: 4611\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.0029045874252915382\n",
            "Train step - Step 830, Loss 0.004623533226549625\n",
            "Train step - Step 840, Loss 0.0033294472377747297\n",
            "Train step - Step 850, Loss 0.004059060011059046\n",
            "Train epoch - Accuracy: 0.9367676767676768 Loss: 0.004001390668140216 Corrects: 4637\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.00367117952555418\n",
            "Train step - Step 870, Loss 0.004106714390218258\n",
            "Train step - Step 880, Loss 0.005523976404219866\n",
            "Train step - Step 890, Loss 0.0037587471306324005\n",
            "Train epoch - Accuracy: 0.9353535353535354 Loss: 0.004161474665043631 Corrects: 4630\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.0037876050919294357\n",
            "Train step - Step 910, Loss 0.004243895411491394\n",
            "Train step - Step 920, Loss 0.004331817850470543\n",
            "Train step - Step 930, Loss 0.0026770245749503374\n",
            "Train epoch - Accuracy: 0.938989898989899 Loss: 0.003793149340916613 Corrects: 4648\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.0035837888717651367\n",
            "Train step - Step 950, Loss 0.004113274160772562\n",
            "Train step - Step 960, Loss 0.0038217983674257994\n",
            "Train step - Step 970, Loss 0.004305736161768436\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.0033846774098999573 Corrects: 4695\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.002724915510043502\n",
            "Train step - Step 990, Loss 0.0038623695727437735\n",
            "Train step - Step 1000, Loss 0.004533261060714722\n",
            "Train step - Step 1010, Loss 0.006591561250388622\n",
            "Train epoch - Accuracy: 0.9446464646464646 Loss: 0.003527659322182187 Corrects: 4676\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0031517082825303078\n",
            "Train step - Step 1030, Loss 0.004278792534023523\n",
            "Train step - Step 1040, Loss 0.003436984261497855\n",
            "Train step - Step 1050, Loss 0.004219201393425465\n",
            "Train epoch - Accuracy: 0.9311111111111111 Loss: 0.004161884626655867 Corrects: 4609\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.004488368984311819\n",
            "Train step - Step 1070, Loss 0.0038780695758759975\n",
            "Train step - Step 1080, Loss 0.004739913623780012\n",
            "Train step - Step 1090, Loss 0.0027423345018178225\n",
            "Train epoch - Accuracy: 0.9383838383838384 Loss: 0.0039883879820505775 Corrects: 4645\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.004023020155727863\n",
            "Train step - Step 1110, Loss 0.0032737632282078266\n",
            "Train step - Step 1120, Loss 0.002468068851158023\n",
            "Train step - Step 1130, Loss 0.0034983220975846052\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.0034815289464901495 Corrects: 4687\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.00226053805090487\n",
            "Train step - Step 1150, Loss 0.004815421998500824\n",
            "Train step - Step 1160, Loss 0.003726630238816142\n",
            "Train epoch - Accuracy: 0.9496969696969697 Loss: 0.0033609593294636167 Corrects: 4701\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0036114947870373726\n",
            "Train step - Step 1180, Loss 0.0028169944416731596\n",
            "Train step - Step 1190, Loss 0.004054272081702948\n",
            "Train step - Step 1200, Loss 0.002566081937402487\n",
            "Train epoch - Accuracy: 0.9488888888888889 Loss: 0.003410469779951705 Corrects: 4697\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0033841340336948633\n",
            "Train step - Step 1220, Loss 0.004557391162961721\n",
            "Train step - Step 1230, Loss 0.003949455916881561\n",
            "Train step - Step 1240, Loss 0.0033714636228978634\n",
            "Train epoch - Accuracy: 0.946060606060606 Loss: 0.0032927329589923222 Corrects: 4683\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0029045080300420523\n",
            "Train step - Step 1260, Loss 0.00268315221183002\n",
            "Train step - Step 1270, Loss 0.0029117807280272245\n",
            "Train step - Step 1280, Loss 0.0029390116687864065\n",
            "Train epoch - Accuracy: 0.9458585858585858 Loss: 0.003569982798036301 Corrects: 4682\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0034023835323750973\n",
            "Train step - Step 1300, Loss 0.0023040762171149254\n",
            "Train step - Step 1310, Loss 0.0036363406106829643\n",
            "Train step - Step 1320, Loss 0.003638745052739978\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.0032689392301395084 Corrects: 4689\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0034767091274261475\n",
            "Train step - Step 1340, Loss 0.003001920413225889\n",
            "Train step - Step 1350, Loss 0.0017195085529237986\n",
            "Train step - Step 1360, Loss 0.0031128611881285906\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.0032209542926137495 Corrects: 4696\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0026628340128809214\n",
            "Train step - Step 1380, Loss 0.0024919514544308186\n",
            "Train step - Step 1390, Loss 0.0043901922181248665\n",
            "Train step - Step 1400, Loss 0.001193698146380484\n",
            "Train epoch - Accuracy: 0.955959595959596 Loss: 0.002865640642874018 Corrects: 4732\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002183574251830578\n",
            "Train step - Step 1420, Loss 0.003958611283451319\n",
            "Train step - Step 1430, Loss 0.003751221811398864\n",
            "Train step - Step 1440, Loss 0.002626110101118684\n",
            "Train epoch - Accuracy: 0.954949494949495 Loss: 0.002937899527488032 Corrects: 4727\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.003338147886097431\n",
            "Train step - Step 1460, Loss 0.003661173628643155\n",
            "Train step - Step 1470, Loss 0.0038604994770139456\n",
            "Train step - Step 1480, Loss 0.0032592921052128077\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.0032559370452707463 Corrects: 4689\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.002296360209584236\n",
            "Train step - Step 1500, Loss 0.0025863852351903915\n",
            "Train step - Step 1510, Loss 0.002577364444732666\n",
            "Train step - Step 1520, Loss 0.0013368746731430292\n",
            "Train epoch - Accuracy: 0.9569696969696969 Loss: 0.0028742355502426927 Corrects: 4737\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.003921410068869591\n",
            "Train step - Step 1540, Loss 0.0020385836251080036\n",
            "Train step - Step 1550, Loss 0.0020295591093599796\n",
            "Train epoch - Accuracy: 0.9555555555555556 Loss: 0.002935499299336413 Corrects: 4730\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0025172741152346134\n",
            "Train step - Step 1570, Loss 0.003518209559842944\n",
            "Train step - Step 1580, Loss 0.003037143498659134\n",
            "Train step - Step 1590, Loss 0.0019155654590576887\n",
            "Train epoch - Accuracy: 0.963030303030303 Loss: 0.0025195405590865347 Corrects: 4767\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0017504259012639523\n",
            "Train step - Step 1610, Loss 0.0021001333370804787\n",
            "Train step - Step 1620, Loss 0.001153315999545157\n",
            "Train step - Step 1630, Loss 0.0019894482102245092\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.002200458414683288 Corrects: 4790\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.003346846206113696\n",
            "Train step - Step 1650, Loss 0.0030368617735803127\n",
            "Train step - Step 1660, Loss 0.0026213519740849733\n",
            "Train step - Step 1670, Loss 0.003979061730206013\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.0023219640178116733 Corrects: 4790\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0012269595172256231\n",
            "Train step - Step 1690, Loss 0.0019889657851308584\n",
            "Train step - Step 1700, Loss 0.0022461891639977694\n",
            "Train step - Step 1710, Loss 0.0016357218846678734\n",
            "Train epoch - Accuracy: 0.9688888888888889 Loss: 0.0022668195229889167 Corrects: 4796\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0016195211792364717\n",
            "Train step - Step 1730, Loss 0.0032624960877001286\n",
            "Train step - Step 1740, Loss 0.002297718310728669\n",
            "Train step - Step 1750, Loss 0.0028895444702357054\n",
            "Train epoch - Accuracy: 0.963030303030303 Loss: 0.0023029215983820686 Corrects: 4767\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002252931473776698\n",
            "Train step - Step 1770, Loss 0.0013410892570391297\n",
            "Train step - Step 1780, Loss 0.0044523016549646854\n",
            "Train step - Step 1790, Loss 0.003850968088954687\n",
            "Train epoch - Accuracy: 0.9595959595959596 Loss: 0.002650019087207814 Corrects: 4750\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0019453895511105657\n",
            "Train step - Step 1810, Loss 0.0032309924717992544\n",
            "Train step - Step 1820, Loss 0.001642788527533412\n",
            "Train step - Step 1830, Loss 0.0033097367268055677\n",
            "Train epoch - Accuracy: 0.9577777777777777 Loss: 0.0027697624313184105 Corrects: 4741\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.003086199052631855\n",
            "Train step - Step 1850, Loss 0.0037286891601979733\n",
            "Train step - Step 1860, Loss 0.0016092280857264996\n",
            "Train step - Step 1870, Loss 0.003109901212155819\n",
            "Train epoch - Accuracy: 0.9591919191919192 Loss: 0.0026951156513332717 Corrects: 4748\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0027388029266148806\n",
            "Train step - Step 1890, Loss 0.0015364150749519467\n",
            "Train step - Step 1900, Loss 0.0027223380748182535\n",
            "Train step - Step 1910, Loss 0.0027947472408413887\n",
            "Train epoch - Accuracy: 0.9670707070707071 Loss: 0.0022364904238569615 Corrects: 4787\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0014574845554307103\n",
            "Train step - Step 1930, Loss 0.0014743275241926312\n",
            "Train step - Step 1940, Loss 0.0008264594944193959\n",
            "Train epoch - Accuracy: 0.981010101010101 Loss: 0.0013927162067748306 Corrects: 4856\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0005387425771914423\n",
            "Train step - Step 1960, Loss 0.0008194475085474551\n",
            "Train step - Step 1970, Loss 0.0005602744640782475\n",
            "Train step - Step 1980, Loss 0.0004921926301904023\n",
            "Train epoch - Accuracy: 0.9927272727272727 Loss: 0.0007979259432782654 Corrects: 4914\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.000706799328327179\n",
            "Train step - Step 2000, Loss 0.0006911470554769039\n",
            "Train step - Step 2010, Loss 0.000538414460606873\n",
            "Train step - Step 2020, Loss 0.0009486221824772656\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0007704569096912188 Corrects: 4916\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0009189675329253078\n",
            "Train step - Step 2040, Loss 0.0006794002838432789\n",
            "Train step - Step 2050, Loss 0.0004258920962456614\n",
            "Train step - Step 2060, Loss 0.0009470895165577531\n",
            "Train epoch - Accuracy: 0.9943434343434343 Loss: 0.0006560240271313097 Corrects: 4922\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.001786783686839044\n",
            "Train step - Step 2080, Loss 0.0005958260735496879\n",
            "Train step - Step 2090, Loss 0.0003565928782336414\n",
            "Train step - Step 2100, Loss 0.0005332326982170343\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0006552698085263296 Corrects: 4917\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.00046266152639873326\n",
            "Train step - Step 2120, Loss 0.000601009523961693\n",
            "Train step - Step 2130, Loss 0.0005069182952865958\n",
            "Train step - Step 2140, Loss 0.0005571506917476654\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.00047997424009754654 Corrects: 4934\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0005226001958362758\n",
            "Train step - Step 2160, Loss 0.0003354829386807978\n",
            "Train step - Step 2170, Loss 0.000790830235928297\n",
            "Train step - Step 2180, Loss 0.0006848208722658455\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.00048730692123015874 Corrects: 4933\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0003624847740866244\n",
            "Train step - Step 2200, Loss 0.00039184835623018444\n",
            "Train step - Step 2210, Loss 0.000571381242480129\n",
            "Train step - Step 2220, Loss 0.000590806535910815\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0004631850255107639 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.00032544834539294243\n",
            "Train step - Step 2240, Loss 0.0003524418279994279\n",
            "Train step - Step 2250, Loss 0.0006875250255689025\n",
            "Train step - Step 2260, Loss 0.0004835827276110649\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00044207153291526166 Corrects: 4938\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.00025695175281725824\n",
            "Train step - Step 2280, Loss 0.0003395004605408758\n",
            "Train step - Step 2290, Loss 0.00029383134096860886\n",
            "Train step - Step 2300, Loss 0.00021002073481213301\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00042640563703231474 Corrects: 4937\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.00018838507821783423\n",
            "Train step - Step 2320, Loss 0.0003316996153444052\n",
            "Train step - Step 2330, Loss 0.00026755270664580166\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003709291909101673 Corrects: 4942\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00018398062093183398\n",
            "Train step - Step 2350, Loss 0.00045465206494554877\n",
            "Train step - Step 2360, Loss 0.0003650604048743844\n",
            "Train step - Step 2370, Loss 0.00038735478301532567\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00039545645529281986 Corrects: 4939\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00023277077707462013\n",
            "Train step - Step 2390, Loss 0.0002924176515080035\n",
            "Train step - Step 2400, Loss 0.00039079884300008416\n",
            "Train step - Step 2410, Loss 0.0002441949909552932\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0003499213187729545 Corrects: 4941\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00024055539688561112\n",
            "Train step - Step 2430, Loss 0.00014475318312179297\n",
            "Train step - Step 2440, Loss 0.0005755641614086926\n",
            "Train step - Step 2450, Loss 0.00024849502369761467\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003603853465815197 Corrects: 4942\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0003524952626321465\n",
            "Train step - Step 2470, Loss 0.00023250251251738518\n",
            "Train step - Step 2480, Loss 0.00028742491849698126\n",
            "Train step - Step 2490, Loss 0.0003833267546724528\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00034400413143260386 Corrects: 4940\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0003295590286143124\n",
            "Train step - Step 2510, Loss 0.0002280695625813678\n",
            "Train step - Step 2520, Loss 0.00023761866032145917\n",
            "Train step - Step 2530, Loss 0.00033456285018473864\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00037375106547977966 Corrects: 4940\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00025638696388341486\n",
            "Train step - Step 2550, Loss 0.000270380376605317\n",
            "Train step - Step 2560, Loss 0.00031887053046375513\n",
            "Train step - Step 2570, Loss 0.0003338068490847945\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003430725151033263 Corrects: 4942\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002906637091655284\n",
            "Train step - Step 2590, Loss 0.00028550694696605206\n",
            "Train step - Step 2600, Loss 0.00021213630679994822\n",
            "Train step - Step 2610, Loss 0.00031400175066664815\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.000342180632628651 Corrects: 4939\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00028265416040085256\n",
            "Train step - Step 2630, Loss 0.00036902635474689305\n",
            "Train step - Step 2640, Loss 0.0007758034626021981\n",
            "Train step - Step 2650, Loss 0.00023580675770062953\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00032598278559321027 Corrects: 4942\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00029628604534082115\n",
            "Train step - Step 2670, Loss 0.00027281278744339943\n",
            "Train step - Step 2680, Loss 0.00029152852948755026\n",
            "Train step - Step 2690, Loss 0.00024804010172374547\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00035601896293828206 Corrects: 4940\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00022331638319883496\n",
            "Train step - Step 2710, Loss 0.00015608149988111109\n",
            "Train step - Step 2720, Loss 0.0003195146273355931\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00033506566264685433 Corrects: 4939\n",
            "Training finished in 241.97172713279724 seconds\n",
            "EVALUATION:  0.92 0.004867006558924913\n",
            "TEST GROUP:  0.882\n",
            "TEST ALL:  0.098\n",
            "GROUP:  10\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.09725315123796463\n",
            "Train step - Step 10, Loss 0.04134760797023773\n",
            "Train step - Step 20, Loss 0.030064985156059265\n",
            "Train step - Step 30, Loss 0.02269906923174858\n",
            "Train epoch - Accuracy: 0.3058585858585859 Loss: 0.03432978967072988 Corrects: 1514\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.021793818101286888\n",
            "Train step - Step 50, Loss 0.01774175651371479\n",
            "Train step - Step 60, Loss 0.017726724967360497\n",
            "Train step - Step 70, Loss 0.016231127083301544\n",
            "Train epoch - Accuracy: 0.5959595959595959 Loss: 0.01798098317601464 Corrects: 2950\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.015392439439892769\n",
            "Train step - Step 90, Loss 0.01420984510332346\n",
            "Train step - Step 100, Loss 0.015523106791079044\n",
            "Train step - Step 110, Loss 0.01346998754888773\n",
            "Train epoch - Accuracy: 0.7018181818181818 Loss: 0.014482678623512537 Corrects: 3474\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.01607729308307171\n",
            "Train step - Step 130, Loss 0.011378264054656029\n",
            "Train step - Step 140, Loss 0.011140245944261551\n",
            "Train step - Step 150, Loss 0.012758735567331314\n",
            "Train epoch - Accuracy: 0.7583838383838384 Loss: 0.01232465497396811 Corrects: 3754\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.011563523672521114\n",
            "Train step - Step 170, Loss 0.00980246253311634\n",
            "Train step - Step 180, Loss 0.00912050623446703\n",
            "Train step - Step 190, Loss 0.010359865613281727\n",
            "Train epoch - Accuracy: 0.798989898989899 Loss: 0.010572273223237557 Corrects: 3955\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.01028791069984436\n",
            "Train step - Step 210, Loss 0.0093643544241786\n",
            "Train step - Step 220, Loss 0.009242012165486813\n",
            "Train step - Step 230, Loss 0.011199905537068844\n",
            "Train epoch - Accuracy: 0.8058585858585858 Loss: 0.00983539129748489 Corrects: 3989\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00739949569106102\n",
            "Train step - Step 250, Loss 0.008951796218752861\n",
            "Train step - Step 260, Loss 0.00977287907153368\n",
            "Train step - Step 270, Loss 0.009376415982842445\n",
            "Train epoch - Accuracy: 0.8333333333333334 Loss: 0.00878108589637159 Corrects: 4125\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.007035528309643269\n",
            "Train step - Step 290, Loss 0.009578499011695385\n",
            "Train step - Step 300, Loss 0.00782548077404499\n",
            "Train step - Step 310, Loss 0.006592242978513241\n",
            "Train epoch - Accuracy: 0.8484848484848485 Loss: 0.008084553182313237 Corrects: 4200\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.01028105802834034\n",
            "Train step - Step 330, Loss 0.008204445242881775\n",
            "Train step - Step 340, Loss 0.009039788506925106\n",
            "Train step - Step 350, Loss 0.006640514358878136\n",
            "Train epoch - Accuracy: 0.8593939393939394 Loss: 0.007526980862021446 Corrects: 4254\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.006709843873977661\n",
            "Train step - Step 370, Loss 0.005013517569750547\n",
            "Train step - Step 380, Loss 0.007523739244788885\n",
            "Train epoch - Accuracy: 0.8725252525252525 Loss: 0.006858535548389861 Corrects: 4319\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.006082171108573675\n",
            "Train step - Step 400, Loss 0.007005976513028145\n",
            "Train step - Step 410, Loss 0.0061792335473001\n",
            "Train step - Step 420, Loss 0.006369731854647398\n",
            "Train epoch - Accuracy: 0.8785858585858586 Loss: 0.0066044417625725875 Corrects: 4349\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.0060400282964110374\n",
            "Train step - Step 440, Loss 0.007070292253047228\n",
            "Train step - Step 450, Loss 0.006216431502252817\n",
            "Train step - Step 460, Loss 0.006739972624927759\n",
            "Train epoch - Accuracy: 0.8848484848484849 Loss: 0.006217846221130605 Corrects: 4380\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.006464974954724312\n",
            "Train step - Step 480, Loss 0.004395715426653624\n",
            "Train step - Step 490, Loss 0.0070349727757275105\n",
            "Train step - Step 500, Loss 0.006988074630498886\n",
            "Train epoch - Accuracy: 0.8907070707070707 Loss: 0.005973350383868121 Corrects: 4409\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.005167176481336355\n",
            "Train step - Step 520, Loss 0.005715963896363974\n",
            "Train step - Step 530, Loss 0.007889971137046814\n",
            "Train step - Step 540, Loss 0.004672096576541662\n",
            "Train epoch - Accuracy: 0.8939393939393939 Loss: 0.005980395572542241 Corrects: 4425\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.005476543214172125\n",
            "Train step - Step 560, Loss 0.00440839771181345\n",
            "Train step - Step 570, Loss 0.00586355896666646\n",
            "Train step - Step 580, Loss 0.0037339217960834503\n",
            "Train epoch - Accuracy: 0.9056565656565656 Loss: 0.005374842483945417 Corrects: 4483\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.004377644043415785\n",
            "Train step - Step 600, Loss 0.005179948173463345\n",
            "Train step - Step 610, Loss 0.005253072828054428\n",
            "Train step - Step 620, Loss 0.006425741594284773\n",
            "Train epoch - Accuracy: 0.9052525252525252 Loss: 0.0052508707568425725 Corrects: 4481\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.005010281223803759\n",
            "Train step - Step 640, Loss 0.0061635361053049564\n",
            "Train step - Step 650, Loss 0.009384408593177795\n",
            "Train step - Step 660, Loss 0.005380908027291298\n",
            "Train epoch - Accuracy: 0.8917171717171717 Loss: 0.0058377255559569656 Corrects: 4414\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.006289947312325239\n",
            "Train step - Step 680, Loss 0.0063524493016302586\n",
            "Train step - Step 690, Loss 0.006936217192560434\n",
            "Train step - Step 700, Loss 0.004528412129729986\n",
            "Train epoch - Accuracy: 0.9034343434343435 Loss: 0.005141980768830487 Corrects: 4472\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.0043050069361925125\n",
            "Train step - Step 720, Loss 0.004834096413105726\n",
            "Train step - Step 730, Loss 0.005409653298556805\n",
            "Train step - Step 740, Loss 0.004567463416606188\n",
            "Train epoch - Accuracy: 0.9094949494949495 Loss: 0.004967407470362054 Corrects: 4502\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.00382500933483243\n",
            "Train step - Step 760, Loss 0.004024076275527477\n",
            "Train step - Step 770, Loss 0.005247593391686678\n",
            "Train epoch - Accuracy: 0.9151515151515152 Loss: 0.004578441806288079 Corrects: 4530\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.003934032749384642\n",
            "Train step - Step 790, Loss 0.002912284107878804\n",
            "Train step - Step 800, Loss 0.003287652740254998\n",
            "Train step - Step 810, Loss 0.0043866331689059734\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.0044108339782917136 Corrects: 4555\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.003991167061030865\n",
            "Train step - Step 830, Loss 0.0032596206292510033\n",
            "Train step - Step 840, Loss 0.004104334395378828\n",
            "Train step - Step 850, Loss 0.0026778157334774733\n",
            "Train epoch - Accuracy: 0.9315151515151515 Loss: 0.003850428361746699 Corrects: 4611\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.001891522784717381\n",
            "Train step - Step 870, Loss 0.005719611421227455\n",
            "Train step - Step 880, Loss 0.0032459020148962736\n",
            "Train step - Step 890, Loss 0.007436002139002085\n",
            "Train epoch - Accuracy: 0.918989898989899 Loss: 0.004271597710786143 Corrects: 4549\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.0057450816966593266\n",
            "Train step - Step 910, Loss 0.0025987662374973297\n",
            "Train step - Step 920, Loss 0.005041562952101231\n",
            "Train step - Step 930, Loss 0.005009551532566547\n",
            "Train epoch - Accuracy: 0.916969696969697 Loss: 0.004468829131901565 Corrects: 4539\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.00393068790435791\n",
            "Train step - Step 950, Loss 0.004098524805158377\n",
            "Train step - Step 960, Loss 0.005679577589035034\n",
            "Train step - Step 970, Loss 0.003231953363865614\n",
            "Train epoch - Accuracy: 0.9246464646464646 Loss: 0.004287192302407941 Corrects: 4577\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0037425884511321783\n",
            "Train step - Step 990, Loss 0.0030235981103032827\n",
            "Train step - Step 1000, Loss 0.002694187918677926\n",
            "Train step - Step 1010, Loss 0.0024698367342352867\n",
            "Train epoch - Accuracy: 0.9363636363636364 Loss: 0.003630114575339989 Corrects: 4635\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.003435717662796378\n",
            "Train step - Step 1030, Loss 0.003888027975335717\n",
            "Train step - Step 1040, Loss 0.0033401502296328545\n",
            "Train step - Step 1050, Loss 0.0034738408867269754\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.0036219757123652735 Corrects: 4652\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0035768321249634027\n",
            "Train step - Step 1070, Loss 0.0035032848827540874\n",
            "Train step - Step 1080, Loss 0.002963375998660922\n",
            "Train step - Step 1090, Loss 0.0033461377024650574\n",
            "Train epoch - Accuracy: 0.937979797979798 Loss: 0.003508446818556298 Corrects: 4643\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.0036555486731231213\n",
            "Train step - Step 1110, Loss 0.0037667995784431696\n",
            "Train step - Step 1120, Loss 0.003379977773874998\n",
            "Train step - Step 1130, Loss 0.004281825851649046\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.003400186222949714 Corrects: 4678\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.0037154224701225758\n",
            "Train step - Step 1150, Loss 0.002318941056728363\n",
            "Train step - Step 1160, Loss 0.002407738473266363\n",
            "Train epoch - Accuracy: 0.9418181818181818 Loss: 0.0034089474601087847 Corrects: 4662\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.003104554954916239\n",
            "Train step - Step 1180, Loss 0.002667094813659787\n",
            "Train step - Step 1190, Loss 0.0027493464294821024\n",
            "Train step - Step 1200, Loss 0.0035253698006272316\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.0026425855452514658 Corrects: 4738\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0025995627511292696\n",
            "Train step - Step 1220, Loss 0.002786224940791726\n",
            "Train step - Step 1230, Loss 0.002466743579134345\n",
            "Train step - Step 1240, Loss 0.0034144637174904346\n",
            "Train epoch - Accuracy: 0.9553535353535354 Loss: 0.002690548893685142 Corrects: 4729\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.002985217608511448\n",
            "Train step - Step 1260, Loss 0.0032114218920469284\n",
            "Train step - Step 1270, Loss 0.002538044471293688\n",
            "Train step - Step 1280, Loss 0.004882053472101688\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.0032542922496419362 Corrects: 4658\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0027991067618131638\n",
            "Train step - Step 1300, Loss 0.005198942497372627\n",
            "Train step - Step 1310, Loss 0.0019548065029084682\n",
            "Train step - Step 1320, Loss 0.0030696731992065907\n",
            "Train epoch - Accuracy: 0.9395959595959597 Loss: 0.0035341113033431648 Corrects: 4651\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.003419408807530999\n",
            "Train step - Step 1340, Loss 0.0029721646569669247\n",
            "Train step - Step 1350, Loss 0.0041975718922913074\n",
            "Train step - Step 1360, Loss 0.00401299586519599\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.0030469853692979675 Corrects: 4689\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0036677096504718065\n",
            "Train step - Step 1380, Loss 0.002749806037172675\n",
            "Train step - Step 1390, Loss 0.0025882513727992773\n",
            "Train step - Step 1400, Loss 0.0020463222172111273\n",
            "Train epoch - Accuracy: 0.9494949494949495 Loss: 0.002936606906975309 Corrects: 4700\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002506477991119027\n",
            "Train step - Step 1420, Loss 0.003197559155523777\n",
            "Train step - Step 1430, Loss 0.0035602960269898176\n",
            "Train step - Step 1440, Loss 0.004130025859922171\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.002815140575603253 Corrects: 4698\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.004241573624312878\n",
            "Train step - Step 1460, Loss 0.0016647864831611514\n",
            "Train step - Step 1470, Loss 0.004230645950883627\n",
            "Train step - Step 1480, Loss 0.0015481465961784124\n",
            "Train epoch - Accuracy: 0.9547474747474748 Loss: 0.00274317147577125 Corrects: 4726\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.002272082259878516\n",
            "Train step - Step 1500, Loss 0.003950697835534811\n",
            "Train step - Step 1510, Loss 0.0023685074411332607\n",
            "Train step - Step 1520, Loss 0.0028037920128554106\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.0028923694007663113 Corrects: 4703\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.0031779396813362837\n",
            "Train step - Step 1540, Loss 0.0034869404044002295\n",
            "Train step - Step 1550, Loss 0.0013202548725530505\n",
            "Train epoch - Accuracy: 0.9545454545454546 Loss: 0.0028517699095825053 Corrects: 4725\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0008032628102228045\n",
            "Train step - Step 1570, Loss 0.0019764616154134274\n",
            "Train step - Step 1580, Loss 0.002480978611856699\n",
            "Train step - Step 1590, Loss 0.0027718706987798214\n",
            "Train epoch - Accuracy: 0.9577777777777777 Loss: 0.0025094283049493424 Corrects: 4741\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.00201245560310781\n",
            "Train step - Step 1610, Loss 0.004267151467502117\n",
            "Train step - Step 1620, Loss 0.0033173044212162495\n",
            "Train step - Step 1630, Loss 0.0026124189607799053\n",
            "Train epoch - Accuracy: 0.9547474747474748 Loss: 0.002630591897124594 Corrects: 4726\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0022068291436880827\n",
            "Train step - Step 1650, Loss 0.0019792078528553247\n",
            "Train step - Step 1660, Loss 0.0028388649225234985\n",
            "Train step - Step 1670, Loss 0.0032222061417996883\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.0026474517041986637 Corrects: 4722\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0027048198971897364\n",
            "Train step - Step 1690, Loss 0.0017218781867995858\n",
            "Train step - Step 1700, Loss 0.0015132860280573368\n",
            "Train step - Step 1710, Loss 0.0018845739541575313\n",
            "Train epoch - Accuracy: 0.9575757575757575 Loss: 0.0026244690511940103 Corrects: 4740\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0015919822035357356\n",
            "Train step - Step 1730, Loss 0.0024437904357910156\n",
            "Train step - Step 1740, Loss 0.0026229482609778643\n",
            "Train step - Step 1750, Loss 0.0015589690301567316\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.002280803696073667 Corrects: 4766\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.001872871071100235\n",
            "Train step - Step 1770, Loss 0.002441286575049162\n",
            "Train step - Step 1780, Loss 0.002585819223895669\n",
            "Train step - Step 1790, Loss 0.0035228352062404156\n",
            "Train epoch - Accuracy: 0.961010101010101 Loss: 0.002380463864202752 Corrects: 4757\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0020989759359508753\n",
            "Train step - Step 1810, Loss 0.003919144626706839\n",
            "Train step - Step 1820, Loss 0.0020204433239996433\n",
            "Train step - Step 1830, Loss 0.0045059784315526485\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.0028343158089226546 Corrects: 4711\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.002331314841285348\n",
            "Train step - Step 1850, Loss 0.001597125781700015\n",
            "Train step - Step 1860, Loss 0.0038759601302444935\n",
            "Train step - Step 1870, Loss 0.001497387420386076\n",
            "Train epoch - Accuracy: 0.9567676767676768 Loss: 0.002538800496194098 Corrects: 4736\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0025786650367081165\n",
            "Train step - Step 1890, Loss 0.0016347133787348866\n",
            "Train step - Step 1900, Loss 0.002028403338044882\n",
            "Train step - Step 1910, Loss 0.002807632787153125\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.00265680647869077 Corrects: 4722\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.003049207152798772\n",
            "Train step - Step 1930, Loss 0.0013552563032135367\n",
            "Train step - Step 1940, Loss 0.0009222569642588496\n",
            "Train epoch - Accuracy: 0.9781818181818182 Loss: 0.001524002111206452 Corrects: 4842\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0011427189456298947\n",
            "Train step - Step 1960, Loss 0.0004892530268989503\n",
            "Train step - Step 1970, Loss 0.0004891370190307498\n",
            "Train step - Step 1980, Loss 0.0005353307351469994\n",
            "Train epoch - Accuracy: 0.9915151515151515 Loss: 0.000904335527577334 Corrects: 4908\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.001304435427300632\n",
            "Train step - Step 2000, Loss 0.0003319570969324559\n",
            "Train step - Step 2010, Loss 0.0007611496839672327\n",
            "Train step - Step 2020, Loss 0.0009016010444611311\n",
            "Train epoch - Accuracy: 0.9921212121212121 Loss: 0.000773922231217677 Corrects: 4911\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0009955313289538026\n",
            "Train step - Step 2040, Loss 0.0006471441593021154\n",
            "Train step - Step 2050, Loss 0.0008473115158267319\n",
            "Train step - Step 2060, Loss 0.0004753855464514345\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0006699935945146012 Corrects: 4917\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0011530376505106688\n",
            "Train step - Step 2080, Loss 0.00046316938824020326\n",
            "Train step - Step 2090, Loss 0.0006326693692244589\n",
            "Train step - Step 2100, Loss 0.0004764024924952537\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0006237018776521313 Corrects: 4927\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.00042017720988951623\n",
            "Train step - Step 2120, Loss 0.0005962526774965227\n",
            "Train step - Step 2130, Loss 0.00027733753086067736\n",
            "Train step - Step 2140, Loss 0.0004110837762709707\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0004987354847282698 Corrects: 4935\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0005121348658576608\n",
            "Train step - Step 2160, Loss 0.0006180790369398892\n",
            "Train step - Step 2170, Loss 0.0007912802393548191\n",
            "Train step - Step 2180, Loss 0.00041013507870957255\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.00050615660073071 Corrects: 4927\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00034283087006770074\n",
            "Train step - Step 2200, Loss 0.0004562288522720337\n",
            "Train step - Step 2210, Loss 0.00036397462827153504\n",
            "Train step - Step 2220, Loss 0.0007146531715989113\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0004853821160845609 Corrects: 4933\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0004853098653256893\n",
            "Train step - Step 2240, Loss 0.0003888392820954323\n",
            "Train step - Step 2250, Loss 0.0009261009399779141\n",
            "Train step - Step 2260, Loss 0.0002309097326360643\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0005513920603000155 Corrects: 4927\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.00028519643819890916\n",
            "Train step - Step 2280, Loss 0.00040480506140738726\n",
            "Train step - Step 2290, Loss 0.0003534035349730402\n",
            "Train step - Step 2300, Loss 0.0007817688747309148\n",
            "Train epoch - Accuracy: 0.9957575757575757 Loss: 0.0005002285018234015 Corrects: 4929\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0002988077758345753\n",
            "Train step - Step 2320, Loss 0.0005854006740264595\n",
            "Train step - Step 2330, Loss 0.0005189475486986339\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0004612998603349269 Corrects: 4932\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00025215381174348295\n",
            "Train step - Step 2350, Loss 0.0003074023697990924\n",
            "Train step - Step 2360, Loss 0.0001904155215015635\n",
            "Train step - Step 2370, Loss 0.00041095251799561083\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00037692177044745123 Corrects: 4940\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00036619562888517976\n",
            "Train step - Step 2390, Loss 0.0008386079571209848\n",
            "Train step - Step 2400, Loss 0.0002938139659818262\n",
            "Train step - Step 2410, Loss 0.00033113188692368567\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.00038848234839135347 Corrects: 4941\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.000498841458465904\n",
            "Train step - Step 2430, Loss 0.0008121086284518242\n",
            "Train step - Step 2440, Loss 0.0003750960750039667\n",
            "Train step - Step 2450, Loss 0.0006187772378325462\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.00039841473155485634 Corrects: 4934\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0004096418560948223\n",
            "Train step - Step 2470, Loss 0.0005969117628410459\n",
            "Train step - Step 2480, Loss 0.00048726052045822144\n",
            "Train step - Step 2490, Loss 0.0003386599419172853\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00035699070545355555 Corrects: 4942\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00017369339184369892\n",
            "Train step - Step 2510, Loss 0.00025301225832663476\n",
            "Train step - Step 2520, Loss 0.0003167487739119679\n",
            "Train step - Step 2530, Loss 0.0002679734898265451\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002987217666661235 Corrects: 4946\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0003443145251367241\n",
            "Train step - Step 2550, Loss 0.0004949638387188315\n",
            "Train step - Step 2560, Loss 0.00033779567456804216\n",
            "Train step - Step 2570, Loss 0.0002102079160977155\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.00036879799516890385 Corrects: 4941\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.00023593723017256707\n",
            "Train step - Step 2590, Loss 0.0009111301624216139\n",
            "Train step - Step 2600, Loss 0.00027571822283789515\n",
            "Train step - Step 2610, Loss 0.00022564578102901578\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00033816600050259795 Corrects: 4940\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00025909554096870124\n",
            "Train step - Step 2630, Loss 0.00024250087153632194\n",
            "Train step - Step 2640, Loss 0.00038425123784691095\n",
            "Train step - Step 2650, Loss 0.00025855202693492174\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00032810509411825077 Corrects: 4943\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0002392565947957337\n",
            "Train step - Step 2670, Loss 0.000331090617692098\n",
            "Train step - Step 2680, Loss 0.00037770465132780373\n",
            "Train step - Step 2690, Loss 0.00021094211842864752\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003146062893416695 Corrects: 4942\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00031801272416487336\n",
            "Train step - Step 2710, Loss 0.00021011776698287576\n",
            "Train step - Step 2720, Loss 0.00018526057829149067\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00035551808720379316 Corrects: 4942\n",
            "Training finished in 245.86927103996277 seconds\n",
            "EVALUATION:  0.96 0.0029134987853467464\n",
            "TEST GROUP:  0.898\n",
            "TEST ALL:  0.0898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BCQoMhtWDJH",
        "colab_type": "text"
      },
      "source": [
        "**Results fine tuning (catastrophic learning)**<br>\n",
        "What we expect is a dramatic drop in the perfomances with repsect to the Joint Training and the incapacity to learn new things without forgetting the old ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz",
        "colab_type": "code",
        "outputId": "ef78d58c-5bd4-46df-9adb-27b5def3dc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        }
      },
      "source": [
        "method = \"finetuning\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI",
        "colab_type": "code",
        "outputId": "aed68e56-9dcc-44bc-e9f3-2eab0f85e0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\"\"\"num_classes_seen = 100\n",
        "dif_accuracies=printAccuracyDifference(net,old_accuracies, num_classes_seen)\n",
        "dif_accuracies\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.784, 0.0),\n",
              " (2, 0.902, 0.0),\n",
              " (3, 0.865, 0.0),\n",
              " (4, 0.904, 0.0),\n",
              " (5, 0.843, 0.0),\n",
              " (6, 0.891, 0.0),\n",
              " (7, 0.89, 0.0),\n",
              " (8, 0.918, 0.0),\n",
              " (9, 0.884, 0.0),\n",
              " (10, 0.888, 0.888)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjGRIqDtNQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}