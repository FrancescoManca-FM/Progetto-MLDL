{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_icarl_point_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/classifiers/main_icarl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Tkq4Z64NfD",
        "colab_type": "code",
        "outputId": "82e00dac-45df-4f65-9033-73ed5ccaeee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "  Following the iCaRL paper specifications.\n",
        "  ...documentation ...\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Following the iCaRL paper specifications.\\n  ...documentation ...\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMSxfKS2gIKU",
        "colab_type": "code",
        "outputId": "542463eb-6436-4a36-c4a3-f00d36fe2f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\"\n",
        "# !pip install --upgrade wandb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiz6sjyFgQFs",
        "colab_type": "code",
        "outputId": "c8e574a2-ff38-4c70-81ef-a11c9a132ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BToWlSKc4km7",
        "colab_type": "code",
        "outputId": "8f08f747-dfba-42eb-9aea-4f85aa772500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Cifar100/': No such file or directory\n",
            "rm: cannot remove 'DATA': No such file or directory\n",
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 338, done.\u001b[K\n",
            "remote: Counting objects: 100% (338/338), done.\u001b[K\n",
            "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
            "remote: Total 2070 (delta 179), reused 244 (delta 91), pack-reused 1732\u001b[K\n",
            "Receiving objects: 100% (2070/2070), 14.56 MiB | 16.54 MiB/s, done.\n",
            "Resolving deltas: 100% (1234/1234), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Raa-DyJgUwV",
        "colab_type": "text"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxhdzcVgWmO",
        "colab_type": "code",
        "outputId": "c5ebe70e-236b-4cd3-874e-4ce1a6c1d208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}/cifar-100-python'.format(DATA_DIR)):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-12 14:46:51--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  33.1MB/s    in 5.5s    \n",
            "\n",
            "2020-06-12 14:46:57 (29.5 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjIXkQbKgZH3",
        "colab_type": "code",
        "outputId": "2a808ab9-fc8c-46c3-a250-f869f87da86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from Cifar100 import utils\n",
        "\n",
        "\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 70     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = 66\n",
        "\n",
        "# icarl params\n",
        "herding = True # if false random exemplars, if true nme (herding)\n",
        "classifier = \"NCM\" # NCM, FCC, KNN, SVC, COS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 66, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnOcQlG_ga8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHXbDzgjgk_B",
        "colab_type": "code",
        "outputId": "7d684959-aed0-405f-cabb-f49bc9ebeab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85q6ZMLgsC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgY-syfF3WRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=1, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsFyMkAyguQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    #val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    #val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10): # for each group of classes\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppBh08iGBARC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeAccuracy(method, net, loader, reverse_index, dataset, all_preds_cm, all_labels_cm):\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  for indices, images, labels in loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "     \n",
        "        # add other classifiers\n",
        "        if classifier == 'NCM':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.classify(images)\n",
        "        elif classifier == 'FCC':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.FCC_classify(images)\n",
        "        elif classifier == 'KNN' or classifier == 'SVC':\n",
        "          preds = net.KNN_SVC_classify(images)\n",
        "          preds = preds.to(DEVICE)\n",
        "        elif classifier == 'COS':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.COS_classify(images)\n",
        "\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "  accuracy = correct/len(dataset)\n",
        "  if method == 'test':\n",
        "    all_preds_cm.extend(preds.tolist())\n",
        "    all_labels_cm.extend(labels.data.tolist())\n",
        "  return accuracy, all_preds_cm, all_labels_cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wupANuY0g1pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, reverse_index, K):\n",
        "    \n",
        "    all_accuracies = []\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "    group_id=1\n",
        "    test_set = None\n",
        "\n",
        "    #for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "    for train_subset, test_subset in zip(train_subsets, test_subsets):\n",
        "        print(\"GROUP: \",group_id)\n",
        "        if test_set is None:\n",
        "          test_set = test_subset\n",
        "          train_set_big = train_subset\n",
        "        else:\n",
        "          test_set = utils.joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "        #val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "        test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "\n",
        "        ####### iCaRL implementation(following alg. 2,3,4,5 on icarl paper) ##################\n",
        "        \n",
        "        new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        # 1 - update representation of the net \n",
        "        #  alg. 3 icarl\n",
        "        # (here the trainset will be augmented with the exemplars too)\n",
        "        # (here the classes are incremented too)\n",
        "        icarl.update_representation(train_subset, train_dataset, new_classes_examined)\n",
        "\n",
        "        # 2 - update m (number of images per class in the exemplar set corresponding to that class)\n",
        "        m = int(math.ceil(K/icarl.n_classes))\n",
        "\n",
        "        print(\"Reducing each exemplar set to size: {}\".format(m))\n",
        "\n",
        "        # 3 - reduce exemplar set for all the previously seen classes\n",
        "        # alg.5 icarl\n",
        "        icarl.reduce_exemplar_sets(m)\n",
        "\n",
        "        # retrieve the 10 classes in the current subset\n",
        "        # NB. Here there will be exemplars too! (if i do not want that, use new_classes_examined)\n",
        "        classes_current_subset = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        print(\"Constructing exemplar sets class...\")\n",
        "        \n",
        "        # 4 - construct the exemplar set for the new classes\n",
        "        for y in new_classes_examined: # for each class in the current subset\n",
        "          \n",
        "          \n",
        "          # extract all the imgs in the train subset that are linked to this class\n",
        "          images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data'] #they're TENSORS NOT IMAGES (the conversion will be done later)         \n",
        "          imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "          class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "\n",
        "          # alg. 4 icarl\n",
        "          icarl.construct_exemplar_set(class_train_subset,m,y)\n",
        "\n",
        "        # update the num classes seen so far\n",
        "        icarl.n_known = icarl.n_classes #n_classes is incremented in 1: updateRepresentation\n",
        "\n",
        "        print(\"Performing classification...\")\n",
        "\n",
        "        # start classifier\n",
        "        icarl.computeMeans()\n",
        "\n",
        "        # common training on exemplars for KNN and SVC classifier\n",
        "        if classifier == 'KNN':\n",
        "          K_nn = 5\n",
        "          icarl.modelTrain(classifier, K_nn)\n",
        "        elif classifier == 'SVC':\n",
        "          icarl.modelTrain(classifier)\n",
        "\n",
        "        #train accuracy\n",
        "        train_accuracy, _, _ = computeAccuracy('train',icarl, train_dataloader, reverse_index, train_subset,all_preds_cm, all_labels_cm)\n",
        "        print ('Train Accuracy (on current group): %.2f\\n' % (100.0 * train_accuracy))\n",
        "\n",
        "        # --- not used\n",
        "        #val_accuracy, _, _ = computeAccuracy('val',icarl, val_dataloader, reverse_index, val_subset)\n",
        "        #print ('Val Accuracy (on current group): %.2f\\n' % (100.0 * val_accuracy))\n",
        "\n",
        "        #test\n",
        "        test_accuracy, all_preds_cm, all_labels_cm = computeAccuracy('test',icarl, test_dataloader, reverse_index, test_set, all_preds_cm, all_labels_cm)\n",
        "        all_accuracies.append(test_accuracy)\n",
        "        print ('Test Accuracy (all groups seen so far): %.2f\\n' % (100.0 * test_accuracy))\n",
        "\n",
        "        print (\"the model knows %d classes:\\n \" % icarl.n_known)\n",
        "\n",
        "        group_id+=1\n",
        "        \n",
        "    return all_accuracies, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAn-c_mMrMB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    This class implements the main model of iCaRL \n",
        "    and all the methods regarding the exemplars\n",
        "    from delivery: iCaRL is made up of 2 components\n",
        "    - feature extractor (a convolutional NN) => resnet32 optimized on cifar100\n",
        "    - classifier => a FC layer OR a non-parametric classifier (NME)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "import copy\n",
        "import gc #extensive use in order to manage memory issues\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToPILImage \n",
        "\n",
        "from Cifar100 import utils\n",
        "from Cifar100.resnet import resnet32\n",
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# new classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "def auto_loss_rebalancing(n_known, n_classes, loss_type):\n",
        "  alpha = n_known/n_classes \n",
        "\n",
        "  if loss_type == 'class':\n",
        "    return 1-alpha\n",
        "  return alpha\n",
        "\n",
        "def get_rebalancing(rebalancing=None):\n",
        "  if rebalancing is None:\n",
        "    return lambda n_known, n_classes, loss_type: 1\n",
        "  if rebalancing in ['auto', 'AUTO']:\n",
        "    return auto_loss_rebalancing\n",
        "  if callable(rebalancing):\n",
        "    return rebalancing\n",
        "\n",
        "# feature_size: 2048, why?\n",
        "# n_classes: 10 => 100\n",
        "class ICaRL(nn.Module):\n",
        "  def __init__(self, feature_size, n_classes,\\\n",
        "      BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE, MILESTONES, MOMENTUM, K,\\\n",
        "      herding, reverse_index = None, class_loss_criterion='bce', dist_loss_criterion='bce', loss_rebalancing='auto', lambda0=1):\n",
        "    super(ICaRL, self).__init__()\n",
        "    self.net = resnet32()\n",
        "    self.net.fc = nn.Linear(self.net.fc.in_features, n_classes)\n",
        "\n",
        "    self.feature_extractor = resnet32()\n",
        "    self.feature_extractor.fc = nn.Sequential()\n",
        "\n",
        "    self.n_classes = n_classes\n",
        "    self.n_known = 0\n",
        "\n",
        "    # Hyper-parameters from iCaRL\n",
        "    self.BATCH_SIZE = BATCH_SIZE\n",
        "    self.WEIGHT_DECAY  = WEIGHT_DECAY\n",
        "    self.LR = LR\n",
        "    self.GAMMA = GAMMA # this allow LR to become 1/5 LR after MILESTONES epochs\n",
        "    self.NUM_EPOCHS = NUM_EPOCHS\n",
        "    self.DEVICE = DEVICE\n",
        "    self.MILESTONES = MILESTONES # when the LR decreases, according to icarl\n",
        "    self.MOMENTUM = MOMENTUM\n",
        "    self.K = K\n",
        "    \n",
        "    self.reverse_index=reverse_index\n",
        "\n",
        "    self.optimizer, self.scheduler = utils.getOptimizerScheduler(self.LR, self.MOMENTUM, self.WEIGHT_DECAY, self.MILESTONES, self.GAMMA, self.parameters())\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    # List containing exemplar_sets\n",
        "    # Each exemplar_set is a np.array of N images\n",
        "    self.exemplar_sets = []\n",
        "    self.exemplar_sets_indices = []\n",
        "\n",
        "    \n",
        "    # for the classification/distillation loss we have two alternatives\n",
        "    # 1- BCE loss with Logits (reduction could be mean or sum)\n",
        "    # 2- BCE loss + sigmoid\n",
        "    # actually we use just one loss as explained on the forum\n",
        "\n",
        "    self.class_loss, self.dist_loss = self.build_loss(class_loss_criterion, dist_loss_criterion, loss_rebalancing, lambda0=lambda0)\n",
        "\n",
        "    # Means of exemplars (cntroids)\n",
        "    self.compute_means = True\n",
        "    self.exemplar_means = []\n",
        "    self.exemplar_mean_nn = [] # means not normalized\n",
        "\n",
        "    self.herding = herding # random choice of exemplars or icarl exemplars strategy?\n",
        "\n",
        "    # this is used as explained in the forum to compute the exemplar mean in a more accurate way\n",
        "    # populated during construct exemplar set and used in the classify step\n",
        "    self.data_from_classes = []\n",
        "    self.means_from_classes = []\n",
        "\n",
        "    # Knn, svc classification\n",
        "    self.model = None\n",
        "\n",
        "    # QUA! #\n",
        "    ###############################################################################################################################################################################################\n",
        "    self.oldNet= None\n",
        "    self.moreOldNet= None\n",
        "\n",
        "    ###############################################################################################################################################################################################\n",
        "  \n",
        "  # increment the number of classes considered by the net\n",
        "  # incremental learning approach, 0,10..100\n",
        "  def increment_classes(self, n):\n",
        "        gc.collect()\n",
        "\n",
        "        in_features = self.net.fc.in_features\n",
        "        out_features = self.net.fc.out_features\n",
        "        weights = self.net.fc.weight.data\n",
        "        bias = self.net.fc.bias.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features + n) #add 10 classes to the fc last layer\n",
        "        self.net.fc.weight.data[:out_features] = weights\n",
        "        self.net.fc.bias.data[:out_features] = bias\n",
        "        self.n_classes += n #icrement #classes considered\n",
        "\n",
        "  # computes the mean of each exemplar set\n",
        "  def computeMeans(self):\n",
        "    torch.no_grad()  \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    # new mean mgmt\n",
        "    tensors_mean = []\n",
        "    exemplar_mean_nn=[]\n",
        "    with torch.no_grad():\n",
        "      for tensor_set in self.data_from_classes:\n",
        "        features = []\n",
        "        for tensor, _ in tensor_set:\n",
        "          \n",
        "          tensor = tensor.to(self.DEVICE)\n",
        "          feature = feature_extractor(tensor)\n",
        "\n",
        "          feature.data = feature.data / feature.data.norm() # Normalize\n",
        "          features.append(feature)\n",
        "\n",
        "          # cleaning \n",
        "          torch.no_grad()\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        features = torch.stack(features) #(num_exemplars,num_features)\n",
        "        mean_tensor = features.mean(0) \n",
        "        exemplar_mean_nn.append(mean_tensor.to('cpu'))\n",
        "        mean_tensor.data = mean_tensor.data / mean_tensor.data.norm() # Re-normalize\n",
        "        mean_tensor = mean_tensor.to('cpu')\n",
        "        tensors_mean.append(mean_tensor)\n",
        "\n",
        "    self.exemplar_means = tensors_mean  # nb the mean is computed over all the imgs\n",
        "    self.exemplar_mean_nn= exemplar_mean_nn # exemplars means not normalized\n",
        "\n",
        "    # cleaning\n",
        "    torch.no_grad()  \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  # train procedure common for KNN and SVC classifier (save a lot of training time)\n",
        "  def modelTrain(self, method, K_nn = None):\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    # -- train a SVC classifier\n",
        "    X_train, y_train = [], []\n",
        "\n",
        "    for exemplar_set in self.exemplar_sets:\n",
        "          for exemplar, label in  exemplar_set:\n",
        "            exemplar = exemplar.to(self.DEVICE)\n",
        "            feature = feature_extractor(exemplar)\n",
        "            feature = feature.squeeze()\n",
        "            feature.data = feature.data / feature.data.norm() # Normalize\n",
        "            X_train.append(feature.cpu().detach().numpy())\n",
        "            y_train.append(label)\n",
        "    \n",
        "    if method == 'KNN':\n",
        "      model = KNeighborsClassifier(n_neighbors = K_nn)\n",
        "    elif method == 'SVC':\n",
        "      model = LinearSVC()\n",
        "    self.model = model.fit(X_train, y_train)\n",
        "\n",
        "  # common classify function\n",
        "  def KNN_SVC_classify(self, images):\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # --- prediction\n",
        "    X_pred = []\n",
        "    images = images.to(self.DEVICE)\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    features = feature_extractor(images)\n",
        "    for feature in features:\n",
        "      feature = feature.squeeze()\n",
        "      feature.data = feature.data / feature.data.norm() # Normalize\n",
        "      X_pred.append(feature.cpu().detach().numpy())\n",
        "    \n",
        "    preds = self.model.predict(X_pred)\n",
        "    # --- end prediction\n",
        "    return torch.tensor(preds)\n",
        "    \n",
        "  # classify base on cosine similarity\n",
        "  def COS_classify(self, batch_imgs):\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_imgs_size = batch_imgs.size(0)\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    means_exemplars = torch.cat(self.exemplar_mean_nn, dim=0)\n",
        "    means_exemplars = torch.stack([means_exemplars] * batch_imgs_size)\n",
        "    means_exemplars = means_exemplars.transpose(1, 2) # means no normalized\n",
        "\n",
        "    feature = feature_extractor(batch_imgs) # features no normalized\n",
        "    \n",
        "    feature=feature.to('cpu')\n",
        "    means_exemplars = means_exemplars.to('cpu')\n",
        "\n",
        "    preds=[]\n",
        "    for a in feature:\n",
        "      a=a.detach().numpy()\n",
        "      aa=np.linalg.norm(a)\n",
        "      res=[]\n",
        "      for b in means_exemplars:\n",
        "        b=b.detach().numpy()\n",
        "        bb=np.linalg.norm(b)\n",
        "        dot = np.dot(a, b)\n",
        "        cos = dot / (aa * bb)\n",
        "        res.append(cos)\n",
        "      preds.append(np.argmax(np.array(res)))\n",
        "\n",
        "    # cleaning\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return torch.FloatTensor(preds).to(self.DEVICE)\n",
        "\n",
        "  # classification via fc layer (similar to lwf approach)\n",
        "  def FCC_classify(self, images):\n",
        "    _, preds = torch.max(torch.softmax(self.net(images), dim=1), dim=1, keepdim=False)\n",
        "    return preds\n",
        "  # NME classification from iCaRL paper\n",
        "  def classify(self, batch_imgs):\n",
        "      \"\"\"Classify images by nearest-mean-of-exemplars\n",
        "      Args:\n",
        "          batch_imgs: input image batch\n",
        "      Returns:\n",
        "          preds: Tensor of size (batch_size,)\n",
        "      \"\"\"\n",
        "      torch.no_grad()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      batch_imgs_size = batch_imgs.size(0)\n",
        "      feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "      feature_extractor.train(False)\n",
        "\n",
        "      # update exemplar_means with the mean\n",
        "      # of all the train data for a given class\n",
        "\n",
        "      means_exemplars = torch.cat(self.exemplar_means, dim=0)\n",
        "      means_exemplars = torch.stack([means_exemplars] * batch_imgs_size)\n",
        "      means_exemplars = means_exemplars.transpose(1, 2) \n",
        "\n",
        "      feature = feature_extractor(batch_imgs) \n",
        "      aus_normalized_features = []\n",
        "      for el in feature: # Normalize\n",
        "          el.data = el.data / el.data.norm()\n",
        "          aus_normalized_features.append(el)\n",
        "\n",
        "      feature = torch.stack(aus_normalized_features,dim=0)\n",
        "\n",
        "      feature = feature.unsqueeze(2) \n",
        "      feature = feature.expand_as(means_exemplars) \n",
        "\n",
        "      means_exemplars = means_exemplars.to(self.DEVICE)\n",
        "\n",
        "      # Nearest prototype\n",
        "      preds = torch.argmin((feature - means_exemplars).pow(2).sum(1),dim=1)\n",
        "\n",
        "      # cleaning\n",
        "      torch.no_grad()\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "\n",
        "      return preds\n",
        "\n",
        "  # implementation of alg. 4 of icarl paper\n",
        "  # iCaRL ConstructExemplarSet\n",
        "  def construct_exemplar_set(self, tensors, m, label):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "          tensors: train_subset containing a single label\n",
        "          m: number of exemplars allowed/exemplar set (class)\n",
        "          label: considered class\n",
        "    \"\"\"\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    exemplar_set_indices = set()\n",
        "    exemplar_list_indices = []\n",
        "    exemplar_set = []\n",
        "    if self.herding:\n",
        "\n",
        "      feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "      feature_extractor.train(False)\n",
        "\n",
        "      # Compute and cache features for each example\n",
        "      features = []\n",
        "\n",
        "      loader = DataLoader(tensors,batch_size=self.BATCH_SIZE,shuffle=True,drop_last=False,num_workers = 4)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for _, images, labels in loader:\n",
        "          images = images.to(self.DEVICE)\n",
        "          labels = labels.to(self.DEVICE)\n",
        "          feature = feature_extractor(images) \n",
        "\n",
        "          feature = feature / np.linalg.norm(feature.cpu()) # Normalize\n",
        "          \n",
        "          features.append(feature)\n",
        "\n",
        "      features_s = torch.cat(features)\n",
        "      \n",
        "      class_mean = features_s.mean(0)\n",
        "      class_mean = class_mean / np.linalg.norm(class_mean.cpu()) # Normalize\n",
        "      class_mean = torch.stack([class_mean]*features_s.size()[0])\n",
        "\n",
        "      summon = torch.zeros(1,features_s.size()[1]).to(self.DEVICE) #(1,num_features)\n",
        "      for k in range(1, (m + 1)):\n",
        "          S = torch.cat([summon]*features_s.size()[0]) # second addend, features in the exemplar set\n",
        "          results = pd.DataFrame((class_mean-(1/k)*(features_s + S)).pow(2).sum(1).cpu(), columns=['result']).sort_values('result')\n",
        "          results['index'] = results.index\n",
        "          results = results.to_numpy()\n",
        "\n",
        "          # select argmin not included in exemplar_set_indices\n",
        "          for i in range(results.shape[0]):\n",
        "            index = results[i, 1]\n",
        "            exemplar_k_index = tensors[index][0]\n",
        "            if exemplar_k_index not in exemplar_set_indices:\n",
        "              exemplar_k = tensors[index][1].unsqueeze(dim = 0) # take the image from the tuple (index, img, label)\n",
        "              exemplar_set.append((exemplar_k, label))\n",
        "              exemplar_k_index = tensors[index][0] # index of the img on the real dataset\n",
        "              \n",
        "              exemplar_list_indices.append(exemplar_k_index)\n",
        "              exemplar_set_indices.add(exemplar_k_index)\n",
        "              break\n",
        "\n",
        "          # features of the exemplar k\n",
        "          phi = feature_extractor(exemplar_k.to(self.DEVICE)) #feature_extractor(exemplar_k.to(self.DEVICE))\n",
        "          summon += phi # update sum of features\n",
        "    else:\n",
        "      tensors_size = len(tensors)\n",
        "      unique_random_indexes = random.sample(range(0, tensors_size), m) # random sample without replacement k exemplars\n",
        "      i = 0\n",
        "      for k in range(1, (m + 1)):\n",
        "        index = unique_random_indexes[i]\n",
        "        exemplar_k = tensors[index][1].unsqueeze(dim = 0)\n",
        "        exemplar_k_index = tensors[index][0]\n",
        "        exemplar_set.append((exemplar_k, label))\n",
        "        exemplar_set_indices.add(exemplar_k_index)\n",
        "        i = i + 1\n",
        "\n",
        "    # --- new ---\n",
        "    tensor_set = []\n",
        "    for i in range(0, len(tensors)):\n",
        "      t = tensors[i][1].unsqueeze(dim = 0)\n",
        "      tensor_set.append((t, label))\n",
        "    \n",
        "    self.exemplar_sets.append(exemplar_set) #update exemplar sets with the updated exemplars images\n",
        "    self.exemplar_sets_indices.append(exemplar_list_indices)\n",
        "\n",
        "    # this is used to compute more accurately the means of the exemplar (see also computeMeans and classify)\n",
        "    self.data_from_classes.append(tensor_set)\n",
        "\n",
        "    # cleaning\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  # build a exemplar dataset as a subset of the train dataset\n",
        "  def build_exemplars_dataset(self, train_dataset): #complete train dataset\n",
        "    all_exemplars_indices = []\n",
        "    for exemplar_set_indices in self.exemplar_sets_indices:\n",
        "        all_exemplars_indices.extend(exemplar_set_indices)\n",
        "\n",
        "    exemplars_dataset = Subset(train_dataset, all_exemplars_indices)\n",
        "    return exemplars_dataset\n",
        "\n",
        "  def update_representation(self, dataset, train_dataset_big, new_classes):\n",
        "    # 1 - retrieve the classes from the dataset (which is the current train_subset)\n",
        "    # 2 - retrieve the new classes\n",
        "    # 1,2 are done in the main_icarl\n",
        "    #gc.collect()\n",
        "\n",
        "    # 3 - increment classes\n",
        "    #          (add output nodes)\n",
        "    #          (update n_classes)\n",
        "    # 5        store network outputs with pre-update parameters\n",
        "    self.increment_classes(len(new_classes))\n",
        "\n",
        "    # 4 - combine current train_subset (dataset) with exemplars\n",
        "    #     to form a new augmented train dataset\n",
        "    # join the datasets\n",
        "    exemplars_dataset = self.build_exemplars_dataset(train_dataset_big)\n",
        "    \n",
        "    ######################################################################################\n",
        "    new_classes_dataset=[]\n",
        "    if self.n_known==0:\n",
        "      cut=0\n",
        "    else:\n",
        "      cut=self.n_known/10\n",
        "    new_dataset=torch.utils.data.Subset(dataset, range(0,int(5000-450*cut)))\n",
        "    print(\"NEW CLASSE SAMPLES: \",len(new_dataset))\n",
        "\n",
        "    ######################################################################################\n",
        "    #\n",
        "    if len(exemplars_dataset) > 0:\n",
        "      join_dataset = ConcatDataset(new_dataset, exemplars_dataset)\n",
        "      augmented_dataset = ConcatDataset(join_dataset, exemplars_dataset)\n",
        "      # load_exemplars = DataLoader(exemplars_dataset, batch_size=self.BATCH_SIZE,shuffle=False, num_workers=4)\n",
        "      # new_image=[]\n",
        "      # old_image=[]\n",
        "      # for _, images, labels in load_exemplars:\n",
        "      #   for img,lab in zip(images,labels):\n",
        "      #     tran=transforms.Compose([transforms.ToPILImage(),transforms.RandomHorizontalFlip(p=1),transforms.ToTensor()])\n",
        "      #     new_img=tran(img)\n",
        "      #     new_image.append((0,new_img,lab))\n",
        "      #     old_image.append((0,img,lab))\n",
        "      # new_join=new_dataset+old_image+new_image\n",
        "      # augmented_dataset=new_join\n",
        "      #augmented_dataset = ConcatDataset(dataset, exemplars_dataset)\n",
        "      #augmented_dataset = utils.joinSubsets(train_dataset_big, [dataset, exemplars_dataset])\n",
        "    else: \n",
        "      augmented_dataset = new_dataset # first iteration\n",
        "\n",
        "    print(\"ALL DB: \",len(augmented_dataset))\n",
        "    # 6 - run network training, with loss function\n",
        "\n",
        "    net = self.net\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=self.LR, weight_decay=self.WEIGHT_DECAY, momentum=self.MOMENTUM)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.MILESTONES, gamma=self.GAMMA, last_epoch=-1)\n",
        "\n",
        "    criterion = utils.getLossCriterion()\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    net = net.to(self.DEVICE)\n",
        "\n",
        "    # define the loader for the augmented_dataset\n",
        "    loader = DataLoader(augmented_dataset, batch_size=self.BATCH_SIZE,shuffle=True, num_workers=4, drop_last = True)\n",
        "\n",
        "    if len(self.exemplar_sets) > 0:\n",
        "      # QUA! #\n",
        "      #########################################################################################\n",
        "\n",
        "      #   print(self.oldNetTeachers[1].size())\n",
        "      if self.oldNet!=None:\n",
        "        self.moreOldNet=self.oldNet\n",
        "      self.oldNet= copy.deepcopy(net)\n",
        "\n",
        "      #########################################################################################\n",
        "    for epoch in range(self.NUM_EPOCHS):\n",
        "        print(\"NUM_EPOCHS: \",epoch,\"/\", self.NUM_EPOCHS,\" LR: \",scheduler.get_lr())\n",
        "        for _, images, labels in loader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(self.DEVICE)\n",
        "            labels = labels.to(self.DEVICE)\n",
        "            net.train()\n",
        "            # PyTorch, by default, accumulates gradients after each backward pass\n",
        "            # We need to manually set the gradients to zero before starting a new iteration\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "            \n",
        " \n",
        "            # QUA! #\n",
        "            #############################################################################################################\n",
        "            # Forward pass to the network\n",
        "            outputs = net(images)\n",
        "            # Loss = only classification on new classes\n",
        "            loss = self.class_loss(outputs, labels, col_start=self.n_known)\n",
        "            class_loss = loss.item() # Used for logging for debugging purposes\n",
        "            \n",
        "            # Distilation loss for old classes, class loss on new classes\n",
        "            dist_loss = None\n",
        "            older_dist_loss=None\n",
        "            if len(self.exemplar_sets) > 0:\n",
        "              old_net=self.oldNet\n",
        "              out_old = torch.sigmoid(old_net(images))\n",
        "              dist_loss = self.dist_loss(outputs, out_old, col_end=self.n_known)\n",
        "\n",
        "              if self.moreOldNet!=None:\n",
        "                older_net=self.moreOldNet # old old net\n",
        "                older_out = torch.sigmoid(older_net(images))\n",
        "                older_dist_loss = self.double_dist_loss(outputs[0:128,0:-20], older_out[0:128,0:-10], col_end=self.n_known)\n",
        "                loss += older_dist_loss\n",
        "\n",
        "              loss += dist_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            ##############################################################################################################\n",
        "\n",
        "        scheduler.step()\n",
        "        print(\"LOSS: \", loss.item(), 'class loss', class_loss, 'dist loss', dist_loss.item() if dist_loss is not None else dist_loss, 'older dist loss',older_dist_loss.item() if older_dist_loss is not None else older_dist_loss)\n",
        "\n",
        "    self.net = copy.deepcopy(net)\n",
        "    self.feature_extractor = copy.deepcopy(net)\n",
        "    self.feature_extractor.fc = nn.Sequential()\n",
        "\n",
        "    #cleaning\n",
        "    del net\n",
        "    torch.cuda.empty_cache()\n",
        " # QUA! #\n",
        " ###################################################################################################################\n",
        "  def double_dist_loss(self,outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    rebalancing=None\n",
        "    rebalancing = get_rebalancing(rebalancing)\n",
        "    dist_loss_func = self.bce_dist_loss\n",
        "    alpha = rebalancing(self.n_known, self.n_classes, 'dist')\n",
        "    return 0.5*alpha*dist_loss_func(outputs, labels, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        " ##################################################################################################################\n",
        "\n",
        "  def build_loss(self, class_loss_criterion, dist_loss_criterion, rebalancing=None, lambda0=1):\n",
        "    class_loss_func = None\n",
        "    dist_loss_func = None\n",
        "\n",
        "    if class_loss_criterion in ['l2', 'L2']:\n",
        "      class_loss_func = self.l2_class_loss\n",
        "    elif class_loss_criterion in ['bce', 'BCE']:\n",
        "      class_loss_func = self.bce_class_loss\n",
        "    elif class_loss_criterion in ['ce', 'CE']:\n",
        "      class_loss_func = self.ce_class_loss\n",
        "\n",
        "    if dist_loss_criterion in ['l2', 'L2']:\n",
        "      dist_loss_func = self.l2_dist_loss\n",
        "    elif dist_loss_criterion in ['bce', 'BCE']:\n",
        "      dist_loss_func = self.bce_dist_loss\n",
        "    elif dist_loss_criterion in ['ce', 'CE']:\n",
        "      dist_loss_func = self.ce_dist_loss\n",
        "\n",
        "    rebalancing = get_rebalancing(rebalancing)\n",
        "    \n",
        "    def class_loss(outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "      alpha = rebalancing(self.n_known, self.n_classes, 'class')\n",
        "      return alpha*class_loss_func(outputs, labels, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "    \n",
        "    def dist_loss(outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "      alpha = rebalancing(self.n_known, self.n_classes, 'dist')\n",
        "      return lambda0*alpha*dist_loss_func(outputs, labels, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "    \n",
        "    return class_loss, dist_loss\n",
        "\n",
        "  def bce_class_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.bce_loss(outputs, labels, encode=True, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def bce_dist_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.bce_loss(outputs, labels, encode=False, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def ce_class_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.ce_loss(outputs, self.reverse_index.getNodes(labels), decode=False, row_start=row_start, row_end=row_end, col_start=None, col_end=col_end)\n",
        "    \n",
        "  def ce_dist_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.ce_loss(outputs, labels, decode=True, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def l2_class_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.l2_loss(outputs, labels, encode=True, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def l2_dist_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.l2_loss(outputs, labels, encode=False, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "\n",
        "  def bce_loss(self, outputs, labels, encode=False, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction = 'mean')\n",
        "\n",
        "    if encode:\n",
        "      labels = utils._one_hot_encode(labels, self.n_classes, self.reverse_index, device=self.DEVICE)\n",
        "      labels = labels.type_as(outputs)\n",
        "\n",
        "    return criterion(outputs[row_start:row_end, col_start:col_end], labels[row_start:row_end, col_start:col_end])\n",
        "\n",
        "\n",
        "  def ce_loss(self, outputs, labels, decode=False, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if decode:\n",
        "      labels = torch.argmax(labels, dim=1)\n",
        "    \n",
        "    return criterion(outputs[row_start:row_end, col_start:col_end], labels[row_start:row_end])\n",
        "\n",
        "\n",
        "  def l2_loss(self, outputs, labels, encode=False, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    criterion = nn.MSELoss(reduction = 'mean')\n",
        "    \n",
        "    if encode:\n",
        "      labels = utils._one_hot_encode(labels, self.n_classes, self.reverse_index, device=self.DEVICE)\n",
        "      labels = labels.type_as(outputs)\n",
        "    \n",
        "    return criterion(outputs[row_start:row_end, col_start:col_end], labels[row_start:row_end, col_start:col_end])\n",
        "\n",
        "\n",
        "  # implementation of alg. 5 of icarl paper\n",
        "  # iCaRL ReduceExemplarSet\n",
        "  def reduce_exemplar_sets(self, m):\n",
        "  \t    # i keep only the first m exemplar images\n",
        "        # where m is the UPDATED K/number_classes_seen\n",
        "        # the number of images per each exemplar set (class) progressively decreases\n",
        "        for y, P_y in enumerate(self.exemplar_sets):\n",
        "            self.exemplar_sets[y] = P_y[:m] \n",
        "        for x, P_x in enumerate(self.exemplar_sets_indices):\n",
        "            self.exemplar_sets_indices[x] = P_x[:m] \n",
        "\n",
        "\n",
        "# ---------- \n",
        "from torch.utils.data import Dataset\n",
        "\"\"\"\n",
        "  Merge two different datasets (train and exemplars in our case)\n",
        "  format:\n",
        "  train\n",
        "  --------\n",
        "  exemplars\n",
        "  train leans on cifar100\n",
        "  exemplars is managed here (exemplar_transform is performed) => changed\n",
        "\"\"\"\n",
        "class ConcatDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset1, dataset2):\n",
        "        self.dataset1 = dataset1\n",
        "        self.dataset2 = dataset2\n",
        "        self.l1 = len(dataset1)\n",
        "        self.l2 = len(dataset2)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        if index < self.l1:\n",
        "            _, image,label = self.dataset1[index] #here it leans on cifar100 get item\n",
        "            return _, image,label\n",
        "        else:\n",
        "            _, image, label = self.dataset2[index - self.l1]\n",
        "            return _, image,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.l1 + self.l2)\n",
        "#------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axANZYKXg6wn",
        "colab_type": "text"
      },
      "source": [
        "**Exemplars management**<br>\n",
        "From iCaRL. We have an exemplar set for each class that we have seen so far. The cardinality of each exemplar set is constant and it is equal, at any time, to m = K/t. Where K is a constraint equal to the amount of memory we're allocating for the exemplars and t is the number of classes that has been seen so far. Implementing iCaRL, whenever a group of (10) classes is trained, it is trained on the train data for those classes (as before) + the current exemplars sets.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx0Woq8uhXyR",
        "colab_type": "code",
        "outputId": "a08e2525-7b85-46d2-f71f-6cc5271dfabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from Cifar100.icarl_model import ICaRL\n",
        "\n",
        "# default params\n",
        "\n",
        "K = 2000\n",
        "n_classes = 0\n",
        "feature_size = 2048\n",
        "\n",
        "icarl = ICaRL(feature_size, n_classes, BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE,MILESTONES,MOMENTUM, K, herding, outputs_labels_mapping)\n",
        "icarl.cuda() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 230, in _feed\n",
            "    close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 177, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ICaRL(\n",
              "  (net): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=64, out_features=0, bias=True)\n",
              "  )\n",
              "  (feature_extractor): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Sequential()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmxtCL8AvYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracies, all_preds_cm, all_labels_cm = incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, outputs_labels_mapping, K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_B01Oa82wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if herding:\n",
        "  method = 'iCaRL_{}_herding'.format(classifier)\n",
        "else:\n",
        "  method = 'iCaRL_{}_random'.format(classifier)\n",
        "\n",
        "print(\"metrics iCaRL for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "# accuracy \n",
        "data_plot_line=[]\n",
        "\n",
        "classes_per_group = 10\n",
        "for group_classes in range(0,10):\n",
        "    data_plot_line.append(((group_classes + 1)*classes_per_group, accuracies[group_classes]))\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write to JSON file\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtGxWw4fyzyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}