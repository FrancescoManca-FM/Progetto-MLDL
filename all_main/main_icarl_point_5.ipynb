{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_icarl_point_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/classifiers/main_icarl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Tkq4Z64NfD",
        "colab_type": "code",
        "outputId": "1504715f-84dd-4a78-d937-ae74f0936deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "  Following the iCaRL paper specifications.\n",
        "  ...documentation ...\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Following the iCaRL paper specifications.\\n  ...documentation ...\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMSxfKS2gIKU",
        "colab_type": "code",
        "outputId": "3437a9b7-b140-4e07-c340-d2959e981033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\"\n",
        "# !pip install --upgrade wandb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiz6sjyFgQFs",
        "colab_type": "code",
        "outputId": "5d71af2b-7da0-4a98-c7f1-dae844e6586a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BToWlSKc4km7",
        "colab_type": "code",
        "outputId": "47ccd786-fe0e-40b8-e130-26ea131e1982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/38)\u001b[K\rremote: Counting objects:   5% (2/38)\u001b[K\rremote: Counting objects:   7% (3/38)\u001b[K\rremote: Counting objects:  10% (4/38)\u001b[K\rremote: Counting objects:  13% (5/38)\u001b[K\rremote: Counting objects:  15% (6/38)\u001b[K\rremote: Counting objects:  18% (7/38)\u001b[K\rremote: Counting objects:  21% (8/38)\u001b[K\rremote: Counting objects:  23% (9/38)\u001b[K\rremote: Counting objects:  26% (10/38)\u001b[K\rremote: Counting objects:  28% (11/38)\u001b[K\rremote: Counting objects:  31% (12/38)\u001b[K\rremote: Counting objects:  34% (13/38)\u001b[K\rremote: Counting objects:  36% (14/38)\u001b[K\rremote: Counting objects:  39% (15/38)\u001b[K\rremote: Counting objects:  42% (16/38)\u001b[K\rremote: Counting objects:  44% (17/38)\u001b[K\rremote: Counting objects:  47% (18/38)\u001b[K\rremote: Counting objects:  50% (19/38)\u001b[K\rremote: Counting objects:  52% (20/38)\u001b[K\rremote: Counting objects:  55% (21/38)\u001b[K\rremote: Counting objects:  57% (22/38)\u001b[K\rremote: Counting objects:  60% (23/38)\u001b[K\rremote: Counting objects:  63% (24/38)\u001b[K\rremote: Counting objects:  65% (25/38)\u001b[K\rremote: Counting objects:  68% (26/38)\u001b[K\rremote: Counting objects:  71% (27/38)\u001b[K\rremote: Counting objects:  73% (28/38)\u001b[K\rremote: Counting objects:  76% (29/38)\u001b[K\rremote: Counting objects:  78% (30/38)\u001b[K\rremote: Counting objects:  81% (31/38)\u001b[K\rremote: Counting objects:  84% (32/38)\u001b[K\rremote: Counting objects:  86% (33/38)\u001b[K\rremote: Counting objects:  89% (34/38)\u001b[K\rremote: Counting objects:  92% (35/38)\u001b[K\rremote: Counting objects:  94% (36/38)\u001b[K\rremote: Counting objects:  97% (37/38)\u001b[K\rremote: Counting objects: 100% (38/38)\u001b[K\rremote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 2157 (delta 16), reused 32 (delta 12), pack-reused 2119\u001b[K\n",
            "Receiving objects: 100% (2157/2157), 18.00 MiB | 16.84 MiB/s, done.\n",
            "Resolving deltas: 100% (1282/1282), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Raa-DyJgUwV",
        "colab_type": "text"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxhdzcVgWmO",
        "colab_type": "code",
        "outputId": "aafe7a05-1f18-4cfe-a3f8-bff26dda5fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}/cifar-100-python'.format(DATA_DIR)):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-13 10:23:33--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz.1’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  33.0MB/s    in 5.5s    \n",
            "\n",
            "2020-06-13 10:23:39 (29.4 MB/s) - ‘cifar-100-python.tar.gz.1’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjIXkQbKgZH3",
        "colab_type": "code",
        "outputId": "64abe5c2-e0e5-4177-d7d7-18afdf724568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from Cifar100 import utils\n",
        "\n",
        "\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 70     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = 66\n",
        "\n",
        "# icarl params\n",
        "herding = True # if false random exemplars, if true nme (herding)\n",
        "classifier = \"NCM\" # NCM, FCC, KNN, SVC, COS"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 66, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnOcQlG_ga8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHXbDzgjgk_B",
        "colab_type": "code",
        "outputId": "3f57283e-e1ec-46b1-d111-29ed13da7f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85q6ZMLgsC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgY-syfF3WRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=1, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsFyMkAyguQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    #val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    #val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10): # for each group of classes\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppBh08iGBARC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeAccuracy(method, net, loader, reverse_index, dataset, all_preds_cm, all_labels_cm):\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  for indices, images, labels in loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "     \n",
        "        # add other classifiers\n",
        "        if classifier == 'NCM':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.classify(images)\n",
        "        elif classifier == 'FCC':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.FCC_classify(images)\n",
        "        elif classifier == 'KNN' or classifier == 'SVC':\n",
        "          preds = net.KNN_SVC_classify(images)\n",
        "          preds = preds.to(DEVICE)\n",
        "        elif classifier == 'COS':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.COS_classify(images)\n",
        "\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "  accuracy = correct/len(dataset)\n",
        "  if method == 'test':\n",
        "    all_preds_cm.extend(preds.tolist())\n",
        "    all_labels_cm.extend(labels.data.tolist())\n",
        "  return accuracy, all_preds_cm, all_labels_cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wupANuY0g1pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, reverse_index, K):\n",
        "    \n",
        "    all_accuracies = []\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "    group_id=1\n",
        "    test_set = None\n",
        "\n",
        "    #for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "    for train_subset, test_subset in zip(train_subsets, test_subsets):\n",
        "        print(\"GROUP: \",group_id)\n",
        "        if test_set is None:\n",
        "          test_set = test_subset\n",
        "          train_set_big = train_subset\n",
        "        else:\n",
        "          test_set = utils.joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "        #val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "        test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "\n",
        "        ####### iCaRL implementation(following alg. 2,3,4,5 on icarl paper) ##################\n",
        "        \n",
        "        new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        # 1 - update representation of the net \n",
        "        #  alg. 3 icarl\n",
        "        # (here the trainset will be augmented with the exemplars too)\n",
        "        # (here the classes are incremented too)\n",
        "        icarl.update_representation(train_subset, train_dataset, new_classes_examined)\n",
        "\n",
        "        # 2 - update m (number of images per class in the exemplar set corresponding to that class)\n",
        "        m = int(math.ceil(K/icarl.n_classes))\n",
        "\n",
        "        print(\"Reducing each exemplar set to size: {}\".format(m))\n",
        "\n",
        "        # 3 - reduce exemplar set for all the previously seen classes\n",
        "        # alg.5 icarl\n",
        "        icarl.reduce_exemplar_sets(m)\n",
        "\n",
        "        # retrieve the 10 classes in the current subset\n",
        "        # NB. Here there will be exemplars too! (if i do not want that, use new_classes_examined)\n",
        "        classes_current_subset = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        print(\"Constructing exemplar sets class...\")\n",
        "        \n",
        "        # 4 - construct the exemplar set for the new classes\n",
        "        for y in new_classes_examined: # for each class in the current subset\n",
        "          \n",
        "          \n",
        "          # extract all the imgs in the train subset that are linked to this class\n",
        "          images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data'] #they're TENSORS NOT IMAGES (the conversion will be done later)         \n",
        "          imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "          class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "\n",
        "          # alg. 4 icarl\n",
        "          icarl.construct_exemplar_set(class_train_subset,m,y)\n",
        "\n",
        "        # update the num classes seen so far\n",
        "        icarl.n_known = icarl.n_classes #n_classes is incremented in 1: updateRepresentation\n",
        "\n",
        "        print(\"Performing classification...\")\n",
        "\n",
        "        # start classifier\n",
        "        icarl.computeMeans()\n",
        "\n",
        "        # common training on exemplars for KNN and SVC classifier\n",
        "        if classifier == 'KNN':\n",
        "          K_nn = 5\n",
        "          icarl.modelTrain(classifier, K_nn)\n",
        "        elif classifier == 'SVC':\n",
        "          icarl.modelTrain(classifier)\n",
        "\n",
        "        #train accuracy\n",
        "        train_accuracy, _, _ = computeAccuracy('train',icarl, train_dataloader, reverse_index, train_subset,all_preds_cm, all_labels_cm)\n",
        "        print ('Train Accuracy (on current group): %.2f\\n' % (100.0 * train_accuracy))\n",
        "\n",
        "        # --- not used\n",
        "        #val_accuracy, _, _ = computeAccuracy('val',icarl, val_dataloader, reverse_index, val_subset)\n",
        "        #print ('Val Accuracy (on current group): %.2f\\n' % (100.0 * val_accuracy))\n",
        "\n",
        "        #test\n",
        "        test_accuracy, all_preds_cm, all_labels_cm = computeAccuracy('test',icarl, test_dataloader, reverse_index, test_set, all_preds_cm, all_labels_cm)\n",
        "        all_accuracies.append(test_accuracy)\n",
        "        print ('Test Accuracy (all groups seen so far): %.2f\\n' % (100.0 * test_accuracy))\n",
        "\n",
        "        print (\"the model knows %d classes:\\n \" % icarl.n_known)\n",
        "\n",
        "        group_id+=1\n",
        "        \n",
        "    return all_accuracies, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAn-c_mMrMB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "    This class implements the main model of iCaRL \n",
        "    and all the methods regarding the exemplars\n",
        "    from delivery: iCaRL is made up of 2 components\n",
        "    - feature extractor (a convolutional NN) => resnet32 optimized on cifar100\n",
        "    - classifier => a FC layer OR a non-parametric classifier (NME)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "from torch.autograd import Variable\n",
        "import copy\n",
        "import gc #extensive use in order to manage memory issues\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torchvision.transforms import ToPILImage \n",
        "\n",
        "from Cifar100 import utils\n",
        "from Cifar100.resnet import resnet32\n",
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# new classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "def auto_loss_rebalancing(n_known, n_classes, loss_type):\n",
        "  alpha = n_known/n_classes \n",
        "\n",
        "  if loss_type == 'class':\n",
        "    return 1-alpha\n",
        "  return alpha\n",
        "\n",
        "def get_rebalancing(rebalancing=None):\n",
        "  if rebalancing is None:\n",
        "    return lambda n_known, n_classes, loss_type: 1\n",
        "  if rebalancing in ['auto', 'AUTO']:\n",
        "    return auto_loss_rebalancing\n",
        "  if callable(rebalancing):\n",
        "    return rebalancing\n",
        "\n",
        "# feature_size: 2048, why?\n",
        "# n_classes: 10 => 100\n",
        "class ICaRL(nn.Module):\n",
        "  def __init__(self, feature_size, n_classes,\\\n",
        "      BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE, MILESTONES, MOMENTUM, K,\\\n",
        "      herding, reverse_index = None, class_loss_criterion='bce', dist_loss_criterion='bce', loss_rebalancing='auto', lambda0=1):\n",
        "    super(ICaRL, self).__init__()\n",
        "    self.net = resnet32()\n",
        "    self.net.fc = nn.Linear(self.net.fc.in_features, n_classes)\n",
        "\n",
        "    self.feature_extractor = resnet32()\n",
        "    self.feature_extractor.fc = nn.Sequential()\n",
        "\n",
        "    self.n_classes = n_classes\n",
        "    self.n_known = 0\n",
        "\n",
        "    # Hyper-parameters from iCaRL\n",
        "    self.BATCH_SIZE = BATCH_SIZE\n",
        "    self.WEIGHT_DECAY  = WEIGHT_DECAY\n",
        "    self.LR = LR\n",
        "    self.GAMMA = GAMMA # this allow LR to become 1/5 LR after MILESTONES epochs\n",
        "    self.NUM_EPOCHS = NUM_EPOCHS\n",
        "    self.DEVICE = DEVICE\n",
        "    self.MILESTONES = MILESTONES # when the LR decreases, according to icarl\n",
        "    self.MOMENTUM = MOMENTUM\n",
        "    self.K = K\n",
        "    \n",
        "    self.reverse_index=reverse_index\n",
        "\n",
        "    self.optimizer, self.scheduler = utils.getOptimizerScheduler(self.LR, self.MOMENTUM, self.WEIGHT_DECAY, self.MILESTONES, self.GAMMA, self.parameters())\n",
        "\n",
        "    gc.collect()\n",
        "    \n",
        "    # List containing exemplar_sets\n",
        "    # Each exemplar_set is a np.array of N images\n",
        "    self.exemplar_sets = []\n",
        "    self.exemplar_sets_indices = []\n",
        "\n",
        "    \n",
        "    # for the classification/distillation loss we have two alternatives\n",
        "    # 1- BCE loss with Logits (reduction could be mean or sum)\n",
        "    # 2- BCE loss + sigmoid\n",
        "    # actually we use just one loss as explained on the forum\n",
        "\n",
        "    self.class_loss, self.dist_loss = self.build_loss(class_loss_criterion, dist_loss_criterion, loss_rebalancing, lambda0=lambda0)\n",
        "\n",
        "    # Means of exemplars (cntroids)\n",
        "    self.compute_means = True\n",
        "    self.exemplar_means = []\n",
        "    self.exemplar_mean_nn = [] # means not normalized\n",
        "\n",
        "    self.herding = herding # random choice of exemplars or icarl exemplars strategy?\n",
        "\n",
        "    # this is used as explained in the forum to compute the exemplar mean in a more accurate way\n",
        "    # populated during construct exemplar set and used in the classify step\n",
        "    self.data_from_classes = []\n",
        "    self.means_from_classes = []\n",
        "\n",
        "    # Knn, svc classification\n",
        "    self.model = None\n",
        "\n",
        "    # QUA! #\n",
        "    ###############################################################################################################################################################################################\n",
        "    self.oldNet= None\n",
        "    self.moreOldNet= None\n",
        "\n",
        "    ###############################################################################################################################################################################################\n",
        "  \n",
        "  # increment the number of classes considered by the net\n",
        "  # incremental learning approach, 0,10..100\n",
        "  def increment_classes(self, n):\n",
        "        gc.collect()\n",
        "\n",
        "        in_features = self.net.fc.in_features\n",
        "        out_features = self.net.fc.out_features\n",
        "        weights = self.net.fc.weight.data\n",
        "        bias = self.net.fc.bias.data\n",
        "\n",
        "        self.net.fc = nn.Linear(in_features, out_features + n) #add 10 classes to the fc last layer\n",
        "        self.net.fc.weight.data[:out_features] = weights\n",
        "        self.net.fc.bias.data[:out_features] = bias\n",
        "        self.n_classes += n #icrement #classes considered\n",
        "\n",
        "  # computes the mean of each exemplar set\n",
        "  def computeMeans(self):\n",
        "    torch.no_grad()  \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    # new mean mgmt\n",
        "    tensors_mean = []\n",
        "    exemplar_mean_nn=[]\n",
        "    with torch.no_grad():\n",
        "      for tensor_set in self.data_from_classes:\n",
        "        features = []\n",
        "        for tensor, _ in tensor_set:\n",
        "          \n",
        "          tensor = tensor.to(self.DEVICE)\n",
        "          feature = feature_extractor(tensor)\n",
        "\n",
        "          feature.data = feature.data / feature.data.norm() # Normalize\n",
        "          features.append(feature)\n",
        "\n",
        "          # cleaning \n",
        "          torch.no_grad()\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "        features = torch.stack(features) #(num_exemplars,num_features)\n",
        "        mean_tensor = features.mean(0) \n",
        "        exemplar_mean_nn.append(mean_tensor.to('cpu'))\n",
        "        mean_tensor.data = mean_tensor.data / mean_tensor.data.norm() # Re-normalize\n",
        "        mean_tensor = mean_tensor.to('cpu')\n",
        "        tensors_mean.append(mean_tensor)\n",
        "\n",
        "    self.exemplar_means = tensors_mean  # nb the mean is computed over all the imgs\n",
        "    self.exemplar_mean_nn= exemplar_mean_nn # exemplars means not normalized\n",
        "\n",
        "    # cleaning\n",
        "    torch.no_grad()  \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  # train procedure common for KNN and SVC classifier (save a lot of training time)\n",
        "  def modelTrain(self, method, K_nn = None):\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    # -- train a SVC classifier\n",
        "    X_train, y_train = [], []\n",
        "\n",
        "    for exemplar_set in self.exemplar_sets:\n",
        "          for exemplar, label in  exemplar_set:\n",
        "            exemplar = exemplar.to(self.DEVICE)\n",
        "            feature = feature_extractor(exemplar)\n",
        "            feature = feature.squeeze()\n",
        "            feature.data = feature.data / feature.data.norm() # Normalize\n",
        "            X_train.append(feature.cpu().detach().numpy())\n",
        "            y_train.append(label)\n",
        "    \n",
        "    if method == 'KNN':\n",
        "      model = KNeighborsClassifier(n_neighbors = K_nn)\n",
        "    elif method == 'SVC':\n",
        "      model = LinearSVC()\n",
        "    self.model = model.fit(X_train, y_train)\n",
        "\n",
        "  # common classify function\n",
        "  def KNN_SVC_classify(self, images):\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # --- prediction\n",
        "    X_pred = []\n",
        "    images = images.to(self.DEVICE)\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    features = feature_extractor(images)\n",
        "    for feature in features:\n",
        "      feature = feature.squeeze()\n",
        "      feature.data = feature.data / feature.data.norm() # Normalize\n",
        "      X_pred.append(feature.cpu().detach().numpy())\n",
        "    \n",
        "    preds = self.model.predict(X_pred)\n",
        "    # --- end prediction\n",
        "    return torch.tensor(preds)\n",
        "    \n",
        "  # classify base on cosine similarity\n",
        "  def COS_classify(self, batch_imgs):\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    batch_imgs_size = batch_imgs.size(0)\n",
        "    feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "    feature_extractor.train(False)\n",
        "\n",
        "    means_exemplars = torch.cat(self.exemplar_mean_nn, dim=0)\n",
        "    means_exemplars = torch.stack([means_exemplars] * batch_imgs_size)\n",
        "    means_exemplars = means_exemplars.transpose(1, 2) # means no normalized\n",
        "\n",
        "    feature = feature_extractor(batch_imgs) # features no normalized\n",
        "    \n",
        "    feature=feature.to('cpu')\n",
        "    means_exemplars = means_exemplars.to('cpu')\n",
        "\n",
        "    preds=[]\n",
        "    for a in feature:\n",
        "      a=a.detach().numpy()\n",
        "      aa=np.linalg.norm(a)\n",
        "      res=[]\n",
        "      for b in means_exemplars:\n",
        "        b=b.detach().numpy()\n",
        "        bb=np.linalg.norm(b)\n",
        "        dot = np.dot(a, b)\n",
        "        cos = dot / (aa * bb)\n",
        "        res.append(cos)\n",
        "      preds.append(np.argmax(np.array(res)))\n",
        "\n",
        "    # cleaning\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return torch.FloatTensor(preds).to(self.DEVICE)\n",
        "\n",
        "  # classification via fc layer (similar to lwf approach)\n",
        "  def FCC_classify(self, images):\n",
        "    _, preds = torch.max(torch.softmax(self.net(images), dim=1), dim=1, keepdim=False)\n",
        "    return preds\n",
        "  # NME classification from iCaRL paper\n",
        "  def classify(self, batch_imgs):\n",
        "      \"\"\"Classify images by nearest-mean-of-exemplars\n",
        "      Args:\n",
        "          batch_imgs: input image batch\n",
        "      Returns:\n",
        "          preds: Tensor of size (batch_size,)\n",
        "      \"\"\"\n",
        "      torch.no_grad()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "      batch_imgs_size = batch_imgs.size(0)\n",
        "      feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "      feature_extractor.train(False)\n",
        "\n",
        "      # update exemplar_means with the mean\n",
        "      # of all the train data for a given class\n",
        "\n",
        "      means_exemplars = torch.cat(self.exemplar_means, dim=0)\n",
        "      means_exemplars = torch.stack([means_exemplars] * batch_imgs_size)\n",
        "      means_exemplars = means_exemplars.transpose(1, 2) \n",
        "\n",
        "      feature = feature_extractor(batch_imgs) \n",
        "      aus_normalized_features = []\n",
        "      for el in feature: # Normalize\n",
        "          el.data = el.data / el.data.norm()\n",
        "          aus_normalized_features.append(el)\n",
        "\n",
        "      feature = torch.stack(aus_normalized_features,dim=0)\n",
        "\n",
        "      feature = feature.unsqueeze(2) \n",
        "      feature = feature.expand_as(means_exemplars) \n",
        "\n",
        "      means_exemplars = means_exemplars.to(self.DEVICE)\n",
        "\n",
        "      # Nearest prototype\n",
        "      preds = torch.argmin((feature - means_exemplars).pow(2).sum(1),dim=1)\n",
        "\n",
        "      # cleaning\n",
        "      torch.no_grad()\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "\n",
        "      return preds\n",
        "\n",
        "  # implementation of alg. 4 of icarl paper\n",
        "  # iCaRL ConstructExemplarSet\n",
        "  def construct_exemplar_set(self, tensors, m, label):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "          tensors: train_subset containing a single label\n",
        "          m: number of exemplars allowed/exemplar set (class)\n",
        "          label: considered class\n",
        "    \"\"\"\n",
        "    torch.no_grad()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    exemplar_set_indices = set()\n",
        "    exemplar_list_indices = []\n",
        "    exemplar_set = []\n",
        "    if self.herding:\n",
        "\n",
        "      feature_extractor = self.feature_extractor.to(self.DEVICE)\n",
        "      feature_extractor.train(False)\n",
        "\n",
        "      # Compute and cache features for each example\n",
        "      features = []\n",
        "\n",
        "      loader = DataLoader(tensors,batch_size=self.BATCH_SIZE,shuffle=True,drop_last=False,num_workers = 4)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for _, images, labels in loader:\n",
        "          images = images.to(self.DEVICE)\n",
        "          labels = labels.to(self.DEVICE)\n",
        "          feature = feature_extractor(images) \n",
        "\n",
        "          feature = feature / np.linalg.norm(feature.cpu()) # Normalize\n",
        "          \n",
        "          features.append(feature)\n",
        "\n",
        "      features_s = torch.cat(features)\n",
        "      \n",
        "      class_mean = features_s.mean(0)\n",
        "      class_mean = class_mean / np.linalg.norm(class_mean.cpu()) # Normalize\n",
        "      class_mean = torch.stack([class_mean]*features_s.size()[0])\n",
        "\n",
        "      summon = torch.zeros(1,features_s.size()[1]).to(self.DEVICE) #(1,num_features)\n",
        "      for k in range(1, (m + 1)):\n",
        "          S = torch.cat([summon]*features_s.size()[0]) # second addend, features in the exemplar set\n",
        "          results = pd.DataFrame((class_mean-(1/k)*(features_s + S)).pow(2).sum(1).cpu(), columns=['result']).sort_values('result')\n",
        "          results['index'] = results.index\n",
        "          results = results.to_numpy()\n",
        "\n",
        "          # select argmin not included in exemplar_set_indices\n",
        "          for i in range(results.shape[0]):\n",
        "            index = results[i, 1]\n",
        "            exemplar_k_index = tensors[index][0]\n",
        "            if exemplar_k_index not in exemplar_set_indices:\n",
        "              exemplar_k = tensors[index][1].unsqueeze(dim = 0) # take the image from the tuple (index, img, label)\n",
        "              exemplar_set.append((exemplar_k, label))\n",
        "              exemplar_k_index = tensors[index][0] # index of the img on the real dataset\n",
        "              \n",
        "              exemplar_list_indices.append(exemplar_k_index)\n",
        "              exemplar_set_indices.add(exemplar_k_index)\n",
        "              break\n",
        "\n",
        "          # features of the exemplar k\n",
        "          phi = feature_extractor(exemplar_k.to(self.DEVICE)) #feature_extractor(exemplar_k.to(self.DEVICE))\n",
        "          summon += phi # update sum of features\n",
        "    else:\n",
        "      tensors_size = len(tensors)\n",
        "      unique_random_indexes = random.sample(range(0, tensors_size), m) # random sample without replacement k exemplars\n",
        "      i = 0\n",
        "      for k in range(1, (m + 1)):\n",
        "        index = unique_random_indexes[i]\n",
        "        exemplar_k = tensors[index][1].unsqueeze(dim = 0)\n",
        "        exemplar_k_index = tensors[index][0]\n",
        "        exemplar_set.append((exemplar_k, label))\n",
        "        exemplar_set_indices.add(exemplar_k_index)\n",
        "        i = i + 1\n",
        "\n",
        "    # --- new ---\n",
        "    tensor_set = []\n",
        "    for i in range(0, len(tensors)):\n",
        "      t = tensors[i][1].unsqueeze(dim = 0)\n",
        "      tensor_set.append((t, label))\n",
        "    \n",
        "    self.exemplar_sets.append(exemplar_set) #update exemplar sets with the updated exemplars images\n",
        "    self.exemplar_sets_indices.append(exemplar_list_indices)\n",
        "\n",
        "    # this is used to compute more accurately the means of the exemplar (see also computeMeans and classify)\n",
        "    self.data_from_classes.append(tensor_set)\n",
        "\n",
        "    # cleaning\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "  # build a exemplar dataset as a subset of the train dataset\n",
        "  def build_exemplars_dataset(self, train_dataset): #complete train dataset\n",
        "    all_exemplars_indices = []\n",
        "    for exemplar_set_indices in self.exemplar_sets_indices:\n",
        "        all_exemplars_indices.extend(exemplar_set_indices)\n",
        "\n",
        "    exemplars_dataset = Subset(train_dataset, all_exemplars_indices)\n",
        "    return exemplars_dataset\n",
        "\n",
        "  def update_representation(self, dataset, train_dataset_big, new_classes):\n",
        "    # 1 - retrieve the classes from the dataset (which is the current train_subset)\n",
        "    # 2 - retrieve the new classes\n",
        "    # 1,2 are done in the main_icarl\n",
        "    #gc.collect()\n",
        "\n",
        "    # 3 - increment classes\n",
        "    #          (add output nodes)\n",
        "    #          (update n_classes)\n",
        "    # 5        store network outputs with pre-update parameters\n",
        "    self.increment_classes(len(new_classes))\n",
        "\n",
        "    # 4 - combine current train_subset (dataset) with exemplars\n",
        "    #     to form a new augmented train dataset\n",
        "    # join the datasets\n",
        "    exemplars_dataset = self.build_exemplars_dataset(train_dataset_big)\n",
        "    \n",
        "    ######################################################################################\n",
        "    new_classes_dataset=[]\n",
        "    if self.n_known==0:\n",
        "      cut=0\n",
        "    else:\n",
        "      cut=self.n_known/10\n",
        "    \n",
        "    new_dataset_size = 5000 - int(math.ceil(450*cut))\n",
        "    unique_random_indexes = random.sample(range(0, len(dataset)), new_dataset_size) # random sample without replacement\n",
        "\n",
        "    new_dataset=torch.utils.data.Subset(dataset, unique_random_indexes)\n",
        "    print(\"NEW CLASS SAMPLES: \",len(new_dataset))\n",
        "    ######################################################################################\n",
        "    #\n",
        "    if len(exemplars_dataset) > 0:\n",
        "      join_dataset = ConcatDataset(new_dataset, exemplars_dataset)\n",
        "      augmented_dataset = ConcatDataset(join_dataset, exemplars_dataset)\n",
        "      # load_exemplars = DataLoader(exemplars_dataset, batch_size=self.BATCH_SIZE,shuffle=False, num_workers=4)\n",
        "      # new_image=[]\n",
        "      # old_image=[]\n",
        "      # for _, images, labels in load_exemplars:\n",
        "      #   for img,lab in zip(images,labels):\n",
        "      #     tran=transforms.Compose([transforms.ToPILImage(),transforms.RandomHorizontalFlip(p=1),transforms.ToTensor()])\n",
        "      #     new_img=tran(img)\n",
        "      #     new_image.append((0,new_img,lab))\n",
        "      #     old_image.append((0,img,lab))\n",
        "      # new_join=new_dataset+old_image+new_image\n",
        "      # augmented_dataset=new_join\n",
        "      #augmented_dataset = ConcatDataset(dataset, exemplars_dataset)\n",
        "      #augmented_dataset = utils.joinSubsets(train_dataset_big, [dataset, exemplars_dataset])\n",
        "    else: \n",
        "      augmented_dataset = new_dataset # first iteration\n",
        "\n",
        "    print(\"ALL DB: \",len(augmented_dataset))\n",
        "    # 6 - run network training, with loss function\n",
        "\n",
        "    net = self.net\n",
        "\n",
        "    optimizer = optim.SGD(net.parameters(), lr=self.LR, weight_decay=self.WEIGHT_DECAY, momentum=self.MOMENTUM)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.MILESTONES, gamma=self.GAMMA, last_epoch=-1)\n",
        "\n",
        "    criterion = utils.getLossCriterion()\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    net = net.to(self.DEVICE)\n",
        "\n",
        "    # define the loader for the augmented_dataset\n",
        "    loader = DataLoader(augmented_dataset, batch_size=self.BATCH_SIZE,shuffle=True, num_workers=4, drop_last = True)\n",
        "\n",
        "    if len(self.exemplar_sets) > 0:\n",
        "      # QUA! #\n",
        "      #########################################################################################\n",
        "\n",
        "      #   print(self.oldNetTeachers[1].size())\n",
        "      if self.oldNet!=None:\n",
        "        self.moreOldNet=self.oldNet\n",
        "      self.oldNet= copy.deepcopy(net)\n",
        "\n",
        "      #########################################################################################\n",
        "    for epoch in range(self.NUM_EPOCHS):\n",
        "        print(\"NUM_EPOCHS: \",epoch,\"/\", self.NUM_EPOCHS,\" LR: \",scheduler.get_lr())\n",
        "        for _, images, labels in loader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(self.DEVICE)\n",
        "            labels = labels.to(self.DEVICE)\n",
        "            net.train()\n",
        "            # PyTorch, by default, accumulates gradients after each backward pass\n",
        "            # We need to manually set the gradients to zero before starting a new iteration\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "            \n",
        " \n",
        "            # QUA! #\n",
        "            #############################################################################################################\n",
        "            # Forward pass to the network\n",
        "            outputs = net(images)\n",
        "            # Loss = only classification on new classes\n",
        "            loss = self.class_loss(outputs, labels, col_start=self.n_known)\n",
        "            class_loss = loss.item() # Used for logging for debugging purposes\n",
        "            \n",
        "            # Distilation loss for old classes, class loss on new classes\n",
        "            dist_loss = None\n",
        "            older_dist_loss=None\n",
        "            if len(self.exemplar_sets) > 0:\n",
        "              old_net=self.oldNet\n",
        "              out_old = torch.sigmoid(old_net(images))\n",
        "              dist_loss = self.dist_loss(outputs, out_old, col_end=self.n_known)\n",
        "\n",
        "              if self.moreOldNet!=None:\n",
        "                older_net=self.moreOldNet # old old net\n",
        "                older_out = torch.sigmoid(older_net(images))\n",
        "                older_dist_loss = self.double_dist_loss(outputs[0:128,0:-20], older_out[0:128,0:-10], col_end=self.n_known)\n",
        "                loss += older_dist_loss\n",
        "\n",
        "              loss += dist_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            ##############################################################################################################\n",
        "\n",
        "        scheduler.step()\n",
        "        print(\"LOSS: \", loss.item(), 'class loss', class_loss, 'dist loss', dist_loss.item() if dist_loss is not None else dist_loss, 'older dist loss',older_dist_loss.item() if older_dist_loss is not None else older_dist_loss)\n",
        "\n",
        "    self.net = copy.deepcopy(net)\n",
        "    self.feature_extractor = copy.deepcopy(net)\n",
        "    self.feature_extractor.fc = nn.Sequential()\n",
        "\n",
        "    #cleaning\n",
        "    del net\n",
        "    torch.cuda.empty_cache()\n",
        " # QUA! #\n",
        " ###################################################################################################################\n",
        "  def double_dist_loss(self,outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    rebalancing=None\n",
        "    rebalancing = get_rebalancing(rebalancing)\n",
        "    dist_loss_func = self.bce_dist_loss\n",
        "    alpha = rebalancing(self.n_known, self.n_classes, 'dist')\n",
        "    return 0.5*alpha*dist_loss_func(outputs, labels, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        " ##################################################################################################################\n",
        "\n",
        "  def build_loss(self, class_loss_criterion, dist_loss_criterion, rebalancing=None, lambda0=1):\n",
        "    class_loss_func = None\n",
        "    dist_loss_func = None\n",
        "\n",
        "    if class_loss_criterion in ['l2', 'L2']:\n",
        "      class_loss_func = self.l2_class_loss\n",
        "    elif class_loss_criterion in ['bce', 'BCE']:\n",
        "      class_loss_func = self.bce_class_loss\n",
        "    elif class_loss_criterion in ['ce', 'CE']:\n",
        "      class_loss_func = self.ce_class_loss\n",
        "\n",
        "    if dist_loss_criterion in ['l2', 'L2']:\n",
        "      dist_loss_func = self.l2_dist_loss\n",
        "    elif dist_loss_criterion in ['bce', 'BCE']:\n",
        "      dist_loss_func = self.bce_dist_loss\n",
        "    elif dist_loss_criterion in ['ce', 'CE']:\n",
        "      dist_loss_func = self.ce_dist_loss\n",
        "\n",
        "    rebalancing = get_rebalancing(rebalancing)\n",
        "    \n",
        "    def class_loss(outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "      alpha = rebalancing(self.n_known, self.n_classes, 'class')\n",
        "      return alpha*class_loss_func(outputs, labels, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "    \n",
        "    def dist_loss(outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "      alpha = rebalancing(self.n_known, self.n_classes, 'dist')\n",
        "      return lambda0*alpha*dist_loss_func(outputs, labels, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "    \n",
        "    return class_loss, dist_loss\n",
        "\n",
        "  def bce_class_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.bce_loss(outputs, labels, encode=True, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def bce_dist_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.bce_loss(outputs, labels, encode=False, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def ce_class_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.ce_loss(outputs, self.reverse_index.getNodes(labels), decode=False, row_start=row_start, row_end=row_end, col_start=None, col_end=col_end)\n",
        "    \n",
        "  def ce_dist_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.ce_loss(outputs, labels, decode=True, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def l2_class_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.l2_loss(outputs, labels, encode=True, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "  def l2_dist_loss(self, outputs, labels, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    return self.l2_loss(outputs, labels, encode=False, row_start=row_start, row_end=row_end, col_start=col_start, col_end=col_end)\n",
        "\n",
        "\n",
        "  def bce_loss(self, outputs, labels, encode=False, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction = 'mean')\n",
        "\n",
        "    if encode:\n",
        "      labels = utils._one_hot_encode(labels, self.n_classes, self.reverse_index, device=self.DEVICE)\n",
        "      labels = labels.type_as(outputs)\n",
        "\n",
        "    return criterion(outputs[row_start:row_end, col_start:col_end], labels[row_start:row_end, col_start:col_end])\n",
        "\n",
        "\n",
        "  def ce_loss(self, outputs, labels, decode=False, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if decode:\n",
        "      labels = torch.argmax(labels, dim=1)\n",
        "    \n",
        "    return criterion(outputs[row_start:row_end, col_start:col_end], labels[row_start:row_end])\n",
        "\n",
        "\n",
        "  def l2_loss(self, outputs, labels, encode=False, row_start=None, row_end=None, col_start=None, col_end=None):\n",
        "    criterion = nn.MSELoss(reduction = 'mean')\n",
        "    \n",
        "    if encode:\n",
        "      labels = utils._one_hot_encode(labels, self.n_classes, self.reverse_index, device=self.DEVICE)\n",
        "      labels = labels.type_as(outputs)\n",
        "    \n",
        "    return criterion(outputs[row_start:row_end, col_start:col_end], labels[row_start:row_end, col_start:col_end])\n",
        "\n",
        "\n",
        "  # implementation of alg. 5 of icarl paper\n",
        "  # iCaRL ReduceExemplarSet\n",
        "  def reduce_exemplar_sets(self, m):\n",
        "  \t    # i keep only the first m exemplar images\n",
        "        # where m is the UPDATED K/number_classes_seen\n",
        "        # the number of images per each exemplar set (class) progressively decreases\n",
        "        for y, P_y in enumerate(self.exemplar_sets):\n",
        "            self.exemplar_sets[y] = P_y[:m] \n",
        "        for x, P_x in enumerate(self.exemplar_sets_indices):\n",
        "            self.exemplar_sets_indices[x] = P_x[:m] \n",
        "\n",
        "\n",
        "# ---------- \n",
        "from torch.utils.data import Dataset\n",
        "\"\"\"\n",
        "  Merge two different datasets (train and exemplars in our case)\n",
        "  format:\n",
        "  train\n",
        "  --------\n",
        "  exemplars\n",
        "  train leans on cifar100\n",
        "  exemplars is managed here (exemplar_transform is performed) => changed\n",
        "\"\"\"\n",
        "class ConcatDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataset1, dataset2):\n",
        "        self.dataset1 = dataset1\n",
        "        self.dataset2 = dataset2\n",
        "        self.l1 = len(dataset1)\n",
        "        self.l2 = len(dataset2)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        if index < self.l1:\n",
        "            _, image,label = self.dataset1[index] #here it leans on cifar100 get item\n",
        "            return _, image,label\n",
        "        else:\n",
        "            _, image, label = self.dataset2[index - self.l1]\n",
        "            return _, image,label\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.l1 + self.l2)\n",
        "#------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axANZYKXg6wn",
        "colab_type": "text"
      },
      "source": [
        "**Exemplars management**<br>\n",
        "From iCaRL. We have an exemplar set for each class that we have seen so far. The cardinality of each exemplar set is constant and it is equal, at any time, to m = K/t. Where K is a constraint equal to the amount of memory we're allocating for the exemplars and t is the number of classes that has been seen so far. Implementing iCaRL, whenever a group of (10) classes is trained, it is trained on the train data for those classes (as before) + the current exemplars sets.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx0Woq8uhXyR",
        "colab_type": "code",
        "outputId": "d9d09466-9f79-4686-aa91-fb549e324844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from Cifar100.icarl_model import ICaRL\n",
        "\n",
        "# default params\n",
        "\n",
        "K = 2000\n",
        "n_classes = 0\n",
        "feature_size = 2048\n",
        "\n",
        "icarl = ICaRL(feature_size, n_classes, BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE,MILESTONES,MOMENTUM, K, herding, outputs_labels_mapping)\n",
        "icarl.cuda() "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ICaRL(\n",
              "  (net): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=64, out_features=0, bias=True)\n",
              "  )\n",
              "  (feature_extractor): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Sequential()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmxtCL8AvYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66542107-be9a-4f7c-f61f-93db82d4b71f"
      },
      "source": [
        "accuracies, all_preds_cm, all_labels_cm = incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, outputs_labels_mapping, K)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "NEW CLASS SAMPLES:  5000\n",
            "ALL DB:  5000\n",
            "NUM_EPOCHS:  0 / 70  LR:  [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LOSS:  0.3253365457057953 class loss 0.3253365457057953 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  1 / 70  LR:  [2]\n",
            "LOSS:  0.31441187858581543 class loss 0.31441187858581543 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  2 / 70  LR:  [2]\n",
            "LOSS:  0.30115795135498047 class loss 0.30115795135498047 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  3 / 70  LR:  [2]\n",
            "LOSS:  0.3022465705871582 class loss 0.3022465705871582 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  4 / 70  LR:  [2]\n",
            "LOSS:  0.2955527901649475 class loss 0.2955527901649475 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  5 / 70  LR:  [2]\n",
            "LOSS:  0.28310737013816833 class loss 0.28310737013816833 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  6 / 70  LR:  [2]\n",
            "LOSS:  0.2789652943611145 class loss 0.2789652943611145 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  7 / 70  LR:  [2]\n",
            "LOSS:  0.28627118468284607 class loss 0.28627118468284607 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  8 / 70  LR:  [2]\n",
            "LOSS:  0.2745454013347626 class loss 0.2745454013347626 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  9 / 70  LR:  [2]\n",
            "LOSS:  0.2817414700984955 class loss 0.2817414700984955 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  10 / 70  LR:  [2]\n",
            "LOSS:  0.26931363344192505 class loss 0.26931363344192505 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  11 / 70  LR:  [2]\n",
            "LOSS:  0.2540307939052582 class loss 0.2540307939052582 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  12 / 70  LR:  [2]\n",
            "LOSS:  0.24941043555736542 class loss 0.24941043555736542 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  13 / 70  LR:  [2]\n",
            "LOSS:  0.23474498093128204 class loss 0.23474498093128204 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  14 / 70  LR:  [2]\n",
            "LOSS:  0.24673156440258026 class loss 0.24673156440258026 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  15 / 70  LR:  [2]\n",
            "LOSS:  0.25007811188697815 class loss 0.25007811188697815 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  16 / 70  LR:  [2]\n",
            "LOSS:  0.23473607003688812 class loss 0.23473607003688812 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  17 / 70  LR:  [2]\n",
            "LOSS:  0.21185517311096191 class loss 0.21185517311096191 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  18 / 70  LR:  [2]\n",
            "LOSS:  0.26025840640068054 class loss 0.26025840640068054 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  19 / 70  LR:  [2]\n",
            "LOSS:  0.24321363866329193 class loss 0.24321363866329193 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  20 / 70  LR:  [2]\n",
            "LOSS:  0.2182299941778183 class loss 0.2182299941778183 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  21 / 70  LR:  [2]\n",
            "LOSS:  0.22511616349220276 class loss 0.22511616349220276 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  22 / 70  LR:  [2]\n",
            "LOSS:  0.22424231469631195 class loss 0.22424231469631195 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  23 / 70  LR:  [2]\n",
            "LOSS:  0.23192457854747772 class loss 0.23192457854747772 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  24 / 70  LR:  [2]\n",
            "LOSS:  0.241392120718956 class loss 0.241392120718956 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  25 / 70  LR:  [2]\n",
            "LOSS:  0.20548568665981293 class loss 0.20548568665981293 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  26 / 70  LR:  [2]\n",
            "LOSS:  0.2018163502216339 class loss 0.2018163502216339 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  27 / 70  LR:  [2]\n",
            "LOSS:  0.2150849848985672 class loss 0.2150849848985672 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  28 / 70  LR:  [2]\n",
            "LOSS:  0.1871984302997589 class loss 0.1871984302997589 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  29 / 70  LR:  [2]\n",
            "LOSS:  0.2012230008840561 class loss 0.2012230008840561 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  30 / 70  LR:  [2]\n",
            "LOSS:  0.1923293024301529 class loss 0.1923293024301529 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  31 / 70  LR:  [2]\n",
            "LOSS:  0.1926116794347763 class loss 0.1926116794347763 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  32 / 70  LR:  [2]\n",
            "LOSS:  0.18029756844043732 class loss 0.18029756844043732 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  33 / 70  LR:  [2]\n",
            "LOSS:  0.18984663486480713 class loss 0.18984663486480713 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  34 / 70  LR:  [2]\n",
            "LOSS:  0.17924648523330688 class loss 0.17924648523330688 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  35 / 70  LR:  [2]\n",
            "LOSS:  0.18053507804870605 class loss 0.18053507804870605 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  36 / 70  LR:  [2]\n",
            "LOSS:  0.15527263283729553 class loss 0.15527263283729553 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  37 / 70  LR:  [2]\n",
            "LOSS:  0.15664251148700714 class loss 0.15664251148700714 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  38 / 70  LR:  [2]\n",
            "LOSS:  0.18460504710674286 class loss 0.18460504710674286 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  39 / 70  LR:  [2]\n",
            "LOSS:  0.15253469347953796 class loss 0.15253469347953796 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  40 / 70  LR:  [2]\n",
            "LOSS:  0.16459670662879944 class loss 0.16459670662879944 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  41 / 70  LR:  [2]\n",
            "LOSS:  0.16698098182678223 class loss 0.16698098182678223 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  42 / 70  LR:  [2]\n",
            "LOSS:  0.14536269009113312 class loss 0.14536269009113312 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  43 / 70  LR:  [2]\n",
            "LOSS:  0.1406853049993515 class loss 0.1406853049993515 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  44 / 70  LR:  [2]\n",
            "LOSS:  0.12941040098667145 class loss 0.12941040098667145 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  45 / 70  LR:  [2]\n",
            "LOSS:  0.12485182285308838 class loss 0.12485182285308838 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  46 / 70  LR:  [2]\n",
            "LOSS:  0.1114787831902504 class loss 0.1114787831902504 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  47 / 70  LR:  [2]\n",
            "LOSS:  0.12231869995594025 class loss 0.12231869995594025 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  48 / 70  LR:  [2]\n",
            "LOSS:  0.09500499814748764 class loss 0.09500499814748764 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  49 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.0935782715678215 class loss 0.0935782715678215 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  50 / 70  LR:  [0.4]\n",
            "LOSS:  0.08764960616827011 class loss 0.08764960616827011 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  51 / 70  LR:  [0.4]\n",
            "LOSS:  0.08060353249311447 class loss 0.08060353249311447 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  52 / 70  LR:  [0.4]\n",
            "LOSS:  0.05238943174481392 class loss 0.05238943174481392 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  53 / 70  LR:  [0.4]\n",
            "LOSS:  0.07672970741987228 class loss 0.07672970741987228 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  54 / 70  LR:  [0.4]\n",
            "LOSS:  0.10593869537115097 class loss 0.10593869537115097 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  55 / 70  LR:  [0.4]\n",
            "LOSS:  0.09086107462644577 class loss 0.09086107462644577 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  56 / 70  LR:  [0.4]\n",
            "LOSS:  0.08920919895172119 class loss 0.08920919895172119 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  57 / 70  LR:  [0.4]\n",
            "LOSS:  0.07385320216417313 class loss 0.07385320216417313 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  58 / 70  LR:  [0.4]\n",
            "LOSS:  0.07128347456455231 class loss 0.07128347456455231 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  59 / 70  LR:  [0.4]\n",
            "LOSS:  0.08251484483480453 class loss 0.08251484483480453 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  60 / 70  LR:  [0.4]\n",
            "LOSS:  0.0603284053504467 class loss 0.0603284053504467 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  61 / 70  LR:  [0.4]\n",
            "LOSS:  0.05236006900668144 class loss 0.05236006900668144 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  62 / 70  LR:  [0.4]\n",
            "LOSS:  0.06244185194373131 class loss 0.06244185194373131 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  63 / 70  LR:  [0.016000000000000004]\n",
            "LOSS:  0.07056808471679688 class loss 0.07056808471679688 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  64 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.05564258247613907 class loss 0.05564258247613907 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  65 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.05851191282272339 class loss 0.05851191282272339 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  66 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.06055488809943199 class loss 0.06055488809943199 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  67 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.050142716616392136 class loss 0.050142716616392136 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  68 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.06044137105345726 class loss 0.06044137105345726 dist loss None older dist loss None\n",
            "NUM_EPOCHS:  69 / 70  LR:  [0.08000000000000002]\n",
            "LOSS:  0.037571292370557785 class loss 0.037571292370557785 dist loss None older dist loss None\n",
            "Reducing each exemplar set to size: 200\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 92.22\n",
            "\n",
            "Test Accuracy (all groups seen so far): 80.30\n",
            "\n",
            "the model knows 10 classes:\n",
            " \n",
            "GROUP:  2\n",
            "NEW CLASS SAMPLES:  4550\n",
            "ALL DB:  8550\n",
            "NUM_EPOCHS:  0 / 70  LR:  [2]\n",
            "LOSS:  0.12952087819576263 class loss 0.08010406047105789 dist loss 0.049416813999414444 older dist loss None\n",
            "NUM_EPOCHS:  1 / 70  LR:  [2]\n",
            "LOSS:  0.13082729279994965 class loss 0.07304295152425766 dist loss 0.05778433755040169 older dist loss None\n",
            "NUM_EPOCHS:  2 / 70  LR:  [2]\n",
            "LOSS:  0.1258857101202011 class loss 0.06906049698591232 dist loss 0.05682520940899849 older dist loss None\n",
            "NUM_EPOCHS:  3 / 70  LR:  [2]\n",
            "LOSS:  0.12293344736099243 class loss 0.06635387241840363 dist loss 0.056579578667879105 older dist loss None\n",
            "NUM_EPOCHS:  4 / 70  LR:  [2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_B01Oa82wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if herding:\n",
        "  method = 'iCaRL_{}_herding'.format(classifier)\n",
        "else:\n",
        "  method = 'iCaRL_{}_random'.format(classifier)\n",
        "\n",
        "print(\"metrics iCaRL for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "# accuracy \n",
        "data_plot_line=[]\n",
        "\n",
        "classes_per_group = 10\n",
        "for group_classes in range(0,10):\n",
        "    data_plot_line.append(((group_classes + 1)*classes_per_group, accuracies[group_classes]))\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write to JSON file\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtGxWw4fyzyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}