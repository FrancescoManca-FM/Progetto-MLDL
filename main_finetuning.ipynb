{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/clean/main_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j40FSXGxD2VD",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudv9Cj8E8OI",
        "colab_type": "code",
        "outputId": "f35bce1c-2eee-4faf-8c3f-8dbc67d83de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dC-rYdjD-E3",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru",
        "colab_type": "code",
        "outputId": "dccc22eb-275c-4e74-da61-749057de11c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lf-WK3hEJCM",
        "colab_type": "text"
      },
      "source": [
        "**Retrieving dataset CIFAR1000**<br>\n",
        "The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. There are 500 training images and 100 testing images per class.\n",
        "The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "Here is an example of classes in the CIFAR-100:<br>\n",
        "**Superclass**\t\n",
        "- aquatic mammals\t\n",
        "\n",
        "**Classes**\n",
        "- beaver, dolphin, otter, seal, whale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1do9ln3OVE",
        "colab_type": "code",
        "outputId": "ffc64704-99e7-4b10-85df-b50b2c72dbcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone -b clean https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/109)\u001b[K\rremote: Counting objects:   1% (2/109)\u001b[K\rremote: Counting objects:   2% (3/109)\u001b[K\rremote: Counting objects:   3% (4/109)\u001b[K\rremote: Counting objects:   4% (5/109)\u001b[K\rremote: Counting objects:   5% (6/109)\u001b[K\rremote: Counting objects:   6% (7/109)\u001b[K\rremote: Counting objects:   7% (8/109)\u001b[K\rremote: Counting objects:   8% (9/109)\u001b[K\rremote: Counting objects:   9% (10/109)\u001b[K\rremote: Counting objects:  10% (11/109)\u001b[K\rremote: Counting objects:  11% (12/109)\u001b[K\rremote: Counting objects:  12% (14/109)\u001b[K\rremote: Counting objects:  13% (15/109)\u001b[K\rremote: Counting objects:  14% (16/109)\u001b[K\rremote: Counting objects:  15% (17/109)\u001b[K\rremote: Counting objects:  16% (18/109)\u001b[K\rremote: Counting objects:  17% (19/109)\u001b[K\rremote: Counting objects:  18% (20/109)\u001b[K\rremote: Counting objects:  19% (21/109)\u001b[K\rremote: Counting objects:  20% (22/109)\u001b[K\rremote: Counting objects:  21% (23/109)\u001b[K\rremote: Counting objects:  22% (24/109)\u001b[K\rremote: Counting objects:  23% (26/109)\u001b[K\rremote: Counting objects:  24% (27/109)\u001b[K\rremote: Counting objects:  25% (28/109)\u001b[K\rremote: Counting objects:  26% (29/109)\u001b[K\rremote: Counting objects:  27% (30/109)\u001b[K\rremote: Counting objects:  28% (31/109)\u001b[K\rremote: Counting objects:  29% (32/109)\u001b[K\rremote: Counting objects:  30% (33/109)\u001b[K\rremote: Counting objects:  31% (34/109)\u001b[K\rremote: Counting objects:  32% (35/109)\u001b[K\rremote: Counting objects:  33% (36/109)\u001b[K\rremote: Counting objects:  34% (38/109)\u001b[K\rremote: Counting objects:  35% (39/109)\u001b[K\rremote: Counting objects:  36% (40/109)\u001b[K\rremote: Counting objects:  37% (41/109)\u001b[K\rremote: Counting objects:  38% (42/109)\u001b[K\rremote: Counting objects:  39% (43/109)\u001b[K\rremote: Counting objects:  40% (44/109)\u001b[K\rremote: Counting objects:  41% (45/109)\u001b[K\rremote: Counting objects:  42% (46/109)\u001b[K\rremote: Counting objects:  43% (47/109)\u001b[K\rremote: Counting objects:  44% (48/109)\u001b[K\rremote: Counting objects:  45% (50/109)\u001b[K\rremote: Counting objects:  46% (51/109)\u001b[K\rremote: Counting objects:  47% (52/109)\u001b[K\rremote: Counting objects:  48% (53/109)\u001b[K\rremote: Counting objects:  49% (54/109)\u001b[K\rremote: Counting objects:  50% (55/109)\u001b[K\rremote: Counting objects:  51% (56/109)\u001b[K\rremote: Counting objects:  52% (57/109)\u001b[K\rremote: Counting objects:  53% (58/109)\u001b[K\rremote: Counting objects:  54% (59/109)\u001b[K\rremote: Counting objects:  55% (60/109)\u001b[K\rremote: Counting objects:  56% (62/109)\u001b[K\rremote: Counting objects:  57% (63/109)\u001b[K\rremote: Counting objects:  58% (64/109)\u001b[K\rremote: Counting objects:  59% (65/109)\u001b[K\rremote: Counting objects:  60% (66/109)\u001b[K\rremote: Counting objects:  61% (67/109)\u001b[K\rremote: Counting objects:  62% (68/109)\u001b[K\rremote: Counting objects:  63% (69/109)\u001b[K\rremote: Counting objects:  64% (70/109)\u001b[K\rremote: Counting objects:  65% (71/109)\u001b[K\rremote: Counting objects:  66% (72/109)\u001b[K\rremote: Counting objects:  67% (74/109)\u001b[K\rremote: Counting objects:  68% (75/109)\u001b[K\rremote: Counting objects:  69% (76/109)\u001b[K\rremote: Counting objects:  70% (77/109)\u001b[K\rremote: Counting objects:  71% (78/109)\u001b[K\rremote: Counting objects:  72% (79/109)\u001b[K\rremote: Counting objects:  73% (80/109)\u001b[K\rremote: Counting objects:  74% (81/109)\u001b[K\rremote: Counting objects:  75% (82/109)\u001b[K\rremote: Counting objects:  76% (83/109)\u001b[K\rremote: Counting objects:  77% (84/109)\u001b[K\rremote: Counting objects:  78% (86/109)\u001b[K\rremote: Counting objects:  79% (87/109)\u001b[K\rremote: Counting objects:  80% (88/109)\u001b[K\rremote: Counting objects:  81% (89/109)\u001b[K\rremote: Counting objects:  82% (90/109)\u001b[K\rremote: Counting objects:  83% (91/109)\u001b[K\rremote: Counting objects:  84% (92/109)\u001b[K\rremote: Counting objects:  85% (93/109)\u001b[K\rremote: Counting objects:  86% (94/109)\u001b[K\rremote: Counting objects:  87% (95/109)\u001b[K\rremote: Counting objects:  88% (96/109)\u001b[K\rremote: Counting objects:  89% (98/109)\u001b[K\rremote: Counting objects:  90% (99/109)\u001b[K\rremote: Counting objects:  91% (100/109)\u001b[K\rremote: Counting objects:  92% (101/109)\u001b[K\rremote: Counting objects:  93% (102/109)\u001b[K\rremote: Counting objects:  94% (103/109)\u001b[K\rremote: Counting objects:  95% (104/109)\u001b[K\rremote: Counting objects:  96% (105/109)\u001b[K\rremote: Counting objects:  97% (106/109)\u001b[K\rremote: Counting objects:  98% (107/109)\u001b[K\rremote: Counting objects:  99% (108/109)\u001b[K\rremote: Counting objects: 100% (109/109)\u001b[K\rremote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/74)\u001b[K\rremote: Compressing objects:   2% (2/74)\u001b[K\rremote: Compressing objects:   4% (3/74)\u001b[K\rremote: Compressing objects:   5% (4/74)\u001b[K\rremote: Compressing objects:   6% (5/74)\u001b[K\rremote: Compressing objects:   8% (6/74)\u001b[K\rremote: Compressing objects:   9% (7/74)\u001b[K\rremote: Compressing objects:  10% (8/74)\u001b[K\rremote: Compressing objects:  12% (9/74)\u001b[K\rremote: Compressing objects:  13% (10/74)\u001b[K\rremote: Compressing objects:  14% (11/74)\u001b[K\rremote: Compressing objects:  16% (12/74)\u001b[K\rremote: Compressing objects:  17% (13/74)\u001b[K\rremote: Compressing objects:  18% (14/74)\u001b[K\rremote: Compressing objects:  20% (15/74)\u001b[K\rremote: Compressing objects:  21% (16/74)\u001b[K\rremote: Compressing objects:  22% (17/74)\u001b[K\rremote: Compressing objects:  24% (18/74)\u001b[K\rremote: Compressing objects:  25% (19/74)\u001b[K\rremote: Compressing objects:  27% (20/74)\u001b[K\rremote: Compressing objects:  28% (21/74)\u001b[K\rremote: Compressing objects:  29% (22/74)\u001b[K\rremote: Compressing objects:  31% (23/74)\u001b[K\rremote: Compressing objects:  32% (24/74)\u001b[K\rremote: Compressing objects:  33% (25/74)\u001b[K\rremote: Compressing objects:  35% (26/74)\u001b[K\rremote: Compressing objects:  36% (27/74)\u001b[K\rremote: Compressing objects:  37% (28/74)\u001b[K\rremote: Compressing objects:  39% (29/74)\u001b[K\rremote: Compressing objects:  40% (30/74)\u001b[K\rremote: Compressing objects:  41% (31/74)\u001b[K\rremote: Compressing objects:  43% (32/74)\u001b[K\rremote: Compressing objects:  44% (33/74)\u001b[K\rremote: Compressing objects:  45% (34/74)\u001b[K\rremote: Compressing objects:  47% (35/74)\u001b[K\rremote: Compressing objects:  48% (36/74)\u001b[K\rremote: Compressing objects:  50% (37/74)\u001b[K\rremote: Compressing objects:  51% (38/74)\u001b[K\rremote: Compressing objects:  52% (39/74)\u001b[K\rremote: Compressing objects:  54% (40/74)\u001b[K\rremote: Compressing objects:  55% (41/74)\u001b[K\rremote: Compressing objects:  56% (42/74)\u001b[K\rremote: Compressing objects:  58% (43/74)\u001b[K\rremote: Compressing objects:  59% (44/74)\u001b[K\rremote: Compressing objects:  60% (45/74)\u001b[K\rremote: Compressing objects:  62% (46/74)\u001b[K\rremote: Compressing objects:  63% (47/74)\u001b[K\rremote: Compressing objects:  64% (48/74)\u001b[K\rremote: Compressing objects:  66% (49/74)\u001b[K\rremote: Compressing objects:  67% (50/74)\u001b[K\rremote: Compressing objects:  68% (51/74)\u001b[K\rremote: Compressing objects:  70% (52/74)\u001b[K\rremote: Compressing objects:  71% (53/74)\u001b[K\rremote: Compressing objects:  72% (54/74)\u001b[K\rremote: Compressing objects:  74% (55/74)\u001b[K\rremote: Compressing objects:  75% (56/74)\u001b[K\rremote: Compressing objects:  77% (57/74)\u001b[K\rremote: Compressing objects:  78% (58/74)\u001b[K\rremote: Compressing objects:  79% (59/74)\u001b[K\rremote: Compressing objects:  81% (60/74)\u001b[K\rremote: Compressing objects:  82% (61/74)\u001b[K\rremote: Compressing objects:  83% (62/74)\u001b[K\rremote: Compressing objects:  85% (63/74)\u001b[K\rremote: Compressing objects:  86% (64/74)\u001b[K\rremote: Compressing objects:  87% (65/74)\u001b[K\rremote: Compressing objects:  89% (66/74)\u001b[K\rremote: Compressing objects:  90% (67/74)\u001b[K\rremote: Compressing objects:  91% (68/74)\u001b[K\rremote: Compressing objects:  93% (69/74)\u001b[K\rremote: Compressing objects:  94% (70/74)\u001b[K\rremote: Compressing objects:  95% (71/74)\u001b[K\rremote: Compressing objects:  97% (72/74)\u001b[K\rremote: Compressing objects:  98% (73/74)\u001b[K\rremote: Compressing objects: 100% (74/74)\u001b[K\rremote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "Receiving objects:   0% (1/378)   \rReceiving objects:   1% (4/378)   \rReceiving objects:   2% (8/378)   \rReceiving objects:   3% (12/378)   \rReceiving objects:   4% (16/378)   \rReceiving objects:   5% (19/378)   \rReceiving objects:   6% (23/378)   \rReceiving objects:   7% (27/378)   \rReceiving objects:   8% (31/378)   \rReceiving objects:   9% (35/378)   \rReceiving objects:  10% (38/378)   \rReceiving objects:  11% (42/378)   \rReceiving objects:  12% (46/378)   \rReceiving objects:  13% (50/378)   \rReceiving objects:  14% (53/378)   \rReceiving objects:  15% (57/378)   \rReceiving objects:  16% (61/378)   \rReceiving objects:  17% (65/378)   \rReceiving objects:  18% (69/378)   \rReceiving objects:  19% (72/378)   \rReceiving objects:  20% (76/378)   \rReceiving objects:  21% (80/378)   \rReceiving objects:  22% (84/378)   \rReceiving objects:  23% (87/378)   \rReceiving objects:  24% (91/378)   \rReceiving objects:  25% (95/378)   \rReceiving objects:  26% (99/378)   \rReceiving objects:  27% (103/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  28% (106/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  29% (110/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  30% (114/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  31% (118/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  32% (121/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  33% (125/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  34% (129/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  35% (133/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  36% (137/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  37% (140/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  38% (144/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  39% (148/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  40% (152/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  41% (155/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  42% (159/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  43% (163/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  44% (167/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  45% (171/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  46% (174/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  47% (178/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  48% (182/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  49% (186/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  50% (189/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  51% (193/378), 2.01 MiB | 3.96 MiB/s   \rremote: Total 378 (delta 66), reused 71 (delta 34), pack-reused 269\u001b[K\n",
            "Receiving objects:  52% (197/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  53% (201/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  54% (205/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  55% (208/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  56% (212/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  57% (216/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  58% (220/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  59% (224/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  60% (227/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  61% (231/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  62% (235/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  63% (239/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  64% (242/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  65% (246/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  66% (250/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  67% (254/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  68% (258/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  69% (261/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  70% (265/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  71% (269/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  72% (273/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  73% (276/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  74% (280/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  75% (284/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  76% (288/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  77% (292/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  78% (295/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  79% (299/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  80% (303/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  81% (307/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  82% (310/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  83% (314/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  84% (318/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  85% (322/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  86% (326/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  87% (329/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  88% (333/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  89% (337/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  90% (341/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  91% (344/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  92% (348/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  93% (352/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  94% (356/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  95% (360/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  96% (363/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  97% (367/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  98% (371/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects:  99% (375/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects: 100% (378/378), 2.01 MiB | 3.96 MiB/s   \rReceiving objects: 100% (378/378), 3.76 MiB | 6.77 MiB/s, done.\n",
            "Resolving deltas:   0% (0/202)   \rResolving deltas:   5% (12/202)   \rResolving deltas:   6% (13/202)   \rResolving deltas:  13% (28/202)   \rResolving deltas:  14% (30/202)   \rResolving deltas:  15% (32/202)   \rResolving deltas:  17% (36/202)   \rResolving deltas:  18% (37/202)   \rResolving deltas:  20% (42/202)   \rResolving deltas:  33% (67/202)   \rResolving deltas:  37% (75/202)   \rResolving deltas:  40% (82/202)   \rResolving deltas:  49% (99/202)   \rResolving deltas:  57% (116/202)   \rResolving deltas:  59% (120/202)   \rResolving deltas:  61% (125/202)   \rResolving deltas:  62% (127/202)   \rResolving deltas:  63% (128/202)   \rResolving deltas:  80% (163/202)   \rResolving deltas:  90% (183/202)   \rResolving deltas:  98% (198/202)   \rResolving deltas: 100% (202/202)   \rResolving deltas: 100% (202/202), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab_type": "code",
        "outputId": "23e31d9f-98d7-4f63-d035-376a1cbef693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-25 19:59:24--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  32.0MB/s    in 5.7s    \n",
            "\n",
            "2020-05-25 19:59:30 (28.4 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XOn3bHMEBzX",
        "colab_type": "text"
      },
      "source": [
        "**Set arguments** - \n",
        "src: iCaRL section 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-pqSNg4_Ris",
        "colab_type": "code",
        "outputId": "b6244d55-c938-4029-dd2e-120259285a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from Cifar100 import utils\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 30, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oJ5m4V-ERDh",
        "colab_type": "text"
      },
      "source": [
        "**Define data preprocessing**<br>\n",
        "This transformations are applied to each images when they're loaded into the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_jHycn_1kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransfomrations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7EVuDrcJj2N"
      },
      "source": [
        "**Prepare dataset**<br>\n",
        "Loading of the train and test split as it comes with CIFAR100. <br>\n",
        "The trainset consists in 50k images, while the test set len is 10k images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJKwvGljJj2T",
        "outputId": "a7ddbf50-e219-4bb6-fb38-92fe0991f567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ckn3H69iJj2X",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLmmQn7JOLc",
        "colab_type": "text"
      },
      "source": [
        "**Build dataset splits and reverse index**<br>\n",
        "Here the train dataset is split into train and validation set, following the proportion XX/YY.<br>\n",
        "Furthermore train, test and validation sets are splitted into 10 groups containing 10 classes each (the split is coherent among the different sets).<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=30)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fov9YAFTlj",
        "colab_type": "text"
      },
      "source": [
        "**Prepare dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn",
        "colab_type": "code",
        "outputId": "9bda1913-f0b7-40df-d8e6-93f834ca4fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)\n",
        "\n",
        "# [ DEBUG ]\n",
        "# test to check classes in different dataset\n",
        "# (coherent split)\n",
        "# RESULT: OK\n",
        "\"\"\"dict_train={}\n",
        "for img_train in train_subsets[0]:\n",
        "  if img_train[1] not in dict_train:\n",
        "    dict_train[img_train[1]]=1\n",
        "  else:\n",
        "    dict_train[img_train[1]]+=1\n",
        "dict_val={}\n",
        "for img_val in val_subsets[0]:\n",
        "  if img_val[1] not in dict_val:\n",
        "    dict_val[img_val[1]]=1\n",
        "  else:\n",
        "    dict_val[img_val[1]]+=1\n",
        "dict_test={}\n",
        "for img_test in test_subsets[0]:\n",
        "  if img_test[1] not in dict_test:\n",
        "    dict_test[img_test[1]]=1\n",
        "  else:\n",
        "    dict_test[img_test[1]]+=1\n",
        "\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dict_train={}\\nfor img_train in train_subsets[0]:\\n  if img_train[1] not in dict_train:\\n    dict_train[img_train[1]]=1\\n  else:\\n    dict_train[img_train[1]]+=1\\ndict_val={}\\nfor img_val in val_subsets[0]:\\n  if img_val[1] not in dict_val:\\n    dict_val[img_val[1]]=1\\n  else:\\n    dict_val[img_val[1]]+=1\\ndict_test={}\\nfor img_test in test_subsets[0]:\\n  if img_test[1] not in dict_test:\\n    dict_test[img_test[1]]=1\\n  else:\\n    dict_test[img_test[1]]+=1\\n\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d19CnhIUg0q",
        "colab_type": "text"
      },
      "source": [
        "**Utility functions to use our customized resnet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ff9pwV10b0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.resnet import resnet32\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getResNet32():\n",
        "    net = resnet32()\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = utils.getLossCriterion()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet32()\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glyt2p3XTEqt",
        "colab_type": "text"
      },
      "source": [
        "**Basic train, test and validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzG6w15UudAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, num_epochs=NUM_EPOCHS):     \n",
        "    # By default, everything is loaded to cpu\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    \n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            # preds = getLabels(outputs_labels_mapping, preds)\n",
        "            # print(preds)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    utils.getLossCriterion()\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "        # Bring data over the device of choice\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        #labels = outputs_labels_mapping.getNodes(labels)\n",
        "        labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(images)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # preds = getLabels(outputs_labels_mapping, preds)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "        \n",
        "    # Calculate Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _ = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiWapdlNNsA0",
        "colab_type": "text"
      },
      "source": [
        "**Joint Training**<br>\n",
        "In this section joint training is perfomed.<br>\n",
        "The train of the network is split into 10 stages, one for each subset classes.\n",
        "At each step, the network is trained on the images corresponding to the current 10 classes and all the data already seen in the previous steps.\n",
        "The joint training score, evaluated in terms of accuracy on the test set, gives us an UB for the next methodologies examined in this project (iCaRL, LWF).<br>\n",
        "Operatively, what happens is a very slow training and, furthermore, we break the assumption of not needing the previous batches of data at each step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4InuBhsENpV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####\n",
        "## Joint training\n",
        "####\n",
        "# Joins 2+ subsets into a new Subset (joint training)\n",
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "def jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getNet()\n",
        "\n",
        "    train_set = None\n",
        "    test_set = None\n",
        "    first_pass = True\n",
        "\n",
        "    current_train_num = 0\n",
        "    total_trains = len(train_subsets)\n",
        "    joint_start = time.time()\n",
        "\n",
        "    print('\\n\\nJoint-training start\\n\\n')\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "        phase_start = time.time()\n",
        "        print('\\n\\nJoint phase {}/{}\\n\\n'.format(current_train_num+1, total_trains))\n",
        "        current_train_num += 1\n",
        "\n",
        "        #num_classes_per_group = 10\n",
        "        num_classes_seen = current_train_num*10\n",
        "\n",
        "        # Builds growing train and test set. The new sets include data from previous class groups and current class group\n",
        "        if train_set is None:\n",
        "            train_set = train_subset\n",
        "        else:\n",
        "            train_set = joinSubsets(train_dataset, [train_set, train_subset])\n",
        "        if test_set is None:\n",
        "            test_set = test_subset\n",
        "        else:\n",
        "            test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        if first_pass:\n",
        "            first_pass = False\n",
        "        else:\n",
        "            addOutputs(net, 10)\n",
        "\n",
        "        # Trains model on previous and current class groups\n",
        "        optimizer, scheduler = getSchedulerOptimizer(net)\n",
        "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "        # Validate model on current class group\n",
        "        val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        v_acc, v_loss = validate(net, val_loader, criterion, num_classes_seen)\n",
        "        print('\\nValidation accuracy: {} - Validation loss: {}\\n'.format(v_acc, v_loss))\n",
        "\n",
        "        # Test the model on previous and current class groups\n",
        "        test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        t_acc = test(net, test_loader, num_classes_seen)\n",
        "        print('\\nTest accuracy: {}\\n'.format(t_acc))\n",
        "\n",
        "        print('\\n\\nPhase completed in {} seconds\\n\\n'.format(time.time() - phase_start))\n",
        "    \n",
        "    print('\\n\\n Joint-training finished in {} seconds'.format(time.time() - joint_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOiPlN8ON4Gn",
        "colab_type": "text"
      },
      "source": [
        "**Test joint training**<br>\n",
        "What we expect is a test accuracy higher of what we'll be able to achieve using iCaRL, LWF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDecUBiHl4G",
        "colab_type": "code",
        "outputId": "6fa6fcd9-90f5-47be-c0c0-b79ca7579a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test Joint training\n",
        "\n",
        "jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets)\n",
        "\n",
        "# [DEBUG]\n",
        "#net, criterion, optimizer, scheduler = getResNet32()\n",
        "#train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "#train(net, train_dataloader, criterion, optimizer, scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Joint-training start\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Joint phase 1/10\n",
            "\n",
            "\n",
            "Starting epoch 1/70, LR = [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.8712100982666016\n",
            "Train step - Step 10, Loss 0.4186106324195862\n",
            "Train step - Step 20, Loss 0.32373008131980896\n",
            "Train step - Step 30, Loss 0.3072291314601898\n",
            "Train epoch - Accuracy: 0.14303030303030304 Loss: 0.3887609377051845 Corrects: 708\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.30423006415367126\n",
            "Train step - Step 50, Loss 0.2925500273704529\n",
            "Train step - Step 60, Loss 0.3075350522994995\n",
            "Train step - Step 70, Loss 0.29483509063720703\n",
            "Train epoch - Accuracy: 0.17434343434343436 Loss: 0.3028095986867192 Corrects: 863\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.31984782218933105\n",
            "Train step - Step 90, Loss 0.2948732376098633\n",
            "Train step - Step 100, Loss 0.2837443947792053\n",
            "Train step - Step 110, Loss 0.28582993149757385\n",
            "Train epoch - Accuracy: 0.1921212121212121 Loss: 0.29691688968677715 Corrects: 951\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.2927238941192627\n",
            "Train step - Step 130, Loss 0.281755268573761\n",
            "Train step - Step 140, Loss 0.2905483841896057\n",
            "Train step - Step 150, Loss 0.3051421642303467\n",
            "Train epoch - Accuracy: 0.22323232323232323 Loss: 0.2945338908470038 Corrects: 1105\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.28209373354911804\n",
            "Train step - Step 170, Loss 0.29061728715896606\n",
            "Train step - Step 180, Loss 0.25942549109458923\n",
            "Train step - Step 190, Loss 0.26906880736351013\n",
            "Train epoch - Accuracy: 0.2777777777777778 Loss: 0.27995338291832894 Corrects: 1375\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.2772751748561859\n",
            "Train step - Step 210, Loss 0.2661075294017792\n",
            "Train step - Step 220, Loss 0.27187761664390564\n",
            "Train step - Step 230, Loss 0.25099802017211914\n",
            "Train epoch - Accuracy: 0.3303030303030303 Loss: 0.2657665302175464 Corrects: 1635\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.25439780950546265\n",
            "Train step - Step 250, Loss 0.25448861718177795\n",
            "Train step - Step 260, Loss 0.25954756140708923\n",
            "Train step - Step 270, Loss 0.2697036564350128\n",
            "Train epoch - Accuracy: 0.3604040404040404 Loss: 0.25548209532342775 Corrects: 1784\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.22537370026111603\n",
            "Train step - Step 290, Loss 0.24830365180969238\n",
            "Train step - Step 300, Loss 0.23872970044612885\n",
            "Train step - Step 310, Loss 0.24105072021484375\n",
            "Train epoch - Accuracy: 0.3882828282828283 Loss: 0.24428004135387113 Corrects: 1922\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.23694847524166107\n",
            "Train step - Step 330, Loss 0.22536857426166534\n",
            "Train step - Step 340, Loss 0.2237796038389206\n",
            "Train step - Step 350, Loss 0.24492233991622925\n",
            "Train epoch - Accuracy: 0.4072727272727273 Loss: 0.236430762151275 Corrects: 2016\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.2189725637435913\n",
            "Train step - Step 370, Loss 0.2531599700450897\n",
            "Train step - Step 380, Loss 0.23844614624977112\n",
            "Train epoch - Accuracy: 0.42727272727272725 Loss: 0.23132169308686498 Corrects: 2115\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.2339554876089096\n",
            "Train step - Step 400, Loss 0.20276780426502228\n",
            "Train step - Step 410, Loss 0.24562013149261475\n",
            "Train step - Step 420, Loss 0.21309752762317657\n",
            "Train epoch - Accuracy: 0.43454545454545457 Loss: 0.2265628675439141 Corrects: 2151\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.23149923980236053\n",
            "Train step - Step 440, Loss 0.20659656822681427\n",
            "Train step - Step 450, Loss 0.20162640511989594\n",
            "Train step - Step 460, Loss 0.21154136955738068\n",
            "Train epoch - Accuracy: 0.46525252525252525 Loss: 0.21929701496856382 Corrects: 2303\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.20367613434791565\n",
            "Train step - Step 480, Loss 0.2198735922574997\n",
            "Train step - Step 490, Loss 0.21712522208690643\n",
            "Train step - Step 500, Loss 0.18986159563064575\n",
            "Train epoch - Accuracy: 0.476969696969697 Loss: 0.21491047385365072 Corrects: 2361\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.19865307211875916\n",
            "Train step - Step 520, Loss 0.19107882678508759\n",
            "Train step - Step 530, Loss 0.19958510994911194\n",
            "Train step - Step 540, Loss 0.2094869464635849\n",
            "Train epoch - Accuracy: 0.5088888888888888 Loss: 0.20550541290129073 Corrects: 2519\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.20072750747203827\n",
            "Train step - Step 560, Loss 0.1909331977367401\n",
            "Train step - Step 570, Loss 0.21674227714538574\n",
            "Train step - Step 580, Loss 0.1980186551809311\n",
            "Train epoch - Accuracy: 0.5432323232323232 Loss: 0.1970035060547819 Corrects: 2689\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.18994393944740295\n",
            "Train step - Step 600, Loss 0.2126777172088623\n",
            "Train step - Step 610, Loss 0.1806192547082901\n",
            "Train step - Step 620, Loss 0.21077485382556915\n",
            "Train epoch - Accuracy: 0.5430303030303031 Loss: 0.19480290358114724 Corrects: 2688\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.19466429948806763\n",
            "Train step - Step 640, Loss 0.19896316528320312\n",
            "Train step - Step 650, Loss 0.18765144050121307\n",
            "Train step - Step 660, Loss 0.17830388247966766\n",
            "Train epoch - Accuracy: 0.556969696969697 Loss: 0.19406381143463983 Corrects: 2757\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.17154602706432343\n",
            "Train step - Step 680, Loss 0.148555725812912\n",
            "Train step - Step 690, Loss 0.18485672771930695\n",
            "Train step - Step 700, Loss 0.182687446475029\n",
            "Train epoch - Accuracy: 0.5773737373737374 Loss: 0.1859386369856921 Corrects: 2858\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.17092886567115784\n",
            "Train step - Step 720, Loss 0.18871285021305084\n",
            "Train step - Step 730, Loss 0.17316710948944092\n",
            "Train step - Step 740, Loss 0.19667507708072662\n",
            "Train epoch - Accuracy: 0.5806060606060606 Loss: 0.1833606557834028 Corrects: 2874\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.16485939919948578\n",
            "Train step - Step 760, Loss 0.1785963624715805\n",
            "Train step - Step 770, Loss 0.1635948270559311\n",
            "Train epoch - Accuracy: 0.5903030303030303 Loss: 0.1800421953983981 Corrects: 2922\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.18758411705493927\n",
            "Train step - Step 790, Loss 0.19072316586971283\n",
            "Train step - Step 800, Loss 0.1711789071559906\n",
            "Train step - Step 810, Loss 0.1852402538061142\n",
            "Train epoch - Accuracy: 0.6062626262626263 Loss: 0.17407115406460233 Corrects: 3001\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.1861720085144043\n",
            "Train step - Step 830, Loss 0.16712284088134766\n",
            "Train step - Step 840, Loss 0.16115720570087433\n",
            "Train step - Step 850, Loss 0.15334711968898773\n",
            "Train epoch - Accuracy: 0.6218181818181818 Loss: 0.17087875277105005 Corrects: 3078\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.17406468093395233\n",
            "Train step - Step 870, Loss 0.18757501244544983\n",
            "Train step - Step 880, Loss 0.17699958384037018\n",
            "Train step - Step 890, Loss 0.15226924419403076\n",
            "Train epoch - Accuracy: 0.621010101010101 Loss: 0.16617576045219346 Corrects: 3074\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.16873399913311005\n",
            "Train step - Step 910, Loss 0.1728380173444748\n",
            "Train step - Step 920, Loss 0.1836526095867157\n",
            "Train step - Step 930, Loss 0.19674669206142426\n",
            "Train epoch - Accuracy: 0.6268686868686869 Loss: 0.16727465541675837 Corrects: 3103\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.17575009167194366\n",
            "Train step - Step 950, Loss 0.16079175472259521\n",
            "Train step - Step 960, Loss 0.14772050082683563\n",
            "Train step - Step 970, Loss 0.15061552822589874\n",
            "Train epoch - Accuracy: 0.648080808080808 Loss: 0.15721328785323133 Corrects: 3208\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.1621740609407425\n",
            "Train step - Step 990, Loss 0.13610012829303741\n",
            "Train step - Step 1000, Loss 0.15555810928344727\n",
            "Train step - Step 1010, Loss 0.14792542159557343\n",
            "Train epoch - Accuracy: 0.6616161616161617 Loss: 0.15508910021998665 Corrects: 3275\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.15164457261562347\n",
            "Train step - Step 1030, Loss 0.15248171985149384\n",
            "Train step - Step 1040, Loss 0.17808958888053894\n",
            "Train step - Step 1050, Loss 0.14609389007091522\n",
            "Train epoch - Accuracy: 0.6620202020202021 Loss: 0.15536658210585816 Corrects: 3277\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.13028383255004883\n",
            "Train step - Step 1070, Loss 0.15337853133678436\n",
            "Train step - Step 1080, Loss 0.18863053619861603\n",
            "Train step - Step 1090, Loss 0.13986670970916748\n",
            "Train epoch - Accuracy: 0.6503030303030303 Loss: 0.15805283364021416 Corrects: 3219\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.1261468231678009\n",
            "Train step - Step 1110, Loss 0.13662682473659515\n",
            "Train step - Step 1120, Loss 0.15902093052864075\n",
            "Train step - Step 1130, Loss 0.14077088236808777\n",
            "Train epoch - Accuracy: 0.6810101010101011 Loss: 0.1509397975483326 Corrects: 3371\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.13836240768432617\n",
            "Train step - Step 1150, Loss 0.14995640516281128\n",
            "Train step - Step 1160, Loss 0.14443989098072052\n",
            "Train epoch - Accuracy: 0.685050505050505 Loss: 0.14307109524204273 Corrects: 3391\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.15275132656097412\n",
            "Train step - Step 1180, Loss 0.14130139350891113\n",
            "Train step - Step 1190, Loss 0.1410534381866455\n",
            "Train step - Step 1200, Loss 0.15481188893318176\n",
            "Train epoch - Accuracy: 0.6971717171717172 Loss: 0.13743336977079662 Corrects: 3451\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.1450696438550949\n",
            "Train step - Step 1220, Loss 0.13767696917057037\n",
            "Train step - Step 1230, Loss 0.15365652740001678\n",
            "Train step - Step 1240, Loss 0.12078966945409775\n",
            "Train epoch - Accuracy: 0.6991919191919191 Loss: 0.14200302758000113 Corrects: 3461\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.12277068942785263\n",
            "Train step - Step 1260, Loss 0.13278716802597046\n",
            "Train step - Step 1270, Loss 0.13709144294261932\n",
            "Train step - Step 1280, Loss 0.12247294187545776\n",
            "Train epoch - Accuracy: 0.7070707070707071 Loss: 0.13669395711084809 Corrects: 3500\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.12857882678508759\n",
            "Train step - Step 1300, Loss 0.12559400498867035\n",
            "Train step - Step 1310, Loss 0.12361148744821548\n",
            "Train step - Step 1320, Loss 0.1371627151966095\n",
            "Train epoch - Accuracy: 0.7191919191919192 Loss: 0.1332357342857303 Corrects: 3560\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.12021732330322266\n",
            "Train step - Step 1340, Loss 0.13866886496543884\n",
            "Train step - Step 1350, Loss 0.13710497319698334\n",
            "Train step - Step 1360, Loss 0.14050568640232086\n",
            "Train epoch - Accuracy: 0.7111111111111111 Loss: 0.1346006467005219 Corrects: 3520\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.13940297067165375\n",
            "Train step - Step 1380, Loss 0.12709327042102814\n",
            "Train step - Step 1390, Loss 0.1418944150209427\n",
            "Train step - Step 1400, Loss 0.1411789506673813\n",
            "Train epoch - Accuracy: 0.7236363636363636 Loss: 0.12904069853551461 Corrects: 3582\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.1422521024942398\n",
            "Train step - Step 1420, Loss 0.122501902282238\n",
            "Train step - Step 1430, Loss 0.1154906302690506\n",
            "Train step - Step 1440, Loss 0.11845769733190536\n",
            "Train epoch - Accuracy: 0.7258585858585859 Loss: 0.1304076246962403 Corrects: 3593\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.11118771880865097\n",
            "Train step - Step 1460, Loss 0.11531096696853638\n",
            "Train step - Step 1470, Loss 0.1360797882080078\n",
            "Train step - Step 1480, Loss 0.12471097707748413\n",
            "Train epoch - Accuracy: 0.724040404040404 Loss: 0.1274770118973472 Corrects: 3584\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.12837815284729004\n",
            "Train step - Step 1500, Loss 0.12312779575586319\n",
            "Train step - Step 1510, Loss 0.10204966366291046\n",
            "Train step - Step 1520, Loss 0.1314980387687683\n",
            "Train epoch - Accuracy: 0.7385858585858586 Loss: 0.1246534185939365 Corrects: 3656\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.1027395948767662\n",
            "Train step - Step 1540, Loss 0.11067231744527817\n",
            "Train step - Step 1550, Loss 0.14524109661579132\n",
            "Train epoch - Accuracy: 0.7440404040404041 Loss: 0.12366936766740047 Corrects: 3683\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.11483228206634521\n",
            "Train step - Step 1570, Loss 0.15857088565826416\n",
            "Train step - Step 1580, Loss 0.10765879601240158\n",
            "Train step - Step 1590, Loss 0.12299089878797531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pts78KY42gXj",
        "colab_type": "text"
      },
      "source": [
        "**Fine tuning (catastrophic forgetting)**<br>\n",
        "In this section of the homework the aim is to demonstrate how, without ad-hoc methodologies, our CNN is unable to learn without dramatically forgetting what it has already been learnt.<br>\n",
        "Operatively, what we do is to perform a training again divided into (ten) steps but without exploiting previous data as before (joint training).\n",
        "What we should observe is a dramatic drop in the perfomances of the network.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrA3WhUzuK67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Fine tuning\n",
        "def sequentialLearning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies, num_classes):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader, num_classes)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb",
        "colab_type": "code",
        "outputId": "93fcaea9-bb3d-4264-f0ca-c8c3dbdcebb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies=sequentialLearning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "Starting epoch 1/70, LR = [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7146422266960144\n",
            "Train step - Step 10, Loss 0.37235966324806213\n",
            "Train step - Step 20, Loss 0.3309747874736786\n",
            "Train step - Step 30, Loss 0.32895463705062866\n",
            "Train epoch - Accuracy: 0.10727272727272727 Loss: 0.40393964466422494 Corrects: 531\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.32330846786499023\n",
            "Train step - Step 50, Loss 0.324926495552063\n",
            "Train step - Step 60, Loss 0.3205913007259369\n",
            "Train step - Step 70, Loss 0.32317373156547546\n",
            "Train epoch - Accuracy: 0.11393939393939394 Loss: 0.32403065947571186 Corrects: 564\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.3208722174167633\n",
            "Train step - Step 90, Loss 0.3274601399898529\n",
            "Train step - Step 100, Loss 0.33108535408973694\n",
            "Train step - Step 110, Loss 0.3152123987674713\n",
            "Train epoch - Accuracy: 0.12404040404040403 Loss: 0.322587579585085 Corrects: 614\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.3213508129119873\n",
            "Train step - Step 130, Loss 0.318751722574234\n",
            "Train step - Step 140, Loss 0.3194692134857178\n",
            "Train step - Step 150, Loss 0.3181431293487549\n",
            "Train epoch - Accuracy: 0.141010101010101 Loss: 0.3187624006921595 Corrects: 698\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.3111330568790436\n",
            "Train step - Step 170, Loss 0.30877748131752014\n",
            "Train step - Step 180, Loss 0.29619720578193665\n",
            "Train step - Step 190, Loss 0.2738131582736969\n",
            "Train epoch - Accuracy: 0.2 Loss: 0.30446928609501234 Corrects: 990\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.284965842962265\n",
            "Train step - Step 210, Loss 0.26922544836997986\n",
            "Train step - Step 220, Loss 0.27909204363822937\n",
            "Train step - Step 230, Loss 0.26480430364608765\n",
            "Train epoch - Accuracy: 0.2773737373737374 Loss: 0.2762860353667327 Corrects: 1373\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.27185600996017456\n",
            "Train step - Step 250, Loss 0.27298736572265625\n",
            "Train step - Step 260, Loss 0.2756156623363495\n",
            "Train step - Step 270, Loss 0.2643459737300873\n",
            "Train epoch - Accuracy: 0.30383838383838385 Loss: 0.2671011749542121 Corrects: 1504\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.2587485909461975\n",
            "Train step - Step 290, Loss 0.25766870379447937\n",
            "Train step - Step 300, Loss 0.2651052176952362\n",
            "Train step - Step 310, Loss 0.26709502935409546\n",
            "Train epoch - Accuracy: 0.301010101010101 Loss: 0.26280591334959474 Corrects: 1490\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.26639944314956665\n",
            "Train step - Step 330, Loss 0.2484612911939621\n",
            "Train step - Step 340, Loss 0.24879729747772217\n",
            "Train step - Step 350, Loss 0.24165605008602142\n",
            "Train epoch - Accuracy: 0.32606060606060605 Loss: 0.2573208747548286 Corrects: 1614\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.2580946981906891\n",
            "Train step - Step 370, Loss 0.25498712062835693\n",
            "Train step - Step 380, Loss 0.2506204843521118\n",
            "Train epoch - Accuracy: 0.37333333333333335 Loss: 0.24955144595016132 Corrects: 1848\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.23671884834766388\n",
            "Train step - Step 400, Loss 0.24696950614452362\n",
            "Train step - Step 410, Loss 0.2601749002933502\n",
            "Train step - Step 420, Loss 0.23572960495948792\n",
            "Train epoch - Accuracy: 0.4018181818181818 Loss: 0.24264841810621396 Corrects: 1989\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.23517833650112152\n",
            "Train step - Step 440, Loss 0.24474330246448517\n",
            "Train step - Step 450, Loss 0.22150669991970062\n",
            "Train step - Step 460, Loss 0.21068373322486877\n",
            "Train epoch - Accuracy: 0.42484848484848486 Loss: 0.23401087975261187 Corrects: 2103\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.23005512356758118\n",
            "Train step - Step 480, Loss 0.26223239302635193\n",
            "Train step - Step 490, Loss 0.20430441200733185\n",
            "Train step - Step 500, Loss 0.2180531769990921\n",
            "Train epoch - Accuracy: 0.45212121212121215 Loss: 0.2277380727397071 Corrects: 2238\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.22280345857143402\n",
            "Train step - Step 520, Loss 0.22589336335659027\n",
            "Train step - Step 530, Loss 0.20959250628948212\n",
            "Train step - Step 540, Loss 0.21688564121723175\n",
            "Train epoch - Accuracy: 0.46646464646464647 Loss: 0.22218010245549558 Corrects: 2309\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.23127470910549164\n",
            "Train step - Step 560, Loss 0.22164659202098846\n",
            "Train step - Step 570, Loss 0.22464978694915771\n",
            "Train step - Step 580, Loss 0.2121724933385849\n",
            "Train epoch - Accuracy: 0.4993939393939394 Loss: 0.2136142829873345 Corrects: 2472\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.210479736328125\n",
            "Train step - Step 600, Loss 0.2151312381029129\n",
            "Train step - Step 610, Loss 0.2216958999633789\n",
            "Train step - Step 620, Loss 0.22161391377449036\n",
            "Train epoch - Accuracy: 0.5103030303030303 Loss: 0.21273232301076253 Corrects: 2526\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.19426868855953217\n",
            "Train step - Step 640, Loss 0.19897964596748352\n",
            "Train step - Step 650, Loss 0.2218509167432785\n",
            "Train step - Step 660, Loss 0.20664794743061066\n",
            "Train epoch - Accuracy: 0.5098989898989899 Loss: 0.20817394358943206 Corrects: 2524\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.19368472695350647\n",
            "Train step - Step 680, Loss 0.21523867547512054\n",
            "Train step - Step 690, Loss 0.21986348927021027\n",
            "Train step - Step 700, Loss 0.2204640656709671\n",
            "Train epoch - Accuracy: 0.5173737373737374 Loss: 0.20630490829246212 Corrects: 2561\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.20325994491577148\n",
            "Train step - Step 720, Loss 0.19918909668922424\n",
            "Train step - Step 730, Loss 0.20705394446849823\n",
            "Train step - Step 740, Loss 0.18780654668807983\n",
            "Train epoch - Accuracy: 0.5173737373737374 Loss: 0.20757186843891337 Corrects: 2561\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.2167348861694336\n",
            "Train step - Step 760, Loss 0.19644415378570557\n",
            "Train step - Step 770, Loss 0.19947536289691925\n",
            "Train epoch - Accuracy: 0.5333333333333333 Loss: 0.20071885256454197 Corrects: 2640\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.20537438988685608\n",
            "Train step - Step 790, Loss 0.20671291649341583\n",
            "Train step - Step 800, Loss 0.17567388713359833\n",
            "Train step - Step 810, Loss 0.19577908515930176\n",
            "Train epoch - Accuracy: 0.5404040404040404 Loss: 0.1946092739610961 Corrects: 2675\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.19858995079994202\n",
            "Train step - Step 830, Loss 0.18223799765110016\n",
            "Train step - Step 840, Loss 0.19572891294956207\n",
            "Train step - Step 850, Loss 0.18752498924732208\n",
            "Train epoch - Accuracy: 0.5492929292929293 Loss: 0.19592416840972324 Corrects: 2719\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.19203320145606995\n",
            "Train step - Step 870, Loss 0.17479948699474335\n",
            "Train step - Step 880, Loss 0.2074969857931137\n",
            "Train step - Step 890, Loss 0.198240265250206\n",
            "Train epoch - Accuracy: 0.553939393939394 Loss: 0.19065976543860003 Corrects: 2742\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.20526914298534393\n",
            "Train step - Step 910, Loss 0.20438022911548615\n",
            "Train step - Step 920, Loss 0.21176354587078094\n",
            "Train step - Step 930, Loss 0.17418083548545837\n",
            "Train epoch - Accuracy: 0.565050505050505 Loss: 0.19023996079810943 Corrects: 2797\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.2048027068376541\n",
            "Train step - Step 950, Loss 0.2000226080417633\n",
            "Train step - Step 960, Loss 0.18325677514076233\n",
            "Train step - Step 970, Loss 0.17633531987667084\n",
            "Train epoch - Accuracy: 0.573939393939394 Loss: 0.18393662625491017 Corrects: 2841\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.18104682862758636\n",
            "Train step - Step 990, Loss 0.17959770560264587\n",
            "Train step - Step 1000, Loss 0.17894048988819122\n",
            "Train step - Step 1010, Loss 0.19382207095623016\n",
            "Train epoch - Accuracy: 0.5878787878787879 Loss: 0.18319679117564 Corrects: 2910\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.18335220217704773\n",
            "Train step - Step 1030, Loss 0.1899515837430954\n",
            "Train step - Step 1040, Loss 0.17522035539150238\n",
            "Train step - Step 1050, Loss 0.16810846328735352\n",
            "Train epoch - Accuracy: 0.5965656565656565 Loss: 0.17984308584169909 Corrects: 2953\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.1738148033618927\n",
            "Train step - Step 1070, Loss 0.17766642570495605\n",
            "Train step - Step 1080, Loss 0.17814357578754425\n",
            "Train step - Step 1090, Loss 0.16975238919258118\n",
            "Train epoch - Accuracy: 0.6034343434343434 Loss: 0.17623909846700803 Corrects: 2987\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.15663181245326996\n",
            "Train step - Step 1110, Loss 0.16381677985191345\n",
            "Train step - Step 1120, Loss 0.16779521107673645\n",
            "Train step - Step 1130, Loss 0.16913068294525146\n",
            "Train epoch - Accuracy: 0.6157575757575757 Loss: 0.17392227139135805 Corrects: 3048\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.16955727338790894\n",
            "Train step - Step 1150, Loss 0.15926027297973633\n",
            "Train step - Step 1160, Loss 0.1510872095823288\n",
            "Train epoch - Accuracy: 0.6309090909090909 Loss: 0.16853436799362453 Corrects: 3123\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.1815551072359085\n",
            "Train step - Step 1180, Loss 0.1424616426229477\n",
            "Train step - Step 1190, Loss 0.17579592764377594\n",
            "Train step - Step 1200, Loss 0.16138039529323578\n",
            "Train epoch - Accuracy: 0.6288888888888889 Loss: 0.1690236360075498 Corrects: 3113\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.15561635792255402\n",
            "Train step - Step 1220, Loss 0.17175109684467316\n",
            "Train step - Step 1230, Loss 0.1659872978925705\n",
            "Train step - Step 1240, Loss 0.18997514247894287\n",
            "Train epoch - Accuracy: 0.6349494949494949 Loss: 0.16722048634230488 Corrects: 3143\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.18748365342617035\n",
            "Train step - Step 1260, Loss 0.1615326702594757\n",
            "Train step - Step 1270, Loss 0.17410019040107727\n",
            "Train step - Step 1280, Loss 0.14577867090702057\n",
            "Train epoch - Accuracy: 0.6430303030303031 Loss: 0.1633907616198665 Corrects: 3183\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.1692545861005783\n",
            "Train step - Step 1300, Loss 0.14285768568515778\n",
            "Train step - Step 1310, Loss 0.15253029763698578\n",
            "Train step - Step 1320, Loss 0.1307983696460724\n",
            "Train epoch - Accuracy: 0.6466666666666666 Loss: 0.16027336596238492 Corrects: 3201\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.16449101269245148\n",
            "Train step - Step 1340, Loss 0.16076302528381348\n",
            "Train step - Step 1350, Loss 0.17266517877578735\n",
            "Train step - Step 1360, Loss 0.15806549787521362\n",
            "Train epoch - Accuracy: 0.6515151515151515 Loss: 0.16075984131206167 Corrects: 3225\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.13783413171768188\n",
            "Train step - Step 1380, Loss 0.15546143054962158\n",
            "Train step - Step 1390, Loss 0.16179892420768738\n",
            "Train step - Step 1400, Loss 0.15884941816329956\n",
            "Train epoch - Accuracy: 0.66 Loss: 0.1554293980321499 Corrects: 3267\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.15242508053779602\n",
            "Train step - Step 1420, Loss 0.14005500078201294\n",
            "Train step - Step 1430, Loss 0.1453876495361328\n",
            "Train step - Step 1440, Loss 0.16628077626228333\n",
            "Train epoch - Accuracy: 0.6654545454545454 Loss: 0.15740646916206438 Corrects: 3294\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.14995057880878448\n",
            "Train step - Step 1460, Loss 0.13929389417171478\n",
            "Train step - Step 1470, Loss 0.15395985543727875\n",
            "Train step - Step 1480, Loss 0.1704058200120926\n",
            "Train epoch - Accuracy: 0.6723232323232323 Loss: 0.1519898903731144 Corrects: 3328\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.15645352005958557\n",
            "Train step - Step 1500, Loss 0.13194622099399567\n",
            "Train step - Step 1510, Loss 0.1636340171098709\n",
            "Train step - Step 1520, Loss 0.15603770315647125\n",
            "Train epoch - Accuracy: 0.6876767676767677 Loss: 0.14720205992761284 Corrects: 3404\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.14744077622890472\n",
            "Train step - Step 1540, Loss 0.1483832448720932\n",
            "Train step - Step 1550, Loss 0.14605435729026794\n",
            "Train epoch - Accuracy: 0.6854545454545454 Loss: 0.1460380540592502 Corrects: 3393\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.12411675602197647\n",
            "Train step - Step 1570, Loss 0.18386562168598175\n",
            "Train step - Step 1580, Loss 0.12857221066951752\n",
            "Train step - Step 1590, Loss 0.11434151977300644\n",
            "Train epoch - Accuracy: 0.6933333333333334 Loss: 0.142517749679209 Corrects: 3432\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.13813263177871704\n",
            "Train step - Step 1610, Loss 0.12730303406715393\n",
            "Train step - Step 1620, Loss 0.14454098045825958\n",
            "Train step - Step 1630, Loss 0.12812577188014984\n",
            "Train epoch - Accuracy: 0.7018181818181818 Loss: 0.13905380243604834 Corrects: 3474\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.12121718376874924\n",
            "Train step - Step 1650, Loss 0.13679902255535126\n",
            "Train step - Step 1660, Loss 0.1504419893026352\n",
            "Train step - Step 1670, Loss 0.12317875772714615\n",
            "Train epoch - Accuracy: 0.7062626262626263 Loss: 0.14023619270685947 Corrects: 3496\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.14285370707511902\n",
            "Train step - Step 1690, Loss 0.12826040387153625\n",
            "Train step - Step 1700, Loss 0.13524287939071655\n",
            "Train step - Step 1710, Loss 0.12569649517536163\n",
            "Train epoch - Accuracy: 0.7123232323232324 Loss: 0.1348160157540832 Corrects: 3526\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.12970824539661407\n",
            "Train step - Step 1730, Loss 0.11911778897047043\n",
            "Train step - Step 1740, Loss 0.1331450194120407\n",
            "Train step - Step 1750, Loss 0.12897472083568573\n",
            "Train epoch - Accuracy: 0.7074747474747475 Loss: 0.13617631128340058 Corrects: 3502\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.12343763560056686\n",
            "Train step - Step 1770, Loss 0.1484348624944687\n",
            "Train step - Step 1780, Loss 0.11723075062036514\n",
            "Train step - Step 1790, Loss 0.14783354103565216\n",
            "Train epoch - Accuracy: 0.7191919191919192 Loss: 0.13086112181345622 Corrects: 3560\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.11575465649366379\n",
            "Train step - Step 1810, Loss 0.11054757982492447\n",
            "Train step - Step 1820, Loss 0.12824897468090057\n",
            "Train step - Step 1830, Loss 0.14241348206996918\n",
            "Train epoch - Accuracy: 0.7288888888888889 Loss: 0.12853094150321653 Corrects: 3608\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.1362312138080597\n",
            "Train step - Step 1850, Loss 0.11486595124006271\n",
            "Train step - Step 1860, Loss 0.11185286194086075\n",
            "Train step - Step 1870, Loss 0.1285076141357422\n",
            "Train epoch - Accuracy: 0.7260606060606061 Loss: 0.1300064922703637 Corrects: 3594\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.12001659721136093\n",
            "Train step - Step 1890, Loss 0.11095600575208664\n",
            "Train step - Step 1900, Loss 0.1496211141347885\n",
            "Train step - Step 1910, Loss 0.15878665447235107\n",
            "Train epoch - Accuracy: 0.7369696969696969 Loss: 0.12518274023075296 Corrects: 3648\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.1175956055521965\n",
            "Train step - Step 1930, Loss 0.1024973914027214\n",
            "Train step - Step 1940, Loss 0.09617464989423752\n",
            "Train epoch - Accuracy: 0.7646464646464647 Loss: 0.11353990672212659 Corrects: 3785\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.11441832035779953\n",
            "Train step - Step 1960, Loss 0.0988197848200798\n",
            "Train step - Step 1970, Loss 0.11012711375951767\n",
            "Train step - Step 1980, Loss 0.11328905075788498\n",
            "Train epoch - Accuracy: 0.7816161616161617 Loss: 0.10488796358156686 Corrects: 3869\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.10390102863311768\n",
            "Train step - Step 2000, Loss 0.0927775651216507\n",
            "Train step - Step 2010, Loss 0.09516310691833496\n",
            "Train step - Step 2020, Loss 0.10586726665496826\n",
            "Train epoch - Accuracy: 0.7919191919191919 Loss: 0.10074122323532297 Corrects: 3920\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.08445260673761368\n",
            "Train step - Step 2040, Loss 0.08406049013137817\n",
            "Train step - Step 2050, Loss 0.10562600940465927\n",
            "Train step - Step 2060, Loss 0.10796362161636353\n",
            "Train epoch - Accuracy: 0.7911111111111111 Loss: 0.1001887513290752 Corrects: 3916\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.11383932828903198\n",
            "Train step - Step 2080, Loss 0.1168343797326088\n",
            "Train step - Step 2090, Loss 0.09122999012470245\n",
            "Train step - Step 2100, Loss 0.09290279448032379\n",
            "Train epoch - Accuracy: 0.8018181818181818 Loss: 0.09635835636444766 Corrects: 3969\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.09027256816625595\n",
            "Train step - Step 2120, Loss 0.09184416383504868\n",
            "Train step - Step 2130, Loss 0.10362222045660019\n",
            "Train step - Step 2140, Loss 0.12359499931335449\n",
            "Train epoch - Accuracy: 0.8018181818181818 Loss: 0.09583029165111406 Corrects: 3969\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.08019789308309555\n",
            "Train step - Step 2160, Loss 0.09553364664316177\n",
            "Train step - Step 2170, Loss 0.09947426617145538\n",
            "Train step - Step 2180, Loss 0.10351904481649399\n",
            "Train epoch - Accuracy: 0.8080808080808081 Loss: 0.09312014698681205 Corrects: 4000\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.09227650612592697\n",
            "Train step - Step 2200, Loss 0.08501430600881577\n",
            "Train step - Step 2210, Loss 0.0857836976647377\n",
            "Train step - Step 2220, Loss 0.10257835686206818\n",
            "Train epoch - Accuracy: 0.8103030303030303 Loss: 0.09169569857192762 Corrects: 4011\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.09020745009183884\n",
            "Train step - Step 2240, Loss 0.07826147228479385\n",
            "Train step - Step 2250, Loss 0.08269687741994858\n",
            "Train step - Step 2260, Loss 0.08510997146368027\n",
            "Train epoch - Accuracy: 0.807070707070707 Loss: 0.09169354069413561 Corrects: 3995\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.08165577054023743\n",
            "Train step - Step 2280, Loss 0.0746871680021286\n",
            "Train step - Step 2290, Loss 0.09917380660772324\n",
            "Train step - Step 2300, Loss 0.1014842689037323\n",
            "Train epoch - Accuracy: 0.8202020202020202 Loss: 0.09020770396849122 Corrects: 4060\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.07490123808383942\n",
            "Train step - Step 2320, Loss 0.07611461728811264\n",
            "Train step - Step 2330, Loss 0.07600826770067215\n",
            "Train epoch - Accuracy: 0.8197979797979797 Loss: 0.08817689519337933 Corrects: 4058\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.1013287827372551\n",
            "Train step - Step 2350, Loss 0.09179618209600449\n",
            "Train step - Step 2360, Loss 0.08165983110666275\n",
            "Train step - Step 2370, Loss 0.095301054418087\n",
            "Train epoch - Accuracy: 0.8244444444444444 Loss: 0.08560199576495874 Corrects: 4081\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.07029592990875244\n",
            "Train step - Step 2390, Loss 0.07289620488882065\n",
            "Train step - Step 2400, Loss 0.07454004138708115\n",
            "Train step - Step 2410, Loss 0.0713891014456749\n",
            "Train epoch - Accuracy: 0.8226262626262626 Loss: 0.08565114822351572 Corrects: 4072\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.08854705095291138\n",
            "Train step - Step 2430, Loss 0.0865972638130188\n",
            "Train step - Step 2440, Loss 0.07710658013820648\n",
            "Train step - Step 2450, Loss 0.08915778249502182\n",
            "Train epoch - Accuracy: 0.825050505050505 Loss: 0.08537621248852123 Corrects: 4084\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.07952821254730225\n",
            "Train step - Step 2470, Loss 0.08819208294153214\n",
            "Train step - Step 2480, Loss 0.07510031759738922\n",
            "Train step - Step 2490, Loss 0.06636401265859604\n",
            "Train epoch - Accuracy: 0.8381818181818181 Loss: 0.07996044436187455 Corrects: 4149\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.06797005981206894\n",
            "Train step - Step 2510, Loss 0.062215518206357956\n",
            "Train step - Step 2520, Loss 0.06917916983366013\n",
            "Train step - Step 2530, Loss 0.08009730279445648\n",
            "Train epoch - Accuracy: 0.8486868686868687 Loss: 0.07722583026898028 Corrects: 4201\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.07718803733587265\n",
            "Train step - Step 2550, Loss 0.08291938155889511\n",
            "Train step - Step 2560, Loss 0.07791414111852646\n",
            "Train step - Step 2570, Loss 0.082947738468647\n",
            "Train epoch - Accuracy: 0.8442424242424242 Loss: 0.07621843870541062 Corrects: 4179\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.07951584458351135\n",
            "Train step - Step 2590, Loss 0.06740209460258484\n",
            "Train step - Step 2600, Loss 0.07651449739933014\n",
            "Train step - Step 2610, Loss 0.06756939738988876\n",
            "Train epoch - Accuracy: 0.8426262626262626 Loss: 0.07579570272655198 Corrects: 4171\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0632573589682579\n",
            "Train step - Step 2630, Loss 0.07504784315824509\n",
            "Train step - Step 2640, Loss 0.08227324485778809\n",
            "Train step - Step 2650, Loss 0.07490096241235733\n",
            "Train epoch - Accuracy: 0.8490909090909091 Loss: 0.07436500559551547 Corrects: 4203\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.08192681521177292\n",
            "Train step - Step 2670, Loss 0.07400795817375183\n",
            "Train step - Step 2680, Loss 0.0644189864397049\n",
            "Train step - Step 2690, Loss 0.06564687937498093\n",
            "Train epoch - Accuracy: 0.8547474747474747 Loss: 0.074444920863166 Corrects: 4231\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.06764554232358932\n",
            "Train step - Step 2710, Loss 0.07868301123380661\n",
            "Train step - Step 2720, Loss 0.09866678714752197\n",
            "Train epoch - Accuracy: 0.8569696969696969 Loss: 0.0740577302346326 Corrects: 4242\n",
            "Training finished in 215.81697177886963 seconds\n",
            "EVALUATION:  0.72 0.1314542293548584\n",
            "TEST GROUP:  0.784\n",
            "TEST ALL:  0.784\n",
            "GROUP:  2\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.43621358275413513\n",
            "Train step - Step 10, Loss 0.19723787903785706\n",
            "Train step - Step 20, Loss 0.1441306620836258\n",
            "Train step - Step 30, Loss 0.12597061693668365\n",
            "Train epoch - Accuracy: 0.30787878787878786 Loss: 0.16450422788509214 Corrects: 1524\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.11134689301252365\n",
            "Train step - Step 50, Loss 0.08880975097417831\n",
            "Train step - Step 60, Loss 0.08655138313770294\n",
            "Train step - Step 70, Loss 0.09017401188611984\n",
            "Train epoch - Accuracy: 0.5943434343434344 Loss: 0.09298144069584934 Corrects: 2942\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.08626242727041245\n",
            "Train step - Step 90, Loss 0.07399425655603409\n",
            "Train step - Step 100, Loss 0.0816694051027298\n",
            "Train step - Step 110, Loss 0.07246750593185425\n",
            "Train epoch - Accuracy: 0.6666666666666666 Loss: 0.07875120346895371 Corrects: 3300\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.07117562741041183\n",
            "Train step - Step 130, Loss 0.06144166737794876\n",
            "Train step - Step 140, Loss 0.07173510640859604\n",
            "Train step - Step 150, Loss 0.07177235186100006\n",
            "Train epoch - Accuracy: 0.7204040404040404 Loss: 0.0678734816430193 Corrects: 3566\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.0703427642583847\n",
            "Train step - Step 170, Loss 0.05934419855475426\n",
            "Train step - Step 180, Loss 0.05054210498929024\n",
            "Train step - Step 190, Loss 0.06299569457769394\n",
            "Train epoch - Accuracy: 0.7494949494949495 Loss: 0.06087386388068247 Corrects: 3710\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.055044591426849365\n",
            "Train step - Step 210, Loss 0.0518430732190609\n",
            "Train step - Step 220, Loss 0.0402454137802124\n",
            "Train step - Step 230, Loss 0.058990802615880966\n",
            "Train epoch - Accuracy: 0.7822222222222223 Loss: 0.05584821909365028 Corrects: 3872\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.049480412155389786\n",
            "Train step - Step 250, Loss 0.05291314050555229\n",
            "Train step - Step 260, Loss 0.058402951806783676\n",
            "Train step - Step 270, Loss 0.06004086881875992\n",
            "Train epoch - Accuracy: 0.7826262626262627 Loss: 0.05388269840767889 Corrects: 3874\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.05620991066098213\n",
            "Train step - Step 290, Loss 0.04397419095039368\n",
            "Train step - Step 300, Loss 0.04750088229775429\n",
            "Train step - Step 310, Loss 0.042368341237306595\n",
            "Train epoch - Accuracy: 0.8094949494949495 Loss: 0.048925878662954676 Corrects: 4007\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.037077777087688446\n",
            "Train step - Step 330, Loss 0.048144496977329254\n",
            "Train step - Step 340, Loss 0.03739309310913086\n",
            "Train step - Step 350, Loss 0.042621910572052\n",
            "Train epoch - Accuracy: 0.82 Loss: 0.045575145157900725 Corrects: 4059\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.05400129780173302\n",
            "Train step - Step 370, Loss 0.04520733281970024\n",
            "Train step - Step 380, Loss 0.04198594391345978\n",
            "Train epoch - Accuracy: 0.8325252525252526 Loss: 0.04366755080945564 Corrects: 4121\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0384889654815197\n",
            "Train step - Step 400, Loss 0.028272753581404686\n",
            "Train step - Step 410, Loss 0.049518417567014694\n",
            "Train step - Step 420, Loss 0.03958021104335785\n",
            "Train epoch - Accuracy: 0.8484848484848485 Loss: 0.04002841728353741 Corrects: 4200\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.041801124811172485\n",
            "Train step - Step 440, Loss 0.04873955249786377\n",
            "Train step - Step 450, Loss 0.03612695634365082\n",
            "Train step - Step 460, Loss 0.03392210230231285\n",
            "Train epoch - Accuracy: 0.8395959595959596 Loss: 0.04090139392650489 Corrects: 4156\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.044537968933582306\n",
            "Train step - Step 480, Loss 0.031054532155394554\n",
            "Train step - Step 490, Loss 0.041406359523534775\n",
            "Train step - Step 500, Loss 0.028562111780047417\n",
            "Train epoch - Accuracy: 0.8624242424242424 Loss: 0.03610612825236537 Corrects: 4269\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.03355935215950012\n",
            "Train step - Step 520, Loss 0.030875731259584427\n",
            "Train step - Step 530, Loss 0.03633187338709831\n",
            "Train step - Step 540, Loss 0.03545659780502319\n",
            "Train epoch - Accuracy: 0.8696969696969697 Loss: 0.03454759581823542 Corrects: 4305\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.03691210597753525\n",
            "Train step - Step 560, Loss 0.03518025204539299\n",
            "Train step - Step 570, Loss 0.0330512598156929\n",
            "Train step - Step 580, Loss 0.04087352752685547\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.03389010672767957 Corrects: 4326\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.03529682755470276\n",
            "Train step - Step 600, Loss 0.05553710460662842\n",
            "Train step - Step 610, Loss 0.02581923082470894\n",
            "Train step - Step 620, Loss 0.03630422428250313\n",
            "Train epoch - Accuracy: 0.8668686868686869 Loss: 0.034545982197077586 Corrects: 4291\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.02254149131476879\n",
            "Train step - Step 640, Loss 0.030935747548937798\n",
            "Train step - Step 650, Loss 0.031518179923295975\n",
            "Train step - Step 660, Loss 0.034283049404621124\n",
            "Train epoch - Accuracy: 0.8892929292929292 Loss: 0.030028910210186784 Corrects: 4402\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.03325017914175987\n",
            "Train step - Step 680, Loss 0.03762641176581383\n",
            "Train step - Step 690, Loss 0.036476511508226395\n",
            "Train step - Step 700, Loss 0.035250257700681686\n",
            "Train epoch - Accuracy: 0.8785858585858586 Loss: 0.032808904760714734 Corrects: 4349\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.030714793130755424\n",
            "Train step - Step 720, Loss 0.01614193059504032\n",
            "Train step - Step 730, Loss 0.027020586654543877\n",
            "Train step - Step 740, Loss 0.026019413024187088\n",
            "Train epoch - Accuracy: 0.8822222222222222 Loss: 0.03044096663594246 Corrects: 4367\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.03223316743969917\n",
            "Train step - Step 760, Loss 0.02658972702920437\n",
            "Train step - Step 770, Loss 0.020636126399040222\n",
            "Train epoch - Accuracy: 0.8933333333333333 Loss: 0.028667909030360404 Corrects: 4422\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.01813148520886898\n",
            "Train step - Step 790, Loss 0.04758627340197563\n",
            "Train step - Step 800, Loss 0.02438160590827465\n",
            "Train step - Step 810, Loss 0.029538962990045547\n",
            "Train epoch - Accuracy: 0.8896969696969697 Loss: 0.02952880102125081 Corrects: 4404\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.02903842367231846\n",
            "Train step - Step 830, Loss 0.03074570558965206\n",
            "Train step - Step 840, Loss 0.03241106495261192\n",
            "Train step - Step 850, Loss 0.035827334970235825\n",
            "Train epoch - Accuracy: 0.896969696969697 Loss: 0.02799166709861972 Corrects: 4440\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.023740684613585472\n",
            "Train step - Step 870, Loss 0.028325995430350304\n",
            "Train step - Step 880, Loss 0.027695028111338615\n",
            "Train step - Step 890, Loss 0.022304175421595573\n",
            "Train epoch - Accuracy: 0.908080808080808 Loss: 0.02450266402252395 Corrects: 4495\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.01579374633729458\n",
            "Train step - Step 910, Loss 0.026939183473587036\n",
            "Train step - Step 920, Loss 0.03105541504919529\n",
            "Train step - Step 930, Loss 0.032263945788145065\n",
            "Train epoch - Accuracy: 0.9076767676767676 Loss: 0.024827014862587957 Corrects: 4493\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.028335755690932274\n",
            "Train step - Step 950, Loss 0.01734497956931591\n",
            "Train step - Step 960, Loss 0.022239794954657555\n",
            "Train step - Step 970, Loss 0.015826119109988213\n",
            "Train epoch - Accuracy: 0.907070707070707 Loss: 0.025042733092500706 Corrects: 4490\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.011546198278665543\n",
            "Train step - Step 990, Loss 0.030874332413077354\n",
            "Train step - Step 1000, Loss 0.020735612139105797\n",
            "Train step - Step 1010, Loss 0.02606300078332424\n",
            "Train epoch - Accuracy: 0.9117171717171717 Loss: 0.023760044823842818 Corrects: 4513\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.029086386784911156\n",
            "Train step - Step 1030, Loss 0.018685340881347656\n",
            "Train step - Step 1040, Loss 0.024143120273947716\n",
            "Train step - Step 1050, Loss 0.02055913768708706\n",
            "Train epoch - Accuracy: 0.9163636363636364 Loss: 0.022989533305770218 Corrects: 4536\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.020209724083542824\n",
            "Train step - Step 1070, Loss 0.01676712930202484\n",
            "Train step - Step 1080, Loss 0.03230826184153557\n",
            "Train step - Step 1090, Loss 0.021427199244499207\n",
            "Train epoch - Accuracy: 0.925050505050505 Loss: 0.020464615033883037 Corrects: 4579\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.017288709059357643\n",
            "Train step - Step 1110, Loss 0.019781501963734627\n",
            "Train step - Step 1120, Loss 0.03276485204696655\n",
            "Train step - Step 1130, Loss 0.021108077839016914\n",
            "Train epoch - Accuracy: 0.9103030303030303 Loss: 0.02442982988149831 Corrects: 4506\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.025025172159075737\n",
            "Train step - Step 1150, Loss 0.019882163032889366\n",
            "Train step - Step 1160, Loss 0.014348397962749004\n",
            "Train epoch - Accuracy: 0.92 Loss: 0.021976179229189652 Corrects: 4554\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.014892511069774628\n",
            "Train step - Step 1180, Loss 0.017567092552781105\n",
            "Train step - Step 1190, Loss 0.015430070459842682\n",
            "Train step - Step 1200, Loss 0.021029403433203697\n",
            "Train epoch - Accuracy: 0.9107070707070707 Loss: 0.024722879307739663 Corrects: 4508\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.03193051367998123\n",
            "Train step - Step 1220, Loss 0.02332337759435177\n",
            "Train step - Step 1230, Loss 0.02183498814702034\n",
            "Train step - Step 1240, Loss 0.019618062302470207\n",
            "Train epoch - Accuracy: 0.9266666666666666 Loss: 0.020437065736964497 Corrects: 4587\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.016811750829219818\n",
            "Train step - Step 1260, Loss 0.018796049058437347\n",
            "Train step - Step 1270, Loss 0.019809193909168243\n",
            "Train step - Step 1280, Loss 0.018950212746858597\n",
            "Train epoch - Accuracy: 0.9294949494949495 Loss: 0.018980434210312487 Corrects: 4601\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0285548847168684\n",
            "Train step - Step 1300, Loss 0.031826216727495193\n",
            "Train step - Step 1310, Loss 0.02089979685842991\n",
            "Train step - Step 1320, Loss 0.01917451061308384\n",
            "Train epoch - Accuracy: 0.9244444444444444 Loss: 0.021067220394057458 Corrects: 4576\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.01723373495042324\n",
            "Train step - Step 1340, Loss 0.025398483499884605\n",
            "Train step - Step 1350, Loss 0.01315850205719471\n",
            "Train step - Step 1360, Loss 0.02006894163787365\n",
            "Train epoch - Accuracy: 0.9323232323232323 Loss: 0.018993204030575174 Corrects: 4615\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.019572526216506958\n",
            "Train step - Step 1380, Loss 0.0172917190939188\n",
            "Train step - Step 1390, Loss 0.014994420111179352\n",
            "Train step - Step 1400, Loss 0.011679737828671932\n",
            "Train epoch - Accuracy: 0.9406060606060606 Loss: 0.016775533222038338 Corrects: 4656\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.013271157629787922\n",
            "Train step - Step 1420, Loss 0.019267229363322258\n",
            "Train step - Step 1430, Loss 0.021717799827456474\n",
            "Train step - Step 1440, Loss 0.020840873941779137\n",
            "Train epoch - Accuracy: 0.9307070707070707 Loss: 0.019529505366026753 Corrects: 4607\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.02640322409570217\n",
            "Train step - Step 1460, Loss 0.01229782309383154\n",
            "Train step - Step 1470, Loss 0.016775697469711304\n",
            "Train step - Step 1480, Loss 0.023921003565192223\n",
            "Train epoch - Accuracy: 0.9337373737373738 Loss: 0.018372455877487107 Corrects: 4622\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0213702991604805\n",
            "Train step - Step 1500, Loss 0.018088994547724724\n",
            "Train step - Step 1510, Loss 0.01501655112951994\n",
            "Train step - Step 1520, Loss 0.023103630170226097\n",
            "Train epoch - Accuracy: 0.9402020202020202 Loss: 0.016905091231067974 Corrects: 4654\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.01094740815460682\n",
            "Train step - Step 1540, Loss 0.020927144214510918\n",
            "Train step - Step 1550, Loss 0.018584102392196655\n",
            "Train epoch - Accuracy: 0.9385858585858586 Loss: 0.016398468384462777 Corrects: 4646\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.01769404672086239\n",
            "Train step - Step 1570, Loss 0.01590314321219921\n",
            "Train step - Step 1580, Loss 0.01652953028678894\n",
            "Train step - Step 1590, Loss 0.017084365710616112\n",
            "Train epoch - Accuracy: 0.9381818181818182 Loss: 0.017252680331167548 Corrects: 4644\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.013019862584769726\n",
            "Train step - Step 1610, Loss 0.017265209928154945\n",
            "Train step - Step 1620, Loss 0.0239561814814806\n",
            "Train step - Step 1630, Loss 0.013625112362205982\n",
            "Train epoch - Accuracy: 0.9387878787878788 Loss: 0.016711420442796113 Corrects: 4647\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.015205754898488522\n",
            "Train step - Step 1650, Loss 0.015923526138067245\n",
            "Train step - Step 1660, Loss 0.023299431428313255\n",
            "Train step - Step 1670, Loss 0.015426987782120705\n",
            "Train epoch - Accuracy: 0.9424242424242424 Loss: 0.016062379342061704 Corrects: 4665\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.017604080960154533\n",
            "Train step - Step 1690, Loss 0.01168620865792036\n",
            "Train step - Step 1700, Loss 0.01338257547467947\n",
            "Train step - Step 1710, Loss 0.02524244785308838\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.01648882027376782 Corrects: 4658\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.010610457509756088\n",
            "Train step - Step 1730, Loss 0.015332981012761593\n",
            "Train step - Step 1740, Loss 0.0219224002212286\n",
            "Train step - Step 1750, Loss 0.014344307594001293\n",
            "Train epoch - Accuracy: 0.935959595959596 Loss: 0.017550338418646293 Corrects: 4633\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.01307159848511219\n",
            "Train step - Step 1770, Loss 0.024208350107073784\n",
            "Train step - Step 1780, Loss 0.012591905891895294\n",
            "Train step - Step 1790, Loss 0.011533181183040142\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.0149218395239476 Corrects: 4703\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.013373279944062233\n",
            "Train step - Step 1810, Loss 0.010592524893581867\n",
            "Train step - Step 1820, Loss 0.011502021923661232\n",
            "Train step - Step 1830, Loss 0.015102875418961048\n",
            "Train epoch - Accuracy: 0.9466666666666667 Loss: 0.015407604025394627 Corrects: 4686\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.018075566738843918\n",
            "Train step - Step 1850, Loss 0.01159659679979086\n",
            "Train step - Step 1860, Loss 0.024866169318556786\n",
            "Train step - Step 1870, Loss 0.024321040138602257\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.013592350967980997 Corrects: 4706\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.012100143358111382\n",
            "Train step - Step 1890, Loss 0.01169552095234394\n",
            "Train step - Step 1900, Loss 0.014691372402012348\n",
            "Train step - Step 1910, Loss 0.008189456537365913\n",
            "Train epoch - Accuracy: 0.9527272727272728 Loss: 0.01378784452047613 Corrects: 4716\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.020608413964509964\n",
            "Train step - Step 1930, Loss 0.01109799463301897\n",
            "Train step - Step 1940, Loss 0.007594217546284199\n",
            "Train epoch - Accuracy: 0.9701010101010101 Loss: 0.009688284748958217 Corrects: 4802\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.005473881959915161\n",
            "Train step - Step 1960, Loss 0.004556467290967703\n",
            "Train step - Step 1970, Loss 0.0061697508208453655\n",
            "Train step - Step 1980, Loss 0.0051711625419557095\n",
            "Train epoch - Accuracy: 0.9818181818181818 Loss: 0.005957656549948334 Corrects: 4860\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.003742055268958211\n",
            "Train step - Step 2000, Loss 0.004962307401001453\n",
            "Train step - Step 2010, Loss 0.0033334679901599884\n",
            "Train step - Step 2020, Loss 0.006258602719753981\n",
            "Train epoch - Accuracy: 0.9848484848484849 Loss: 0.005490855975735067 Corrects: 4875\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.007871541194617748\n",
            "Train step - Step 2040, Loss 0.0035395887680351734\n",
            "Train step - Step 2050, Loss 0.0089413495734334\n",
            "Train step - Step 2060, Loss 0.00291049899533391\n",
            "Train epoch - Accuracy: 0.9854545454545455 Loss: 0.005048072408658988 Corrects: 4878\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.003033221932128072\n",
            "Train step - Step 2080, Loss 0.0026515924837440252\n",
            "Train step - Step 2090, Loss 0.004427596926689148\n",
            "Train step - Step 2100, Loss 0.0034634419716894627\n",
            "Train epoch - Accuracy: 0.9876767676767677 Loss: 0.004582871449829051 Corrects: 4889\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.004158479161560535\n",
            "Train step - Step 2120, Loss 0.006623177323490381\n",
            "Train step - Step 2130, Loss 0.003304483136162162\n",
            "Train step - Step 2140, Loss 0.003398037049919367\n",
            "Train epoch - Accuracy: 0.9882828282828283 Loss: 0.004208137648876268 Corrects: 4892\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0025971734430640936\n",
            "Train step - Step 2160, Loss 0.0022685157600790262\n",
            "Train step - Step 2170, Loss 0.0021664767991751432\n",
            "Train step - Step 2180, Loss 0.006645399611443281\n",
            "Train epoch - Accuracy: 0.9892929292929293 Loss: 0.004083091863007708 Corrects: 4897\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0022943911608308554\n",
            "Train step - Step 2200, Loss 0.0027023942675441504\n",
            "Train step - Step 2210, Loss 0.002150867134332657\n",
            "Train step - Step 2220, Loss 0.005716688930988312\n",
            "Train epoch - Accuracy: 0.9894949494949495 Loss: 0.0037679625682608044 Corrects: 4898\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.006686262786388397\n",
            "Train step - Step 2240, Loss 0.0035907623823732138\n",
            "Train step - Step 2250, Loss 0.002896300982683897\n",
            "Train step - Step 2260, Loss 0.005004240199923515\n",
            "Train epoch - Accuracy: 0.990909090909091 Loss: 0.003832526968773266 Corrects: 4905\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.00766034284606576\n",
            "Train step - Step 2280, Loss 0.005878295749425888\n",
            "Train step - Step 2290, Loss 0.0026190446224063635\n",
            "Train step - Step 2300, Loss 0.005234870593994856\n",
            "Train epoch - Accuracy: 0.9901010101010101 Loss: 0.0035268102384953186 Corrects: 4901\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0037603669334203005\n",
            "Train step - Step 2320, Loss 0.005443664733320475\n",
            "Train step - Step 2330, Loss 0.0016330209327861667\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0030077573973121066 Corrects: 4916\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.004560159984976053\n",
            "Train step - Step 2350, Loss 0.003398110391572118\n",
            "Train step - Step 2360, Loss 0.002765980316326022\n",
            "Train step - Step 2370, Loss 0.0018701173830777407\n",
            "Train epoch - Accuracy: 0.9927272727272727 Loss: 0.0031404793574804006 Corrects: 4914\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00330012827180326\n",
            "Train step - Step 2390, Loss 0.006523838732391596\n",
            "Train step - Step 2400, Loss 0.0033985942136496305\n",
            "Train step - Step 2410, Loss 0.0035779804456979036\n",
            "Train epoch - Accuracy: 0.9919191919191919 Loss: 0.0029675588324063955 Corrects: 4910\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0020752425771206617\n",
            "Train step - Step 2430, Loss 0.0008793192100711167\n",
            "Train step - Step 2440, Loss 0.005264258477836847\n",
            "Train step - Step 2450, Loss 0.0013650000328198075\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0027117378253376846 Corrects: 4916\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0026444809045642614\n",
            "Train step - Step 2470, Loss 0.0032144745346158743\n",
            "Train step - Step 2480, Loss 0.0021122461184859276\n",
            "Train step - Step 2490, Loss 0.0011686010984703898\n",
            "Train epoch - Accuracy: 0.9949494949494949 Loss: 0.002424538148933965 Corrects: 4925\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.000918192439712584\n",
            "Train step - Step 2510, Loss 0.0033884623553603888\n",
            "Train step - Step 2520, Loss 0.0030889026820659637\n",
            "Train step - Step 2530, Loss 0.0034222565591335297\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0021994764191531247 Corrects: 4928\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.004244671668857336\n",
            "Train step - Step 2550, Loss 0.001727201626636088\n",
            "Train step - Step 2560, Loss 0.0018305398989468813\n",
            "Train step - Step 2570, Loss 0.0007458640029653907\n",
            "Train epoch - Accuracy: 0.9947474747474747 Loss: 0.0025175986623372695 Corrects: 4924\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.003515389282256365\n",
            "Train step - Step 2590, Loss 0.002949861576780677\n",
            "Train step - Step 2600, Loss 0.0018750190502032638\n",
            "Train step - Step 2610, Loss 0.0013488441472873092\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.001883994617823963 Corrects: 4936\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0009030838846229017\n",
            "Train step - Step 2630, Loss 0.0024695422034710646\n",
            "Train step - Step 2640, Loss 0.0012306093703955412\n",
            "Train step - Step 2650, Loss 0.0011853001778945327\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.002012283977008227 Corrects: 4935\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.005540012381970882\n",
            "Train step - Step 2670, Loss 0.0038129822351038456\n",
            "Train step - Step 2680, Loss 0.0015687075210735202\n",
            "Train step - Step 2690, Loss 0.002538022818043828\n",
            "Train epoch - Accuracy: 0.9945454545454545 Loss: 0.002439228245762713 Corrects: 4923\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0016144581604748964\n",
            "Train step - Step 2710, Loss 0.002139130374416709\n",
            "Train step - Step 2720, Loss 0.0012347073061391711\n",
            "Train epoch - Accuracy: 0.9947474747474747 Loss: 0.002322573833675547 Corrects: 4924\n",
            "Training finished in 215.69706058502197 seconds\n",
            "EVALUATION:  0.94 0.02906498685479164\n",
            "TEST GROUP:  0.902\n",
            "TEST ALL:  0.451\n",
            "GROUP:  3\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.3675967752933502\n",
            "Train step - Step 10, Loss 0.11711596697568893\n",
            "Train step - Step 20, Loss 0.08923394978046417\n",
            "Train step - Step 30, Loss 0.07793808728456497\n",
            "Train epoch - Accuracy: 0.3242424242424242 Loss: 0.11169754788731084 Corrects: 1605\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.06608114391565323\n",
            "Train step - Step 50, Loss 0.06326144933700562\n",
            "Train step - Step 60, Loss 0.06539236009120941\n",
            "Train step - Step 70, Loss 0.06383680552244186\n",
            "Train epoch - Accuracy: 0.5741414141414142 Loss: 0.06347808490798931 Corrects: 2842\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.0569925419986248\n",
            "Train step - Step 90, Loss 0.05084037780761719\n",
            "Train step - Step 100, Loss 0.054940011352300644\n",
            "Train step - Step 110, Loss 0.05766461044549942\n",
            "Train epoch - Accuracy: 0.6555555555555556 Loss: 0.05387346666720178 Corrects: 3245\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.044205956161022186\n",
            "Train step - Step 130, Loss 0.055614959448575974\n",
            "Train step - Step 140, Loss 0.047344330698251724\n",
            "Train step - Step 150, Loss 0.036651384085416794\n",
            "Train epoch - Accuracy: 0.7022222222222222 Loss: 0.04798760145752117 Corrects: 3476\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.04536525160074234\n",
            "Train step - Step 170, Loss 0.04639727622270584\n",
            "Train step - Step 180, Loss 0.04908308386802673\n",
            "Train step - Step 190, Loss 0.04090164229273796\n",
            "Train epoch - Accuracy: 0.7329292929292929 Loss: 0.043637236719480665 Corrects: 3628\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.03511764481663704\n",
            "Train step - Step 210, Loss 0.032896023243665695\n",
            "Train step - Step 220, Loss 0.03279223293066025\n",
            "Train step - Step 230, Loss 0.038566332310438156\n",
            "Train epoch - Accuracy: 0.7696969696969697 Loss: 0.039332385221214 Corrects: 3810\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.03731859475374222\n",
            "Train step - Step 250, Loss 0.04071095213294029\n",
            "Train step - Step 260, Loss 0.034059733152389526\n",
            "Train step - Step 270, Loss 0.03475591540336609\n",
            "Train epoch - Accuracy: 0.7802020202020202 Loss: 0.03708231007360449 Corrects: 3862\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.03233973681926727\n",
            "Train step - Step 290, Loss 0.031820472329854965\n",
            "Train step - Step 300, Loss 0.03386250510811806\n",
            "Train step - Step 310, Loss 0.035250820219516754\n",
            "Train epoch - Accuracy: 0.8028282828282828 Loss: 0.034060724907451205 Corrects: 3974\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.02424674667418003\n",
            "Train step - Step 330, Loss 0.024255400523543358\n",
            "Train step - Step 340, Loss 0.026824209839105606\n",
            "Train step - Step 350, Loss 0.03405914455652237\n",
            "Train epoch - Accuracy: 0.8197979797979797 Loss: 0.031204019312304678 Corrects: 4058\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.030621372163295746\n",
            "Train step - Step 370, Loss 0.03249971568584442\n",
            "Train step - Step 380, Loss 0.02649952471256256\n",
            "Train epoch - Accuracy: 0.8222222222222222 Loss: 0.031228689044111906 Corrects: 4070\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.02626054733991623\n",
            "Train step - Step 400, Loss 0.030238671228289604\n",
            "Train step - Step 410, Loss 0.032381754368543625\n",
            "Train step - Step 420, Loss 0.027460450306534767\n",
            "Train epoch - Accuracy: 0.8248484848484848 Loss: 0.030277964840031632 Corrects: 4083\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.019438419491052628\n",
            "Train step - Step 440, Loss 0.023291090503335\n",
            "Train step - Step 450, Loss 0.028172755613923073\n",
            "Train step - Step 460, Loss 0.031506821513175964\n",
            "Train epoch - Accuracy: 0.8347474747474748 Loss: 0.028472532861009994 Corrects: 4132\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.026041289791464806\n",
            "Train step - Step 480, Loss 0.02743278071284294\n",
            "Train step - Step 490, Loss 0.023676307871937752\n",
            "Train step - Step 500, Loss 0.024437837302684784\n",
            "Train epoch - Accuracy: 0.8474747474747475 Loss: 0.025916242495630726 Corrects: 4195\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.015993157401680946\n",
            "Train step - Step 520, Loss 0.02431894652545452\n",
            "Train step - Step 530, Loss 0.018198423087596893\n",
            "Train step - Step 540, Loss 0.03120039775967598\n",
            "Train epoch - Accuracy: 0.8575757575757575 Loss: 0.02559925394001031 Corrects: 4245\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.023162581026554108\n",
            "Train step - Step 560, Loss 0.024708516895771027\n",
            "Train step - Step 570, Loss 0.022308072075247765\n",
            "Train step - Step 580, Loss 0.027825845405459404\n",
            "Train epoch - Accuracy: 0.8545454545454545 Loss: 0.025383903439899887 Corrects: 4230\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.02591019682586193\n",
            "Train step - Step 600, Loss 0.01783001981675625\n",
            "Train step - Step 610, Loss 0.02376808412373066\n",
            "Train step - Step 620, Loss 0.022512780502438545\n",
            "Train epoch - Accuracy: 0.8715151515151515 Loss: 0.022750966183916487 Corrects: 4314\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.02360539697110653\n",
            "Train step - Step 640, Loss 0.024295711889863014\n",
            "Train step - Step 650, Loss 0.02523895353078842\n",
            "Train step - Step 660, Loss 0.019600512459874153\n",
            "Train epoch - Accuracy: 0.8787878787878788 Loss: 0.02174540882309278 Corrects: 4350\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.015643548220396042\n",
            "Train step - Step 680, Loss 0.02707662805914879\n",
            "Train step - Step 690, Loss 0.019621185958385468\n",
            "Train step - Step 700, Loss 0.030692771077156067\n",
            "Train epoch - Accuracy: 0.8694949494949495 Loss: 0.02346674315104581 Corrects: 4304\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.02661343663930893\n",
            "Train step - Step 720, Loss 0.01519637368619442\n",
            "Train step - Step 730, Loss 0.025448493659496307\n",
            "Train step - Step 740, Loss 0.02700825408101082\n",
            "Train epoch - Accuracy: 0.8806060606060606 Loss: 0.02091774951177414 Corrects: 4359\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.02035331353545189\n",
            "Train step - Step 760, Loss 0.016258906573057175\n",
            "Train step - Step 770, Loss 0.015513565391302109\n",
            "Train epoch - Accuracy: 0.8909090909090909 Loss: 0.019306488013779273 Corrects: 4410\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.015350881963968277\n",
            "Train step - Step 790, Loss 0.022454367950558662\n",
            "Train step - Step 800, Loss 0.013110995292663574\n",
            "Train step - Step 810, Loss 0.019251976162195206\n",
            "Train epoch - Accuracy: 0.8913131313131313 Loss: 0.019579224746787187 Corrects: 4412\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.020911650732159615\n",
            "Train step - Step 830, Loss 0.01856783777475357\n",
            "Train step - Step 840, Loss 0.017197029665112495\n",
            "Train step - Step 850, Loss 0.01757632941007614\n",
            "Train epoch - Accuracy: 0.9004040404040404 Loss: 0.01830112945476566 Corrects: 4457\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.01592567376792431\n",
            "Train step - Step 870, Loss 0.018448060378432274\n",
            "Train step - Step 880, Loss 0.015843039378523827\n",
            "Train step - Step 890, Loss 0.01799320988357067\n",
            "Train epoch - Accuracy: 0.9046464646464647 Loss: 0.01739675854643186 Corrects: 4478\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.018235808238387108\n",
            "Train step - Step 910, Loss 0.01801910065114498\n",
            "Train step - Step 920, Loss 0.019158629700541496\n",
            "Train step - Step 930, Loss 0.021686915308237076\n",
            "Train epoch - Accuracy: 0.9028282828282829 Loss: 0.018026034790608617 Corrects: 4469\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.02216256596148014\n",
            "Train step - Step 950, Loss 0.012634008191525936\n",
            "Train step - Step 960, Loss 0.019236084073781967\n",
            "Train step - Step 970, Loss 0.013474630191922188\n",
            "Train epoch - Accuracy: 0.9024242424242425 Loss: 0.01763847264602329 Corrects: 4467\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.020283054560422897\n",
            "Train step - Step 990, Loss 0.013081047683954239\n",
            "Train step - Step 1000, Loss 0.021038111299276352\n",
            "Train step - Step 1010, Loss 0.0137363001704216\n",
            "Train epoch - Accuracy: 0.9 Loss: 0.01792709946782902 Corrects: 4455\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.014548338949680328\n",
            "Train step - Step 1030, Loss 0.01301953662186861\n",
            "Train step - Step 1040, Loss 0.01152885239571333\n",
            "Train step - Step 1050, Loss 0.023010218515992165\n",
            "Train epoch - Accuracy: 0.916969696969697 Loss: 0.0151658173985403 Corrects: 4539\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.012452781200408936\n",
            "Train step - Step 1070, Loss 0.015871256589889526\n",
            "Train step - Step 1080, Loss 0.016948439180850983\n",
            "Train step - Step 1090, Loss 0.018362630158662796\n",
            "Train epoch - Accuracy: 0.9092929292929293 Loss: 0.016140466514937203 Corrects: 4501\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.009132773615419865\n",
            "Train step - Step 1110, Loss 0.009820296429097652\n",
            "Train step - Step 1120, Loss 0.016943149268627167\n",
            "Train step - Step 1130, Loss 0.01844477467238903\n",
            "Train epoch - Accuracy: 0.9224242424242424 Loss: 0.01449300883168524 Corrects: 4566\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.010838291607797146\n",
            "Train step - Step 1150, Loss 0.012392129749059677\n",
            "Train step - Step 1160, Loss 0.013599151745438576\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.014099273432911646 Corrects: 4555\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.011361302807927132\n",
            "Train step - Step 1180, Loss 0.01281516719609499\n",
            "Train step - Step 1190, Loss 0.014257747679948807\n",
            "Train step - Step 1200, Loss 0.012077325955033302\n",
            "Train epoch - Accuracy: 0.9252525252525252 Loss: 0.014169533565038382 Corrects: 4580\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.017050737515091896\n",
            "Train step - Step 1220, Loss 0.011937052011489868\n",
            "Train step - Step 1230, Loss 0.015904292464256287\n",
            "Train step - Step 1240, Loss 0.015514262951910496\n",
            "Train epoch - Accuracy: 0.9246464646464646 Loss: 0.014427222635860396 Corrects: 4577\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.013617713004350662\n",
            "Train step - Step 1260, Loss 0.012212160043418407\n",
            "Train step - Step 1270, Loss 0.010305728763341904\n",
            "Train step - Step 1280, Loss 0.014456029050052166\n",
            "Train epoch - Accuracy: 0.9226262626262626 Loss: 0.013863264953322484 Corrects: 4567\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.010819357819855213\n",
            "Train step - Step 1300, Loss 0.010256817564368248\n",
            "Train step - Step 1310, Loss 0.00968532171100378\n",
            "Train step - Step 1320, Loss 0.011294564232230186\n",
            "Train epoch - Accuracy: 0.9307070707070707 Loss: 0.01272565223276615 Corrects: 4607\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.014506655745208263\n",
            "Train step - Step 1340, Loss 0.011223872192203999\n",
            "Train step - Step 1350, Loss 0.01001705601811409\n",
            "Train step - Step 1360, Loss 0.013764449395239353\n",
            "Train epoch - Accuracy: 0.9365656565656566 Loss: 0.01235737712658716 Corrects: 4636\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.013697006739675999\n",
            "Train step - Step 1380, Loss 0.009916920214891434\n",
            "Train step - Step 1390, Loss 0.009920514188706875\n",
            "Train step - Step 1400, Loss 0.009643024764955044\n",
            "Train epoch - Accuracy: 0.934949494949495 Loss: 0.012357329909097065 Corrects: 4628\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.014822538010776043\n",
            "Train step - Step 1420, Loss 0.013246445916593075\n",
            "Train step - Step 1430, Loss 0.0249895378947258\n",
            "Train step - Step 1440, Loss 0.008965156972408295\n",
            "Train epoch - Accuracy: 0.9262626262626262 Loss: 0.013345150209662288 Corrects: 4585\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.016077304258942604\n",
            "Train step - Step 1460, Loss 0.0074865552596747875\n",
            "Train step - Step 1470, Loss 0.010942921042442322\n",
            "Train step - Step 1480, Loss 0.013065747916698456\n",
            "Train epoch - Accuracy: 0.9432323232323232 Loss: 0.010974794045993776 Corrects: 4669\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.007921794429421425\n",
            "Train step - Step 1500, Loss 0.008630524389445782\n",
            "Train step - Step 1510, Loss 0.009999989531934261\n",
            "Train step - Step 1520, Loss 0.012828522361814976\n",
            "Train epoch - Accuracy: 0.9448484848484848 Loss: 0.011198191276629164 Corrects: 4677\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.009730740450322628\n",
            "Train step - Step 1540, Loss 0.008794971741735935\n",
            "Train step - Step 1550, Loss 0.010127149522304535\n",
            "Train epoch - Accuracy: 0.9395959595959597 Loss: 0.011174149356707177 Corrects: 4651\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.006319667212665081\n",
            "Train step - Step 1570, Loss 0.012081545777618885\n",
            "Train step - Step 1580, Loss 0.00976024754345417\n",
            "Train step - Step 1590, Loss 0.01278728898614645\n",
            "Train epoch - Accuracy: 0.9385858585858586 Loss: 0.011374947760592807 Corrects: 4646\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.009410872124135494\n",
            "Train step - Step 1610, Loss 0.01327222865074873\n",
            "Train step - Step 1620, Loss 0.021975411102175713\n",
            "Train step - Step 1630, Loss 0.01462582964450121\n",
            "Train epoch - Accuracy: 0.9385858585858586 Loss: 0.012103827689031158 Corrects: 4646\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.013128513470292091\n",
            "Train step - Step 1650, Loss 0.011457892134785652\n",
            "Train step - Step 1660, Loss 0.010625241324305534\n",
            "Train step - Step 1670, Loss 0.0056382124312222\n",
            "Train epoch - Accuracy: 0.9418181818181818 Loss: 0.010821059125691953 Corrects: 4662\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0062022400088608265\n",
            "Train step - Step 1690, Loss 0.011379309929907322\n",
            "Train step - Step 1700, Loss 0.014479017816483974\n",
            "Train step - Step 1710, Loss 0.005049019120633602\n",
            "Train epoch - Accuracy: 0.9519191919191919 Loss: 0.00944324692523088 Corrects: 4712\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.012013087049126625\n",
            "Train step - Step 1730, Loss 0.01584698259830475\n",
            "Train step - Step 1740, Loss 0.00826090108603239\n",
            "Train step - Step 1750, Loss 0.011037585325539112\n",
            "Train epoch - Accuracy: 0.943030303030303 Loss: 0.010890986031354076 Corrects: 4668\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.023423487320542336\n",
            "Train step - Step 1770, Loss 0.013105444610118866\n",
            "Train step - Step 1780, Loss 0.007919522933661938\n",
            "Train step - Step 1790, Loss 0.00933796912431717\n",
            "Train epoch - Accuracy: 0.9375757575757576 Loss: 0.011679878395163651 Corrects: 4641\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.00987398810684681\n",
            "Train step - Step 1810, Loss 0.01126632560044527\n",
            "Train step - Step 1820, Loss 0.007243866566568613\n",
            "Train step - Step 1830, Loss 0.010533411987125874\n",
            "Train epoch - Accuracy: 0.9454545454545454 Loss: 0.01017932421217362 Corrects: 4680\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.007837193086743355\n",
            "Train step - Step 1850, Loss 0.010787470266222954\n",
            "Train step - Step 1860, Loss 0.011690233834087849\n",
            "Train step - Step 1870, Loss 0.012349413707852364\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.009349795029395156 Corrects: 4706\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.005759625229984522\n",
            "Train step - Step 1890, Loss 0.006606701295822859\n",
            "Train step - Step 1900, Loss 0.007535744924098253\n",
            "Train step - Step 1910, Loss 0.021682534366846085\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.009277100025704412 Corrects: 4715\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.005013762507587671\n",
            "Train step - Step 1930, Loss 0.006379346363246441\n",
            "Train step - Step 1940, Loss 0.0033949476201087236\n",
            "Train epoch - Accuracy: 0.9705050505050505 Loss: 0.006275216947601299 Corrects: 4804\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.003023124998435378\n",
            "Train step - Step 1960, Loss 0.002309908624738455\n",
            "Train step - Step 1970, Loss 0.0035917069762945175\n",
            "Train step - Step 1980, Loss 0.0034928566310554743\n",
            "Train epoch - Accuracy: 0.9890909090909091 Loss: 0.0032340499372550784 Corrects: 4896\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.002790834754705429\n",
            "Train step - Step 2000, Loss 0.002051290590316057\n",
            "Train step - Step 2010, Loss 0.004792888183146715\n",
            "Train step - Step 2020, Loss 0.0015630454290658236\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0032598836965049907 Corrects: 4886\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.001249297522008419\n",
            "Train step - Step 2040, Loss 0.0020431214943528175\n",
            "Train step - Step 2050, Loss 0.00591867882758379\n",
            "Train step - Step 2060, Loss 0.0033404710702598095\n",
            "Train epoch - Accuracy: 0.990909090909091 Loss: 0.0026642781238287987 Corrects: 4905\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0029929231386631727\n",
            "Train step - Step 2080, Loss 0.003909752704203129\n",
            "Train step - Step 2090, Loss 0.0015338986413553357\n",
            "Train step - Step 2100, Loss 0.0012513238471001387\n",
            "Train epoch - Accuracy: 0.98989898989899 Loss: 0.0027107274319713164 Corrects: 4900\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0017527537420392036\n",
            "Train step - Step 2120, Loss 0.003661931259557605\n",
            "Train step - Step 2130, Loss 0.0023622498847544193\n",
            "Train step - Step 2140, Loss 0.0012183269718661904\n",
            "Train epoch - Accuracy: 0.9929292929292929 Loss: 0.0022785578657769493 Corrects: 4915\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.004484427627176046\n",
            "Train step - Step 2160, Loss 0.0022910188417881727\n",
            "Train step - Step 2170, Loss 0.0018308820435777307\n",
            "Train step - Step 2180, Loss 0.0024934757966548204\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0021288659030364618 Corrects: 4916\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0019279348198324442\n",
            "Train step - Step 2200, Loss 0.0006579366163350642\n",
            "Train step - Step 2210, Loss 0.0015038616256788373\n",
            "Train step - Step 2220, Loss 0.0012149681570008397\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0018217524008430316 Corrects: 4928\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0016896306769922376\n",
            "Train step - Step 2240, Loss 0.001624968135729432\n",
            "Train step - Step 2250, Loss 0.000928158056922257\n",
            "Train step - Step 2260, Loss 0.0015097028808668256\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0018092035845091398 Corrects: 4921\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0023050957825034857\n",
            "Train step - Step 2280, Loss 0.0017985185841098428\n",
            "Train step - Step 2290, Loss 0.0020249502267688513\n",
            "Train step - Step 2300, Loss 0.0011267894878983498\n",
            "Train epoch - Accuracy: 0.9937373737373737 Loss: 0.0018942844397341362 Corrects: 4919\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0013568442082032561\n",
            "Train step - Step 2320, Loss 0.0016690961783751845\n",
            "Train step - Step 2330, Loss 0.00146387773565948\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0017045768912919241 Corrects: 4928\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0011679654708132148\n",
            "Train step - Step 2350, Loss 0.000989576568827033\n",
            "Train step - Step 2360, Loss 0.0015537108993157744\n",
            "Train step - Step 2370, Loss 0.0011047706939280033\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0014943128311536227 Corrects: 4937\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0019960817880928516\n",
            "Train step - Step 2390, Loss 0.00206641829572618\n",
            "Train step - Step 2400, Loss 0.0015859048580750823\n",
            "Train step - Step 2410, Loss 0.002177288057282567\n",
            "Train epoch - Accuracy: 0.9959595959595959 Loss: 0.0015437458274001727 Corrects: 4930\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0005663319607265294\n",
            "Train step - Step 2430, Loss 0.0015960013261064887\n",
            "Train step - Step 2440, Loss 0.0007900171331129968\n",
            "Train step - Step 2450, Loss 0.002643872518092394\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0016353948566723954 Corrects: 4921\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0006684661493636668\n",
            "Train step - Step 2470, Loss 0.0011849857401102781\n",
            "Train step - Step 2480, Loss 0.0036348907742649317\n",
            "Train step - Step 2490, Loss 0.001452223863452673\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.001442133817690039 Corrects: 4931\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0007647860911674798\n",
            "Train step - Step 2510, Loss 0.0022766089532524347\n",
            "Train step - Step 2520, Loss 0.0006559398025274277\n",
            "Train step - Step 2530, Loss 0.0008544879965484142\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0011967313811747414 Corrects: 4937\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.002166150603443384\n",
            "Train step - Step 2550, Loss 0.0007909386768005788\n",
            "Train step - Step 2560, Loss 0.001812193775549531\n",
            "Train step - Step 2570, Loss 0.0007370769744738936\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0013144017407915208 Corrects: 4933\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0003742189728654921\n",
            "Train step - Step 2590, Loss 0.0007194048375822604\n",
            "Train step - Step 2600, Loss 0.0019291964126750827\n",
            "Train step - Step 2610, Loss 0.00048923643771559\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0011945793916932261 Corrects: 4939\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0006513961125165224\n",
            "Train step - Step 2630, Loss 0.000730261905118823\n",
            "Train step - Step 2640, Loss 0.0006704207044094801\n",
            "Train step - Step 2650, Loss 0.0009126201621256769\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00112638030022458 Corrects: 4937\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0012308744480833411\n",
            "Train step - Step 2670, Loss 0.0011373806046321988\n",
            "Train step - Step 2680, Loss 0.0018470467766746879\n",
            "Train step - Step 2690, Loss 0.0029420307837426662\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.001323297137601508 Corrects: 4933\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0009781012777239084\n",
            "Train step - Step 2710, Loss 0.001626618206501007\n",
            "Train step - Step 2720, Loss 0.0006171210552565753\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.0011774942806611459 Corrects: 4940\n",
            "Training finished in 213.10378170013428 seconds\n",
            "EVALUATION:  0.9 0.01720186322927475\n",
            "TEST GROUP:  0.865\n",
            "TEST ALL:  0.28833333333333333\n",
            "GROUP:  4\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.2552151381969452\n",
            "Train step - Step 10, Loss 0.09789574146270752\n",
            "Train step - Step 20, Loss 0.06859182566404343\n",
            "Train step - Step 30, Loss 0.05417438969016075\n",
            "Train epoch - Accuracy: 0.337979797979798 Loss: 0.08514394101319891 Corrects: 1673\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.05257058143615723\n",
            "Train step - Step 50, Loss 0.04839283600449562\n",
            "Train step - Step 60, Loss 0.0390111580491066\n",
            "Train step - Step 70, Loss 0.04098166897892952\n",
            "Train epoch - Accuracy: 0.637979797979798 Loss: 0.04299260614345772 Corrects: 3158\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.036836229264736176\n",
            "Train step - Step 90, Loss 0.031836289912462234\n",
            "Train step - Step 100, Loss 0.029109979048371315\n",
            "Train step - Step 110, Loss 0.03570517897605896\n",
            "Train epoch - Accuracy: 0.7276767676767677 Loss: 0.0337153904027108 Corrects: 3602\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.026806000620126724\n",
            "Train step - Step 130, Loss 0.03098326362669468\n",
            "Train step - Step 140, Loss 0.02901935949921608\n",
            "Train step - Step 150, Loss 0.02557450532913208\n",
            "Train epoch - Accuracy: 0.7735353535353535 Loss: 0.028591097465368233 Corrects: 3829\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.02184789441525936\n",
            "Train step - Step 170, Loss 0.02406911365687847\n",
            "Train step - Step 180, Loss 0.027429088950157166\n",
            "Train step - Step 190, Loss 0.021880995482206345\n",
            "Train epoch - Accuracy: 0.8006060606060607 Loss: 0.025713359341025352 Corrects: 3963\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.02130644954741001\n",
            "Train step - Step 210, Loss 0.023051081225275993\n",
            "Train step - Step 220, Loss 0.01972123049199581\n",
            "Train step - Step 230, Loss 0.020224735140800476\n",
            "Train epoch - Accuracy: 0.8254545454545454 Loss: 0.022424954310661615 Corrects: 4086\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.02445252053439617\n",
            "Train step - Step 250, Loss 0.01669064164161682\n",
            "Train step - Step 260, Loss 0.01790737360715866\n",
            "Train step - Step 270, Loss 0.017917130142450333\n",
            "Train epoch - Accuracy: 0.8446464646464646 Loss: 0.020403686405883897 Corrects: 4181\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.015392154455184937\n",
            "Train step - Step 290, Loss 0.014079387299716473\n",
            "Train step - Step 300, Loss 0.016627676784992218\n",
            "Train step - Step 310, Loss 0.025822997093200684\n",
            "Train epoch - Accuracy: 0.8488888888888889 Loss: 0.019387830261028173 Corrects: 4202\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.018511105328798294\n",
            "Train step - Step 330, Loss 0.019265761598944664\n",
            "Train step - Step 340, Loss 0.017557824030518532\n",
            "Train step - Step 350, Loss 0.021939197555184364\n",
            "Train epoch - Accuracy: 0.8705050505050506 Loss: 0.017509831929899224 Corrects: 4309\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.015911759808659554\n",
            "Train step - Step 370, Loss 0.015197048895061016\n",
            "Train step - Step 380, Loss 0.018484119325876236\n",
            "Train epoch - Accuracy: 0.8775757575757576 Loss: 0.0168420832130042 Corrects: 4344\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.012295961380004883\n",
            "Train step - Step 400, Loss 0.012316654436290264\n",
            "Train step - Step 410, Loss 0.014886157587170601\n",
            "Train step - Step 420, Loss 0.011573872528970242\n",
            "Train epoch - Accuracy: 0.8907070707070707 Loss: 0.015440851623060727 Corrects: 4409\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.015336628071963787\n",
            "Train step - Step 440, Loss 0.013705856166779995\n",
            "Train step - Step 450, Loss 0.017251834273338318\n",
            "Train step - Step 460, Loss 0.01404572743922472\n",
            "Train epoch - Accuracy: 0.8870707070707071 Loss: 0.014983451616282414 Corrects: 4391\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.013806234113872051\n",
            "Train step - Step 480, Loss 0.015502582304179668\n",
            "Train step - Step 490, Loss 0.014536368660628796\n",
            "Train step - Step 500, Loss 0.009868010878562927\n",
            "Train epoch - Accuracy: 0.9034343434343435 Loss: 0.013661579010312003 Corrects: 4472\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.013289625756442547\n",
            "Train step - Step 520, Loss 0.013605065643787384\n",
            "Train step - Step 530, Loss 0.012733777053654194\n",
            "Train step - Step 540, Loss 0.01261033583432436\n",
            "Train epoch - Accuracy: 0.8981818181818182 Loss: 0.013119375452850805 Corrects: 4446\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.012941229157149792\n",
            "Train step - Step 560, Loss 0.009363955818116665\n",
            "Train step - Step 570, Loss 0.012832313776016235\n",
            "Train step - Step 580, Loss 0.014423603191971779\n",
            "Train epoch - Accuracy: 0.9018181818181819 Loss: 0.013277318079513732 Corrects: 4464\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.01594018004834652\n",
            "Train step - Step 600, Loss 0.01006433367729187\n",
            "Train step - Step 610, Loss 0.013616770505905151\n",
            "Train step - Step 620, Loss 0.012312362901866436\n",
            "Train epoch - Accuracy: 0.9094949494949495 Loss: 0.012838151707793727 Corrects: 4502\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.008949722163379192\n",
            "Train step - Step 640, Loss 0.012457308359444141\n",
            "Train step - Step 650, Loss 0.013109355233609676\n",
            "Train step - Step 660, Loss 0.015410350635647774\n",
            "Train epoch - Accuracy: 0.9266666666666666 Loss: 0.010839910110590434 Corrects: 4587\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.009853753261268139\n",
            "Train step - Step 680, Loss 0.00982955563813448\n",
            "Train step - Step 690, Loss 0.008462169207632542\n",
            "Train step - Step 700, Loss 0.009824241511523724\n",
            "Train epoch - Accuracy: 0.9246464646464646 Loss: 0.010471317208550796 Corrects: 4577\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.00899880938231945\n",
            "Train step - Step 720, Loss 0.009931588545441628\n",
            "Train step - Step 730, Loss 0.009831494651734829\n",
            "Train step - Step 740, Loss 0.013233941048383713\n",
            "Train epoch - Accuracy: 0.926060606060606 Loss: 0.009845782339271874 Corrects: 4584\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.010239078663289547\n",
            "Train step - Step 760, Loss 0.007403419818729162\n",
            "Train step - Step 770, Loss 0.01521958876401186\n",
            "Train epoch - Accuracy: 0.9303030303030303 Loss: 0.009598109296174965 Corrects: 4605\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.0056306058540940285\n",
            "Train step - Step 790, Loss 0.00825920607894659\n",
            "Train step - Step 800, Loss 0.006616801023483276\n",
            "Train step - Step 810, Loss 0.009997720830142498\n",
            "Train epoch - Accuracy: 0.9351515151515152 Loss: 0.009121206897978832 Corrects: 4629\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.008879899978637695\n",
            "Train step - Step 830, Loss 0.006319610867649317\n",
            "Train step - Step 840, Loss 0.010577787645161152\n",
            "Train step - Step 850, Loss 0.00698809465393424\n",
            "Train epoch - Accuracy: 0.9361616161616162 Loss: 0.009142934483560648 Corrects: 4634\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.006136711221188307\n",
            "Train step - Step 870, Loss 0.005740177817642689\n",
            "Train step - Step 880, Loss 0.008260327391326427\n",
            "Train step - Step 890, Loss 0.008605520240962505\n",
            "Train epoch - Accuracy: 0.9402020202020202 Loss: 0.008815505380619957 Corrects: 4654\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.007822299376130104\n",
            "Train step - Step 910, Loss 0.00708911195397377\n",
            "Train step - Step 920, Loss 0.00848690327256918\n",
            "Train step - Step 930, Loss 0.009396838955581188\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.008522722785633922 Corrects: 4687\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.006228791084140539\n",
            "Train step - Step 950, Loss 0.005960388109087944\n",
            "Train step - Step 960, Loss 0.008434205316007137\n",
            "Train step - Step 970, Loss 0.012516848742961884\n",
            "Train epoch - Accuracy: 0.9456565656565656 Loss: 0.008149002512371299 Corrects: 4681\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.007673963904380798\n",
            "Train step - Step 990, Loss 0.012437517754733562\n",
            "Train step - Step 1000, Loss 0.008804243989288807\n",
            "Train step - Step 1010, Loss 0.007615016307681799\n",
            "Train epoch - Accuracy: 0.9414141414141414 Loss: 0.008038101094878382 Corrects: 4660\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.011390474624931812\n",
            "Train step - Step 1030, Loss 0.007646096404641867\n",
            "Train step - Step 1040, Loss 0.020229032263159752\n",
            "Train step - Step 1050, Loss 0.007374981883913279\n",
            "Train epoch - Accuracy: 0.9391919191919192 Loss: 0.009076690705624795 Corrects: 4649\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.007277254015207291\n",
            "Train step - Step 1070, Loss 0.005654376000165939\n",
            "Train step - Step 1080, Loss 0.006867982447147369\n",
            "Train step - Step 1090, Loss 0.009803633205592632\n",
            "Train epoch - Accuracy: 0.9496969696969697 Loss: 0.0071190951147464794 Corrects: 4701\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.00873616524040699\n",
            "Train step - Step 1110, Loss 0.005609078798443079\n",
            "Train step - Step 1120, Loss 0.01068869512528181\n",
            "Train step - Step 1130, Loss 0.005655555985867977\n",
            "Train epoch - Accuracy: 0.9575757575757575 Loss: 0.006479050055371993 Corrects: 4740\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.007665636483579874\n",
            "Train step - Step 1150, Loss 0.007083266973495483\n",
            "Train step - Step 1160, Loss 0.007963800802826881\n",
            "Train epoch - Accuracy: 0.9488888888888889 Loss: 0.0071930385610521445 Corrects: 4697\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.00933212973177433\n",
            "Train step - Step 1180, Loss 0.006710350513458252\n",
            "Train step - Step 1190, Loss 0.005793231073766947\n",
            "Train step - Step 1200, Loss 0.007262273225933313\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.0070155201777063235 Corrects: 4715\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.004425209015607834\n",
            "Train step - Step 1220, Loss 0.009238379076123238\n",
            "Train step - Step 1230, Loss 0.005847594700753689\n",
            "Train step - Step 1240, Loss 0.005450337193906307\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.006902657203903102 Corrects: 4715\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.009274248033761978\n",
            "Train step - Step 1260, Loss 0.008180777542293072\n",
            "Train step - Step 1270, Loss 0.006372328381985426\n",
            "Train step - Step 1280, Loss 0.010816032998263836\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.007058647245620236 Corrects: 4708\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.005493967793881893\n",
            "Train step - Step 1300, Loss 0.003837065538391471\n",
            "Train step - Step 1310, Loss 0.005651974584907293\n",
            "Train step - Step 1320, Loss 0.004664833191782236\n",
            "Train epoch - Accuracy: 0.9551515151515152 Loss: 0.006617738389306598 Corrects: 4728\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0038699761498719454\n",
            "Train step - Step 1340, Loss 0.008633704856038094\n",
            "Train step - Step 1350, Loss 0.005740751978009939\n",
            "Train step - Step 1360, Loss 0.008073604665696621\n",
            "Train epoch - Accuracy: 0.9492929292929293 Loss: 0.007071637183879361 Corrects: 4699\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0051032970659434795\n",
            "Train step - Step 1380, Loss 0.008822922594845295\n",
            "Train step - Step 1390, Loss 0.009288600645959377\n",
            "Train step - Step 1400, Loss 0.007088105659931898\n",
            "Train epoch - Accuracy: 0.9606060606060606 Loss: 0.006402785319910206 Corrects: 4755\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.00533970957621932\n",
            "Train step - Step 1420, Loss 0.010262622497975826\n",
            "Train step - Step 1430, Loss 0.004300854634493589\n",
            "Train step - Step 1440, Loss 0.007949761115014553\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.006559100802423376 Corrects: 4711\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0039007719606161118\n",
            "Train step - Step 1460, Loss 0.01156542357057333\n",
            "Train step - Step 1470, Loss 0.005508111324161291\n",
            "Train step - Step 1480, Loss 0.010530466213822365\n",
            "Train epoch - Accuracy: 0.9551515151515152 Loss: 0.006944231412777997 Corrects: 4728\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.007192258723080158\n",
            "Train step - Step 1500, Loss 0.0059919352643191814\n",
            "Train step - Step 1510, Loss 0.006232759449630976\n",
            "Train step - Step 1520, Loss 0.0077316127717494965\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.007690115855498747 Corrects: 4703\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.003995393868535757\n",
            "Train step - Step 1540, Loss 0.007658910937607288\n",
            "Train step - Step 1550, Loss 0.0040490226820111275\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.005603608144353135 Corrects: 4758\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.001929180114530027\n",
            "Train step - Step 1570, Loss 0.00379965896718204\n",
            "Train step - Step 1580, Loss 0.003675673855468631\n",
            "Train step - Step 1590, Loss 0.007462553214281797\n",
            "Train epoch - Accuracy: 0.9698989898989899 Loss: 0.0047125461037186055 Corrects: 4801\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0033789537847042084\n",
            "Train step - Step 1610, Loss 0.0048891277983784676\n",
            "Train step - Step 1620, Loss 0.005012057721614838\n",
            "Train step - Step 1630, Loss 0.008157605305314064\n",
            "Train epoch - Accuracy: 0.9701010101010101 Loss: 0.004930185463204228 Corrects: 4802\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.005299034994095564\n",
            "Train step - Step 1650, Loss 0.00838017463684082\n",
            "Train step - Step 1660, Loss 0.0044111767783761024\n",
            "Train step - Step 1670, Loss 0.005344196688383818\n",
            "Train epoch - Accuracy: 0.9626262626262626 Loss: 0.005267914248009523 Corrects: 4765\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.006453573703765869\n",
            "Train step - Step 1690, Loss 0.00444986904039979\n",
            "Train step - Step 1700, Loss 0.00426087761297822\n",
            "Train step - Step 1710, Loss 0.004180843010544777\n",
            "Train epoch - Accuracy: 0.962020202020202 Loss: 0.0055592822674850025 Corrects: 4762\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.004561937879770994\n",
            "Train step - Step 1730, Loss 0.004071040544658899\n",
            "Train step - Step 1740, Loss 0.006466140039265156\n",
            "Train step - Step 1750, Loss 0.004225078038871288\n",
            "Train epoch - Accuracy: 0.9682828282828283 Loss: 0.0048019643863569 Corrects: 4793\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.00558299059048295\n",
            "Train step - Step 1770, Loss 0.0059496015310287476\n",
            "Train step - Step 1780, Loss 0.004748673178255558\n",
            "Train step - Step 1790, Loss 0.0033386300783604383\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.005622586797584187 Corrects: 4769\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.003718433203175664\n",
            "Train step - Step 1810, Loss 0.00399570120498538\n",
            "Train step - Step 1820, Loss 0.005600790958851576\n",
            "Train step - Step 1830, Loss 0.009207084774971008\n",
            "Train epoch - Accuracy: 0.9670707070707071 Loss: 0.0051979112649581044 Corrects: 4787\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.002046161098405719\n",
            "Train step - Step 1850, Loss 0.00519381882622838\n",
            "Train step - Step 1860, Loss 0.00425503496080637\n",
            "Train step - Step 1870, Loss 0.0062598721124231815\n",
            "Train epoch - Accuracy: 0.9682828282828283 Loss: 0.005220050716565715 Corrects: 4793\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.004576969426125288\n",
            "Train step - Step 1890, Loss 0.0031831394881010056\n",
            "Train step - Step 1900, Loss 0.006317976396530867\n",
            "Train step - Step 1910, Loss 0.007174070458859205\n",
            "Train epoch - Accuracy: 0.9664646464646465 Loss: 0.004834597633982246 Corrects: 4784\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0034043416380882263\n",
            "Train step - Step 1930, Loss 0.0018543638288974762\n",
            "Train step - Step 1940, Loss 0.001772252144291997\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0026987491078637165 Corrects: 4886\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0007235720404423773\n",
            "Train step - Step 1960, Loss 0.001619736896827817\n",
            "Train step - Step 1970, Loss 0.0017490339232608676\n",
            "Train step - Step 1980, Loss 0.0021292909514158964\n",
            "Train epoch - Accuracy: 0.9939393939393939 Loss: 0.001628017339178107 Corrects: 4920\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0016726016765460372\n",
            "Train step - Step 2000, Loss 0.0010090477298945189\n",
            "Train step - Step 2010, Loss 0.0004822187765967101\n",
            "Train step - Step 2020, Loss 0.001820235513150692\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.001334644624342521 Corrects: 4927\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0012043699389323592\n",
            "Train step - Step 2040, Loss 0.0015173234278336167\n",
            "Train step - Step 2050, Loss 0.0017130920896306634\n",
            "Train step - Step 2060, Loss 0.0007455440936610103\n",
            "Train epoch - Accuracy: 0.9949494949494949 Loss: 0.0013120062087634296 Corrects: 4925\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0017087598098441958\n",
            "Train step - Step 2080, Loss 0.0006484671612270176\n",
            "Train step - Step 2090, Loss 0.0010113082826137543\n",
            "Train step - Step 2100, Loss 0.0007359767332673073\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0010935738848550528 Corrects: 4927\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.001399437547661364\n",
            "Train step - Step 2120, Loss 0.0017037842189893126\n",
            "Train step - Step 2130, Loss 0.000887652684468776\n",
            "Train step - Step 2140, Loss 0.0009834779193624854\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0009617865022572905 Corrects: 4936\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.00033843537676148117\n",
            "Train step - Step 2160, Loss 0.0004449780099093914\n",
            "Train step - Step 2170, Loss 0.0006734004127793014\n",
            "Train step - Step 2180, Loss 0.0004933366435579956\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.0008629581652525248 Corrects: 4934\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0007554646581411362\n",
            "Train step - Step 2200, Loss 0.0004705824831034988\n",
            "Train step - Step 2210, Loss 0.0008202022290788591\n",
            "Train step - Step 2220, Loss 0.0006456025294028223\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0007558210388606772 Corrects: 4942\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.000660899851936847\n",
            "Train step - Step 2240, Loss 0.0004301907611079514\n",
            "Train step - Step 2250, Loss 0.0005386836128309369\n",
            "Train step - Step 2260, Loss 0.0010415740543976426\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0006934903040199041 Corrects: 4942\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0002770721912384033\n",
            "Train step - Step 2280, Loss 0.0009538069716654718\n",
            "Train step - Step 2290, Loss 0.000471983861643821\n",
            "Train step - Step 2300, Loss 0.0006962292245589197\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0006539460914350595 Corrects: 4942\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0009245816618204117\n",
            "Train step - Step 2320, Loss 0.0004583265690598637\n",
            "Train step - Step 2330, Loss 0.0010978098725900054\n",
            "Train epoch - Accuracy: 0.9997979797979798 Loss: 0.0005917367682735802 Corrects: 4949\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0005037657101638615\n",
            "Train step - Step 2350, Loss 0.0004596230573952198\n",
            "Train step - Step 2360, Loss 0.0003917024878319353\n",
            "Train step - Step 2370, Loss 0.0005736801540479064\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0006124922116710381 Corrects: 4945\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00042600190499797463\n",
            "Train step - Step 2390, Loss 0.00040192491724155843\n",
            "Train step - Step 2400, Loss 0.0008617310086265206\n",
            "Train step - Step 2410, Loss 0.0006123575731180608\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.0006915735450074679 Corrects: 4940\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0006051234086044133\n",
            "Train step - Step 2430, Loss 0.00043948908569291234\n",
            "Train step - Step 2440, Loss 0.00040683289989829063\n",
            "Train step - Step 2450, Loss 0.0006297111394815147\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0005874063454173279 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0007422873168252409\n",
            "Train step - Step 2470, Loss 0.0006793162901885808\n",
            "Train step - Step 2480, Loss 0.0003499687882140279\n",
            "Train step - Step 2490, Loss 0.00028357963310554624\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.000547685099676289 Corrects: 4942\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00021575838036369532\n",
            "Train step - Step 2510, Loss 0.0005428173462860286\n",
            "Train step - Step 2520, Loss 0.00026543409330770373\n",
            "Train step - Step 2530, Loss 0.00040667163557372987\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0005693941431783253 Corrects: 4943\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0003738864907063544\n",
            "Train step - Step 2550, Loss 0.0006167939282022417\n",
            "Train step - Step 2560, Loss 0.0003882245800923556\n",
            "Train step - Step 2570, Loss 0.0003235238546039909\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.0005106831046592708 Corrects: 4948\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0005933464271947742\n",
            "Train step - Step 2590, Loss 0.0005933825159445405\n",
            "Train step - Step 2600, Loss 0.00036534591345116496\n",
            "Train step - Step 2610, Loss 0.000430027925176546\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00046681475882051567 Corrects: 4947\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00038302986649796367\n",
            "Train step - Step 2630, Loss 0.00043150075362063944\n",
            "Train step - Step 2640, Loss 0.0005803744425065815\n",
            "Train step - Step 2650, Loss 0.0003380099660716951\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0004948049557696312 Corrects: 4947\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0004052820149809122\n",
            "Train step - Step 2670, Loss 0.0005849929875694215\n",
            "Train step - Step 2680, Loss 0.0004236186796333641\n",
            "Train step - Step 2690, Loss 0.0007155832718126476\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0005108000475659289 Corrects: 4946\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0003845723404083401\n",
            "Train step - Step 2710, Loss 0.00027894522645510733\n",
            "Train step - Step 2720, Loss 0.0005235648131929338\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0005199300262587841 Corrects: 4945\n",
            "Training finished in 213.18157696723938 seconds\n",
            "EVALUATION:  0.88 0.022113442420959473\n",
            "TEST GROUP:  0.904\n",
            "TEST ALL:  0.226\n",
            "GROUP:  5\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.20948737859725952\n",
            "Train step - Step 10, Loss 0.0793403685092926\n",
            "Train step - Step 20, Loss 0.05541129782795906\n",
            "Train step - Step 30, Loss 0.052005138248205185\n",
            "Train epoch - Accuracy: 0.2795959595959596 Loss: 0.07031914400632935 Corrects: 1384\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.046909116208553314\n",
            "Train step - Step 50, Loss 0.04408122971653938\n",
            "Train step - Step 60, Loss 0.037182994186878204\n",
            "Train step - Step 70, Loss 0.03905229642987251\n",
            "Train epoch - Accuracy: 0.5529292929292929 Loss: 0.03953630797489725 Corrects: 2737\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.03484739735722542\n",
            "Train step - Step 90, Loss 0.03214443475008011\n",
            "Train step - Step 100, Loss 0.038766954094171524\n",
            "Train step - Step 110, Loss 0.027095820754766464\n",
            "Train epoch - Accuracy: 0.6228282828282828 Loss: 0.03405628558361169 Corrects: 3083\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.033598292618989944\n",
            "Train step - Step 130, Loss 0.03233882784843445\n",
            "Train step - Step 140, Loss 0.024925721809267998\n",
            "Train step - Step 150, Loss 0.03243747726082802\n",
            "Train epoch - Accuracy: 0.6781818181818182 Loss: 0.030109494059073805 Corrects: 3357\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.02720082551240921\n",
            "Train step - Step 170, Loss 0.0223922748118639\n",
            "Train step - Step 180, Loss 0.03457134962081909\n",
            "Train step - Step 190, Loss 0.02201572060585022\n",
            "Train epoch - Accuracy: 0.721010101010101 Loss: 0.02676086427737968 Corrects: 3569\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.02492506057024002\n",
            "Train step - Step 210, Loss 0.02292587235569954\n",
            "Train step - Step 220, Loss 0.022630147635936737\n",
            "Train step - Step 230, Loss 0.02406483143568039\n",
            "Train epoch - Accuracy: 0.7482828282828283 Loss: 0.024815901415516633 Corrects: 3704\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.020166348665952682\n",
            "Train step - Step 250, Loss 0.023571742698550224\n",
            "Train step - Step 260, Loss 0.022049201652407646\n",
            "Train step - Step 270, Loss 0.025230588391423225\n",
            "Train epoch - Accuracy: 0.7654545454545455 Loss: 0.02320711011386881 Corrects: 3789\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.018776245415210724\n",
            "Train step - Step 290, Loss 0.026421431452035904\n",
            "Train step - Step 300, Loss 0.0230572409927845\n",
            "Train step - Step 310, Loss 0.019037887454032898\n",
            "Train epoch - Accuracy: 0.7775757575757576 Loss: 0.02215285363522443 Corrects: 3849\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.017708271741867065\n",
            "Train step - Step 330, Loss 0.023464743047952652\n",
            "Train step - Step 340, Loss 0.021166352555155754\n",
            "Train step - Step 350, Loss 0.029818708077073097\n",
            "Train epoch - Accuracy: 0.7973737373737374 Loss: 0.020414907955611596 Corrects: 3947\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.022243790328502655\n",
            "Train step - Step 370, Loss 0.018195664510130882\n",
            "Train step - Step 380, Loss 0.014863277785480022\n",
            "Train epoch - Accuracy: 0.8135353535353536 Loss: 0.01938379745892804 Corrects: 4027\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.015125610865652561\n",
            "Train step - Step 400, Loss 0.01777377724647522\n",
            "Train step - Step 410, Loss 0.02162995934486389\n",
            "Train step - Step 420, Loss 0.01531436201184988\n",
            "Train epoch - Accuracy: 0.821010101010101 Loss: 0.018256093010005324 Corrects: 4064\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.019060220569372177\n",
            "Train step - Step 440, Loss 0.019141405820846558\n",
            "Train step - Step 450, Loss 0.014068816788494587\n",
            "Train step - Step 460, Loss 0.014372984878718853\n",
            "Train epoch - Accuracy: 0.8327272727272728 Loss: 0.017374797394179336 Corrects: 4122\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.019603990018367767\n",
            "Train step - Step 480, Loss 0.01714456081390381\n",
            "Train step - Step 490, Loss 0.02536354400217533\n",
            "Train step - Step 500, Loss 0.01685107871890068\n",
            "Train epoch - Accuracy: 0.8383838383838383 Loss: 0.016960362852221786 Corrects: 4150\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.01229115016758442\n",
            "Train step - Step 520, Loss 0.019822511821985245\n",
            "Train step - Step 530, Loss 0.022343944758176804\n",
            "Train step - Step 540, Loss 0.01232945453375578\n",
            "Train epoch - Accuracy: 0.8551515151515151 Loss: 0.015551159387887127 Corrects: 4233\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.011174281127750874\n",
            "Train step - Step 560, Loss 0.011049768887460232\n",
            "Train step - Step 570, Loss 0.017794238403439522\n",
            "Train step - Step 580, Loss 0.01571580208837986\n",
            "Train epoch - Accuracy: 0.8604040404040404 Loss: 0.015171979261618672 Corrects: 4259\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.016279496252536774\n",
            "Train step - Step 600, Loss 0.014790067449212074\n",
            "Train step - Step 610, Loss 0.017512507736682892\n",
            "Train step - Step 620, Loss 0.009558752179145813\n",
            "Train epoch - Accuracy: 0.8563636363636363 Loss: 0.015032164671580599 Corrects: 4239\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.017858678475022316\n",
            "Train step - Step 640, Loss 0.011720784939825535\n",
            "Train step - Step 650, Loss 0.014838051050901413\n",
            "Train step - Step 660, Loss 0.016330305486917496\n",
            "Train epoch - Accuracy: 0.8654545454545455 Loss: 0.014499394518106876 Corrects: 4284\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.01219942793250084\n",
            "Train step - Step 680, Loss 0.015358067117631435\n",
            "Train step - Step 690, Loss 0.015271184034645557\n",
            "Train step - Step 700, Loss 0.011541835963726044\n",
            "Train epoch - Accuracy: 0.8575757575757575 Loss: 0.01504955871463424 Corrects: 4245\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.01495976373553276\n",
            "Train step - Step 720, Loss 0.013156828470528126\n",
            "Train step - Step 730, Loss 0.01778087206184864\n",
            "Train step - Step 740, Loss 0.016920000314712524\n",
            "Train epoch - Accuracy: 0.8729292929292929 Loss: 0.013691952963068028 Corrects: 4321\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.014437822625041008\n",
            "Train step - Step 760, Loss 0.018188167363405228\n",
            "Train step - Step 770, Loss 0.015475568361580372\n",
            "Train epoch - Accuracy: 0.8658585858585859 Loss: 0.013841383457936422 Corrects: 4286\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.01023582648485899\n",
            "Train step - Step 790, Loss 0.013768013566732407\n",
            "Train step - Step 800, Loss 0.012751124799251556\n",
            "Train step - Step 810, Loss 0.01058112271130085\n",
            "Train epoch - Accuracy: 0.8840404040404041 Loss: 0.012580392161252523 Corrects: 4376\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.008321767672896385\n",
            "Train step - Step 830, Loss 0.013498122803866863\n",
            "Train step - Step 840, Loss 0.01177181489765644\n",
            "Train step - Step 850, Loss 0.015182816423475742\n",
            "Train epoch - Accuracy: 0.8765656565656565 Loss: 0.012855409781890686 Corrects: 4339\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.012164841406047344\n",
            "Train step - Step 870, Loss 0.01116661261767149\n",
            "Train step - Step 880, Loss 0.010265471413731575\n",
            "Train step - Step 890, Loss 0.007947087287902832\n",
            "Train epoch - Accuracy: 0.8937373737373737 Loss: 0.011691228716135628 Corrects: 4424\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.010228997096419334\n",
            "Train step - Step 910, Loss 0.008601206354796886\n",
            "Train step - Step 920, Loss 0.013212362304329872\n",
            "Train step - Step 930, Loss 0.01234458852559328\n",
            "Train epoch - Accuracy: 0.8917171717171717 Loss: 0.011732641575161858 Corrects: 4414\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.010618414729833603\n",
            "Train step - Step 950, Loss 0.010983148589730263\n",
            "Train step - Step 960, Loss 0.012232339009642601\n",
            "Train step - Step 970, Loss 0.013025626540184021\n",
            "Train epoch - Accuracy: 0.8913131313131313 Loss: 0.011679843736417365 Corrects: 4412\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.010868539102375507\n",
            "Train step - Step 990, Loss 0.009089767001569271\n",
            "Train step - Step 1000, Loss 0.007981376722455025\n",
            "Train step - Step 1010, Loss 0.012746321968734264\n",
            "Train epoch - Accuracy: 0.8997979797979798 Loss: 0.010693225865863791 Corrects: 4454\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.00943613238632679\n",
            "Train step - Step 1030, Loss 0.010258368216454983\n",
            "Train step - Step 1040, Loss 0.011155213229358196\n",
            "Train step - Step 1050, Loss 0.012279098853468895\n",
            "Train epoch - Accuracy: 0.9022222222222223 Loss: 0.010917325063486291 Corrects: 4466\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.008668044582009315\n",
            "Train step - Step 1070, Loss 0.009871606715023518\n",
            "Train step - Step 1080, Loss 0.01059094537049532\n",
            "Train step - Step 1090, Loss 0.009306511841714382\n",
            "Train epoch - Accuracy: 0.9062626262626262 Loss: 0.010229593445405815 Corrects: 4486\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.010076234117150307\n",
            "Train step - Step 1110, Loss 0.010033912025392056\n",
            "Train step - Step 1120, Loss 0.012035004794597626\n",
            "Train step - Step 1130, Loss 0.011051615700125694\n",
            "Train epoch - Accuracy: 0.8997979797979798 Loss: 0.01055760781647581 Corrects: 4454\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.010595414787530899\n",
            "Train step - Step 1150, Loss 0.010166458785533905\n",
            "Train step - Step 1160, Loss 0.008223477751016617\n",
            "Train epoch - Accuracy: 0.9042424242424243 Loss: 0.010251523542660053 Corrects: 4476\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.010889430530369282\n",
            "Train step - Step 1180, Loss 0.009736882522702217\n",
            "Train step - Step 1190, Loss 0.008916168473660946\n",
            "Train step - Step 1200, Loss 0.009782484732568264\n",
            "Train epoch - Accuracy: 0.9008080808080808 Loss: 0.010589682194921705 Corrects: 4459\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.008824511431157589\n",
            "Train step - Step 1220, Loss 0.009823531843721867\n",
            "Train step - Step 1230, Loss 0.010170037858188152\n",
            "Train step - Step 1240, Loss 0.011114360764622688\n",
            "Train epoch - Accuracy: 0.9078787878787878 Loss: 0.009978978292207525 Corrects: 4494\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.005016578361392021\n",
            "Train step - Step 1260, Loss 0.006833766121417284\n",
            "Train step - Step 1270, Loss 0.008500296622514725\n",
            "Train step - Step 1280, Loss 0.010413246229290962\n",
            "Train epoch - Accuracy: 0.9165656565656566 Loss: 0.00931009328971156 Corrects: 4537\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.010344254784286022\n",
            "Train step - Step 1300, Loss 0.006614356301724911\n",
            "Train step - Step 1310, Loss 0.008938178420066833\n",
            "Train step - Step 1320, Loss 0.010485008358955383\n",
            "Train epoch - Accuracy: 0.9127272727272727 Loss: 0.009348085853788587 Corrects: 4518\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.009535389952361584\n",
            "Train step - Step 1340, Loss 0.009001686237752438\n",
            "Train step - Step 1350, Loss 0.009294021874666214\n",
            "Train step - Step 1360, Loss 0.009945839643478394\n",
            "Train epoch - Accuracy: 0.926060606060606 Loss: 0.008528356178466118 Corrects: 4584\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.006511967163532972\n",
            "Train step - Step 1380, Loss 0.01060996763408184\n",
            "Train step - Step 1390, Loss 0.004619490820914507\n",
            "Train step - Step 1400, Loss 0.0074305459856987\n",
            "Train epoch - Accuracy: 0.9268686868686868 Loss: 0.008197256136647981 Corrects: 4588\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.006679991260170937\n",
            "Train step - Step 1420, Loss 0.010411425493657589\n",
            "Train step - Step 1430, Loss 0.007706227246671915\n",
            "Train step - Step 1440, Loss 0.007679010275751352\n",
            "Train epoch - Accuracy: 0.9248484848484848 Loss: 0.008290769822632122 Corrects: 4578\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.006058232858777046\n",
            "Train step - Step 1460, Loss 0.00740697979927063\n",
            "Train step - Step 1470, Loss 0.0067581734620034695\n",
            "Train step - Step 1480, Loss 0.0097883902490139\n",
            "Train epoch - Accuracy: 0.9296969696969697 Loss: 0.008242056669309886 Corrects: 4602\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.008892664685845375\n",
            "Train step - Step 1500, Loss 0.006018775049597025\n",
            "Train step - Step 1510, Loss 0.007099863141775131\n",
            "Train step - Step 1520, Loss 0.01526502426713705\n",
            "Train epoch - Accuracy: 0.9298989898989899 Loss: 0.00791965231035996 Corrects: 4603\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.007935061119496822\n",
            "Train step - Step 1540, Loss 0.008343769237399101\n",
            "Train step - Step 1550, Loss 0.009913264773786068\n",
            "Train epoch - Accuracy: 0.9187878787878788 Loss: 0.008782569741209348 Corrects: 4548\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.004245369229465723\n",
            "Train step - Step 1570, Loss 0.003373348619788885\n",
            "Train step - Step 1580, Loss 0.006785219069570303\n",
            "Train step - Step 1590, Loss 0.0058961245231330395\n",
            "Train epoch - Accuracy: 0.9311111111111111 Loss: 0.007565548369905564 Corrects: 4609\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0069324844516813755\n",
            "Train step - Step 1610, Loss 0.0045644789934158325\n",
            "Train step - Step 1620, Loss 0.006097202189266682\n",
            "Train step - Step 1630, Loss 0.010648184455931187\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.0075267259042822955 Corrects: 4621\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.007560758385807276\n",
            "Train step - Step 1650, Loss 0.00442179711535573\n",
            "Train step - Step 1660, Loss 0.007203827146440744\n",
            "Train step - Step 1670, Loss 0.007563504856079817\n",
            "Train epoch - Accuracy: 0.9355555555555556 Loss: 0.007516209802430386 Corrects: 4631\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.004922308027744293\n",
            "Train step - Step 1690, Loss 0.005190021358430386\n",
            "Train step - Step 1700, Loss 0.005878574680536985\n",
            "Train step - Step 1710, Loss 0.0069277845323085785\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.007606183500452475 Corrects: 4621\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.008188005536794662\n",
            "Train step - Step 1730, Loss 0.007527737878262997\n",
            "Train step - Step 1740, Loss 0.00962253287434578\n",
            "Train step - Step 1750, Loss 0.009285259060561657\n",
            "Train epoch - Accuracy: 0.9319191919191919 Loss: 0.007925393322125229 Corrects: 4613\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.008068259805440903\n",
            "Train step - Step 1770, Loss 0.006816699169576168\n",
            "Train step - Step 1780, Loss 0.009567664936184883\n",
            "Train step - Step 1790, Loss 0.008994683623313904\n",
            "Train epoch - Accuracy: 0.9408080808080808 Loss: 0.007086178128315945 Corrects: 4657\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.006261319853365421\n",
            "Train step - Step 1810, Loss 0.007073253393173218\n",
            "Train step - Step 1820, Loss 0.011860285885632038\n",
            "Train step - Step 1830, Loss 0.006483769044280052\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.007673126270034999 Corrects: 4621\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.00604606606066227\n",
            "Train step - Step 1850, Loss 0.006231517530977726\n",
            "Train step - Step 1860, Loss 0.007992839440703392\n",
            "Train step - Step 1870, Loss 0.010784962214529514\n",
            "Train epoch - Accuracy: 0.9367676767676768 Loss: 0.007226796709377356 Corrects: 4637\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0071112243458628654\n",
            "Train step - Step 1890, Loss 0.004692938644438982\n",
            "Train step - Step 1900, Loss 0.0050856987945735455\n",
            "Train step - Step 1910, Loss 0.009854396805167198\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.0069069531537366636 Corrects: 4652\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.004652312956750393\n",
            "Train step - Step 1930, Loss 0.004501511808484793\n",
            "Train step - Step 1940, Loss 0.0031515306327492\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.004256866158390738 Corrects: 4790\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.004539270885288715\n",
            "Train step - Step 1960, Loss 0.004341555293649435\n",
            "Train step - Step 1970, Loss 0.002860715612769127\n",
            "Train step - Step 1980, Loss 0.0014326580567285419\n",
            "Train epoch - Accuracy: 0.9854545454545455 Loss: 0.002643219067367038 Corrects: 4878\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0018987610237672925\n",
            "Train step - Step 2000, Loss 0.0017271555261686444\n",
            "Train step - Step 2010, Loss 0.0021196678280830383\n",
            "Train step - Step 2020, Loss 0.0019073899602517486\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0022374604348883486 Corrects: 4886\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0013835059944540262\n",
            "Train step - Step 2040, Loss 0.0022970440331846476\n",
            "Train step - Step 2050, Loss 0.0016323057934641838\n",
            "Train step - Step 2060, Loss 0.000869912386406213\n",
            "Train epoch - Accuracy: 0.9901010101010101 Loss: 0.001886281513731287 Corrects: 4901\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0027324818074703217\n",
            "Train step - Step 2080, Loss 0.0014372728765010834\n",
            "Train step - Step 2090, Loss 0.003976162057369947\n",
            "Train step - Step 2100, Loss 0.0018511825473979115\n",
            "Train epoch - Accuracy: 0.9894949494949495 Loss: 0.0018578170539077484 Corrects: 4898\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.001961460104212165\n",
            "Train step - Step 2120, Loss 0.001433626632206142\n",
            "Train step - Step 2130, Loss 0.00187626329716295\n",
            "Train step - Step 2140, Loss 0.002275836421176791\n",
            "Train epoch - Accuracy: 0.9923232323232323 Loss: 0.0016287552576154621 Corrects: 4912\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0008709108806215227\n",
            "Train step - Step 2160, Loss 0.00243981066159904\n",
            "Train step - Step 2170, Loss 0.0019956817850470543\n",
            "Train step - Step 2180, Loss 0.0014345641247928143\n",
            "Train epoch - Accuracy: 0.9905050505050506 Loss: 0.001677235071029928 Corrects: 4903\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0006048640934750438\n",
            "Train step - Step 2200, Loss 0.0015111896209418774\n",
            "Train step - Step 2210, Loss 0.0007850761758163571\n",
            "Train step - Step 2220, Loss 0.0017024052795022726\n",
            "Train epoch - Accuracy: 0.9943434343434343 Loss: 0.001382430869935438 Corrects: 4922\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0012795807560905814\n",
            "Train step - Step 2240, Loss 0.0012824618024751544\n",
            "Train step - Step 2250, Loss 0.0012794524664059281\n",
            "Train step - Step 2260, Loss 0.0009057206334546208\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0013823451860008216 Corrects: 4916\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.001407127594575286\n",
            "Train step - Step 2280, Loss 0.0017200682777911425\n",
            "Train step - Step 2290, Loss 0.001099221408367157\n",
            "Train step - Step 2300, Loss 0.0018431126372888684\n",
            "Train epoch - Accuracy: 0.9937373737373737 Loss: 0.0013496781683837375 Corrects: 4919\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.001361108967103064\n",
            "Train step - Step 2320, Loss 0.0007324395701289177\n",
            "Train step - Step 2330, Loss 0.0019441258627921343\n",
            "Train epoch - Accuracy: 0.9947474747474747 Loss: 0.001133014320823919 Corrects: 4924\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0008688359521329403\n",
            "Train step - Step 2350, Loss 0.0006447462365031242\n",
            "Train step - Step 2360, Loss 0.002409347565844655\n",
            "Train step - Step 2370, Loss 0.0023230474907904863\n",
            "Train epoch - Accuracy: 0.9937373737373737 Loss: 0.0011988843989210447 Corrects: 4919\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.001347650890238583\n",
            "Train step - Step 2390, Loss 0.0007674531661905348\n",
            "Train step - Step 2400, Loss 0.0008327013347297907\n",
            "Train step - Step 2410, Loss 0.001263437676243484\n",
            "Train epoch - Accuracy: 0.9937373737373737 Loss: 0.0011263356201651723 Corrects: 4919\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0006090038805268705\n",
            "Train step - Step 2430, Loss 0.0009558112942613661\n",
            "Train step - Step 2440, Loss 0.0005079308757558465\n",
            "Train step - Step 2450, Loss 0.0006106019136495888\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.0009691911555986588 Corrects: 4934\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0009185904054902494\n",
            "Train step - Step 2470, Loss 0.0008038136875256896\n",
            "Train step - Step 2480, Loss 0.0014518762473016977\n",
            "Train step - Step 2490, Loss 0.0009185926173813641\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.0009715091603610551 Corrects: 4934\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0009294615592807531\n",
            "Train step - Step 2510, Loss 0.0010221858974546194\n",
            "Train step - Step 2520, Loss 0.001296735368669033\n",
            "Train step - Step 2530, Loss 0.001018651993945241\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0008988487481073749 Corrects: 4933\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0014679250307381153\n",
            "Train step - Step 2550, Loss 0.001090005855076015\n",
            "Train step - Step 2560, Loss 0.0015798923559486866\n",
            "Train step - Step 2570, Loss 0.0006150126573629677\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0009299320256633853 Corrects: 4935\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.002048766938969493\n",
            "Train step - Step 2590, Loss 0.0009266775450669229\n",
            "Train step - Step 2600, Loss 0.0012227613478899002\n",
            "Train step - Step 2610, Loss 0.0008071783231571317\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0008733884941297349 Corrects: 4936\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0005456354119814932\n",
            "Train step - Step 2630, Loss 0.0017362276557832956\n",
            "Train step - Step 2640, Loss 0.0004618622187990695\n",
            "Train step - Step 2650, Loss 0.0006399173871614039\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0008880156454526716 Corrects: 4937\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0007035916205495596\n",
            "Train step - Step 2670, Loss 0.0009006335167214274\n",
            "Train step - Step 2680, Loss 0.0005448605515994132\n",
            "Train step - Step 2690, Loss 0.0008227649959735572\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.0008974261585895837 Corrects: 4934\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0010580687085166574\n",
            "Train step - Step 2710, Loss 0.000654166447930038\n",
            "Train step - Step 2720, Loss 0.0006995895528234541\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0008444943591350256 Corrects: 4935\n",
            "Training finished in 211.51966667175293 seconds\n",
            "EVALUATION:  0.9 0.011183729395270348\n",
            "TEST GROUP:  0.843\n",
            "TEST ALL:  0.1686\n",
            "GROUP:  6\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.19517365097999573\n",
            "Train step - Step 10, Loss 0.08040018379688263\n",
            "Train step - Step 20, Loss 0.05559643357992172\n",
            "Train step - Step 30, Loss 0.04515158385038376\n",
            "Train epoch - Accuracy: 0.24383838383838383 Loss: 0.06467977681695813 Corrects: 1207\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.037615831941366196\n",
            "Train step - Step 50, Loss 0.03600534424185753\n",
            "Train step - Step 60, Loss 0.03213825076818466\n",
            "Train step - Step 70, Loss 0.030767494812607765\n",
            "Train epoch - Accuracy: 0.5521212121212121 Loss: 0.03349645459817516 Corrects: 2733\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.03075031191110611\n",
            "Train step - Step 90, Loss 0.027125360444188118\n",
            "Train step - Step 100, Loss 0.02691422402858734\n",
            "Train step - Step 110, Loss 0.019885696470737457\n",
            "Train epoch - Accuracy: 0.6872727272727273 Loss: 0.026024455349102166 Corrects: 3402\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.021252967417240143\n",
            "Train step - Step 130, Loss 0.023429859429597855\n",
            "Train step - Step 140, Loss 0.021461158990859985\n",
            "Train step - Step 150, Loss 0.023117557168006897\n",
            "Train epoch - Accuracy: 0.7533333333333333 Loss: 0.02152074335801481 Corrects: 3729\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.013899510726332664\n",
            "Train step - Step 170, Loss 0.0180899016559124\n",
            "Train step - Step 180, Loss 0.01698816381394863\n",
            "Train step - Step 190, Loss 0.01605629175901413\n",
            "Train epoch - Accuracy: 0.7977777777777778 Loss: 0.017701695176838624 Corrects: 3949\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.01679038256406784\n",
            "Train step - Step 210, Loss 0.018055351451039314\n",
            "Train step - Step 220, Loss 0.020512716844677925\n",
            "Train step - Step 230, Loss 0.015066400170326233\n",
            "Train epoch - Accuracy: 0.8185858585858586 Loss: 0.016203364718592527 Corrects: 4052\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.01545180194079876\n",
            "Train step - Step 250, Loss 0.016064606606960297\n",
            "Train step - Step 260, Loss 0.01120750606060028\n",
            "Train step - Step 270, Loss 0.018277468159794807\n",
            "Train epoch - Accuracy: 0.8315151515151515 Loss: 0.014935262956553036 Corrects: 4116\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.014554399996995926\n",
            "Train step - Step 290, Loss 0.011957856826484203\n",
            "Train step - Step 300, Loss 0.0114304069429636\n",
            "Train step - Step 310, Loss 0.017324283719062805\n",
            "Train epoch - Accuracy: 0.8494949494949495 Loss: 0.013569423665828776 Corrects: 4205\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.01128673180937767\n",
            "Train step - Step 330, Loss 0.013160662725567818\n",
            "Train step - Step 340, Loss 0.010939028114080429\n",
            "Train step - Step 350, Loss 0.010048647411167622\n",
            "Train epoch - Accuracy: 0.8636363636363636 Loss: 0.012249198612766434 Corrects: 4275\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.010155984200537205\n",
            "Train step - Step 370, Loss 0.01599186100065708\n",
            "Train step - Step 380, Loss 0.010973428376019001\n",
            "Train epoch - Accuracy: 0.8577777777777778 Loss: 0.012633595949772633 Corrects: 4246\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.010565144009888172\n",
            "Train step - Step 400, Loss 0.010278052650392056\n",
            "Train step - Step 410, Loss 0.012258615344762802\n",
            "Train step - Step 420, Loss 0.013605699874460697\n",
            "Train epoch - Accuracy: 0.8745454545454545 Loss: 0.01126443686283598 Corrects: 4329\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.010648716241121292\n",
            "Train step - Step 440, Loss 0.012782614678144455\n",
            "Train step - Step 450, Loss 0.010892966762185097\n",
            "Train step - Step 460, Loss 0.012178588658571243\n",
            "Train epoch - Accuracy: 0.8808080808080808 Loss: 0.010980387995715695 Corrects: 4360\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.00793751422315836\n",
            "Train step - Step 480, Loss 0.00810862798243761\n",
            "Train step - Step 490, Loss 0.010426619090139866\n",
            "Train step - Step 500, Loss 0.008087065070867538\n",
            "Train epoch - Accuracy: 0.8977777777777778 Loss: 0.009689369185855895 Corrects: 4444\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.006524423137307167\n",
            "Train step - Step 520, Loss 0.007892577908933163\n",
            "Train step - Step 530, Loss 0.010191017761826515\n",
            "Train step - Step 540, Loss 0.008995497599244118\n",
            "Train epoch - Accuracy: 0.9012121212121212 Loss: 0.009385889026176448 Corrects: 4461\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.010431487113237381\n",
            "Train step - Step 560, Loss 0.00998147577047348\n",
            "Train step - Step 570, Loss 0.0066551994532346725\n",
            "Train step - Step 580, Loss 0.008433648385107517\n",
            "Train epoch - Accuracy: 0.9058585858585858 Loss: 0.008727094569441044 Corrects: 4484\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.007837570272386074\n",
            "Train step - Step 600, Loss 0.00695486506447196\n",
            "Train step - Step 610, Loss 0.007991461083292961\n",
            "Train step - Step 620, Loss 0.00862215831875801\n",
            "Train epoch - Accuracy: 0.9137373737373737 Loss: 0.008055190553305426 Corrects: 4523\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.007383744232356548\n",
            "Train step - Step 640, Loss 0.01122164074331522\n",
            "Train step - Step 650, Loss 0.008120788261294365\n",
            "Train step - Step 660, Loss 0.00926709920167923\n",
            "Train epoch - Accuracy: 0.9111111111111111 Loss: 0.00846457704769993 Corrects: 4510\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.008324711583554745\n",
            "Train step - Step 680, Loss 0.008561162278056145\n",
            "Train step - Step 690, Loss 0.00607665441930294\n",
            "Train step - Step 700, Loss 0.011875223368406296\n",
            "Train epoch - Accuracy: 0.9074747474747474 Loss: 0.008661227949866743 Corrects: 4492\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.011560212820768356\n",
            "Train step - Step 720, Loss 0.005473090335726738\n",
            "Train step - Step 730, Loss 0.010478641837835312\n",
            "Train step - Step 740, Loss 0.013174532912671566\n",
            "Train epoch - Accuracy: 0.9151515151515152 Loss: 0.007962054684381895 Corrects: 4530\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.0063912998884916306\n",
            "Train step - Step 760, Loss 0.007857179269194603\n",
            "Train step - Step 770, Loss 0.007797577418386936\n",
            "Train epoch - Accuracy: 0.9238383838383838 Loss: 0.007230564691126346 Corrects: 4573\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.00536412512883544\n",
            "Train step - Step 790, Loss 0.006296531762927771\n",
            "Train step - Step 800, Loss 0.006596946157515049\n",
            "Train step - Step 810, Loss 0.010762820020318031\n",
            "Train epoch - Accuracy: 0.9236363636363636 Loss: 0.007169115927183267 Corrects: 4572\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.0061318473890423775\n",
            "Train step - Step 830, Loss 0.005964090581983328\n",
            "Train step - Step 840, Loss 0.0039238091558218\n",
            "Train step - Step 850, Loss 0.007305465172976255\n",
            "Train epoch - Accuracy: 0.9347474747474748 Loss: 0.006338810601807905 Corrects: 4627\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.004237907472997904\n",
            "Train step - Step 870, Loss 0.005621572490781546\n",
            "Train step - Step 880, Loss 0.006970398128032684\n",
            "Train step - Step 890, Loss 0.004895866382867098\n",
            "Train epoch - Accuracy: 0.9361616161616162 Loss: 0.0062763060461917914 Corrects: 4634\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.003987894393503666\n",
            "Train step - Step 910, Loss 0.004573005251586437\n",
            "Train step - Step 920, Loss 0.003498575882986188\n",
            "Train step - Step 930, Loss 0.006419006269425154\n",
            "Train epoch - Accuracy: 0.9286868686868687 Loss: 0.006719166056224794 Corrects: 4597\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.006571623496711254\n",
            "Train step - Step 950, Loss 0.006474286783486605\n",
            "Train step - Step 960, Loss 0.005926602985709906\n",
            "Train step - Step 970, Loss 0.005002239253371954\n",
            "Train epoch - Accuracy: 0.9317171717171717 Loss: 0.006456563925427017 Corrects: 4612\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0071308002807199955\n",
            "Train step - Step 990, Loss 0.006464791484177113\n",
            "Train step - Step 1000, Loss 0.00498205004259944\n",
            "Train step - Step 1010, Loss 0.011880380101501942\n",
            "Train epoch - Accuracy: 0.9395959595959597 Loss: 0.005969850083982402 Corrects: 4651\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0068840389139950275\n",
            "Train step - Step 1030, Loss 0.005661082454025745\n",
            "Train step - Step 1040, Loss 0.005550679285079241\n",
            "Train step - Step 1050, Loss 0.007817854173481464\n",
            "Train epoch - Accuracy: 0.9377777777777778 Loss: 0.006075349054252259 Corrects: 4642\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.009630588814616203\n",
            "Train step - Step 1070, Loss 0.003953832667320967\n",
            "Train step - Step 1080, Loss 0.005488155875355005\n",
            "Train step - Step 1090, Loss 0.0049506668001413345\n",
            "Train epoch - Accuracy: 0.9426262626262626 Loss: 0.005879994340880651 Corrects: 4666\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.0034020566381514072\n",
            "Train step - Step 1110, Loss 0.006289639975875616\n",
            "Train step - Step 1120, Loss 0.005223235115408897\n",
            "Train step - Step 1130, Loss 0.0032791306730359793\n",
            "Train epoch - Accuracy: 0.9509090909090909 Loss: 0.004957079517589224 Corrects: 4707\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.0054320041090250015\n",
            "Train step - Step 1150, Loss 0.004328506533056498\n",
            "Train step - Step 1160, Loss 0.00432271882891655\n",
            "Train epoch - Accuracy: 0.9464646464646465 Loss: 0.0049886210541231464 Corrects: 4685\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.00479754526168108\n",
            "Train step - Step 1180, Loss 0.005602055229246616\n",
            "Train step - Step 1190, Loss 0.0019764667376875877\n",
            "Train step - Step 1200, Loss 0.005773593671619892\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.005337439693435274 Corrects: 4698\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.005551938433200121\n",
            "Train step - Step 1220, Loss 0.008885458111763\n",
            "Train step - Step 1230, Loss 0.007159926928579807\n",
            "Train step - Step 1240, Loss 0.004161901772022247\n",
            "Train epoch - Accuracy: 0.9442424242424242 Loss: 0.005400206325199417 Corrects: 4674\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.005050133913755417\n",
            "Train step - Step 1260, Loss 0.005280546844005585\n",
            "Train step - Step 1270, Loss 0.004000697750598192\n",
            "Train step - Step 1280, Loss 0.005569122731685638\n",
            "Train epoch - Accuracy: 0.9496969696969697 Loss: 0.0049403297205013455 Corrects: 4701\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.005644690711051226\n",
            "Train step - Step 1300, Loss 0.005728497635573149\n",
            "Train step - Step 1310, Loss 0.005173795390874147\n",
            "Train step - Step 1320, Loss 0.005242052022367716\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.00525724438969234 Corrects: 4703\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.005872061010450125\n",
            "Train step - Step 1340, Loss 0.004853717517107725\n",
            "Train step - Step 1350, Loss 0.004449006635695696\n",
            "Train step - Step 1360, Loss 0.005757294129580259\n",
            "Train epoch - Accuracy: 0.9513131313131313 Loss: 0.004851311099800196 Corrects: 4709\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.005705013405531645\n",
            "Train step - Step 1380, Loss 0.004213198088109493\n",
            "Train step - Step 1390, Loss 0.00524496054276824\n",
            "Train step - Step 1400, Loss 0.0038727358914911747\n",
            "Train epoch - Accuracy: 0.9567676767676768 Loss: 0.004594278371695316 Corrects: 4736\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0035538633819669485\n",
            "Train step - Step 1420, Loss 0.004045390523970127\n",
            "Train step - Step 1430, Loss 0.003940865863114595\n",
            "Train step - Step 1440, Loss 0.005840817932039499\n",
            "Train epoch - Accuracy: 0.9519191919191919 Loss: 0.0046047793592166415 Corrects: 4712\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.003725520335137844\n",
            "Train step - Step 1460, Loss 0.0037141721695661545\n",
            "Train step - Step 1470, Loss 0.007704395335167646\n",
            "Train step - Step 1480, Loss 0.006006819196045399\n",
            "Train epoch - Accuracy: 0.9557575757575758 Loss: 0.004482496840258439 Corrects: 4731\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.006982285063713789\n",
            "Train step - Step 1500, Loss 0.004799484740942717\n",
            "Train step - Step 1510, Loss 0.0036859067622572184\n",
            "Train step - Step 1520, Loss 0.008188092149794102\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.005775256591538588 Corrects: 4652\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.006008874159306288\n",
            "Train step - Step 1540, Loss 0.005896690767258406\n",
            "Train step - Step 1550, Loss 0.0058839949779212475\n",
            "Train epoch - Accuracy: 0.9545454545454546 Loss: 0.004504949642401753 Corrects: 4725\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.003303189529106021\n",
            "Train step - Step 1570, Loss 0.0071230195462703705\n",
            "Train step - Step 1580, Loss 0.003312975401058793\n",
            "Train step - Step 1590, Loss 0.004138595424592495\n",
            "Train epoch - Accuracy: 0.9545454545454546 Loss: 0.00460522214195343 Corrects: 4725\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.001592562417499721\n",
            "Train step - Step 1610, Loss 0.0021222333889454603\n",
            "Train step - Step 1620, Loss 0.005362590309232473\n",
            "Train step - Step 1630, Loss 0.003126696916297078\n",
            "Train epoch - Accuracy: 0.9597979797979798 Loss: 0.003926757168062407 Corrects: 4751\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.006481596268713474\n",
            "Train step - Step 1650, Loss 0.005646115634590387\n",
            "Train step - Step 1660, Loss 0.004305301234126091\n",
            "Train step - Step 1670, Loss 0.0034609059803187847\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.0042730069627063445 Corrects: 4724\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.003657102817669511\n",
            "Train step - Step 1690, Loss 0.0027502537705004215\n",
            "Train step - Step 1700, Loss 0.0063041760586202145\n",
            "Train step - Step 1710, Loss 0.0073824115097522736\n",
            "Train epoch - Accuracy: 0.9614141414141414 Loss: 0.003860235787043818 Corrects: 4759\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0027534798718988895\n",
            "Train step - Step 1730, Loss 0.003642812604084611\n",
            "Train step - Step 1740, Loss 0.0024337389040738344\n",
            "Train step - Step 1750, Loss 0.005820955149829388\n",
            "Train epoch - Accuracy: 0.9622222222222222 Loss: 0.0037404094734276184 Corrects: 4763\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.005075572989881039\n",
            "Train step - Step 1770, Loss 0.0031970408745110035\n",
            "Train step - Step 1780, Loss 0.0033583466429263353\n",
            "Train step - Step 1790, Loss 0.004254017490893602\n",
            "Train epoch - Accuracy: 0.9662626262626263 Loss: 0.003599964498702173 Corrects: 4783\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0048398785293102264\n",
            "Train step - Step 1810, Loss 0.001941668801009655\n",
            "Train step - Step 1820, Loss 0.00454709492623806\n",
            "Train step - Step 1830, Loss 0.0015811206540092826\n",
            "Train epoch - Accuracy: 0.961010101010101 Loss: 0.003938500706595604 Corrects: 4757\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0025543076917529106\n",
            "Train step - Step 1850, Loss 0.0025089923292398453\n",
            "Train step - Step 1860, Loss 0.0033001420088112354\n",
            "Train step - Step 1870, Loss 0.001651691971346736\n",
            "Train epoch - Accuracy: 0.971919191919192 Loss: 0.0030051622815392533 Corrects: 4811\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0016677348176017404\n",
            "Train step - Step 1890, Loss 0.0028255549259483814\n",
            "Train step - Step 1900, Loss 0.003396984888240695\n",
            "Train step - Step 1910, Loss 0.0015491435769945383\n",
            "Train epoch - Accuracy: 0.9707070707070707 Loss: 0.002935254735909779 Corrects: 4805\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0015339524252340198\n",
            "Train step - Step 1930, Loss 0.0024292354937642813\n",
            "Train step - Step 1940, Loss 0.0013535734033212066\n",
            "Train epoch - Accuracy: 0.9852525252525253 Loss: 0.0018775552969350659 Corrects: 4877\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.000614857068285346\n",
            "Train step - Step 1960, Loss 0.0012922313762828708\n",
            "Train step - Step 1970, Loss 0.0008319368353113532\n",
            "Train step - Step 1980, Loss 0.0007685753516852856\n",
            "Train epoch - Accuracy: 0.9925252525252525 Loss: 0.0012445784266097376 Corrects: 4913\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0012569321552291512\n",
            "Train step - Step 2000, Loss 0.0006784372963011265\n",
            "Train step - Step 2010, Loss 0.0007159335073083639\n",
            "Train step - Step 2020, Loss 0.001070511294528842\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0009181879195996155 Corrects: 4927\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0007633373606950045\n",
            "Train step - Step 2040, Loss 0.0003646208788268268\n",
            "Train step - Step 2050, Loss 0.000521263515111059\n",
            "Train step - Step 2060, Loss 0.0006545053911395371\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0008577760635414208 Corrects: 4928\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0005364701501093805\n",
            "Train step - Step 2080, Loss 0.0006175998714752495\n",
            "Train step - Step 2090, Loss 0.0005333772860467434\n",
            "Train step - Step 2100, Loss 0.0006867230404168367\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0007324870891229372 Corrects: 4933\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0003664983669295907\n",
            "Train step - Step 2120, Loss 0.0007179490639828146\n",
            "Train step - Step 2130, Loss 0.0007749430951662362\n",
            "Train step - Step 2140, Loss 0.0006106426590122283\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0005778229326442486 Corrects: 4941\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.000637369928881526\n",
            "Train step - Step 2160, Loss 0.0005310089909471571\n",
            "Train step - Step 2170, Loss 0.0009307875297963619\n",
            "Train step - Step 2180, Loss 0.0010970886796712875\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0006850898274422783 Corrects: 4933\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00029983706190250814\n",
            "Train step - Step 2200, Loss 0.0009854469681158662\n",
            "Train step - Step 2210, Loss 0.00039530746289528906\n",
            "Train step - Step 2220, Loss 0.0005976291140541434\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0004975959319372031 Corrects: 4944\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0006192497094161808\n",
            "Train step - Step 2240, Loss 0.00024218445469159633\n",
            "Train step - Step 2250, Loss 0.0005609455984085798\n",
            "Train step - Step 2260, Loss 0.0003592825378291309\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00048055743933843466 Corrects: 4942\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0004902507644146681\n",
            "Train step - Step 2280, Loss 0.0005697053275071084\n",
            "Train step - Step 2290, Loss 0.0002605592890176922\n",
            "Train step - Step 2300, Loss 0.00033212261041626334\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0006208255346347061 Corrects: 4937\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0008071970660239458\n",
            "Train step - Step 2320, Loss 0.00017483285046182573\n",
            "Train step - Step 2330, Loss 0.0008395642507821321\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0005230672232044691 Corrects: 4938\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00034121464705094695\n",
            "Train step - Step 2350, Loss 0.0004206316079944372\n",
            "Train step - Step 2360, Loss 0.000560120097361505\n",
            "Train step - Step 2370, Loss 0.00022648574667982757\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0004801181254607409 Corrects: 4943\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0004349213559180498\n",
            "Train step - Step 2390, Loss 0.0004458012117538601\n",
            "Train step - Step 2400, Loss 0.0002400463417870924\n",
            "Train step - Step 2410, Loss 0.0008021717658266425\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0005041042957078628 Corrects: 4944\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0005772763397544622\n",
            "Train step - Step 2430, Loss 0.00019163537945132703\n",
            "Train step - Step 2440, Loss 0.0005768953706137836\n",
            "Train step - Step 2450, Loss 0.0004131864116061479\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0004407375871269691 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00048202910693362355\n",
            "Train step - Step 2470, Loss 0.0005788857815787196\n",
            "Train step - Step 2480, Loss 0.0006010231445543468\n",
            "Train step - Step 2490, Loss 0.0002666979271452874\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.00044053376762836116 Corrects: 4946\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0005049872561357915\n",
            "Train step - Step 2510, Loss 0.00034886159119196236\n",
            "Train step - Step 2520, Loss 0.0002678152814041823\n",
            "Train step - Step 2530, Loss 0.0005904544377699494\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00042274793307767297 Corrects: 4944\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0002826926065608859\n",
            "Train step - Step 2550, Loss 0.00017901451792567968\n",
            "Train step - Step 2560, Loss 0.00029834109591320157\n",
            "Train step - Step 2570, Loss 0.00035129731986671686\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.000391653302605405 Corrects: 4942\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.00029364399961195886\n",
            "Train step - Step 2590, Loss 0.00032903425744734704\n",
            "Train step - Step 2600, Loss 0.0002971894573420286\n",
            "Train step - Step 2610, Loss 0.0003894793626386672\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.0003899988825103701 Corrects: 4948\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00019427097868174314\n",
            "Train step - Step 2630, Loss 0.00024876929819583893\n",
            "Train step - Step 2640, Loss 0.0004956421325914562\n",
            "Train step - Step 2650, Loss 0.00020527170272544026\n",
            "Train epoch - Accuracy: 0.9997979797979798 Loss: 0.00036614647824223143 Corrects: 4949\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.000249284174060449\n",
            "Train step - Step 2670, Loss 0.0003319462120998651\n",
            "Train step - Step 2680, Loss 0.0004576749633997679\n",
            "Train step - Step 2690, Loss 0.001573727815411985\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0004275549613786015 Corrects: 4941\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0005371856386773288\n",
            "Train step - Step 2710, Loss 0.0002181137097068131\n",
            "Train step - Step 2720, Loss 0.00019923443323932588\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.00035927622760128646 Corrects: 4946\n",
            "Training finished in 211.43144702911377 seconds\n",
            "EVALUATION:  0.76 0.02453586272895336\n",
            "TEST GROUP:  0.891\n",
            "TEST ALL:  0.1485\n",
            "GROUP:  7\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.15023307502269745\n",
            "Train step - Step 10, Loss 0.06152123585343361\n",
            "Train step - Step 20, Loss 0.0368470661342144\n",
            "Train step - Step 30, Loss 0.029224807396531105\n",
            "Train epoch - Accuracy: 0.3377777777777778 Loss: 0.048478059487962966 Corrects: 1672\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.023006990551948547\n",
            "Train step - Step 50, Loss 0.02258932963013649\n",
            "Train step - Step 60, Loss 0.017994973808526993\n",
            "Train step - Step 70, Loss 0.020403722301125526\n",
            "Train epoch - Accuracy: 0.6604040404040404 Loss: 0.022362535543212988 Corrects: 3269\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.01809459552168846\n",
            "Train step - Step 90, Loss 0.018722794950008392\n",
            "Train step - Step 100, Loss 0.015490969642996788\n",
            "Train step - Step 110, Loss 0.016409611329436302\n",
            "Train epoch - Accuracy: 0.7268686868686869 Loss: 0.01750288133067314 Corrects: 3598\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.017187705263495445\n",
            "Train step - Step 130, Loss 0.013773172162473202\n",
            "Train step - Step 140, Loss 0.015102541074156761\n",
            "Train step - Step 150, Loss 0.015680449083447456\n",
            "Train epoch - Accuracy: 0.7636363636363637 Loss: 0.015166281367642712 Corrects: 3780\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.014819159172475338\n",
            "Train step - Step 170, Loss 0.014897179789841175\n",
            "Train step - Step 180, Loss 0.011453778482973576\n",
            "Train step - Step 190, Loss 0.012239721603691578\n",
            "Train epoch - Accuracy: 0.7876767676767676 Loss: 0.014026615329914623 Corrects: 3899\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.01131297368556261\n",
            "Train step - Step 210, Loss 0.01279527973383665\n",
            "Train step - Step 220, Loss 0.014666898176074028\n",
            "Train step - Step 230, Loss 0.011486558243632317\n",
            "Train epoch - Accuracy: 0.813939393939394 Loss: 0.012801191149034885 Corrects: 4029\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.011333975940942764\n",
            "Train step - Step 250, Loss 0.012136302888393402\n",
            "Train step - Step 260, Loss 0.013579539023339748\n",
            "Train step - Step 270, Loss 0.009195290505886078\n",
            "Train epoch - Accuracy: 0.8270707070707071 Loss: 0.011584446914117745 Corrects: 4094\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.010290431790053844\n",
            "Train step - Step 290, Loss 0.014652318321168423\n",
            "Train step - Step 300, Loss 0.010131854563951492\n",
            "Train step - Step 310, Loss 0.011613981798291206\n",
            "Train epoch - Accuracy: 0.8462626262626263 Loss: 0.010978605732547515 Corrects: 4189\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.013302221894264221\n",
            "Train step - Step 330, Loss 0.008003910072147846\n",
            "Train step - Step 340, Loss 0.009585746563971043\n",
            "Train step - Step 350, Loss 0.00891990214586258\n",
            "Train epoch - Accuracy: 0.8678787878787879 Loss: 0.009624984863430563 Corrects: 4296\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.008694350719451904\n",
            "Train step - Step 370, Loss 0.009991810657083988\n",
            "Train step - Step 380, Loss 0.008927052840590477\n",
            "Train epoch - Accuracy: 0.8755555555555555 Loss: 0.00914805528980614 Corrects: 4334\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.007537811994552612\n",
            "Train step - Step 400, Loss 0.008048986084759235\n",
            "Train step - Step 410, Loss 0.010594653896987438\n",
            "Train step - Step 420, Loss 0.008779590018093586\n",
            "Train epoch - Accuracy: 0.8911111111111111 Loss: 0.00834756407209418 Corrects: 4411\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.0073006656020879745\n",
            "Train step - Step 440, Loss 0.007505228742957115\n",
            "Train step - Step 450, Loss 0.007457043509930372\n",
            "Train step - Step 460, Loss 0.007503514643758535\n",
            "Train epoch - Accuracy: 0.8763636363636363 Loss: 0.008646178609418749 Corrects: 4338\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.00681906845420599\n",
            "Train step - Step 480, Loss 0.008130953647196293\n",
            "Train step - Step 490, Loss 0.008854960091412067\n",
            "Train step - Step 500, Loss 0.008117086254060268\n",
            "Train epoch - Accuracy: 0.8802020202020202 Loss: 0.008827181465999045 Corrects: 4357\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.00827330257743597\n",
            "Train step - Step 520, Loss 0.00712873600423336\n",
            "Train step - Step 530, Loss 0.0049937693402171135\n",
            "Train step - Step 540, Loss 0.007387654390186071\n",
            "Train epoch - Accuracy: 0.8975757575757576 Loss: 0.007554917708415576 Corrects: 4443\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.007230224087834358\n",
            "Train step - Step 560, Loss 0.006678625009953976\n",
            "Train step - Step 570, Loss 0.00810406543314457\n",
            "Train step - Step 580, Loss 0.005262104794383049\n",
            "Train epoch - Accuracy: 0.9004040404040404 Loss: 0.007513721725818785 Corrects: 4457\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.00778779573738575\n",
            "Train step - Step 600, Loss 0.00820243451744318\n",
            "Train step - Step 610, Loss 0.007286053150892258\n",
            "Train step - Step 620, Loss 0.005931206978857517\n",
            "Train epoch - Accuracy: 0.9107070707070707 Loss: 0.00673036440228573 Corrects: 4508\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.00815508235245943\n",
            "Train step - Step 640, Loss 0.008017409592866898\n",
            "Train step - Step 650, Loss 0.006932299584150314\n",
            "Train step - Step 660, Loss 0.00914167333394289\n",
            "Train epoch - Accuracy: 0.9197979797979798 Loss: 0.006311090661758425 Corrects: 4553\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.008397230878472328\n",
            "Train step - Step 680, Loss 0.006521104834973812\n",
            "Train step - Step 690, Loss 0.007224898785352707\n",
            "Train step - Step 700, Loss 0.007031787186861038\n",
            "Train epoch - Accuracy: 0.9155555555555556 Loss: 0.006415523614997816 Corrects: 4532\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.004096352960914373\n",
            "Train step - Step 720, Loss 0.00610593194141984\n",
            "Train step - Step 730, Loss 0.002797442954033613\n",
            "Train step - Step 740, Loss 0.0057536279782652855\n",
            "Train epoch - Accuracy: 0.9131313131313131 Loss: 0.006676340487343494 Corrects: 4520\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.0087214270606637\n",
            "Train step - Step 760, Loss 0.006709024775773287\n",
            "Train step - Step 770, Loss 0.005953291896730661\n",
            "Train epoch - Accuracy: 0.9141414141414141 Loss: 0.0065855279034285836 Corrects: 4525\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.006663650274276733\n",
            "Train step - Step 790, Loss 0.0047726077027618885\n",
            "Train step - Step 800, Loss 0.008353620767593384\n",
            "Train step - Step 810, Loss 0.006396975833922625\n",
            "Train epoch - Accuracy: 0.9258585858585858 Loss: 0.0058678103129219525 Corrects: 4583\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.004537367727607489\n",
            "Train step - Step 830, Loss 0.003599358955398202\n",
            "Train step - Step 840, Loss 0.0045699491165578365\n",
            "Train step - Step 850, Loss 0.0046180980280041695\n",
            "Train epoch - Accuracy: 0.9329292929292929 Loss: 0.005309711801208029 Corrects: 4618\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.00580999068915844\n",
            "Train step - Step 870, Loss 0.008089396171271801\n",
            "Train step - Step 880, Loss 0.006897384766489267\n",
            "Train step - Step 890, Loss 0.009194898419082165\n",
            "Train epoch - Accuracy: 0.9090909090909091 Loss: 0.007210833963495914 Corrects: 4500\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.005654218606650829\n",
            "Train step - Step 910, Loss 0.004207127261906862\n",
            "Train step - Step 920, Loss 0.006228781770914793\n",
            "Train step - Step 930, Loss 0.007115062791854143\n",
            "Train epoch - Accuracy: 0.9309090909090909 Loss: 0.005551774769720405 Corrects: 4608\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.003974838647991419\n",
            "Train step - Step 950, Loss 0.004701879341155291\n",
            "Train step - Step 960, Loss 0.006879599764943123\n",
            "Train step - Step 970, Loss 0.006545263808220625\n",
            "Train epoch - Accuracy: 0.938989898989899 Loss: 0.005065232181187832 Corrects: 4648\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.005554829258471727\n",
            "Train step - Step 990, Loss 0.003359951777383685\n",
            "Train step - Step 1000, Loss 0.004256638698279858\n",
            "Train step - Step 1010, Loss 0.004944463260471821\n",
            "Train epoch - Accuracy: 0.9351515151515152 Loss: 0.005140863897448236 Corrects: 4629\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.005220597609877586\n",
            "Train step - Step 1030, Loss 0.007140057627111673\n",
            "Train step - Step 1040, Loss 0.004760755226016045\n",
            "Train step - Step 1050, Loss 0.005685925483703613\n",
            "Train epoch - Accuracy: 0.9494949494949495 Loss: 0.0042718186475938615 Corrects: 4700\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.005940562579780817\n",
            "Train step - Step 1070, Loss 0.0024257090408354998\n",
            "Train step - Step 1080, Loss 0.005063531920313835\n",
            "Train step - Step 1090, Loss 0.0030696045141667128\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.004302037118209733 Corrects: 4670\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.00445721298456192\n",
            "Train step - Step 1110, Loss 0.005691681522876024\n",
            "Train step - Step 1120, Loss 0.006198587827384472\n",
            "Train step - Step 1130, Loss 0.007463523186743259\n",
            "Train epoch - Accuracy: 0.9301010101010101 Loss: 0.005343459490498509 Corrects: 4604\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.005414724349975586\n",
            "Train step - Step 1150, Loss 0.005927248392254114\n",
            "Train step - Step 1160, Loss 0.006683895364403725\n",
            "Train epoch - Accuracy: 0.9393939393939394 Loss: 0.00476594191957077 Corrects: 4650\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0035258852876722813\n",
            "Train step - Step 1180, Loss 0.0033235771115869284\n",
            "Train step - Step 1190, Loss 0.0046668886207044125\n",
            "Train step - Step 1200, Loss 0.0047437031753361225\n",
            "Train epoch - Accuracy: 0.9597979797979798 Loss: 0.003514340685285402 Corrects: 4751\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0024377990048378706\n",
            "Train step - Step 1220, Loss 0.002887892536818981\n",
            "Train step - Step 1230, Loss 0.004169481340795755\n",
            "Train step - Step 1240, Loss 0.0027365332935005426\n",
            "Train epoch - Accuracy: 0.9537373737373738 Loss: 0.003978604209242445 Corrects: 4721\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0039748032577335835\n",
            "Train step - Step 1260, Loss 0.0080360546708107\n",
            "Train step - Step 1270, Loss 0.0029961878899484873\n",
            "Train step - Step 1280, Loss 0.0044715506955981255\n",
            "Train epoch - Accuracy: 0.9519191919191919 Loss: 0.004004450483304081 Corrects: 4712\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0033543279860168695\n",
            "Train step - Step 1300, Loss 0.002847017953172326\n",
            "Train step - Step 1310, Loss 0.003658451372757554\n",
            "Train step - Step 1320, Loss 0.00691497977823019\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.0038903476262107644 Corrects: 4711\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0032615801319479942\n",
            "Train step - Step 1340, Loss 0.0032695354893803596\n",
            "Train step - Step 1350, Loss 0.003232955001294613\n",
            "Train step - Step 1360, Loss 0.004859758075326681\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.004305298420967478 Corrects: 4695\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004565217066556215\n",
            "Train step - Step 1380, Loss 0.006603662855923176\n",
            "Train step - Step 1390, Loss 0.003591888351365924\n",
            "Train step - Step 1400, Loss 0.007717156317085028\n",
            "Train epoch - Accuracy: 0.935959595959596 Loss: 0.005016986169485432 Corrects: 4633\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.004027117043733597\n",
            "Train step - Step 1420, Loss 0.00353556708432734\n",
            "Train step - Step 1430, Loss 0.0028765990864485502\n",
            "Train step - Step 1440, Loss 0.004450771491974592\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.004337077929892323 Corrects: 4696\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.004300772212445736\n",
            "Train step - Step 1460, Loss 0.006276142317801714\n",
            "Train step - Step 1470, Loss 0.003993305843323469\n",
            "Train step - Step 1480, Loss 0.005080678034573793\n",
            "Train epoch - Accuracy: 0.9545454545454546 Loss: 0.003811344025901171 Corrects: 4725\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.002423873171210289\n",
            "Train step - Step 1500, Loss 0.002763177268207073\n",
            "Train step - Step 1510, Loss 0.0036657811142504215\n",
            "Train step - Step 1520, Loss 0.0017185098258778453\n",
            "Train epoch - Accuracy: 0.9597979797979798 Loss: 0.0033631265248557684 Corrects: 4751\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.004236521199345589\n",
            "Train step - Step 1540, Loss 0.0024301446974277496\n",
            "Train step - Step 1550, Loss 0.005574367940425873\n",
            "Train epoch - Accuracy: 0.9585858585858585 Loss: 0.0034352300489660014 Corrects: 4745\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0022471121046692133\n",
            "Train step - Step 1570, Loss 0.003017133567482233\n",
            "Train step - Step 1580, Loss 0.0027464241720736027\n",
            "Train step - Step 1590, Loss 0.0014457397628575563\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.0036461431074022044 Corrects: 4724\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.004199631977826357\n",
            "Train step - Step 1610, Loss 0.005701610818505287\n",
            "Train step - Step 1620, Loss 0.002335246652364731\n",
            "Train step - Step 1630, Loss 0.0038459589704871178\n",
            "Train epoch - Accuracy: 0.9527272727272728 Loss: 0.0039511537072107646 Corrects: 4716\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.004237484186887741\n",
            "Train step - Step 1650, Loss 0.002360214479267597\n",
            "Train step - Step 1660, Loss 0.005909283645451069\n",
            "Train step - Step 1670, Loss 0.002737899776548147\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.003400694913785867 Corrects: 4760\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.003350307932123542\n",
            "Train step - Step 1690, Loss 0.006226507481187582\n",
            "Train step - Step 1700, Loss 0.005926438607275486\n",
            "Train step - Step 1710, Loss 0.004972756840288639\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.004052023383967503 Corrects: 4695\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0026116452645510435\n",
            "Train step - Step 1730, Loss 0.0034148332197219133\n",
            "Train step - Step 1740, Loss 0.0031592552550137043\n",
            "Train step - Step 1750, Loss 0.002361467108130455\n",
            "Train epoch - Accuracy: 0.958989898989899 Loss: 0.003590730648450177 Corrects: 4747\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002912307158112526\n",
            "Train step - Step 1770, Loss 0.001758091151714325\n",
            "Train step - Step 1780, Loss 0.0026749223470687866\n",
            "Train step - Step 1790, Loss 0.003212138544768095\n",
            "Train epoch - Accuracy: 0.9632323232323232 Loss: 0.0030693941018685245 Corrects: 4768\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0019093096489086747\n",
            "Train step - Step 1810, Loss 0.002044906374067068\n",
            "Train step - Step 1820, Loss 0.0029789195396006107\n",
            "Train step - Step 1830, Loss 0.003116162260994315\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.0032725992290811106 Corrects: 4772\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0040771737694740295\n",
            "Train step - Step 1850, Loss 0.002468351973220706\n",
            "Train step - Step 1860, Loss 0.0036500985734164715\n",
            "Train step - Step 1870, Loss 0.0018336926586925983\n",
            "Train epoch - Accuracy: 0.9694949494949495 Loss: 0.0025984934344887734 Corrects: 4799\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.00425616092979908\n",
            "Train step - Step 1890, Loss 0.003124365583062172\n",
            "Train step - Step 1900, Loss 0.0028377226553857327\n",
            "Train step - Step 1910, Loss 0.0021512885577976704\n",
            "Train epoch - Accuracy: 0.9648484848484848 Loss: 0.0030345861258154567 Corrects: 4776\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.001212865230627358\n",
            "Train step - Step 1930, Loss 0.0013463528594002128\n",
            "Train step - Step 1940, Loss 0.002053760224953294\n",
            "Train epoch - Accuracy: 0.9856565656565657 Loss: 0.0016144536646327586 Corrects: 4879\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0008562349830754101\n",
            "Train step - Step 1960, Loss 0.000521759211551398\n",
            "Train step - Step 1970, Loss 0.0009098342270590365\n",
            "Train step - Step 1980, Loss 0.0008148718625307083\n",
            "Train epoch - Accuracy: 0.9937373737373737 Loss: 0.0009685359246125727 Corrects: 4919\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0005607092753052711\n",
            "Train step - Step 2000, Loss 0.0006357874372042716\n",
            "Train step - Step 2010, Loss 0.0003832040529232472\n",
            "Train step - Step 2020, Loss 0.0005015485803596675\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0007831554901739112 Corrects: 4921\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0007258024415932596\n",
            "Train step - Step 2040, Loss 0.0010644715512171388\n",
            "Train step - Step 2050, Loss 0.0006246098200790584\n",
            "Train step - Step 2060, Loss 0.000416777387727052\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0006981483687449134 Corrects: 4933\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0004923677770420909\n",
            "Train step - Step 2080, Loss 0.000815442530438304\n",
            "Train step - Step 2090, Loss 0.0004349564842414111\n",
            "Train step - Step 2100, Loss 0.00038614735240116715\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0006199750228022987 Corrects: 4936\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0007348762010224164\n",
            "Train step - Step 2120, Loss 0.0006760613759979606\n",
            "Train step - Step 2130, Loss 0.0010110317962244153\n",
            "Train step - Step 2140, Loss 0.0012051278026774526\n",
            "Train epoch - Accuracy: 0.9947474747474747 Loss: 0.0006896195272124852 Corrects: 4924\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0005242196493782103\n",
            "Train step - Step 2160, Loss 0.0004240138514433056\n",
            "Train step - Step 2170, Loss 0.0005449614836834371\n",
            "Train step - Step 2180, Loss 0.001531156711280346\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0006126164857091175 Corrects: 4931\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0004025447997264564\n",
            "Train step - Step 2200, Loss 0.0007747184135951102\n",
            "Train step - Step 2210, Loss 0.00022683452698402107\n",
            "Train step - Step 2220, Loss 0.0004332253593020141\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0004859032550582079 Corrects: 4943\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0006256076158024371\n",
            "Train step - Step 2240, Loss 0.000370149064110592\n",
            "Train step - Step 2250, Loss 0.000607144960667938\n",
            "Train step - Step 2260, Loss 0.0006361565319821239\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0004675872570416429 Corrects: 4943\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0006942505133338273\n",
            "Train step - Step 2280, Loss 0.00031636570929549634\n",
            "Train step - Step 2290, Loss 0.0003136764862574637\n",
            "Train step - Step 2300, Loss 0.001266744453459978\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0004551438864960213 Corrects: 4938\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0004254213417880237\n",
            "Train step - Step 2320, Loss 0.00019255637016613036\n",
            "Train step - Step 2330, Loss 0.00031045032665133476\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0004360661814941771 Corrects: 4937\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0003705581766553223\n",
            "Train step - Step 2350, Loss 0.0001832096022553742\n",
            "Train step - Step 2360, Loss 0.00026441499358043075\n",
            "Train step - Step 2370, Loss 0.00024339077936019748\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00038744696328943276 Corrects: 4943\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0003713882470037788\n",
            "Train step - Step 2390, Loss 0.00035874536843039095\n",
            "Train step - Step 2400, Loss 0.00042265982483513653\n",
            "Train step - Step 2410, Loss 0.0004855988372582942\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.000411096184956606 Corrects: 4941\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00015067921776790172\n",
            "Train step - Step 2430, Loss 0.00032751349499449134\n",
            "Train step - Step 2440, Loss 0.0004519434878602624\n",
            "Train step - Step 2450, Loss 0.0005376604385674\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0003808878940845266 Corrects: 4945\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.000188796067959629\n",
            "Train step - Step 2470, Loss 0.0003451516677159816\n",
            "Train step - Step 2480, Loss 0.000314627424813807\n",
            "Train step - Step 2490, Loss 0.00036659740726463497\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00036093045224793103 Corrects: 4947\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00024988187942653894\n",
            "Train step - Step 2510, Loss 0.00027502054581418633\n",
            "Train step - Step 2520, Loss 0.00021757587091997266\n",
            "Train step - Step 2530, Loss 0.000387851323466748\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.0003806538924556037 Corrects: 4940\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0009126365184783936\n",
            "Train step - Step 2550, Loss 0.0003857846313621849\n",
            "Train step - Step 2560, Loss 0.0010634103091433644\n",
            "Train step - Step 2570, Loss 0.00022510226699523628\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0003776202607086173 Corrects: 4943\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.00017985889280680567\n",
            "Train step - Step 2590, Loss 0.000281676126178354\n",
            "Train step - Step 2600, Loss 0.000638327153865248\n",
            "Train step - Step 2610, Loss 0.000256094936048612\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0003452681383527251 Corrects: 4945\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0002432744367979467\n",
            "Train step - Step 2630, Loss 0.000385584426112473\n",
            "Train step - Step 2640, Loss 0.00020326400408521295\n",
            "Train step - Step 2650, Loss 0.00023177042021416128\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00032695100376984535 Corrects: 4947\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0003891625674441457\n",
            "Train step - Step 2670, Loss 0.00025573643506504595\n",
            "Train step - Step 2680, Loss 0.00034799150307662785\n",
            "Train step - Step 2690, Loss 0.0003739972016774118\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002965296262338983 Corrects: 4946\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00021662903600372374\n",
            "Train step - Step 2710, Loss 0.00020431779557839036\n",
            "Train step - Step 2720, Loss 0.00014123682922217995\n",
            "Train epoch - Accuracy: 0.9997979797979798 Loss: 0.00027994211892493895 Corrects: 4949\n",
            "Training finished in 212.62339639663696 seconds\n",
            "EVALUATION:  0.88 0.019250676035881042\n",
            "TEST GROUP:  0.89\n",
            "TEST ALL:  0.12714285714285714\n",
            "GROUP:  8\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.16465787589550018\n",
            "Train step - Step 10, Loss 0.06259465217590332\n",
            "Train step - Step 20, Loss 0.03802430257201195\n",
            "Train step - Step 30, Loss 0.029282907024025917\n",
            "Train epoch - Accuracy: 0.29313131313131313 Loss: 0.047613212924563525 Corrects: 1451\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.022459212690591812\n",
            "Train step - Step 50, Loss 0.024062203243374825\n",
            "Train step - Step 60, Loss 0.019056132063269615\n",
            "Train step - Step 70, Loss 0.01730361394584179\n",
            "Train epoch - Accuracy: 0.6729292929292929 Loss: 0.02091067400770356 Corrects: 3331\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.016256868839263916\n",
            "Train step - Step 90, Loss 0.014720278792083263\n",
            "Train step - Step 100, Loss 0.013039171695709229\n",
            "Train step - Step 110, Loss 0.011309681460261345\n",
            "Train epoch - Accuracy: 0.785050505050505 Loss: 0.014452693219287226 Corrects: 3886\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.014452481642365456\n",
            "Train step - Step 130, Loss 0.012907608412206173\n",
            "Train step - Step 140, Loss 0.013928336091339588\n",
            "Train step - Step 150, Loss 0.008181752637028694\n",
            "Train epoch - Accuracy: 0.8385858585858585 Loss: 0.01117838413200595 Corrects: 4151\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.01186645682901144\n",
            "Train step - Step 170, Loss 0.010548255406320095\n",
            "Train step - Step 180, Loss 0.011235538870096207\n",
            "Train step - Step 190, Loss 0.013208004646003246\n",
            "Train epoch - Accuracy: 0.8460606060606061 Loss: 0.01061099718955129 Corrects: 4188\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.008240028284490108\n",
            "Train step - Step 210, Loss 0.009860122576355934\n",
            "Train step - Step 220, Loss 0.007708802819252014\n",
            "Train step - Step 230, Loss 0.009423516690731049\n",
            "Train epoch - Accuracy: 0.8725252525252525 Loss: 0.009015208441726487 Corrects: 4319\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00884540006518364\n",
            "Train step - Step 250, Loss 0.008196072652935982\n",
            "Train step - Step 260, Loss 0.00829666294157505\n",
            "Train step - Step 270, Loss 0.007962550967931747\n",
            "Train epoch - Accuracy: 0.878989898989899 Loss: 0.008338261103690273 Corrects: 4351\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.0072368234395980835\n",
            "Train step - Step 290, Loss 0.007552880793809891\n",
            "Train step - Step 300, Loss 0.009504415094852448\n",
            "Train step - Step 310, Loss 0.007511545903980732\n",
            "Train epoch - Accuracy: 0.8913131313131313 Loss: 0.007539756409635749 Corrects: 4412\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.004442086908966303\n",
            "Train step - Step 330, Loss 0.00859470572322607\n",
            "Train step - Step 340, Loss 0.007870418950915337\n",
            "Train step - Step 350, Loss 0.00984677579253912\n",
            "Train epoch - Accuracy: 0.9042424242424243 Loss: 0.0067317738335090456 Corrects: 4476\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.005855002906173468\n",
            "Train step - Step 370, Loss 0.007590984459966421\n",
            "Train step - Step 380, Loss 0.006319369655102491\n",
            "Train epoch - Accuracy: 0.9026262626262627 Loss: 0.006577843100095939 Corrects: 4468\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.00484013557434082\n",
            "Train step - Step 400, Loss 0.008311565034091473\n",
            "Train step - Step 410, Loss 0.005539417266845703\n",
            "Train step - Step 420, Loss 0.006272125989198685\n",
            "Train epoch - Accuracy: 0.9167676767676768 Loss: 0.005956584018551641 Corrects: 4538\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.004616198129951954\n",
            "Train step - Step 440, Loss 0.005620819516479969\n",
            "Train step - Step 450, Loss 0.005332715809345245\n",
            "Train step - Step 460, Loss 0.0066460841335356236\n",
            "Train epoch - Accuracy: 0.927070707070707 Loss: 0.005392950238151984 Corrects: 4589\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.005114059429615736\n",
            "Train step - Step 480, Loss 0.0055137560702860355\n",
            "Train step - Step 490, Loss 0.003563439240679145\n",
            "Train step - Step 500, Loss 0.004939378704875708\n",
            "Train epoch - Accuracy: 0.9296969696969697 Loss: 0.005044876271576592 Corrects: 4602\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.0031572473235428333\n",
            "Train step - Step 520, Loss 0.005684805568307638\n",
            "Train step - Step 530, Loss 0.006331411190330982\n",
            "Train step - Step 540, Loss 0.008486366830766201\n",
            "Train epoch - Accuracy: 0.9242424242424242 Loss: 0.0054319621690294955 Corrects: 4575\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.004979023709893227\n",
            "Train step - Step 560, Loss 0.0025778801646083593\n",
            "Train step - Step 570, Loss 0.0036601366009563208\n",
            "Train step - Step 580, Loss 0.004298138897866011\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.004726485745285195 Corrects: 4621\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.0037123386282473803\n",
            "Train step - Step 600, Loss 0.004330277442932129\n",
            "Train step - Step 610, Loss 0.004181741736829281\n",
            "Train step - Step 620, Loss 0.00459883501753211\n",
            "Train epoch - Accuracy: 0.942020202020202 Loss: 0.004221433030272072 Corrects: 4663\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.002888165879994631\n",
            "Train step - Step 640, Loss 0.005092555191367865\n",
            "Train step - Step 650, Loss 0.0037927546072751284\n",
            "Train step - Step 660, Loss 0.004582816734910011\n",
            "Train epoch - Accuracy: 0.936969696969697 Loss: 0.004520729923564376 Corrects: 4638\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.0033294917084276676\n",
            "Train step - Step 680, Loss 0.003621116280555725\n",
            "Train step - Step 690, Loss 0.004381132312119007\n",
            "Train step - Step 700, Loss 0.004960913211107254\n",
            "Train epoch - Accuracy: 0.9416161616161616 Loss: 0.004145574954460667 Corrects: 4661\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.0039497921243309975\n",
            "Train step - Step 720, Loss 0.004524565767496824\n",
            "Train step - Step 730, Loss 0.003779048565775156\n",
            "Train step - Step 740, Loss 0.0026132450439035892\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.003986403743237859 Corrects: 4678\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.0024047777988016605\n",
            "Train step - Step 760, Loss 0.004016348626464605\n",
            "Train step - Step 770, Loss 0.003143173875287175\n",
            "Train epoch - Accuracy: 0.9498989898989899 Loss: 0.003567178955094682 Corrects: 4702\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.003098765155300498\n",
            "Train step - Step 790, Loss 0.0027855373919010162\n",
            "Train step - Step 800, Loss 0.0039039209950715303\n",
            "Train step - Step 810, Loss 0.005294883623719215\n",
            "Train epoch - Accuracy: 0.9519191919191919 Loss: 0.003729961733757095 Corrects: 4712\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.004437159281224012\n",
            "Train step - Step 830, Loss 0.006925211753696203\n",
            "Train step - Step 840, Loss 0.0028876657597720623\n",
            "Train step - Step 850, Loss 0.002744868863373995\n",
            "Train epoch - Accuracy: 0.9452525252525252 Loss: 0.003919182115921167 Corrects: 4679\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.0034923681523650885\n",
            "Train step - Step 870, Loss 0.003485334338620305\n",
            "Train step - Step 880, Loss 0.004256939981132746\n",
            "Train step - Step 890, Loss 0.003307608887553215\n",
            "Train epoch - Accuracy: 0.946060606060606 Loss: 0.004032069013613944 Corrects: 4683\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.0021592972334474325\n",
            "Train step - Step 910, Loss 0.004270027857273817\n",
            "Train step - Step 920, Loss 0.002042546635493636\n",
            "Train step - Step 930, Loss 0.004248034209012985\n",
            "Train epoch - Accuracy: 0.9573737373737373 Loss: 0.003177065708288791 Corrects: 4739\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.00268920068629086\n",
            "Train step - Step 950, Loss 0.002189303981140256\n",
            "Train step - Step 960, Loss 0.002656706143170595\n",
            "Train step - Step 970, Loss 0.004144058097153902\n",
            "Train epoch - Accuracy: 0.9591919191919192 Loss: 0.0029553190518095337 Corrects: 4748\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0022141963709145784\n",
            "Train step - Step 990, Loss 0.001824833801947534\n",
            "Train step - Step 1000, Loss 0.002443162491545081\n",
            "Train step - Step 1010, Loss 0.0034915830474346876\n",
            "Train epoch - Accuracy: 0.9606060606060606 Loss: 0.0029841392236112647 Corrects: 4755\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.00384159991517663\n",
            "Train step - Step 1030, Loss 0.0034694464411586523\n",
            "Train step - Step 1040, Loss 0.0021356740035116673\n",
            "Train step - Step 1050, Loss 0.002696092939004302\n",
            "Train epoch - Accuracy: 0.9573737373737373 Loss: 0.003080332021257191 Corrects: 4739\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0052792904898524284\n",
            "Train step - Step 1070, Loss 0.003101189387962222\n",
            "Train step - Step 1080, Loss 0.004504846874624491\n",
            "Train step - Step 1090, Loss 0.0017517689848318696\n",
            "Train epoch - Accuracy: 0.9585858585858585 Loss: 0.003005975183155952 Corrects: 4745\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.003914026077836752\n",
            "Train step - Step 1110, Loss 0.003624711185693741\n",
            "Train step - Step 1120, Loss 0.0013917448231950402\n",
            "Train step - Step 1130, Loss 0.002993214875459671\n",
            "Train epoch - Accuracy: 0.9636363636363636 Loss: 0.0027329233364023343 Corrects: 4770\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.002452622400596738\n",
            "Train step - Step 1150, Loss 0.0016461672494187951\n",
            "Train step - Step 1160, Loss 0.0016898422036319971\n",
            "Train epoch - Accuracy: 0.9632323232323232 Loss: 0.0026771065391449616 Corrects: 4768\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0015292817261070013\n",
            "Train step - Step 1180, Loss 0.0020365393720567226\n",
            "Train step - Step 1190, Loss 0.002161421813070774\n",
            "Train step - Step 1200, Loss 0.0022576823830604553\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.002659052269006468 Corrects: 4772\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0013557822676375508\n",
            "Train step - Step 1220, Loss 0.0015473294770345092\n",
            "Train step - Step 1230, Loss 0.0024950539227575064\n",
            "Train step - Step 1240, Loss 0.005158399697393179\n",
            "Train epoch - Accuracy: 0.9618181818181818 Loss: 0.0029305708897535247 Corrects: 4761\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0023985975421965122\n",
            "Train step - Step 1260, Loss 0.004241150338202715\n",
            "Train step - Step 1270, Loss 0.0022008654195815325\n",
            "Train step - Step 1280, Loss 0.003720533801242709\n",
            "Train epoch - Accuracy: 0.9567676767676768 Loss: 0.003100227179532551 Corrects: 4736\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.001534096198156476\n",
            "Train step - Step 1300, Loss 0.002348305657505989\n",
            "Train step - Step 1310, Loss 0.0017935800133273005\n",
            "Train step - Step 1320, Loss 0.002441783668473363\n",
            "Train epoch - Accuracy: 0.9688888888888889 Loss: 0.0023598423277526493 Corrects: 4796\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0023496784269809723\n",
            "Train step - Step 1340, Loss 0.001566995750181377\n",
            "Train step - Step 1350, Loss 0.0021106356289237738\n",
            "Train step - Step 1360, Loss 0.0015511258970946074\n",
            "Train epoch - Accuracy: 0.973939393939394 Loss: 0.0021422224028995545 Corrects: 4821\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.002922728890553117\n",
            "Train step - Step 1380, Loss 0.0026062268298119307\n",
            "Train step - Step 1390, Loss 0.0014555270317941904\n",
            "Train step - Step 1400, Loss 0.0024346616119146347\n",
            "Train epoch - Accuracy: 0.9737373737373738 Loss: 0.002217469996763299 Corrects: 4820\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002210325328633189\n",
            "Train step - Step 1420, Loss 0.0016934737795963883\n",
            "Train step - Step 1430, Loss 0.003954753279685974\n",
            "Train step - Step 1440, Loss 0.0016331274528056383\n",
            "Train epoch - Accuracy: 0.971919191919192 Loss: 0.0022799916340583803 Corrects: 4811\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.001391397207044065\n",
            "Train step - Step 1460, Loss 0.0032220555003732443\n",
            "Train step - Step 1470, Loss 0.002441928954795003\n",
            "Train step - Step 1480, Loss 0.002436833456158638\n",
            "Train epoch - Accuracy: 0.9806060606060606 Loss: 0.001873725267748038 Corrects: 4854\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0018470879876986146\n",
            "Train step - Step 1500, Loss 0.003156939521431923\n",
            "Train step - Step 1510, Loss 0.0024914913810789585\n",
            "Train step - Step 1520, Loss 0.0027921071741729975\n",
            "Train epoch - Accuracy: 0.9753535353535353 Loss: 0.002088755215941505 Corrects: 4828\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.0012950955424457788\n",
            "Train step - Step 1540, Loss 0.0030953946989029646\n",
            "Train step - Step 1550, Loss 0.0016532129375264049\n",
            "Train epoch - Accuracy: 0.9777777777777777 Loss: 0.0017915396130352159 Corrects: 4840\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0020129613112658262\n",
            "Train step - Step 1570, Loss 0.0009994505671784282\n",
            "Train step - Step 1580, Loss 0.0009856742108240724\n",
            "Train step - Step 1590, Loss 0.0022996338084340096\n",
            "Train epoch - Accuracy: 0.9763636363636363 Loss: 0.0018583846949229035 Corrects: 4833\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0031995230820029974\n",
            "Train step - Step 1610, Loss 0.002228444442152977\n",
            "Train step - Step 1620, Loss 0.0029575563967227936\n",
            "Train step - Step 1630, Loss 0.0021924455650150776\n",
            "Train epoch - Accuracy: 0.9743434343434343 Loss: 0.0020258522296625406 Corrects: 4823\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.002236784202978015\n",
            "Train step - Step 1650, Loss 0.003759898943826556\n",
            "Train step - Step 1660, Loss 0.0025804024189710617\n",
            "Train step - Step 1670, Loss 0.002245651325210929\n",
            "Train epoch - Accuracy: 0.9709090909090909 Loss: 0.0021245630473049 Corrects: 4806\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0016874741995707154\n",
            "Train step - Step 1690, Loss 0.0036466338206082582\n",
            "Train step - Step 1700, Loss 0.0022150948643684387\n",
            "Train step - Step 1710, Loss 0.0012277206405997276\n",
            "Train epoch - Accuracy: 0.9753535353535353 Loss: 0.0020102833691194202 Corrects: 4828\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0020133533980697393\n",
            "Train step - Step 1730, Loss 0.0017605938483029604\n",
            "Train step - Step 1740, Loss 0.0007656817324459553\n",
            "Train step - Step 1750, Loss 0.0030856213998049498\n",
            "Train epoch - Accuracy: 0.9713131313131314 Loss: 0.002221672305310465 Corrects: 4808\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.0013078629272058606\n",
            "Train step - Step 1770, Loss 0.0028532512951642275\n",
            "Train step - Step 1780, Loss 0.0037138238549232483\n",
            "Train step - Step 1790, Loss 0.0032729250378906727\n",
            "Train epoch - Accuracy: 0.9682828282828283 Loss: 0.002494768438992476 Corrects: 4793\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0016104551032185555\n",
            "Train step - Step 1810, Loss 0.0033581405878067017\n",
            "Train step - Step 1820, Loss 0.001734747551381588\n",
            "Train step - Step 1830, Loss 0.001253192313015461\n",
            "Train epoch - Accuracy: 0.9664646464646465 Loss: 0.0025136073176382167 Corrects: 4784\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.001767170848324895\n",
            "Train step - Step 1850, Loss 0.0031018233858048916\n",
            "Train step - Step 1860, Loss 0.0019086592365056276\n",
            "Train step - Step 1870, Loss 0.001656074426136911\n",
            "Train epoch - Accuracy: 0.9664646464646465 Loss: 0.0025561750738533457 Corrects: 4784\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.002790867118164897\n",
            "Train step - Step 1890, Loss 0.004439359065145254\n",
            "Train step - Step 1900, Loss 0.0025498680770397186\n",
            "Train step - Step 1910, Loss 0.0009984015487134457\n",
            "Train epoch - Accuracy: 0.9721212121212122 Loss: 0.002216752391459063 Corrects: 4812\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0009590823319740593\n",
            "Train step - Step 1930, Loss 0.001610978739336133\n",
            "Train step - Step 1940, Loss 0.000849632197059691\n",
            "Train epoch - Accuracy: 0.9846464646464647 Loss: 0.0013290112866841332 Corrects: 4874\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0004341981839388609\n",
            "Train step - Step 1960, Loss 0.000576539896428585\n",
            "Train step - Step 1970, Loss 0.000725357502233237\n",
            "Train step - Step 1980, Loss 0.0004895463935099542\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0007909281683069738 Corrects: 4917\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0006876759580336511\n",
            "Train step - Step 2000, Loss 0.0002393868489889428\n",
            "Train step - Step 2010, Loss 0.0006300967652350664\n",
            "Train step - Step 2020, Loss 0.00030784125556237996\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.000583458320200067 Corrects: 4932\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.00035526647116057575\n",
            "Train step - Step 2040, Loss 0.00044195548980496824\n",
            "Train step - Step 2050, Loss 0.0006289875018410385\n",
            "Train step - Step 2060, Loss 0.0004543998802546412\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0005474113902744997 Corrects: 4936\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.00038290387601591647\n",
            "Train step - Step 2080, Loss 0.0004861713096033782\n",
            "Train step - Step 2090, Loss 0.00036794127663597465\n",
            "Train step - Step 2100, Loss 0.000228411634452641\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00041944824861165025 Corrects: 4939\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0005941952113062143\n",
            "Train step - Step 2120, Loss 0.0003373697691131383\n",
            "Train step - Step 2130, Loss 0.00038100421079434454\n",
            "Train step - Step 2140, Loss 0.0002585445763543248\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0003993308713019948 Corrects: 4939\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.00024095697153825313\n",
            "Train step - Step 2160, Loss 0.00033285198151133955\n",
            "Train step - Step 2170, Loss 0.0006890587392263114\n",
            "Train step - Step 2180, Loss 0.00032228906638920307\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00036091192501992215 Corrects: 4944\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0003658188506960869\n",
            "Train step - Step 2200, Loss 0.000302332075079903\n",
            "Train step - Step 2210, Loss 0.00038170989137142897\n",
            "Train step - Step 2220, Loss 0.00021321923122741282\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00035917223642834207 Corrects: 4942\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0004914439632557333\n",
            "Train step - Step 2240, Loss 0.00019944296218454838\n",
            "Train step - Step 2250, Loss 0.00025867632939480245\n",
            "Train step - Step 2260, Loss 0.00019576666818466038\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00040943792078060786 Corrects: 4938\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.00038969615707173944\n",
            "Train step - Step 2280, Loss 0.000219979090616107\n",
            "Train step - Step 2290, Loss 0.00023514438362326473\n",
            "Train step - Step 2300, Loss 0.000498542096465826\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.0003089150118481631 Corrects: 4948\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.00038804757059551775\n",
            "Train step - Step 2320, Loss 0.00029393789009191096\n",
            "Train step - Step 2330, Loss 0.00018026224279310554\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.000333829076221034 Corrects: 4945\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00023071168106980622\n",
            "Train step - Step 2350, Loss 0.00020661487360484898\n",
            "Train step - Step 2360, Loss 0.00021197991736698896\n",
            "Train step - Step 2370, Loss 0.00019052837160415947\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.000296349338881408 Corrects: 4947\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00027414000942371786\n",
            "Train step - Step 2390, Loss 0.00020337307068984956\n",
            "Train step - Step 2400, Loss 0.00031524288351647556\n",
            "Train step - Step 2410, Loss 0.00013201404362916946\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0003137999345111012 Corrects: 4943\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0003432638186495751\n",
            "Train step - Step 2430, Loss 0.0004410732944961637\n",
            "Train step - Step 2440, Loss 0.0002486243029125035\n",
            "Train step - Step 2450, Loss 0.001097153639420867\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0002983601416009619 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00016881567717064172\n",
            "Train step - Step 2470, Loss 0.00038557976949959993\n",
            "Train step - Step 2480, Loss 0.00016177627549041063\n",
            "Train step - Step 2490, Loss 0.0001262801670236513\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.000251163994714693 Corrects: 4947\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0008432999602518976\n",
            "Train step - Step 2510, Loss 0.000528165022842586\n",
            "Train step - Step 2520, Loss 0.00015840207925066352\n",
            "Train step - Step 2530, Loss 0.00022869375243317336\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0002810029979828143 Corrects: 4944\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00024161585315596312\n",
            "Train step - Step 2550, Loss 0.00018857685790862888\n",
            "Train step - Step 2560, Loss 0.0001783135812729597\n",
            "Train step - Step 2570, Loss 0.0003293613553978503\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00025481356370187544 Corrects: 4948\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002785393444355577\n",
            "Train step - Step 2590, Loss 0.00033089934731833637\n",
            "Train step - Step 2600, Loss 0.00011175929103046656\n",
            "Train step - Step 2610, Loss 0.000293794582830742\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00024767421895633405 Corrects: 4948\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00018227779946755618\n",
            "Train step - Step 2630, Loss 0.000248270807787776\n",
            "Train step - Step 2640, Loss 0.00021135770657565445\n",
            "Train step - Step 2650, Loss 0.00047409749822691083\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00023944739429891635 Corrects: 4947\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0001466084795538336\n",
            "Train step - Step 2670, Loss 0.00025467207888141274\n",
            "Train step - Step 2680, Loss 0.00022896121663507074\n",
            "Train step - Step 2690, Loss 0.00024854179355315864\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00025325446339051304 Corrects: 4943\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00018966618517879397\n",
            "Train step - Step 2710, Loss 0.00015276441990863532\n",
            "Train step - Step 2720, Loss 0.00023243467148859054\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00022503922858647062 Corrects: 4948\n",
            "Training finished in 209.4181125164032 seconds\n",
            "EVALUATION:  0.88 0.00726945698261261\n",
            "TEST GROUP:  0.918\n",
            "TEST ALL:  0.11475\n",
            "GROUP:  9\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.12260647118091583\n",
            "Train step - Step 10, Loss 0.050530947744846344\n",
            "Train step - Step 20, Loss 0.03092491254210472\n",
            "Train step - Step 30, Loss 0.02659221738576889\n",
            "Train epoch - Accuracy: 0.2971717171717172 Loss: 0.03935155123697989 Corrects: 1471\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.022024035453796387\n",
            "Train step - Step 50, Loss 0.019956130534410477\n",
            "Train step - Step 60, Loss 0.01775215193629265\n",
            "Train step - Step 70, Loss 0.015876278281211853\n",
            "Train epoch - Accuracy: 0.6450505050505051 Loss: 0.01846952210171054 Corrects: 3193\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.01423962414264679\n",
            "Train step - Step 90, Loss 0.01718536764383316\n",
            "Train step - Step 100, Loss 0.010930108837783337\n",
            "Train step - Step 110, Loss 0.012747615575790405\n",
            "Train epoch - Accuracy: 0.7537373737373737 Loss: 0.013868442093483126 Corrects: 3731\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.012842890806496143\n",
            "Train step - Step 130, Loss 0.010672101750969887\n",
            "Train step - Step 140, Loss 0.011244406923651695\n",
            "Train step - Step 150, Loss 0.01122558955103159\n",
            "Train epoch - Accuracy: 0.7828282828282829 Loss: 0.012090046044175674 Corrects: 3875\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.011329527013003826\n",
            "Train step - Step 170, Loss 0.011323714628815651\n",
            "Train step - Step 180, Loss 0.00933657493442297\n",
            "Train step - Step 190, Loss 0.008238614536821842\n",
            "Train epoch - Accuracy: 0.8222222222222222 Loss: 0.01038387984376062 Corrects: 4070\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.00899200327694416\n",
            "Train step - Step 210, Loss 0.007551240269094706\n",
            "Train step - Step 220, Loss 0.011613786220550537\n",
            "Train step - Step 230, Loss 0.00819062814116478\n",
            "Train epoch - Accuracy: 0.8404040404040404 Loss: 0.009384133448128147 Corrects: 4160\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.01013721153140068\n",
            "Train step - Step 250, Loss 0.007988609373569489\n",
            "Train step - Step 260, Loss 0.00782678835093975\n",
            "Train step - Step 270, Loss 0.00744768138974905\n",
            "Train epoch - Accuracy: 0.8533333333333334 Loss: 0.00861529825386977 Corrects: 4224\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.006317558232694864\n",
            "Train step - Step 290, Loss 0.009252529591321945\n",
            "Train step - Step 300, Loss 0.009576220996677876\n",
            "Train step - Step 310, Loss 0.00664703082293272\n",
            "Train epoch - Accuracy: 0.8676767676767677 Loss: 0.007951142737133937 Corrects: 4295\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.005280293524265289\n",
            "Train step - Step 330, Loss 0.006005029194056988\n",
            "Train step - Step 340, Loss 0.008539942093193531\n",
            "Train step - Step 350, Loss 0.008354000747203827\n",
            "Train epoch - Accuracy: 0.8795959595959596 Loss: 0.007233821746676859 Corrects: 4354\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.008678711019456387\n",
            "Train step - Step 370, Loss 0.007185663096606731\n",
            "Train step - Step 380, Loss 0.00814258586615324\n",
            "Train epoch - Accuracy: 0.8793939393939394 Loss: 0.00721908764970122 Corrects: 4353\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0049924529157578945\n",
            "Train step - Step 400, Loss 0.005759719293564558\n",
            "Train step - Step 410, Loss 0.007585578598082066\n",
            "Train step - Step 420, Loss 0.006634585093706846\n",
            "Train epoch - Accuracy: 0.8991919191919192 Loss: 0.006299749248557621 Corrects: 4451\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.005310600157827139\n",
            "Train step - Step 440, Loss 0.007843400351703167\n",
            "Train step - Step 450, Loss 0.005898158065974712\n",
            "Train step - Step 460, Loss 0.0069573246873915195\n",
            "Train epoch - Accuracy: 0.8917171717171717 Loss: 0.0063889808309349145 Corrects: 4414\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.005885581485927105\n",
            "Train step - Step 480, Loss 0.004761133808642626\n",
            "Train step - Step 490, Loss 0.0072249434888362885\n",
            "Train step - Step 500, Loss 0.006381616927683353\n",
            "Train epoch - Accuracy: 0.8971717171717172 Loss: 0.006147846680021647 Corrects: 4441\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.005842672660946846\n",
            "Train step - Step 520, Loss 0.004137026146054268\n",
            "Train step - Step 530, Loss 0.00842814426869154\n",
            "Train step - Step 540, Loss 0.004948612302541733\n",
            "Train epoch - Accuracy: 0.9026262626262627 Loss: 0.005909604818720107 Corrects: 4468\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.005485139321535826\n",
            "Train step - Step 560, Loss 0.004476987291127443\n",
            "Train step - Step 570, Loss 0.003984869457781315\n",
            "Train step - Step 580, Loss 0.00606547063216567\n",
            "Train epoch - Accuracy: 0.9175757575757576 Loss: 0.005231095237676242 Corrects: 4542\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.006579182576388121\n",
            "Train step - Step 600, Loss 0.003895205445587635\n",
            "Train step - Step 610, Loss 0.004678564611822367\n",
            "Train step - Step 620, Loss 0.0034345064777880907\n",
            "Train epoch - Accuracy: 0.9084848484848485 Loss: 0.0056162196273605025 Corrects: 4497\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.006178767420351505\n",
            "Train step - Step 640, Loss 0.005234615411609411\n",
            "Train step - Step 650, Loss 0.006339618470519781\n",
            "Train step - Step 660, Loss 0.005216569639742374\n",
            "Train epoch - Accuracy: 0.9155555555555556 Loss: 0.005462262350689582 Corrects: 4532\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.004493796732276678\n",
            "Train step - Step 680, Loss 0.005511728581041098\n",
            "Train step - Step 690, Loss 0.006854028441011906\n",
            "Train step - Step 700, Loss 0.007736920844763517\n",
            "Train epoch - Accuracy: 0.9165656565656566 Loss: 0.005077243947583919 Corrects: 4537\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.004250410012900829\n",
            "Train step - Step 720, Loss 0.004547423683106899\n",
            "Train step - Step 730, Loss 0.006370944436639547\n",
            "Train step - Step 740, Loss 0.008877626620233059\n",
            "Train epoch - Accuracy: 0.9252525252525252 Loss: 0.004774103940210559 Corrects: 4580\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.0038110767491161823\n",
            "Train step - Step 760, Loss 0.004974867682904005\n",
            "Train step - Step 770, Loss 0.005025974940508604\n",
            "Train epoch - Accuracy: 0.9226262626262626 Loss: 0.004689916650190799 Corrects: 4567\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.004456622991710901\n",
            "Train step - Step 790, Loss 0.003457625163719058\n",
            "Train step - Step 800, Loss 0.003093142295256257\n",
            "Train step - Step 810, Loss 0.00464655552059412\n",
            "Train epoch - Accuracy: 0.9268686868686868 Loss: 0.004472442206484501 Corrects: 4588\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.003586479229852557\n",
            "Train step - Step 830, Loss 0.003882564138621092\n",
            "Train step - Step 840, Loss 0.005258786026388407\n",
            "Train step - Step 850, Loss 0.003977552521973848\n",
            "Train epoch - Accuracy: 0.9315151515151515 Loss: 0.004418456500226801 Corrects: 4611\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.004479016177356243\n",
            "Train step - Step 870, Loss 0.0033452727366238832\n",
            "Train step - Step 880, Loss 0.004316822625696659\n",
            "Train step - Step 890, Loss 0.005615150555968285\n",
            "Train epoch - Accuracy: 0.927070707070707 Loss: 0.004570875471514283 Corrects: 4589\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.0035078611690551043\n",
            "Train step - Step 910, Loss 0.0038024710956960917\n",
            "Train step - Step 920, Loss 0.00328736356459558\n",
            "Train step - Step 930, Loss 0.003983526956290007\n",
            "Train epoch - Accuracy: 0.9276767676767677 Loss: 0.004403886804827536 Corrects: 4592\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.005144362337887287\n",
            "Train step - Step 950, Loss 0.005695623811334372\n",
            "Train step - Step 960, Loss 0.005210502538830042\n",
            "Train step - Step 970, Loss 0.004045539069920778\n",
            "Train epoch - Accuracy: 0.9375757575757576 Loss: 0.004010539598518399 Corrects: 4641\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.004437141586095095\n",
            "Train step - Step 990, Loss 0.004120346158742905\n",
            "Train step - Step 1000, Loss 0.0049415514804422855\n",
            "Train step - Step 1010, Loss 0.004286418668925762\n",
            "Train epoch - Accuracy: 0.9414141414141414 Loss: 0.003762042968712672 Corrects: 4660\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.003722868161275983\n",
            "Train step - Step 1030, Loss 0.0051147229969501495\n",
            "Train step - Step 1040, Loss 0.004299038555473089\n",
            "Train step - Step 1050, Loss 0.0031473487615585327\n",
            "Train epoch - Accuracy: 0.9363636363636364 Loss: 0.004073051654103429 Corrects: 4635\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.004126173444092274\n",
            "Train step - Step 1070, Loss 0.002602101769298315\n",
            "Train step - Step 1080, Loss 0.00487350020557642\n",
            "Train step - Step 1090, Loss 0.005211115814745426\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.0035099782406192537 Corrects: 4703\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.0030652410350739956\n",
            "Train step - Step 1110, Loss 0.0027566631324589252\n",
            "Train step - Step 1120, Loss 0.004041176754981279\n",
            "Train step - Step 1130, Loss 0.003808630397543311\n",
            "Train epoch - Accuracy: 0.9478787878787879 Loss: 0.0033012663984125614 Corrects: 4692\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.0019270326010882854\n",
            "Train step - Step 1150, Loss 0.0019887208472937346\n",
            "Train step - Step 1160, Loss 0.004544596653431654\n",
            "Train epoch - Accuracy: 0.9456565656565656 Loss: 0.0035911417999916306 Corrects: 4681\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0021707634441554546\n",
            "Train step - Step 1180, Loss 0.0030327122658491135\n",
            "Train step - Step 1190, Loss 0.0038228665944188833\n",
            "Train step - Step 1200, Loss 0.0033544886391609907\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.003432399034311976 Corrects: 4689\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0039586410857737064\n",
            "Train step - Step 1220, Loss 0.003959983587265015\n",
            "Train step - Step 1230, Loss 0.0038832752034068108\n",
            "Train step - Step 1240, Loss 0.002925968961790204\n",
            "Train epoch - Accuracy: 0.9436363636363636 Loss: 0.003617201352096868 Corrects: 4671\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.00452348031103611\n",
            "Train step - Step 1260, Loss 0.002154303714632988\n",
            "Train step - Step 1270, Loss 0.004098096396774054\n",
            "Train step - Step 1280, Loss 0.003951665945351124\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.0033178705394719585 Corrects: 4708\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0021196920424699783\n",
            "Train step - Step 1300, Loss 0.0027173946145921946\n",
            "Train step - Step 1310, Loss 0.003321136813610792\n",
            "Train step - Step 1320, Loss 0.003725595772266388\n",
            "Train epoch - Accuracy: 0.9519191919191919 Loss: 0.003112585384662103 Corrects: 4712\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0027031817007809877\n",
            "Train step - Step 1340, Loss 0.002824597992002964\n",
            "Train step - Step 1350, Loss 0.004243700299412012\n",
            "Train step - Step 1360, Loss 0.0016263758298009634\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.002724762272861118 Corrects: 4758\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0017843276727944613\n",
            "Train step - Step 1380, Loss 0.0018275970360264182\n",
            "Train step - Step 1390, Loss 0.002889160765334964\n",
            "Train step - Step 1400, Loss 0.002611509757116437\n",
            "Train epoch - Accuracy: 0.954949494949495 Loss: 0.0026977379333152614 Corrects: 4727\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0033176769502460957\n",
            "Train step - Step 1420, Loss 0.0027020189445465803\n",
            "Train step - Step 1430, Loss 0.002618257189169526\n",
            "Train step - Step 1440, Loss 0.001726840971969068\n",
            "Train epoch - Accuracy: 0.9595959595959596 Loss: 0.002692430063216674 Corrects: 4750\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0011061710538342595\n",
            "Train step - Step 1460, Loss 0.0016971029108390212\n",
            "Train step - Step 1470, Loss 0.002078002318739891\n",
            "Train step - Step 1480, Loss 0.003850855166092515\n",
            "Train epoch - Accuracy: 0.9567676767676768 Loss: 0.002849355563145093 Corrects: 4736\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0025005501229315996\n",
            "Train step - Step 1500, Loss 0.0031247895676642656\n",
            "Train step - Step 1510, Loss 0.004180690739303827\n",
            "Train step - Step 1520, Loss 0.003554594237357378\n",
            "Train epoch - Accuracy: 0.9525252525252526 Loss: 0.003018803076272962 Corrects: 4715\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.00277836830355227\n",
            "Train step - Step 1540, Loss 0.001815662020817399\n",
            "Train step - Step 1550, Loss 0.003094995394349098\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.0031171046435419054 Corrects: 4722\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0017985692247748375\n",
            "Train step - Step 1570, Loss 0.0016362647293135524\n",
            "Train step - Step 1580, Loss 0.003137307008728385\n",
            "Train step - Step 1590, Loss 0.004323345609009266\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.0031991239348802755 Corrects: 4696\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.00517052598297596\n",
            "Train step - Step 1610, Loss 0.004533198196440935\n",
            "Train step - Step 1620, Loss 0.0025094773154705763\n",
            "Train step - Step 1630, Loss 0.002942873165011406\n",
            "Train epoch - Accuracy: 0.9593939393939394 Loss: 0.0026769510943047475 Corrects: 4749\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0024556235875934362\n",
            "Train step - Step 1650, Loss 0.002011225325986743\n",
            "Train step - Step 1660, Loss 0.0029801700729876757\n",
            "Train step - Step 1670, Loss 0.0015418586554005742\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.002412117924164943 Corrects: 4769\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0022107167169451714\n",
            "Train step - Step 1690, Loss 0.0021301719825714827\n",
            "Train step - Step 1700, Loss 0.0024178202729672194\n",
            "Train step - Step 1710, Loss 0.0012919307919219136\n",
            "Train epoch - Accuracy: 0.9668686868686869 Loss: 0.002324744072705131 Corrects: 4786\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.002792064333334565\n",
            "Train step - Step 1730, Loss 0.00251899566501379\n",
            "Train step - Step 1740, Loss 0.0021251305006444454\n",
            "Train step - Step 1750, Loss 0.003119006520137191\n",
            "Train epoch - Accuracy: 0.965050505050505 Loss: 0.00239818305426249 Corrects: 4777\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.0031967496033757925\n",
            "Train step - Step 1770, Loss 0.0036777788773179054\n",
            "Train step - Step 1780, Loss 0.0019975982140749693\n",
            "Train step - Step 1790, Loss 0.0008509610197506845\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.0022278708380393006 Corrects: 4790\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0021119469311088324\n",
            "Train step - Step 1810, Loss 0.0028399634175002575\n",
            "Train step - Step 1820, Loss 0.003153511555865407\n",
            "Train step - Step 1830, Loss 0.0015680801589041948\n",
            "Train epoch - Accuracy: 0.9577777777777777 Loss: 0.002727807237663203 Corrects: 4741\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.002075034659355879\n",
            "Train step - Step 1850, Loss 0.0027501920703798532\n",
            "Train step - Step 1860, Loss 0.00233441055752337\n",
            "Train step - Step 1870, Loss 0.003150294069200754\n",
            "Train epoch - Accuracy: 0.96 Loss: 0.0026031502272294027 Corrects: 4752\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0035201162099838257\n",
            "Train step - Step 1890, Loss 0.002754387678578496\n",
            "Train step - Step 1900, Loss 0.0028456926811486483\n",
            "Train step - Step 1910, Loss 0.002158240182325244\n",
            "Train epoch - Accuracy: 0.9656565656565657 Loss: 0.0022702280861899406 Corrects: 4780\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0023282922338694334\n",
            "Train step - Step 1930, Loss 0.0008406071574427187\n",
            "Train step - Step 1940, Loss 0.0006224654498510063\n",
            "Train epoch - Accuracy: 0.9812121212121212 Loss: 0.0014433874563323428 Corrects: 4857\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0010177238145843148\n",
            "Train step - Step 1960, Loss 0.0007768808281980455\n",
            "Train step - Step 1970, Loss 0.0008868456352502108\n",
            "Train step - Step 1980, Loss 0.0005952197243459523\n",
            "Train epoch - Accuracy: 0.990909090909091 Loss: 0.0008600232930797519 Corrects: 4905\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.00030304977553896606\n",
            "Train step - Step 2000, Loss 0.0006374753429554403\n",
            "Train step - Step 2010, Loss 0.00039045989979058504\n",
            "Train step - Step 2020, Loss 0.0005323833902366459\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.0006427710035326656 Corrects: 4934\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0004560827510431409\n",
            "Train step - Step 2040, Loss 0.0003800567355938256\n",
            "Train step - Step 2050, Loss 0.00024766408023424447\n",
            "Train step - Step 2060, Loss 0.0005001626559533179\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0004923550768242679 Corrects: 4938\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0003886853810399771\n",
            "Train step - Step 2080, Loss 0.00037985644303262234\n",
            "Train step - Step 2090, Loss 0.0006394468364305794\n",
            "Train step - Step 2100, Loss 0.0008581625297665596\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0004751309349126361 Corrects: 4936\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.000669044500682503\n",
            "Train step - Step 2120, Loss 0.00033332465682178736\n",
            "Train step - Step 2130, Loss 0.0005545673193410039\n",
            "Train step - Step 2140, Loss 0.00021842970454599708\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.000441034061098095 Corrects: 4938\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0002819714427459985\n",
            "Train step - Step 2160, Loss 0.0003288537263870239\n",
            "Train step - Step 2170, Loss 0.00032843524240888655\n",
            "Train step - Step 2180, Loss 0.00031603206298314035\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0004432580729527869 Corrects: 4935\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00044125362182967365\n",
            "Train step - Step 2200, Loss 0.00037956214509904385\n",
            "Train step - Step 2210, Loss 0.0004482348740566522\n",
            "Train step - Step 2220, Loss 0.0005132225924171507\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00044787510079472806 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0004015690938103944\n",
            "Train step - Step 2240, Loss 0.0006293839542195201\n",
            "Train step - Step 2250, Loss 0.00043062178883701563\n",
            "Train step - Step 2260, Loss 0.0009767274605110288\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0004451533043851154 Corrects: 4935\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0003586293605621904\n",
            "Train step - Step 2280, Loss 0.000597262813244015\n",
            "Train step - Step 2290, Loss 0.00024134454724844545\n",
            "Train step - Step 2300, Loss 0.000538838969077915\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00040857028905208216 Corrects: 4938\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.00019428982341196388\n",
            "Train step - Step 2320, Loss 0.00044329726370051503\n",
            "Train step - Step 2330, Loss 0.0003405746247153729\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0004009158787025948 Corrects: 4941\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00023673697432968765\n",
            "Train step - Step 2350, Loss 0.00013516994658857584\n",
            "Train step - Step 2360, Loss 0.0003682659298647195\n",
            "Train step - Step 2370, Loss 0.00021014655067119747\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00035456032332296326 Corrects: 4945\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0003761535044759512\n",
            "Train step - Step 2390, Loss 0.0006245731492526829\n",
            "Train step - Step 2400, Loss 0.00034512189449742436\n",
            "Train step - Step 2410, Loss 0.0006809046026319265\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00036629806115113275 Corrects: 4942\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00024136307183653116\n",
            "Train step - Step 2430, Loss 0.0001891085266834125\n",
            "Train step - Step 2440, Loss 0.00015895927208475769\n",
            "Train step - Step 2450, Loss 0.000270815915428102\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0003628676383276329 Corrects: 4939\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00026835399330593646\n",
            "Train step - Step 2470, Loss 0.000922369014006108\n",
            "Train step - Step 2480, Loss 0.00044519768562167883\n",
            "Train step - Step 2490, Loss 0.00033013676875270903\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.0003521366805459062 Corrects: 4940\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00017982562712859362\n",
            "Train step - Step 2510, Loss 0.00029311730759218335\n",
            "Train step - Step 2520, Loss 0.0003160594205837697\n",
            "Train step - Step 2530, Loss 0.00028765451861545444\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.000334579898902883 Corrects: 4944\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00024080612638499588\n",
            "Train step - Step 2550, Loss 0.00035657055559568107\n",
            "Train step - Step 2560, Loss 0.00034930731635540724\n",
            "Train step - Step 2570, Loss 0.0004992461181245744\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.0003390891545080589 Corrects: 4940\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002000904205488041\n",
            "Train step - Step 2590, Loss 0.00026719033485278487\n",
            "Train step - Step 2600, Loss 0.00037574960151687264\n",
            "Train step - Step 2610, Loss 0.00040575911407358944\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.00033851680384638407 Corrects: 4941\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.000340048864018172\n",
            "Train step - Step 2630, Loss 0.00016404676716774702\n",
            "Train step - Step 2640, Loss 0.00023194914683699608\n",
            "Train step - Step 2650, Loss 0.0002332193253096193\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0002945212215112259 Corrects: 4942\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0001700582797639072\n",
            "Train step - Step 2670, Loss 0.0006331705371849239\n",
            "Train step - Step 2680, Loss 0.00019126506231259555\n",
            "Train step - Step 2690, Loss 0.000462805648567155\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00031457855341476246 Corrects: 4944\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0004050839052069932\n",
            "Train step - Step 2710, Loss 0.00036934303352609277\n",
            "Train step - Step 2720, Loss 0.0003773939679376781\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.00030715996695851737 Corrects: 4946\n",
            "Training finished in 208.23304080963135 seconds\n",
            "EVALUATION:  0.88 0.008050763979554176\n",
            "TEST GROUP:  0.884\n",
            "TEST ALL:  0.09822222222222222\n",
            "GROUP:  10\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.12422757595777512\n",
            "Train step - Step 10, Loss 0.056797631084918976\n",
            "Train step - Step 20, Loss 0.028952525928616524\n",
            "Train step - Step 30, Loss 0.02299593947827816\n",
            "Train epoch - Accuracy: 0.30343434343434345 Loss: 0.03826752955338569 Corrects: 1502\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.02079376019537449\n",
            "Train step - Step 50, Loss 0.017617778852581978\n",
            "Train step - Step 60, Loss 0.015455812215805054\n",
            "Train step - Step 70, Loss 0.01692831702530384\n",
            "Train epoch - Accuracy: 0.6329292929292929 Loss: 0.01730606437293869 Corrects: 3133\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.014474173076450825\n",
            "Train step - Step 90, Loss 0.01575741544365883\n",
            "Train step - Step 100, Loss 0.013274924829602242\n",
            "Train step - Step 110, Loss 0.013249984942376614\n",
            "Train epoch - Accuracy: 0.7290909090909091 Loss: 0.013691868353823218 Corrects: 3609\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.008852004073560238\n",
            "Train step - Step 130, Loss 0.010181089863181114\n",
            "Train step - Step 140, Loss 0.011511211283504963\n",
            "Train step - Step 150, Loss 0.008631777949631214\n",
            "Train epoch - Accuracy: 0.7749494949494949 Loss: 0.01136058425399089 Corrects: 3836\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.008824188262224197\n",
            "Train step - Step 170, Loss 0.009388190694153309\n",
            "Train step - Step 180, Loss 0.010638096369802952\n",
            "Train step - Step 190, Loss 0.012982813641428947\n",
            "Train epoch - Accuracy: 0.8036363636363636 Loss: 0.010030618011575154 Corrects: 3978\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.009431618265807629\n",
            "Train step - Step 210, Loss 0.012437714263796806\n",
            "Train step - Step 220, Loss 0.010373898781836033\n",
            "Train step - Step 230, Loss 0.006240917835384607\n",
            "Train epoch - Accuracy: 0.8218181818181818 Loss: 0.009247182265036936 Corrects: 4068\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00856197439134121\n",
            "Train step - Step 250, Loss 0.006026441231369972\n",
            "Train step - Step 260, Loss 0.008400456979870796\n",
            "Train step - Step 270, Loss 0.009829659014940262\n",
            "Train epoch - Accuracy: 0.850909090909091 Loss: 0.008126520393322213 Corrects: 4212\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.006039767060428858\n",
            "Train step - Step 290, Loss 0.007349287159740925\n",
            "Train step - Step 300, Loss 0.010009166784584522\n",
            "Train step - Step 310, Loss 0.009404441341757774\n",
            "Train epoch - Accuracy: 0.8543434343434343 Loss: 0.007588233585008467 Corrects: 4229\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.006660336162894964\n",
            "Train step - Step 330, Loss 0.00868950504809618\n",
            "Train step - Step 340, Loss 0.007702031638473272\n",
            "Train step - Step 350, Loss 0.007812189869582653\n",
            "Train epoch - Accuracy: 0.8595959595959596 Loss: 0.007343647763358824 Corrects: 4255\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.006914017256349325\n",
            "Train step - Step 370, Loss 0.008327901363372803\n",
            "Train step - Step 380, Loss 0.006508295424282551\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.00682945686420708 Corrects: 4326\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.005587706808000803\n",
            "Train step - Step 400, Loss 0.00734888156875968\n",
            "Train step - Step 410, Loss 0.005706878378987312\n",
            "Train step - Step 420, Loss 0.004730769898742437\n",
            "Train epoch - Accuracy: 0.8836363636363637 Loss: 0.006228446085382291 Corrects: 4374\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.004125730134546757\n",
            "Train step - Step 440, Loss 0.005208911839872599\n",
            "Train step - Step 450, Loss 0.0060067749582231045\n",
            "Train step - Step 460, Loss 0.006907059345394373\n",
            "Train epoch - Accuracy: 0.8828282828282829 Loss: 0.006151694910544338 Corrects: 4370\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.004694676958024502\n",
            "Train step - Step 480, Loss 0.006689529400318861\n",
            "Train step - Step 490, Loss 0.006528331898152828\n",
            "Train step - Step 500, Loss 0.006703583989292383\n",
            "Train epoch - Accuracy: 0.8872727272727273 Loss: 0.006046980197983559 Corrects: 4392\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.0042100632563233376\n",
            "Train step - Step 520, Loss 0.004820440895855427\n",
            "Train step - Step 530, Loss 0.00652708625420928\n",
            "Train step - Step 540, Loss 0.004824145697057247\n",
            "Train epoch - Accuracy: 0.8997979797979798 Loss: 0.005525171368411093 Corrects: 4454\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.005962157156318426\n",
            "Train step - Step 560, Loss 0.00448728958144784\n",
            "Train step - Step 570, Loss 0.005301184020936489\n",
            "Train step - Step 580, Loss 0.005460614338517189\n",
            "Train epoch - Accuracy: 0.9133333333333333 Loss: 0.005023244877882076 Corrects: 4521\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.003759917803108692\n",
            "Train step - Step 600, Loss 0.004943816922605038\n",
            "Train step - Step 610, Loss 0.005809992551803589\n",
            "Train step - Step 620, Loss 0.004567876923829317\n",
            "Train epoch - Accuracy: 0.9107070707070707 Loss: 0.004908194117661979 Corrects: 4508\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.0036569559015333652\n",
            "Train step - Step 640, Loss 0.004790959879755974\n",
            "Train step - Step 650, Loss 0.004565281793475151\n",
            "Train step - Step 660, Loss 0.005784199573099613\n",
            "Train epoch - Accuracy: 0.92 Loss: 0.004450878855593578 Corrects: 4554\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.004913671873509884\n",
            "Train step - Step 680, Loss 0.003999889828264713\n",
            "Train step - Step 690, Loss 0.003802425693720579\n",
            "Train step - Step 700, Loss 0.005256214179098606\n",
            "Train epoch - Accuracy: 0.9119191919191919 Loss: 0.004711426813531705 Corrects: 4514\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.005473481956869364\n",
            "Train step - Step 720, Loss 0.004043235909193754\n",
            "Train step - Step 730, Loss 0.005278927739709616\n",
            "Train step - Step 740, Loss 0.0034389677457511425\n",
            "Train epoch - Accuracy: 0.9121212121212121 Loss: 0.004610080570923258 Corrects: 4515\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.005227777641266584\n",
            "Train step - Step 760, Loss 0.004457751754671335\n",
            "Train step - Step 770, Loss 0.00438800361007452\n",
            "Train epoch - Accuracy: 0.9183838383838384 Loss: 0.0045415837558532 Corrects: 4546\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.0037263997364789248\n",
            "Train step - Step 790, Loss 0.0037400065921247005\n",
            "Train step - Step 800, Loss 0.0035195068921893835\n",
            "Train step - Step 810, Loss 0.004146886523813009\n",
            "Train epoch - Accuracy: 0.9218181818181819 Loss: 0.004509544027781095 Corrects: 4563\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.005294998176395893\n",
            "Train step - Step 830, Loss 0.006023544352501631\n",
            "Train step - Step 840, Loss 0.0040735541842877865\n",
            "Train step - Step 850, Loss 0.0032630031928420067\n",
            "Train epoch - Accuracy: 0.9226262626262626 Loss: 0.004293470444966747 Corrects: 4567\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.0031132863368839025\n",
            "Train step - Step 870, Loss 0.004011970013380051\n",
            "Train step - Step 880, Loss 0.0034768630284816027\n",
            "Train step - Step 890, Loss 0.0038532468024641275\n",
            "Train epoch - Accuracy: 0.9248484848484848 Loss: 0.004277103632274602 Corrects: 4578\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.002850719029083848\n",
            "Train step - Step 910, Loss 0.0037795668467879295\n",
            "Train step - Step 920, Loss 0.00542090181261301\n",
            "Train step - Step 930, Loss 0.0034057716839015484\n",
            "Train epoch - Accuracy: 0.9333333333333333 Loss: 0.0038395746285566175 Corrects: 4620\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.003515653545036912\n",
            "Train step - Step 950, Loss 0.004893068689852953\n",
            "Train step - Step 960, Loss 0.0024038529954850674\n",
            "Train step - Step 970, Loss 0.004815457854419947\n",
            "Train epoch - Accuracy: 0.9377777777777778 Loss: 0.0036778724351615617 Corrects: 4642\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0028009843081235886\n",
            "Train step - Step 990, Loss 0.0029426205437630415\n",
            "Train step - Step 1000, Loss 0.0038073682226240635\n",
            "Train step - Step 1010, Loss 0.0032148577738553286\n",
            "Train epoch - Accuracy: 0.9298989898989899 Loss: 0.003798104112384596 Corrects: 4603\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0031830118969082832\n",
            "Train step - Step 1030, Loss 0.0025035946164280176\n",
            "Train step - Step 1040, Loss 0.004234994761645794\n",
            "Train step - Step 1050, Loss 0.004146191757172346\n",
            "Train epoch - Accuracy: 0.9448484848484848 Loss: 0.003230671149518604 Corrects: 4677\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.002426064107567072\n",
            "Train step - Step 1070, Loss 0.002935422584414482\n",
            "Train step - Step 1080, Loss 0.002790435217320919\n",
            "Train step - Step 1090, Loss 0.0025360840372741222\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.003109306569935547 Corrects: 4687\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.005378255620598793\n",
            "Train step - Step 1110, Loss 0.004158603958785534\n",
            "Train step - Step 1120, Loss 0.0060843126848340034\n",
            "Train step - Step 1130, Loss 0.0024565637577325106\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.0033483449481615814 Corrects: 4658\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.0021026479080319405\n",
            "Train step - Step 1150, Loss 0.0028233821503818035\n",
            "Train step - Step 1160, Loss 0.0031026548240333796\n",
            "Train epoch - Accuracy: 0.946060606060606 Loss: 0.0032024711253817637 Corrects: 4683\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0017706232611089945\n",
            "Train step - Step 1180, Loss 0.002856789156794548\n",
            "Train step - Step 1190, Loss 0.0026483843103051186\n",
            "Train step - Step 1200, Loss 0.002201619790866971\n",
            "Train epoch - Accuracy: 0.9519191919191919 Loss: 0.0028735364815502457 Corrects: 4712\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0023172018118202686\n",
            "Train step - Step 1220, Loss 0.002869191812351346\n",
            "Train step - Step 1230, Loss 0.0028203362599015236\n",
            "Train step - Step 1240, Loss 0.003006753046065569\n",
            "Train epoch - Accuracy: 0.946060606060606 Loss: 0.003042847356109908 Corrects: 4683\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0022541906218975782\n",
            "Train step - Step 1260, Loss 0.0033255021553486586\n",
            "Train step - Step 1270, Loss 0.0030188346281647682\n",
            "Train step - Step 1280, Loss 0.002290245844051242\n",
            "Train epoch - Accuracy: 0.9357575757575758 Loss: 0.003580505322062909 Corrects: 4632\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0028787364717572927\n",
            "Train step - Step 1300, Loss 0.0032290141098201275\n",
            "Train step - Step 1310, Loss 0.0033700119238346815\n",
            "Train step - Step 1320, Loss 0.003455393947660923\n",
            "Train epoch - Accuracy: 0.9414141414141414 Loss: 0.003408676890298875 Corrects: 4660\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0035695999395102262\n",
            "Train step - Step 1340, Loss 0.0026265131309628487\n",
            "Train step - Step 1350, Loss 0.004030055832117796\n",
            "Train step - Step 1360, Loss 0.0030458318069577217\n",
            "Train epoch - Accuracy: 0.9498989898989899 Loss: 0.0029010861984106024 Corrects: 4702\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0035463236272335052\n",
            "Train step - Step 1380, Loss 0.0011684512719511986\n",
            "Train step - Step 1390, Loss 0.0016771790105849504\n",
            "Train step - Step 1400, Loss 0.0030790758319199085\n",
            "Train epoch - Accuracy: 0.9537373737373738 Loss: 0.002766400415243374 Corrects: 4721\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0020435538608580828\n",
            "Train step - Step 1420, Loss 0.0030280272476375103\n",
            "Train step - Step 1430, Loss 0.0034302775748074055\n",
            "Train step - Step 1440, Loss 0.0047635543160140514\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.0029396176954844234 Corrects: 4698\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.002385815605521202\n",
            "Train step - Step 1460, Loss 0.002162420656532049\n",
            "Train step - Step 1470, Loss 0.003966216929256916\n",
            "Train step - Step 1480, Loss 0.00315911415964365\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.0030458776688560693 Corrects: 4698\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0018900911090895534\n",
            "Train step - Step 1500, Loss 0.0018766390858218074\n",
            "Train step - Step 1510, Loss 0.0018005829770117998\n",
            "Train step - Step 1520, Loss 0.0033034333027899265\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.0028841316502428416 Corrects: 4706\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.003322364529594779\n",
            "Train step - Step 1540, Loss 0.0021595871075987816\n",
            "Train step - Step 1550, Loss 0.0037136513274163008\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.002886579515544152 Corrects: 4696\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.001732351491227746\n",
            "Train step - Step 1570, Loss 0.0028533977456390858\n",
            "Train step - Step 1580, Loss 0.0023589821066707373\n",
            "Train step - Step 1590, Loss 0.0028496598824858665\n",
            "Train epoch - Accuracy: 0.962020202020202 Loss: 0.0023935198612661675 Corrects: 4762\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0013916983734816313\n",
            "Train step - Step 1610, Loss 0.0028186929412186146\n",
            "Train step - Step 1620, Loss 0.001562581630423665\n",
            "Train step - Step 1630, Loss 0.002033304190263152\n",
            "Train epoch - Accuracy: 0.9654545454545455 Loss: 0.00215124300474094 Corrects: 4779\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.003187861992046237\n",
            "Train step - Step 1650, Loss 0.0026999968104064465\n",
            "Train step - Step 1660, Loss 0.003410191275179386\n",
            "Train step - Step 1670, Loss 0.0011768529657274485\n",
            "Train epoch - Accuracy: 0.971919191919192 Loss: 0.001984358471677159 Corrects: 4811\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0019311652285978198\n",
            "Train step - Step 1690, Loss 0.004561559297144413\n",
            "Train step - Step 1700, Loss 0.005426683463156223\n",
            "Train step - Step 1710, Loss 0.0032681350130587816\n",
            "Train epoch - Accuracy: 0.9446464646464646 Loss: 0.003221531139893664 Corrects: 4676\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.005316145718097687\n",
            "Train step - Step 1730, Loss 0.0033611906692385674\n",
            "Train step - Step 1740, Loss 0.0016386340139433742\n",
            "Train step - Step 1750, Loss 0.002520614769309759\n",
            "Train epoch - Accuracy: 0.9480808080808081 Loss: 0.003161044752394611 Corrects: 4693\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002983946818858385\n",
            "Train step - Step 1770, Loss 0.00438741035759449\n",
            "Train step - Step 1780, Loss 0.0024638348259031773\n",
            "Train step - Step 1790, Loss 0.00464714877307415\n",
            "Train epoch - Accuracy: 0.9482828282828283 Loss: 0.003095525879826811 Corrects: 4694\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0030085307080298662\n",
            "Train step - Step 1810, Loss 0.0036295943427830935\n",
            "Train step - Step 1820, Loss 0.0038157356902956963\n",
            "Train step - Step 1830, Loss 0.0013168330769985914\n",
            "Train epoch - Accuracy: 0.9591919191919192 Loss: 0.002416469759749945 Corrects: 4748\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0030897450633347034\n",
            "Train step - Step 1850, Loss 0.0011483703274279833\n",
            "Train step - Step 1860, Loss 0.001727163209579885\n",
            "Train step - Step 1870, Loss 0.0019159795483574271\n",
            "Train epoch - Accuracy: 0.9701010101010101 Loss: 0.0018633044115973242 Corrects: 4802\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0017072497867047787\n",
            "Train step - Step 1890, Loss 0.0022565838880836964\n",
            "Train step - Step 1900, Loss 0.0011419873917475343\n",
            "Train step - Step 1910, Loss 0.0017458060756325722\n",
            "Train epoch - Accuracy: 0.9688888888888889 Loss: 0.0020087665586610032 Corrects: 4796\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0009793854551389813\n",
            "Train step - Step 1930, Loss 0.000850754149723798\n",
            "Train step - Step 1940, Loss 0.0009474486578255892\n",
            "Train epoch - Accuracy: 0.9812121212121212 Loss: 0.0013590334940965128 Corrects: 4857\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0007240863051265478\n",
            "Train step - Step 1960, Loss 0.00034520262852311134\n",
            "Train step - Step 1970, Loss 0.0004738777643069625\n",
            "Train step - Step 1980, Loss 0.0008448607986792922\n",
            "Train epoch - Accuracy: 0.9937373737373737 Loss: 0.0007276186135108348 Corrects: 4919\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0004240404814481735\n",
            "Train step - Step 2000, Loss 0.0008330756099894643\n",
            "Train step - Step 2010, Loss 0.0005559222772717476\n",
            "Train step - Step 2020, Loss 0.0009288048604503274\n",
            "Train epoch - Accuracy: 0.9939393939393939 Loss: 0.0006765042832873836 Corrects: 4920\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.000719703733921051\n",
            "Train step - Step 2040, Loss 0.00045503026922233403\n",
            "Train step - Step 2050, Loss 0.0004896650207228959\n",
            "Train step - Step 2060, Loss 0.00041642904398031533\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0005704369704295514 Corrects: 4928\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0002942715655080974\n",
            "Train step - Step 2080, Loss 0.0004199896939098835\n",
            "Train step - Step 2090, Loss 0.0005702387425117195\n",
            "Train step - Step 2100, Loss 0.00046259432565420866\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0005256811043275803 Corrects: 4931\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0002747078542597592\n",
            "Train step - Step 2120, Loss 0.0013508175034075975\n",
            "Train step - Step 2130, Loss 0.00038219025009311736\n",
            "Train step - Step 2140, Loss 0.0007055231835693121\n",
            "Train epoch - Accuracy: 0.9957575757575757 Loss: 0.0005202841447816804 Corrects: 4929\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0003221138031221926\n",
            "Train step - Step 2160, Loss 0.0006241816445253789\n",
            "Train step - Step 2170, Loss 0.00027498940471559763\n",
            "Train step - Step 2180, Loss 0.0008075280929915607\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0004636880385482477 Corrects: 4933\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00021019711857661605\n",
            "Train step - Step 2200, Loss 0.00038883715751580894\n",
            "Train step - Step 2210, Loss 0.00045332679292187095\n",
            "Train step - Step 2220, Loss 0.00032653461676090956\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00040469032914537673 Corrects: 4938\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0003468439681455493\n",
            "Train step - Step 2240, Loss 0.0006304754060693085\n",
            "Train step - Step 2250, Loss 0.00041114105260930955\n",
            "Train step - Step 2260, Loss 0.0005178695428185165\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00039519602414032424 Corrects: 4937\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.000506171549204737\n",
            "Train step - Step 2280, Loss 0.0005619610892608762\n",
            "Train step - Step 2290, Loss 0.0006075726123526692\n",
            "Train step - Step 2300, Loss 0.00045971947838552296\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0004351398113037864 Corrects: 4937\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0003700860543176532\n",
            "Train step - Step 2320, Loss 0.00033818534575402737\n",
            "Train step - Step 2330, Loss 0.00043588338303379714\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0003452127574086942 Corrects: 4944\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.000520460307598114\n",
            "Train step - Step 2350, Loss 0.00027011887868866324\n",
            "Train step - Step 2360, Loss 0.00040311639895662665\n",
            "Train step - Step 2370, Loss 0.0003349061880726367\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.0003432610438727407 Corrects: 4940\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0003177001199219376\n",
            "Train step - Step 2390, Loss 0.0003707715659402311\n",
            "Train step - Step 2400, Loss 0.00025974446907639503\n",
            "Train step - Step 2410, Loss 0.0002901306434068829\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00032263036172912275 Corrects: 4943\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00018408868345431983\n",
            "Train step - Step 2430, Loss 0.0003459092113189399\n",
            "Train step - Step 2440, Loss 0.00037174750468693674\n",
            "Train step - Step 2450, Loss 0.00019862811313942075\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00032489709019886725 Corrects: 4944\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0003951439866796136\n",
            "Train step - Step 2470, Loss 0.00024156455765478313\n",
            "Train step - Step 2480, Loss 0.0001571853063069284\n",
            "Train step - Step 2490, Loss 0.00019895938748959452\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00030759689293453717 Corrects: 4944\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00019073284056503326\n",
            "Train step - Step 2510, Loss 0.00025696196826174855\n",
            "Train step - Step 2520, Loss 0.0007062259246595204\n",
            "Train step - Step 2530, Loss 0.0003011988883372396\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00030470737615938894 Corrects: 4944\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00037888428778387606\n",
            "Train step - Step 2550, Loss 0.00024757938808761537\n",
            "Train step - Step 2560, Loss 0.0006696118507534266\n",
            "Train step - Step 2570, Loss 0.00020230391237419099\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00030311712878756226 Corrects: 4947\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0005733086145482957\n",
            "Train step - Step 2590, Loss 0.0003517074801493436\n",
            "Train step - Step 2600, Loss 0.00018836699018720537\n",
            "Train step - Step 2610, Loss 0.0005660223541781306\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00032221038081457445 Corrects: 4945\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00039260860648937523\n",
            "Train step - Step 2630, Loss 0.00026362176868133247\n",
            "Train step - Step 2640, Loss 0.00018425799498800188\n",
            "Train step - Step 2650, Loss 0.0005757596809417009\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00031114682920907406 Corrects: 4940\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00021146405197214335\n",
            "Train step - Step 2670, Loss 0.00032008145353756845\n",
            "Train step - Step 2680, Loss 0.0003361014532856643\n",
            "Train step - Step 2690, Loss 0.00023970077745616436\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0002855107027359984 Corrects: 4945\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0002759949420578778\n",
            "Train step - Step 2710, Loss 0.0002449408348184079\n",
            "Train step - Step 2720, Loss 0.0002404710976406932\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.0002855756763554639 Corrects: 4948\n",
            "Training finished in 206.86770391464233 seconds\n",
            "EVALUATION:  0.98 0.0012080427259206772\n",
            "TEST GROUP:  0.888\n",
            "TEST ALL:  0.0888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "aed68e56-9dcc-44bc-e9f3-2eab0f85e0b1"
      },
      "source": [
        "num_classes_seen = 100\n",
        "dif_accuracies=printAccuracyDifference(net,old_accuracies, num_classes_seen)\n",
        "dif_accuracies"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.784, 0.0),\n",
              " (2, 0.902, 0.0),\n",
              " (3, 0.865, 0.0),\n",
              " (4, 0.904, 0.0),\n",
              " (5, 0.843, 0.0),\n",
              " (6, 0.891, 0.0),\n",
              " (7, 0.89, 0.0),\n",
              " (8, 0.918, 0.0),\n",
              " (9, 0.884, 0.0),\n",
              " (10, 0.888, 0.888)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BCQoMhtWDJH",
        "colab_type": "text"
      },
      "source": [
        "**Results fine tuning (catastrophic learning)**<br>\n",
        "What we expect is a dramatic drop in the perfomances with repsect to the Joint Training and the incapacity to learn new things without forgetting the old ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        },
        "outputId": "f817f93e-fc16-48e9-a08f-e571a955f59e"
      },
      "source": [
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(data_plot_line)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}