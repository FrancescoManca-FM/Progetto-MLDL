{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/master/main_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j40FSXGxD2VD",
        "colab_type": "text"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudv9Cj8E8OI",
        "colab_type": "code",
        "outputId": "5cfa7fc2-a83c-4c07-9bc4-e12908af2125",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dC-rYdjD-E3",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru",
        "colab_type": "code",
        "outputId": "8a4e4f9f-2d0a-439b-d776-59241659b7e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lf-WK3hEJCM",
        "colab_type": "text"
      },
      "source": [
        "**Retrieving dataset CIFAR1000**<br>\n",
        "The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. There are 500 training images and 100 testing images per class.\n",
        "The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "Here is an example of classes in the CIFAR-100:<br>\n",
        "**Superclass**\t\n",
        "- aquatic mammals\t\n",
        "\n",
        "**Classes**\n",
        "- beaver, dolphin, otter, seal, whale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1do9ln3OVE",
        "colab_type": "code",
        "outputId": "495e33e3-5a67-4f2b-e291-1bf19e6db531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone -b clean https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/132)\u001b[K\rremote: Counting objects:   1% (2/132)\u001b[K\rremote: Counting objects:   2% (3/132)\u001b[K\rremote: Counting objects:   3% (4/132)\u001b[K\rremote: Counting objects:   4% (6/132)\u001b[K\rremote: Counting objects:   5% (7/132)\u001b[K\rremote: Counting objects:   6% (8/132)\u001b[K\rremote: Counting objects:   7% (10/132)\u001b[K\rremote: Counting objects:   8% (11/132)\u001b[K\rremote: Counting objects:   9% (12/132)\u001b[K\rremote: Counting objects:  10% (14/132)\u001b[K\rremote: Counting objects:  11% (15/132)\u001b[K\rremote: Counting objects:  12% (16/132)\u001b[K\rremote: Counting objects:  13% (18/132)\u001b[K\rremote: Counting objects:  14% (19/132)\u001b[K\rremote: Counting objects:  15% (20/132)\u001b[K\rremote: Counting objects:  16% (22/132)\u001b[K\rremote: Counting objects:  17% (23/132)\u001b[K\rremote: Counting objects:  18% (24/132)\u001b[K\rremote: Counting objects:  19% (26/132)\u001b[K\rremote: Counting objects:  20% (27/132)\u001b[K\rremote: Counting objects:  21% (28/132)\u001b[K\rremote: Counting objects:  22% (30/132)\u001b[K\rremote: Counting objects:  23% (31/132)\u001b[K\rremote: Counting objects:  24% (32/132)\u001b[K\rremote: Counting objects:  25% (33/132)\u001b[K\rremote: Counting objects:  26% (35/132)\u001b[K\rremote: Counting objects:  27% (36/132)\u001b[K\rremote: Counting objects:  28% (37/132)\u001b[K\rremote: Counting objects:  29% (39/132)\u001b[K\rremote: Counting objects:  30% (40/132)\u001b[K\rremote: Counting objects:  31% (41/132)\u001b[K\rremote: Counting objects:  32% (43/132)\u001b[K\rremote: Counting objects:  33% (44/132)\u001b[K\rremote: Counting objects:  34% (45/132)\u001b[K\rremote: Counting objects:  35% (47/132)\u001b[K\rremote: Counting objects:  36% (48/132)\u001b[K\rremote: Counting objects:  37% (49/132)\u001b[K\rremote: Counting objects:  38% (51/132)\u001b[K\rremote: Counting objects:  39% (52/132)\u001b[K\rremote: Counting objects:  40% (53/132)\u001b[K\rremote: Counting objects:  41% (55/132)\u001b[K\rremote: Counting objects:  42% (56/132)\u001b[K\rremote: Counting objects:  43% (57/132)\u001b[K\rremote: Counting objects:  44% (59/132)\u001b[K\rremote: Counting objects:  45% (60/132)\u001b[K\rremote: Counting objects:  46% (61/132)\u001b[K\rremote: Counting objects:  47% (63/132)\u001b[K\rremote: Counting objects:  48% (64/132)\u001b[K\rremote: Counting objects:  49% (65/132)\u001b[K\rremote: Counting objects:  50% (66/132)\u001b[K\rremote: Counting objects:  51% (68/132)\u001b[K\rremote: Counting objects:  52% (69/132)\u001b[K\rremote: Counting objects:  53% (70/132)\u001b[K\rremote: Counting objects:  54% (72/132)\u001b[K\rremote: Counting objects:  55% (73/132)\u001b[K\rremote: Counting objects:  56% (74/132)\u001b[K\rremote: Counting objects:  57% (76/132)\u001b[K\rremote: Counting objects:  58% (77/132)\u001b[K\rremote: Counting objects:  59% (78/132)\u001b[K\rremote: Counting objects:  60% (80/132)\u001b[K\rremote: Counting objects:  61% (81/132)\u001b[K\rremote: Counting objects:  62% (82/132)\u001b[K\rremote: Counting objects:  63% (84/132)\u001b[K\rremote: Counting objects:  64% (85/132)\u001b[K\rremote: Counting objects:  65% (86/132)\u001b[K\rremote: Counting objects:  66% (88/132)\u001b[K\rremote: Counting objects:  67% (89/132)\u001b[K\rremote: Counting objects:  68% (90/132)\u001b[K\rremote: Counting objects:  69% (92/132)\u001b[K\rremote: Counting objects:  70% (93/132)\u001b[K\rremote: Counting objects:  71% (94/132)\u001b[K\rremote: Counting objects:  72% (96/132)\u001b[K\rremote: Counting objects:  73% (97/132)\u001b[K\rremote: Counting objects:  74% (98/132)\u001b[K\rremote: Counting objects:  75% (99/132)\u001b[K\rremote: Counting objects:  76% (101/132)\u001b[K\rremote: Counting objects:  77% (102/132)\u001b[K\rremote: Counting objects:  78% (103/132)\u001b[K\rremote: Counting objects:  79% (105/132)\u001b[K\rremote: Counting objects:  80% (106/132)\u001b[K\rremote: Counting objects:  81% (107/132)\u001b[K\rremote: Counting objects:  82% (109/132)\u001b[K\rremote: Counting objects:  83% (110/132)\u001b[K\rremote: Counting objects:  84% (111/132)\u001b[K\rremote: Counting objects:  85% (113/132)\u001b[K\rremote: Counting objects:  86% (114/132)\u001b[K\rremote: Counting objects:  87% (115/132)\u001b[K\rremote: Counting objects:  88% (117/132)\u001b[K\rremote: Counting objects:  89% (118/132)\u001b[K\rremote: Counting objects:  90% (119/132)\u001b[K\rremote: Counting objects:  91% (121/132)\u001b[K\rremote: Counting objects:  92% (122/132)\u001b[K\rremote: Counting objects:  93% (123/132)\u001b[K\rremote: Counting objects:  94% (125/132)\u001b[K\rremote: Counting objects:  95% (126/132)\u001b[K\rremote: Counting objects:  96% (127/132)\u001b[K\rremote: Counting objects:  97% (129/132)\u001b[K\rremote: Counting objects:  98% (130/132)\u001b[K\rremote: Counting objects:  99% (131/132)\u001b[K\rremote: Counting objects: 100% (132/132)\u001b[K\rremote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 401 (delta 80), reused 85 (delta 40), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (401/401), 3.85 MiB | 6.91 MiB/s, done.\n",
            "Resolving deltas: 100% (216/216), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab_type": "code",
        "outputId": "556b5b37-2396-4bc9-fd41-52995156a248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-26 11:43:36--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  12.3MB/s    in 15s     \n",
            "\n",
            "2020-05-26 11:43:52 (10.4 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XOn3bHMEBzX",
        "colab_type": "text"
      },
      "source": [
        "**Set arguments** - \n",
        "src: iCaRL section 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-pqSNg4_Ris",
        "colab_type": "code",
        "outputId": "a0e42498-e2c9-4f92-bf06-d68130b0e389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from Cifar100 import utils\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = dictHyperparams[\"SEED\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 30, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oJ5m4V-ERDh",
        "colab_type": "text"
      },
      "source": [
        "**Define data preprocessing**<br>\n",
        "This transformations are applied to each images when they're loaded into the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_jHycn_1kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7EVuDrcJj2N"
      },
      "source": [
        "**Prepare dataset**<br>\n",
        "Loading of the train and test split as it comes with CIFAR100. <br>\n",
        "The trainset consists in 50k images, while the test set len is 10k images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nJKwvGljJj2T",
        "outputId": "8eaaa966-5c69-448e-f722-806b37fad903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ckn3H69iJj2X",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLmmQn7JOLc",
        "colab_type": "text"
      },
      "source": [
        "**Build dataset splits and reverse index**<br>\n",
        "Here the train dataset is split into train and validation set, following the proportion XX/YY.<br>\n",
        "Furthermore train, test and validation sets are splitted into 10 groups containing 10 classes each (the split is coherent among the different sets).<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fov9YAFTlj",
        "colab_type": "text"
      },
      "source": [
        "**Prepare dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn",
        "colab_type": "code",
        "outputId": "7c3e9dc3-88f3-43dd-91ac-821a9392c0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)\n",
        "\n",
        "# [ DEBUG ]\n",
        "# test to check classes in different dataset\n",
        "# (coherent split)\n",
        "# RESULT: OK\n",
        "\"\"\"dict_train={}\n",
        "for img_train in train_subsets[0]:\n",
        "  if img_train[1] not in dict_train:\n",
        "    dict_train[img_train[1]]=1\n",
        "  else:\n",
        "    dict_train[img_train[1]]+=1\n",
        "dict_val={}\n",
        "for img_val in val_subsets[0]:\n",
        "  if img_val[1] not in dict_val:\n",
        "    dict_val[img_val[1]]=1\n",
        "  else:\n",
        "    dict_val[img_val[1]]+=1\n",
        "dict_test={}\n",
        "for img_test in test_subsets[0]:\n",
        "  if img_test[1] not in dict_test:\n",
        "    dict_test[img_test[1]]=1\n",
        "  else:\n",
        "    dict_test[img_test[1]]+=1\n",
        "\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dict_train={}\\nfor img_train in train_subsets[0]:\\n  if img_train[1] not in dict_train:\\n    dict_train[img_train[1]]=1\\n  else:\\n    dict_train[img_train[1]]+=1\\ndict_val={}\\nfor img_val in val_subsets[0]:\\n  if img_val[1] not in dict_val:\\n    dict_val[img_val[1]]=1\\n  else:\\n    dict_val[img_val[1]]+=1\\ndict_test={}\\nfor img_test in test_subsets[0]:\\n  if img_test[1] not in dict_test:\\n    dict_test[img_test[1]]=1\\n  else:\\n    dict_test[img_test[1]]+=1\\n\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d19CnhIUg0q",
        "colab_type": "text"
      },
      "source": [
        "**Utility functions to use our customized resnet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ff9pwV10b0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.resnet import resnet32\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getResNet32():\n",
        "    net = resnet32()\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = utils.getLossCriterion()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet32()\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glyt2p3XTEqt",
        "colab_type": "text"
      },
      "source": [
        "**Basic train, test and validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzG6w15UudAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, num_epochs=NUM_EPOCHS):     \n",
        "    # By default, everything is loaded to cpu\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    \n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            outputs = net(images)\n",
        "\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            # preds = getLabels(outputs_labels_mapping, preds)\n",
        "            # print(preds)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    utils.getLossCriterion()\n",
        "\n",
        "    # confusion matrix\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "        # Bring data over the device of choice\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        #labels = outputs_labels_mapping.getNodes(labels)\n",
        "        labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputs = net(images)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # preds = getLabels(outputs_labels_mapping, preds)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    # Calculate Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiWapdlNNsA0",
        "colab_type": "text"
      },
      "source": [
        "**Joint Training**<br>\n",
        "In this section joint training is perfomed.<br>\n",
        "The train of the network is split into 10 stages, one for each subset classes.\n",
        "At each step, the network is trained on the images corresponding to the current 10 classes and all the data already seen in the previous steps.\n",
        "The joint training score, evaluated in terms of accuracy on the test set, gives us an UB for the next methodologies examined in this project (iCaRL, LWF).<br>\n",
        "Operatively, what happens is a very slow training and, furthermore, we break the assumption of not needing the previous batches of data at each step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4InuBhsENpV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####\n",
        "## Joint training\n",
        "####\n",
        "# Joins 2+ subsets into a new Subset (joint training)\n",
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)\n",
        "\n",
        "def jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getNet()\n",
        "\n",
        "    train_set = None\n",
        "    test_set = None\n",
        "    first_pass = True\n",
        "\n",
        "    current_train_num = 0\n",
        "    total_trains = len(train_subsets)\n",
        "    joint_start = time.time()\n",
        "\n",
        "    print('\\n\\nJoint-training start\\n\\n')\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "        phase_start = time.time()\n",
        "        print('\\n\\nJoint phase {}/{}\\n\\n'.format(current_train_num+1, total_trains))\n",
        "        current_train_num += 1\n",
        "\n",
        "        #num_classes_per_group = 10\n",
        "        num_classes_seen = current_train_num*10\n",
        "\n",
        "        # Builds growing train and test set. The new sets include data from previous class groups and current class group\n",
        "        if train_set is None:\n",
        "            train_set = train_subset\n",
        "        else:\n",
        "            train_set = joinSubsets(train_dataset, [train_set, train_subset])\n",
        "        if test_set is None:\n",
        "            test_set = test_subset\n",
        "        else:\n",
        "            test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        if first_pass:\n",
        "            first_pass = False\n",
        "        else:\n",
        "            addOutputs(net, 10)\n",
        "\n",
        "        # Trains model on previous and current class groups\n",
        "        optimizer, scheduler = getSchedulerOptimizer(net)\n",
        "        train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "        # Validate model on current class group\n",
        "        val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        v_acc, v_loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "        print('\\nValidation accuracy: {} - Validation loss: {}\\n'.format(v_acc, v_loss))\n",
        "\n",
        "        # Test the model on previous and current class groups\n",
        "        test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        t_acc, _, _ = test(net, test_loader, num_classes_seen)\n",
        "        print('\\nTest accuracy: {}\\n'.format(t_acc))\n",
        "\n",
        "        print('\\n\\nPhase completed in {} seconds\\n\\n'.format(time.time() - phase_start))\n",
        "    \n",
        "    print('\\n\\n Joint-training finished in {} seconds'.format(time.time() - joint_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOiPlN8ON4Gn",
        "colab_type": "text"
      },
      "source": [
        "**Test joint training**<br>\n",
        "What we expect is a test accuracy higher of what we'll be able to achieve using iCaRL, LWF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDecUBiHl4G",
        "colab_type": "code",
        "outputId": "929ea021-ecd9-4027-9e4a-71a3460e14db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Test Joint training\n",
        "\n",
        "jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets)\n",
        "\n",
        "# [DEBUG]\n",
        "#net, criterion, optimizer, scheduler = getResNet32()\n",
        "#train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "#train(net, train_dataloader, criterion, optimizer, scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Joint-training start\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Joint phase 1/10\n",
            "\n",
            "\n",
            "Starting epoch 1/70, LR = [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.7429662942886353\n",
            "Train step - Step 10, Loss 0.32703524827957153\n",
            "Train step - Step 20, Loss 0.3312636911869049\n",
            "Train step - Step 30, Loss 0.3079148828983307\n",
            "Train epoch - Accuracy: 0.1713131313131313 Loss: 0.3803643833507191 Corrects: 848\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.29889723658561707\n",
            "Train step - Step 50, Loss 0.3192194998264313\n",
            "Train step - Step 60, Loss 0.2911781966686249\n",
            "Train step - Step 70, Loss 0.3006952702999115\n",
            "Train epoch - Accuracy: 0.1921212121212121 Loss: 0.30280308876374756 Corrects: 951\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.28880444169044495\n",
            "Train step - Step 90, Loss 0.3030160665512085\n",
            "Train step - Step 100, Loss 0.2934960126876831\n",
            "Train step - Step 110, Loss 0.2879207730293274\n",
            "Train epoch - Accuracy: 0.19777777777777777 Loss: 0.2980433771947418 Corrects: 979\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.29113563895225525\n",
            "Train step - Step 130, Loss 0.2826595902442932\n",
            "Train step - Step 140, Loss 0.297550767660141\n",
            "Train step - Step 150, Loss 0.2636171877384186\n",
            "Train epoch - Accuracy: 0.2492929292929293 Loss: 0.28839626403770063 Corrects: 1234\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.2775713801383972\n",
            "Train step - Step 170, Loss 0.2747049927711487\n",
            "Train step - Step 180, Loss 0.26414430141448975\n",
            "Train step - Step 190, Loss 0.2561437785625458\n",
            "Train epoch - Accuracy: 0.2927272727272727 Loss: 0.270256168396786 Corrects: 1449\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.2667299211025238\n",
            "Train step - Step 210, Loss 0.26025351881980896\n",
            "Train step - Step 220, Loss 0.27019497752189636\n",
            "Train step - Step 230, Loss 0.2631756365299225\n",
            "Train epoch - Accuracy: 0.33636363636363636 Loss: 0.2635904746826249 Corrects: 1665\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.25613686442375183\n",
            "Train step - Step 250, Loss 0.23862747848033905\n",
            "Train step - Step 260, Loss 0.24900098145008087\n",
            "Train step - Step 270, Loss 0.2487730085849762\n",
            "Train epoch - Accuracy: 0.3925252525252525 Loss: 0.2527214943339126 Corrects: 1943\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.24997113645076752\n",
            "Train step - Step 290, Loss 0.24344661831855774\n",
            "Train step - Step 300, Loss 0.22383132576942444\n",
            "Train step - Step 310, Loss 0.22675231099128723\n",
            "Train epoch - Accuracy: 0.4064646464646465 Loss: 0.23890713152861354 Corrects: 2012\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.22152912616729736\n",
            "Train step - Step 330, Loss 0.2354361116886139\n",
            "Train step - Step 340, Loss 0.2265665978193283\n",
            "Train step - Step 350, Loss 0.2128651738166809\n",
            "Train epoch - Accuracy: 0.43676767676767675 Loss: 0.23060712811922787 Corrects: 2162\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.22027461230754852\n",
            "Train step - Step 370, Loss 0.2195167988538742\n",
            "Train step - Step 380, Loss 0.21207356452941895\n",
            "Train epoch - Accuracy: 0.45616161616161616 Loss: 0.22309220852273884 Corrects: 2258\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.2181127816438675\n",
            "Train step - Step 400, Loss 0.19631944596767426\n",
            "Train step - Step 410, Loss 0.19692476093769073\n",
            "Train step - Step 420, Loss 0.23435239493846893\n",
            "Train epoch - Accuracy: 0.4993939393939394 Loss: 0.21557560300586198 Corrects: 2472\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.21221187710762024\n",
            "Train step - Step 440, Loss 0.184578537940979\n",
            "Train step - Step 450, Loss 0.21619565784931183\n",
            "Train step - Step 460, Loss 0.2135452777147293\n",
            "Train epoch - Accuracy: 0.5048484848484849 Loss: 0.2072556428776847 Corrects: 2499\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.2080054134130478\n",
            "Train step - Step 480, Loss 0.2234663963317871\n",
            "Train step - Step 490, Loss 0.21189649403095245\n",
            "Train step - Step 500, Loss 0.19551800191402435\n",
            "Train epoch - Accuracy: 0.5149494949494949 Loss: 0.2043913670441117 Corrects: 2549\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.1954154223203659\n",
            "Train step - Step 520, Loss 0.1744072437286377\n",
            "Train step - Step 530, Loss 0.1922796070575714\n",
            "Train step - Step 540, Loss 0.2193857729434967\n",
            "Train epoch - Accuracy: 0.5256565656565657 Loss: 0.2015839560284759 Corrects: 2602\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.2025502771139145\n",
            "Train step - Step 560, Loss 0.19880937039852142\n",
            "Train step - Step 570, Loss 0.20545916259288788\n",
            "Train step - Step 580, Loss 0.21074311435222626\n",
            "Train epoch - Accuracy: 0.541010101010101 Loss: 0.20086271786930585 Corrects: 2678\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.20494790375232697\n",
            "Train step - Step 600, Loss 0.1897607147693634\n",
            "Train step - Step 610, Loss 0.19460387527942657\n",
            "Train step - Step 620, Loss 0.22177255153656006\n",
            "Train epoch - Accuracy: 0.5402020202020202 Loss: 0.19546827514364262 Corrects: 2674\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.20394711196422577\n",
            "Train step - Step 640, Loss 0.22823309898376465\n",
            "Train step - Step 650, Loss 0.19861173629760742\n",
            "Train step - Step 660, Loss 0.17510393261909485\n",
            "Train epoch - Accuracy: 0.5515151515151515 Loss: 0.19293023435756412 Corrects: 2730\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.19066579639911652\n",
            "Train step - Step 680, Loss 0.1895303875207901\n",
            "Train step - Step 690, Loss 0.20938222110271454\n",
            "Train step - Step 700, Loss 0.19049003720283508\n",
            "Train epoch - Accuracy: 0.5585858585858586 Loss: 0.19000031635014697 Corrects: 2765\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.16584394872188568\n",
            "Train step - Step 720, Loss 0.18760786950588226\n",
            "Train step - Step 730, Loss 0.1762271672487259\n",
            "Train step - Step 740, Loss 0.18707981705665588\n",
            "Train epoch - Accuracy: 0.5688888888888889 Loss: 0.18812332479640692 Corrects: 2816\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.15031202137470245\n",
            "Train step - Step 760, Loss 0.1981228142976761\n",
            "Train step - Step 770, Loss 0.1710626184940338\n",
            "Train epoch - Accuracy: 0.5909090909090909 Loss: 0.1825393121651929 Corrects: 2925\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.17543987929821014\n",
            "Train step - Step 790, Loss 0.1931743621826172\n",
            "Train step - Step 800, Loss 0.17316177487373352\n",
            "Train step - Step 810, Loss 0.18001508712768555\n",
            "Train epoch - Accuracy: 0.5852525252525252 Loss: 0.18221119371327488 Corrects: 2897\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.16355259716510773\n",
            "Train step - Step 830, Loss 0.19610847532749176\n",
            "Train step - Step 840, Loss 0.1764543056488037\n",
            "Train step - Step 850, Loss 0.1636020988225937\n",
            "Train epoch - Accuracy: 0.5973737373737373 Loss: 0.1797396669303528 Corrects: 2957\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.17771542072296143\n",
            "Train step - Step 870, Loss 0.20257845520973206\n",
            "Train step - Step 880, Loss 0.1664976328611374\n",
            "Train step - Step 890, Loss 0.16843776404857635\n",
            "Train epoch - Accuracy: 0.5905050505050505 Loss: 0.178744127232619 Corrects: 2923\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.17040275037288666\n",
            "Train step - Step 910, Loss 0.1695907562971115\n",
            "Train step - Step 920, Loss 0.1640537828207016\n",
            "Train step - Step 930, Loss 0.19347460567951202\n",
            "Train epoch - Accuracy: 0.6101010101010101 Loss: 0.17405684064132998 Corrects: 3020\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.16151152551174164\n",
            "Train step - Step 950, Loss 0.17592623829841614\n",
            "Train step - Step 960, Loss 0.15955781936645508\n",
            "Train step - Step 970, Loss 0.17801962792873383\n",
            "Train epoch - Accuracy: 0.6159595959595959 Loss: 0.17088173017357336 Corrects: 3049\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.17841331660747528\n",
            "Train step - Step 990, Loss 0.16086812317371368\n",
            "Train step - Step 1000, Loss 0.15249192714691162\n",
            "Train step - Step 1010, Loss 0.18528278172016144\n",
            "Train epoch - Accuracy: 0.6143434343434343 Loss: 0.17007112354943246 Corrects: 3041\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.15230704843997955\n",
            "Train step - Step 1030, Loss 0.15269958972930908\n",
            "Train step - Step 1040, Loss 0.1810535043478012\n",
            "Train step - Step 1050, Loss 0.14639165997505188\n",
            "Train epoch - Accuracy: 0.6305050505050505 Loss: 0.16580507409693016 Corrects: 3121\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.15384109318256378\n",
            "Train step - Step 1070, Loss 0.17010927200317383\n",
            "Train step - Step 1080, Loss 0.15686218440532684\n",
            "Train step - Step 1090, Loss 0.1569317877292633\n",
            "Train epoch - Accuracy: 0.6321212121212121 Loss: 0.16550373267645788 Corrects: 3129\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.15602056682109833\n",
            "Train step - Step 1110, Loss 0.1800592988729477\n",
            "Train step - Step 1120, Loss 0.15899117290973663\n",
            "Train step - Step 1130, Loss 0.17489273846149445\n",
            "Train epoch - Accuracy: 0.642020202020202 Loss: 0.16221726315792162 Corrects: 3178\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.180691197514534\n",
            "Train step - Step 1150, Loss 0.13969635963439941\n",
            "Train step - Step 1160, Loss 0.1635269671678543\n",
            "Train epoch - Accuracy: 0.6557575757575758 Loss: 0.15706382410092787 Corrects: 3246\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.1463739275932312\n",
            "Train step - Step 1180, Loss 0.15482346713542938\n",
            "Train step - Step 1190, Loss 0.14485441148281097\n",
            "Train step - Step 1200, Loss 0.1484391689300537\n",
            "Train epoch - Accuracy: 0.6684848484848485 Loss: 0.15584439984475723 Corrects: 3309\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.14795972406864166\n",
            "Train step - Step 1220, Loss 0.16099761426448822\n",
            "Train step - Step 1230, Loss 0.14282956719398499\n",
            "Train step - Step 1240, Loss 0.13792411983013153\n",
            "Train epoch - Accuracy: 0.6533333333333333 Loss: 0.1591603541916067 Corrects: 3234\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.14107565581798553\n",
            "Train step - Step 1260, Loss 0.1400766223669052\n",
            "Train step - Step 1270, Loss 0.13824093341827393\n",
            "Train step - Step 1280, Loss 0.14139072597026825\n",
            "Train epoch - Accuracy: 0.6727272727272727 Loss: 0.15207873545511805 Corrects: 3330\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.14741019904613495\n",
            "Train step - Step 1300, Loss 0.15487253665924072\n",
            "Train step - Step 1310, Loss 0.14218056201934814\n",
            "Train step - Step 1320, Loss 0.14554117619991302\n",
            "Train epoch - Accuracy: 0.675959595959596 Loss: 0.14875573967141334 Corrects: 3346\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.14102031290531158\n",
            "Train step - Step 1340, Loss 0.16535469889640808\n",
            "Train step - Step 1350, Loss 0.14455796778202057\n",
            "Train step - Step 1360, Loss 0.1370120644569397\n",
            "Train epoch - Accuracy: 0.6878787878787879 Loss: 0.14565604270106614 Corrects: 3405\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.15690329670906067\n",
            "Train step - Step 1380, Loss 0.13717129826545715\n",
            "Train step - Step 1390, Loss 0.15011298656463623\n",
            "Train step - Step 1400, Loss 0.15222008526325226\n",
            "Train epoch - Accuracy: 0.6905050505050505 Loss: 0.1458125693087626 Corrects: 3418\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.13655944168567657\n",
            "Train step - Step 1420, Loss 0.1274525225162506\n",
            "Train step - Step 1430, Loss 0.11677467077970505\n",
            "Train step - Step 1440, Loss 0.1292009800672531\n",
            "Train epoch - Accuracy: 0.703030303030303 Loss: 0.13872250695421237 Corrects: 3480\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.17078208923339844\n",
            "Train step - Step 1460, Loss 0.14629380404949188\n",
            "Train step - Step 1470, Loss 0.15504375100135803\n",
            "Train step - Step 1480, Loss 0.1580837070941925\n",
            "Train epoch - Accuracy: 0.6995959595959595 Loss: 0.14193435232145618 Corrects: 3463\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.12724018096923828\n",
            "Train step - Step 1500, Loss 0.13464300334453583\n",
            "Train step - Step 1510, Loss 0.15733079612255096\n",
            "Train step - Step 1520, Loss 0.14450247585773468\n",
            "Train epoch - Accuracy: 0.7101010101010101 Loss: 0.1376103761882493 Corrects: 3515\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.10141272842884064\n",
            "Train step - Step 1540, Loss 0.1366582214832306\n",
            "Train step - Step 1550, Loss 0.16330017149448395\n",
            "Train epoch - Accuracy: 0.7105050505050505 Loss: 0.13868484047928242 Corrects: 3517\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.1395394504070282\n",
            "Train step - Step 1570, Loss 0.12491414695978165\n",
            "Train step - Step 1580, Loss 0.1406542807817459\n",
            "Train step - Step 1590, Loss 0.12852813303470612\n",
            "Train epoch - Accuracy: 0.7175757575757575 Loss: 0.13142618011344562 Corrects: 3552\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.14125272631645203\n",
            "Train step - Step 1610, Loss 0.13750095665454865\n",
            "Train step - Step 1620, Loss 0.12318005412817001\n",
            "Train step - Step 1630, Loss 0.12473578751087189\n",
            "Train epoch - Accuracy: 0.7258585858585859 Loss: 0.1289955976755932 Corrects: 3593\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.14279994368553162\n",
            "Train step - Step 1650, Loss 0.12409909814596176\n",
            "Train step - Step 1660, Loss 0.1111290380358696\n",
            "Train step - Step 1670, Loss 0.11413838714361191\n",
            "Train epoch - Accuracy: 0.7311111111111112 Loss: 0.13056503918435838 Corrects: 3619\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.13386006653308868\n",
            "Train step - Step 1690, Loss 0.11075377464294434\n",
            "Train step - Step 1700, Loss 0.13101553916931152\n",
            "Train step - Step 1710, Loss 0.12411009520292282\n",
            "Train epoch - Accuracy: 0.7333333333333333 Loss: 0.12738375453033832 Corrects: 3630\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.12711191177368164\n",
            "Train step - Step 1730, Loss 0.10957600921392441\n",
            "Train step - Step 1740, Loss 0.12233257293701172\n",
            "Train step - Step 1750, Loss 0.11479216814041138\n",
            "Train epoch - Accuracy: 0.7377777777777778 Loss: 0.12490857879320781 Corrects: 3652\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.13089577853679657\n",
            "Train step - Step 1770, Loss 0.1217941865324974\n",
            "Train step - Step 1780, Loss 0.13539104163646698\n",
            "Train step - Step 1790, Loss 0.14442168176174164\n",
            "Train epoch - Accuracy: 0.7404040404040404 Loss: 0.12431812075954495 Corrects: 3665\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.10732841491699219\n",
            "Train step - Step 1810, Loss 0.1359798163175583\n",
            "Train step - Step 1820, Loss 0.11213260143995285\n",
            "Train step - Step 1830, Loss 0.15580841898918152\n",
            "Train epoch - Accuracy: 0.7402020202020202 Loss: 0.12385670556865558 Corrects: 3664\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.11910319328308105\n",
            "Train step - Step 1850, Loss 0.1036866307258606\n",
            "Train step - Step 1860, Loss 0.11746680736541748\n",
            "Train step - Step 1870, Loss 0.1019245982170105\n",
            "Train epoch - Accuracy: 0.7585858585858586 Loss: 0.1177290851239002 Corrects: 3755\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.13599036633968353\n",
            "Train step - Step 1890, Loss 0.12700363993644714\n",
            "Train step - Step 1900, Loss 0.14847245812416077\n",
            "Train step - Step 1910, Loss 0.11999937146902084\n",
            "Train epoch - Accuracy: 0.7361616161616161 Loss: 0.12445382178732843 Corrects: 3644\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.09117644280195236\n",
            "Train step - Step 1930, Loss 0.10425367206335068\n",
            "Train step - Step 1940, Loss 0.10250937193632126\n",
            "Train epoch - Accuracy: 0.7828282828282829 Loss: 0.1054888455103142 Corrects: 3875\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.08847871422767639\n",
            "Train step - Step 1960, Loss 0.0907929390668869\n",
            "Train step - Step 1970, Loss 0.09045148640871048\n",
            "Train step - Step 1980, Loss 0.08474689722061157\n",
            "Train epoch - Accuracy: 0.8088888888888889 Loss: 0.09638907255849453 Corrects: 4004\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.08246176689863205\n",
            "Train step - Step 2000, Loss 0.09990978240966797\n",
            "Train step - Step 2010, Loss 0.07944417744874954\n",
            "Train step - Step 2020, Loss 0.098477303981781\n",
            "Train epoch - Accuracy: 0.8076767676767677 Loss: 0.09451362552365872 Corrects: 3998\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.09445048868656158\n",
            "Train step - Step 2040, Loss 0.10319943726062775\n",
            "Train step - Step 2050, Loss 0.08786211162805557\n",
            "Train step - Step 2060, Loss 0.11448679119348526\n",
            "Train epoch - Accuracy: 0.8151515151515152 Loss: 0.09059775908788045 Corrects: 4035\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.08488382399082184\n",
            "Train step - Step 2080, Loss 0.07619933038949966\n",
            "Train step - Step 2090, Loss 0.07566886395215988\n",
            "Train step - Step 2100, Loss 0.09021427482366562\n",
            "Train epoch - Accuracy: 0.8121212121212121 Loss: 0.09127073599533601 Corrects: 4020\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.08458153158426285\n",
            "Train step - Step 2120, Loss 0.08499685674905777\n",
            "Train step - Step 2130, Loss 0.09281324595212936\n",
            "Train step - Step 2140, Loss 0.08302055299282074\n",
            "Train epoch - Accuracy: 0.816969696969697 Loss: 0.08778303976612861 Corrects: 4044\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.08360997587442398\n",
            "Train step - Step 2160, Loss 0.07968946546316147\n",
            "Train step - Step 2170, Loss 0.09186386317014694\n",
            "Train step - Step 2180, Loss 0.10231727361679077\n",
            "Train epoch - Accuracy: 0.8303030303030303 Loss: 0.08611631059285366 Corrects: 4110\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.07874061912298203\n",
            "Train step - Step 2200, Loss 0.08908281475305557\n",
            "Train step - Step 2210, Loss 0.09588342905044556\n",
            "Train step - Step 2220, Loss 0.06030404567718506\n",
            "Train epoch - Accuracy: 0.8278787878787879 Loss: 0.08482319213826246 Corrects: 4098\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.08719366043806076\n",
            "Train step - Step 2240, Loss 0.08125237375497818\n",
            "Train step - Step 2250, Loss 0.06991039961576462\n",
            "Train step - Step 2260, Loss 0.07479087263345718\n",
            "Train epoch - Accuracy: 0.8315151515151515 Loss: 0.08358989831474092 Corrects: 4116\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.08570297062397003\n",
            "Train step - Step 2280, Loss 0.07410021871328354\n",
            "Train step - Step 2290, Loss 0.09245222061872482\n",
            "Train step - Step 2300, Loss 0.11191647499799728\n",
            "Train epoch - Accuracy: 0.8375757575757575 Loss: 0.08123434942479085 Corrects: 4146\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.06823094189167023\n",
            "Train step - Step 2320, Loss 0.0715770423412323\n",
            "Train step - Step 2330, Loss 0.10045323520898819\n",
            "Train epoch - Accuracy: 0.8387878787878787 Loss: 0.08124217191127815 Corrects: 4152\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.08021984994411469\n",
            "Train step - Step 2350, Loss 0.08079002052545547\n",
            "Train step - Step 2360, Loss 0.086839959025383\n",
            "Train step - Step 2370, Loss 0.07159867882728577\n",
            "Train epoch - Accuracy: 0.8379797979797979 Loss: 0.08001919935146967 Corrects: 4148\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.08675074577331543\n",
            "Train step - Step 2390, Loss 0.07408712059259415\n",
            "Train step - Step 2400, Loss 0.0649491474032402\n",
            "Train step - Step 2410, Loss 0.08235570043325424\n",
            "Train epoch - Accuracy: 0.844040404040404 Loss: 0.07850805806090133 Corrects: 4178\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.07339699566364288\n",
            "Train step - Step 2430, Loss 0.08452735096216202\n",
            "Train step - Step 2440, Loss 0.06902177631855011\n",
            "Train step - Step 2450, Loss 0.08554084599018097\n",
            "Train epoch - Accuracy: 0.8367676767676767 Loss: 0.0804105899972145 Corrects: 4142\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.08947781473398209\n",
            "Train step - Step 2470, Loss 0.0687035620212555\n",
            "Train step - Step 2480, Loss 0.06848666816949844\n",
            "Train step - Step 2490, Loss 0.09358885139226913\n",
            "Train epoch - Accuracy: 0.8604040404040404 Loss: 0.07176658606589442 Corrects: 4259\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.05867161974310875\n",
            "Train step - Step 2510, Loss 0.04798876866698265\n",
            "Train step - Step 2520, Loss 0.07666522264480591\n",
            "Train step - Step 2530, Loss 0.07348009198904037\n",
            "Train epoch - Accuracy: 0.8583838383838384 Loss: 0.07061469156633723 Corrects: 4249\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.07993578165769577\n",
            "Train step - Step 2550, Loss 0.05896955728530884\n",
            "Train step - Step 2560, Loss 0.08174124360084534\n",
            "Train step - Step 2570, Loss 0.061841972172260284\n",
            "Train epoch - Accuracy: 0.8719191919191919 Loss: 0.06784982435631029 Corrects: 4316\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0636134147644043\n",
            "Train step - Step 2590, Loss 0.06822400540113449\n",
            "Train step - Step 2600, Loss 0.0757477656006813\n",
            "Train step - Step 2610, Loss 0.07623932510614395\n",
            "Train epoch - Accuracy: 0.8674747474747475 Loss: 0.0687341329064032 Corrects: 4294\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.07023055106401443\n",
            "Train step - Step 2630, Loss 0.06766851246356964\n",
            "Train step - Step 2640, Loss 0.07710917294025421\n",
            "Train step - Step 2650, Loss 0.0620800144970417\n",
            "Train epoch - Accuracy: 0.8703030303030304 Loss: 0.06628273307374029 Corrects: 4308\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.08031522482633591\n",
            "Train step - Step 2670, Loss 0.057265378534793854\n",
            "Train step - Step 2680, Loss 0.06689061224460602\n",
            "Train step - Step 2690, Loss 0.08370959013700485\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.06522978630029794 Corrects: 4326\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.05583931878209114\n",
            "Train step - Step 2710, Loss 0.06355749815702438\n",
            "Train step - Step 2720, Loss 0.061925437301397324\n",
            "Train epoch - Accuracy: 0.8743434343434343 Loss: 0.06670607571951066 Corrects: 4328\n",
            "Training finished in 245.60316801071167 seconds\n",
            "\n",
            "Validation accuracy: 0.8 - Validation loss: 0.1112990751862526\n",
            "\n",
            "\n",
            "Test accuracy: 0.79\n",
            "\n",
            "\n",
            "\n",
            "Phase completed in 246.5885829925537 seconds\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Joint phase 2/10\n",
            "\n",
            "\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.4282964766025543\n",
            "Train step - Step 10, Loss 0.21385300159454346\n",
            "Train step - Step 20, Loss 0.14567910134792328\n",
            "Train step - Step 30, Loss 0.13297997415065765\n",
            "Train step - Step 40, Loss 0.12478774040937424\n",
            "Train step - Step 50, Loss 0.12235019356012344\n",
            "Train step - Step 60, Loss 0.12903113663196564\n",
            "Train step - Step 70, Loss 0.1136651560664177\n",
            "Train epoch - Accuracy: 0.45131313131313133 Loss: 0.1415517591617324 Corrects: 4468\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.1125483289361\n",
            "Train step - Step 90, Loss 0.10336122661828995\n",
            "Train step - Step 100, Loss 0.1144673153758049\n",
            "Train step - Step 110, Loss 0.10546918958425522\n",
            "Train step - Step 120, Loss 0.11136871576309204\n",
            "Train step - Step 130, Loss 0.09485266357660294\n",
            "Train step - Step 140, Loss 0.11292853206396103\n",
            "Train step - Step 150, Loss 0.08313176035881042\n",
            "Train epoch - Accuracy: 0.5801010101010101 Loss: 0.10360888984769281 Corrects: 5743\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.09463579952716827\n",
            "Train step - Step 170, Loss 0.09692436456680298\n",
            "Train step - Step 180, Loss 0.0916130542755127\n",
            "Train step - Step 190, Loss 0.11032605171203613\n",
            "Train step - Step 200, Loss 0.08239071816205978\n",
            "Train step - Step 210, Loss 0.10443248599767685\n",
            "Train step - Step 220, Loss 0.08767455071210861\n",
            "Train step - Step 230, Loss 0.08982120454311371\n",
            "Train epoch - Accuracy: 0.6223232323232323 Loss: 0.0944408223093158 Corrects: 6161\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.08030586689710617\n",
            "Train step - Step 250, Loss 0.08947514742612839\n",
            "Train step - Step 260, Loss 0.07844262570142746\n",
            "Train step - Step 270, Loss 0.08813414722681046\n",
            "Train step - Step 280, Loss 0.09285637736320496\n",
            "Train step - Step 290, Loss 0.08889377117156982\n",
            "Train step - Step 300, Loss 0.08633798360824585\n",
            "Train step - Step 310, Loss 0.0852283164858818\n",
            "Train epoch - Accuracy: 0.6543434343434343 Loss: 0.0870961034297943 Corrects: 6478\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.08426918089389801\n",
            "Train step - Step 330, Loss 0.0912899523973465\n",
            "Train step - Step 340, Loss 0.08445396274328232\n",
            "Train step - Step 350, Loss 0.08682281523942947\n",
            "Train step - Step 360, Loss 0.08553247898817062\n",
            "Train step - Step 370, Loss 0.09276457875967026\n",
            "Train step - Step 380, Loss 0.0739857479929924\n",
            "Train epoch - Accuracy: 0.674040404040404 Loss: 0.08308782683177428 Corrects: 6673\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0774555578827858\n",
            "Train step - Step 400, Loss 0.09932942688465118\n",
            "Train step - Step 410, Loss 0.10040346533060074\n",
            "Train step - Step 420, Loss 0.07730390876531601\n",
            "Train step - Step 430, Loss 0.06102396175265312\n",
            "Train step - Step 440, Loss 0.08314654231071472\n",
            "Train step - Step 450, Loss 0.0806865394115448\n",
            "Train step - Step 460, Loss 0.07937485724687576\n",
            "Train epoch - Accuracy: 0.6876767676767677 Loss: 0.07953444773199582 Corrects: 6808\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.07543598860502243\n",
            "Train step - Step 480, Loss 0.07331555336713791\n",
            "Train step - Step 490, Loss 0.08175557851791382\n",
            "Train step - Step 500, Loss 0.08997410535812378\n",
            "Train step - Step 510, Loss 0.09232055395841599\n",
            "Train step - Step 520, Loss 0.08772196620702744\n",
            "Train step - Step 530, Loss 0.0703262984752655\n",
            "Train step - Step 540, Loss 0.07343351095914841\n",
            "Train epoch - Accuracy: 0.7042424242424242 Loss: 0.07728533562385674 Corrects: 6972\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.06914959847927094\n",
            "Train step - Step 560, Loss 0.07363809645175934\n",
            "Train step - Step 570, Loss 0.0713539719581604\n",
            "Train step - Step 580, Loss 0.06786970049142838\n",
            "Train step - Step 590, Loss 0.06988126039505005\n",
            "Train step - Step 600, Loss 0.07691982388496399\n",
            "Train step - Step 610, Loss 0.07285504043102264\n",
            "Train step - Step 620, Loss 0.057900410145521164\n",
            "Train epoch - Accuracy: 0.7180808080808081 Loss: 0.07317837491782024 Corrects: 7109\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.07969313114881516\n",
            "Train step - Step 640, Loss 0.07914312928915024\n",
            "Train step - Step 650, Loss 0.06489907950162888\n",
            "Train step - Step 660, Loss 0.07749208807945251\n",
            "Train step - Step 670, Loss 0.07612299919128418\n",
            "Train step - Step 680, Loss 0.06139644607901573\n",
            "Train step - Step 690, Loss 0.07188548147678375\n",
            "Train step - Step 700, Loss 0.06774674355983734\n",
            "Train epoch - Accuracy: 0.7242424242424242 Loss: 0.071913243812142 Corrects: 7170\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.06141168996691704\n",
            "Train step - Step 720, Loss 0.07450305670499802\n",
            "Train step - Step 730, Loss 0.07454486936330795\n",
            "Train step - Step 740, Loss 0.0611545704305172\n",
            "Train step - Step 750, Loss 0.07318396866321564\n",
            "Train step - Step 760, Loss 0.06451087445020676\n",
            "Train step - Step 770, Loss 0.07639002799987793\n",
            "Train epoch - Accuracy: 0.7391919191919192 Loss: 0.06845591631802646 Corrects: 7318\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.0768330916762352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-553730f75ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test Joint training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjointTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddOutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# [DEBUG]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-52ad12d5a631>\u001b[0m in \u001b[0;36mjointTraining\u001b[0;34m(getNet, addOutputs, train_subsets, val_subsets, test_subsets)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSchedulerOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Validate model on current class group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-1734a9aa94d7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_dataloader, criterion, optimizer, scheduler, num_classes, num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Compute gradients for each layer and update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# backward pass: computes gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update weights based on accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pts78KY42gXj",
        "colab_type": "text"
      },
      "source": [
        "**Fine tuning (catastrophic forgetting)**<br>\n",
        "In this section of the homework the aim is to demonstrate how, without ad-hoc methodologies, our CNN is unable to learn without dramatically forgetting what it has already been learnt.<br>\n",
        "Operatively, what we do is to perform a training again divided into (ten) steps but without exploiting previous data as before (joint training).\n",
        "What we should observe is a dramatic drop in the perfomances of the network.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrA3WhUzuK67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Fine tuning\n",
        "def sequentialLearning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    #confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb",
        "colab_type": "code",
        "outputId": "d4e375ff-1709-4446-cb51-f8eda1546f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "Starting epoch 1/70, LR = [2]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:396: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.6901078820228577\n",
            "Train step - Step 10, Loss 0.3247760236263275\n",
            "Train step - Step 20, Loss 0.2987397015094757\n",
            "Train step - Step 30, Loss 0.30344995856285095\n",
            "Train epoch - Accuracy: 0.16121212121212122 Loss: 0.3912074251488002 Corrects: 798\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.30295270681381226\n",
            "Train step - Step 50, Loss 0.2963450849056244\n",
            "Train step - Step 60, Loss 0.2957838475704193\n",
            "Train step - Step 70, Loss 0.3007523715496063\n",
            "Train epoch - Accuracy: 0.18484848484848485 Loss: 0.29860427785401394 Corrects: 915\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.29217034578323364\n",
            "Train step - Step 90, Loss 0.30655863881111145\n",
            "Train step - Step 100, Loss 0.30829039216041565\n",
            "Train step - Step 110, Loss 0.30797630548477173\n",
            "Train epoch - Accuracy: 0.19494949494949496 Loss: 0.2986088549007069 Corrects: 965\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.3140912652015686\n",
            "Train step - Step 130, Loss 0.2932884097099304\n",
            "Train step - Step 140, Loss 0.29770171642303467\n",
            "Train step - Step 150, Loss 0.28470897674560547\n",
            "Train epoch - Accuracy: 0.22363636363636363 Loss: 0.29485977222221066 Corrects: 1107\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.2905299663543701\n",
            "Train step - Step 170, Loss 0.27265414595603943\n",
            "Train step - Step 180, Loss 0.27559974789619446\n",
            "Train step - Step 190, Loss 0.2821387052536011\n",
            "Train epoch - Accuracy: 0.25414141414141417 Loss: 0.2824004531629158 Corrects: 1258\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.26950764656066895\n",
            "Train step - Step 210, Loss 0.2510541081428528\n",
            "Train step - Step 220, Loss 0.26384496688842773\n",
            "Train step - Step 230, Loss 0.25922998785972595\n",
            "Train epoch - Accuracy: 0.3191919191919192 Loss: 0.26614451651621346 Corrects: 1580\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.24871687591075897\n",
            "Train step - Step 250, Loss 0.24074554443359375\n",
            "Train step - Step 260, Loss 0.248219296336174\n",
            "Train step - Step 270, Loss 0.2575720548629761\n",
            "Train epoch - Accuracy: 0.4018181818181818 Loss: 0.24585399430207533 Corrects: 1989\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.2312520295381546\n",
            "Train step - Step 290, Loss 0.25699055194854736\n",
            "Train step - Step 300, Loss 0.2190731018781662\n",
            "Train step - Step 310, Loss 0.22500324249267578\n",
            "Train epoch - Accuracy: 0.43212121212121213 Loss: 0.2322071938743495 Corrects: 2139\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.2241048365831375\n",
            "Train step - Step 330, Loss 0.23162841796875\n",
            "Train step - Step 340, Loss 0.21151648461818695\n",
            "Train step - Step 350, Loss 0.21710649132728577\n",
            "Train epoch - Accuracy: 0.4672727272727273 Loss: 0.22447970350583393 Corrects: 2313\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.22115802764892578\n",
            "Train step - Step 370, Loss 0.2110581398010254\n",
            "Train step - Step 380, Loss 0.2128748893737793\n",
            "Train epoch - Accuracy: 0.4818181818181818 Loss: 0.21671947188449628 Corrects: 2385\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.21181975305080414\n",
            "Train step - Step 400, Loss 0.1980506181716919\n",
            "Train step - Step 410, Loss 0.21058058738708496\n",
            "Train step - Step 420, Loss 0.20589803159236908\n",
            "Train epoch - Accuracy: 0.5038383838383839 Loss: 0.20938549623344885 Corrects: 2494\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.19858253002166748\n",
            "Train step - Step 440, Loss 0.22053375840187073\n",
            "Train step - Step 450, Loss 0.2081248015165329\n",
            "Train step - Step 460, Loss 0.21572640538215637\n",
            "Train epoch - Accuracy: 0.5111111111111111 Loss: 0.20833375936204737 Corrects: 2530\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.20275166630744934\n",
            "Train step - Step 480, Loss 0.1999359279870987\n",
            "Train step - Step 490, Loss 0.21364589035511017\n",
            "Train step - Step 500, Loss 0.1937791407108307\n",
            "Train epoch - Accuracy: 0.5305050505050505 Loss: 0.20161331842644045 Corrects: 2626\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.19234316051006317\n",
            "Train step - Step 520, Loss 0.19526706635951996\n",
            "Train step - Step 530, Loss 0.1955813765525818\n",
            "Train step - Step 540, Loss 0.17865432798862457\n",
            "Train epoch - Accuracy: 0.5424242424242425 Loss: 0.19546172712186372 Corrects: 2685\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.17553436756134033\n",
            "Train step - Step 560, Loss 0.1878637820482254\n",
            "Train step - Step 570, Loss 0.16954346001148224\n",
            "Train step - Step 580, Loss 0.18576310575008392\n",
            "Train epoch - Accuracy: 0.5634343434343434 Loss: 0.1883637442974129 Corrects: 2789\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.18622279167175293\n",
            "Train step - Step 600, Loss 0.19491635262966156\n",
            "Train step - Step 610, Loss 0.18377788364887238\n",
            "Train step - Step 620, Loss 0.19408130645751953\n",
            "Train epoch - Accuracy: 0.5715151515151515 Loss: 0.18570700237245272 Corrects: 2829\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.18937914073467255\n",
            "Train step - Step 640, Loss 0.1932188719511032\n",
            "Train step - Step 650, Loss 0.19486887753009796\n",
            "Train step - Step 660, Loss 0.18944770097732544\n",
            "Train epoch - Accuracy: 0.5822222222222222 Loss: 0.18424124017508342 Corrects: 2882\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.18966703116893768\n",
            "Train step - Step 680, Loss 0.15178106725215912\n",
            "Train step - Step 690, Loss 0.18656866252422333\n",
            "Train step - Step 700, Loss 0.163358673453331\n",
            "Train epoch - Accuracy: 0.573939393939394 Loss: 0.1837520956993103 Corrects: 2841\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.17936034500598907\n",
            "Train step - Step 720, Loss 0.1632305383682251\n",
            "Train step - Step 730, Loss 0.2159961313009262\n",
            "Train step - Step 740, Loss 0.1692410111427307\n",
            "Train epoch - Accuracy: 0.5951515151515151 Loss: 0.17671286214481702 Corrects: 2946\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.16915953159332275\n",
            "Train step - Step 760, Loss 0.1887507289648056\n",
            "Train step - Step 770, Loss 0.18885980546474457\n",
            "Train epoch - Accuracy: 0.5971717171717171 Loss: 0.17792140142484145 Corrects: 2956\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.1796293705701828\n",
            "Train step - Step 790, Loss 0.15668144822120667\n",
            "Train step - Step 800, Loss 0.19705413281917572\n",
            "Train step - Step 810, Loss 0.18155932426452637\n",
            "Train epoch - Accuracy: 0.6050505050505051 Loss: 0.17502308002023986 Corrects: 2995\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.17253349721431732\n",
            "Train step - Step 830, Loss 0.16964830458164215\n",
            "Train step - Step 840, Loss 0.1735209971666336\n",
            "Train step - Step 850, Loss 0.19208894670009613\n",
            "Train epoch - Accuracy: 0.6135353535353535 Loss: 0.1691733884690988 Corrects: 3037\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.16746294498443604\n",
            "Train step - Step 870, Loss 0.17184777557849884\n",
            "Train step - Step 880, Loss 0.1724710911512375\n",
            "Train step - Step 890, Loss 0.17334316670894623\n",
            "Train epoch - Accuracy: 0.6208080808080808 Loss: 0.1697686023844613 Corrects: 3073\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.15959720313549042\n",
            "Train step - Step 910, Loss 0.2035789042711258\n",
            "Train step - Step 920, Loss 0.16213785111904144\n",
            "Train step - Step 930, Loss 0.19265393912792206\n",
            "Train epoch - Accuracy: 0.6191919191919192 Loss: 0.16988704905365454 Corrects: 3065\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.16756455600261688\n",
            "Train step - Step 950, Loss 0.1546563357114792\n",
            "Train step - Step 960, Loss 0.2000211775302887\n",
            "Train step - Step 970, Loss 0.16144441068172455\n",
            "Train epoch - Accuracy: 0.6325252525252525 Loss: 0.16487869427059637 Corrects: 3131\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.1522998809814453\n",
            "Train step - Step 990, Loss 0.16139595210552216\n",
            "Train step - Step 1000, Loss 0.1476876139640808\n",
            "Train step - Step 1010, Loss 0.19299577176570892\n",
            "Train epoch - Accuracy: 0.6432323232323233 Loss: 0.16222547381815283 Corrects: 3184\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.16852818429470062\n",
            "Train step - Step 1030, Loss 0.15513724088668823\n",
            "Train step - Step 1040, Loss 0.1801801174879074\n",
            "Train step - Step 1050, Loss 0.15107880532741547\n",
            "Train epoch - Accuracy: 0.6505050505050505 Loss: 0.16036565840244293 Corrects: 3220\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.16082195937633514\n",
            "Train step - Step 1070, Loss 0.1433466523885727\n",
            "Train step - Step 1080, Loss 0.15410013496875763\n",
            "Train step - Step 1090, Loss 0.1730615347623825\n",
            "Train epoch - Accuracy: 0.6466666666666666 Loss: 0.15817576998412006 Corrects: 3201\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.15759482979774475\n",
            "Train step - Step 1110, Loss 0.14425499737262726\n",
            "Train step - Step 1120, Loss 0.1488225758075714\n",
            "Train step - Step 1130, Loss 0.14714056253433228\n",
            "Train epoch - Accuracy: 0.6662626262626262 Loss: 0.1542401823130521 Corrects: 3298\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.1534873992204666\n",
            "Train step - Step 1150, Loss 0.1578260213136673\n",
            "Train step - Step 1160, Loss 0.1421336978673935\n",
            "Train epoch - Accuracy: 0.6690909090909091 Loss: 0.151212920522449 Corrects: 3312\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.1586669236421585\n",
            "Train step - Step 1180, Loss 0.16323547065258026\n",
            "Train step - Step 1190, Loss 0.1496584266424179\n",
            "Train step - Step 1200, Loss 0.1437714397907257\n",
            "Train epoch - Accuracy: 0.6719191919191919 Loss: 0.15191645680653929 Corrects: 3326\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.16267822682857513\n",
            "Train step - Step 1220, Loss 0.14302152395248413\n",
            "Train step - Step 1230, Loss 0.14368656277656555\n",
            "Train step - Step 1240, Loss 0.18481400609016418\n",
            "Train epoch - Accuracy: 0.6767676767676768 Loss: 0.1520385874461646 Corrects: 3350\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.14695993065834045\n",
            "Train step - Step 1260, Loss 0.13147182762622833\n",
            "Train step - Step 1270, Loss 0.13468877971172333\n",
            "Train step - Step 1280, Loss 0.1445833295583725\n",
            "Train epoch - Accuracy: 0.6737373737373737 Loss: 0.15109791051859808 Corrects: 3335\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.16779756546020508\n",
            "Train step - Step 1300, Loss 0.11713699251413345\n",
            "Train step - Step 1310, Loss 0.17373645305633545\n",
            "Train step - Step 1320, Loss 0.18266670405864716\n",
            "Train epoch - Accuracy: 0.6941414141414142 Loss: 0.14382400507878776 Corrects: 3436\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.13012893497943878\n",
            "Train step - Step 1340, Loss 0.13366244733333588\n",
            "Train step - Step 1350, Loss 0.15465150773525238\n",
            "Train step - Step 1360, Loss 0.15379993617534637\n",
            "Train epoch - Accuracy: 0.6995959595959595 Loss: 0.14607291753845986 Corrects: 3463\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.16448937356472015\n",
            "Train step - Step 1380, Loss 0.13546375930309296\n",
            "Train step - Step 1390, Loss 0.1379089653491974\n",
            "Train step - Step 1400, Loss 0.12373208999633789\n",
            "Train epoch - Accuracy: 0.7034343434343434 Loss: 0.14174613234972713 Corrects: 3482\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.14479656517505646\n",
            "Train step - Step 1420, Loss 0.1327618658542633\n",
            "Train step - Step 1430, Loss 0.12997858226299286\n",
            "Train step - Step 1440, Loss 0.14337444305419922\n",
            "Train epoch - Accuracy: 0.7002020202020202 Loss: 0.14116126676400503 Corrects: 3466\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.13889315724372864\n",
            "Train step - Step 1460, Loss 0.1466086357831955\n",
            "Train step - Step 1470, Loss 0.14870773255825043\n",
            "Train step - Step 1480, Loss 0.14485983550548553\n",
            "Train epoch - Accuracy: 0.6983838383838383 Loss: 0.14199699774535016 Corrects: 3457\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.159211665391922\n",
            "Train step - Step 1500, Loss 0.12480495125055313\n",
            "Train step - Step 1510, Loss 0.13620996475219727\n",
            "Train step - Step 1520, Loss 0.14062964916229248\n",
            "Train epoch - Accuracy: 0.7008080808080808 Loss: 0.14148251104836512 Corrects: 3469\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.12447476387023926\n",
            "Train step - Step 1540, Loss 0.13696913421154022\n",
            "Train step - Step 1550, Loss 0.13570237159729004\n",
            "Train epoch - Accuracy: 0.7232323232323232 Loss: 0.13485934225597768 Corrects: 3580\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.15386514365673065\n",
            "Train step - Step 1570, Loss 0.13167865574359894\n",
            "Train step - Step 1580, Loss 0.10861688107252121\n",
            "Train step - Step 1590, Loss 0.11644666641950607\n",
            "Train epoch - Accuracy: 0.7252525252525253 Loss: 0.1333844464716285 Corrects: 3590\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.14021314680576324\n",
            "Train step - Step 1610, Loss 0.13801497220993042\n",
            "Train step - Step 1620, Loss 0.12932847440242767\n",
            "Train step - Step 1630, Loss 0.13638313114643097\n",
            "Train epoch - Accuracy: 0.722020202020202 Loss: 0.13033047111949536 Corrects: 3574\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.14206068217754364\n",
            "Train step - Step 1650, Loss 0.13858386874198914\n",
            "Train step - Step 1660, Loss 0.12054290622472763\n",
            "Train step - Step 1670, Loss 0.13844351470470428\n",
            "Train epoch - Accuracy: 0.7173737373737373 Loss: 0.13195284579739427 Corrects: 3551\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.11154361814260483\n",
            "Train step - Step 1690, Loss 0.11724617332220078\n",
            "Train step - Step 1700, Loss 0.13521789014339447\n",
            "Train step - Step 1710, Loss 0.10117312520742416\n",
            "Train epoch - Accuracy: 0.7369696969696969 Loss: 0.1264944218114169 Corrects: 3648\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.1333567351102829\n",
            "Train step - Step 1730, Loss 0.12334175407886505\n",
            "Train step - Step 1740, Loss 0.10877414047718048\n",
            "Train step - Step 1750, Loss 0.13031506538391113\n",
            "Train epoch - Accuracy: 0.7492929292929293 Loss: 0.12201914978147757 Corrects: 3709\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.13099628686904907\n",
            "Train step - Step 1770, Loss 0.10733123123645782\n",
            "Train step - Step 1780, Loss 0.12915711104869843\n",
            "Train step - Step 1790, Loss 0.1358059197664261\n",
            "Train epoch - Accuracy: 0.7468686868686869 Loss: 0.1228895594104372 Corrects: 3697\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.09393034875392914\n",
            "Train step - Step 1810, Loss 0.12679457664489746\n",
            "Train step - Step 1820, Loss 0.12852643430233002\n",
            "Train step - Step 1830, Loss 0.10484113544225693\n",
            "Train epoch - Accuracy: 0.7468686868686869 Loss: 0.12289822089852709 Corrects: 3697\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.1367531269788742\n",
            "Train step - Step 1850, Loss 0.11800310760736465\n",
            "Train step - Step 1860, Loss 0.12923073768615723\n",
            "Train step - Step 1870, Loss 0.10751869529485703\n",
            "Train epoch - Accuracy: 0.7525252525252525 Loss: 0.1192450451579961 Corrects: 3725\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.12905795872211456\n",
            "Train step - Step 1890, Loss 0.11194753646850586\n",
            "Train step - Step 1900, Loss 0.1315135806798935\n",
            "Train step - Step 1910, Loss 0.1116330698132515\n",
            "Train epoch - Accuracy: 0.761010101010101 Loss: 0.11688380986452103 Corrects: 3767\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.11541698127985\n",
            "Train step - Step 1930, Loss 0.10274423658847809\n",
            "Train step - Step 1940, Loss 0.10647566616535187\n",
            "Train epoch - Accuracy: 0.7826262626262627 Loss: 0.10497140234166925 Corrects: 3874\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.10782575607299805\n",
            "Train step - Step 1960, Loss 0.0904649943113327\n",
            "Train step - Step 1970, Loss 0.09647219628095627\n",
            "Train step - Step 1980, Loss 0.09028778225183487\n",
            "Train epoch - Accuracy: 0.8078787878787879 Loss: 0.09532141376926441 Corrects: 3999\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.09024786949157715\n",
            "Train step - Step 2000, Loss 0.08068373054265976\n",
            "Train step - Step 2010, Loss 0.0947253555059433\n",
            "Train step - Step 2020, Loss 0.07569487392902374\n",
            "Train epoch - Accuracy: 0.8086868686868687 Loss: 0.09561182382732931 Corrects: 4003\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.10815327614545822\n",
            "Train step - Step 2040, Loss 0.07946032285690308\n",
            "Train step - Step 2050, Loss 0.10199729353189468\n",
            "Train step - Step 2060, Loss 0.08753698319196701\n",
            "Train epoch - Accuracy: 0.812929292929293 Loss: 0.09374040264673908 Corrects: 4024\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.07384135574102402\n",
            "Train step - Step 2080, Loss 0.10184741020202637\n",
            "Train step - Step 2090, Loss 0.0748792439699173\n",
            "Train step - Step 2100, Loss 0.0945902094244957\n",
            "Train epoch - Accuracy: 0.8268686868686869 Loss: 0.08917460025259943 Corrects: 4093\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.083185113966465\n",
            "Train step - Step 2120, Loss 0.08823948353528976\n",
            "Train step - Step 2130, Loss 0.06945449858903885\n",
            "Train step - Step 2140, Loss 0.10341067612171173\n",
            "Train epoch - Accuracy: 0.8248484848484848 Loss: 0.0878452530412963 Corrects: 4083\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.08749665319919586\n",
            "Train step - Step 2160, Loss 0.09760095924139023\n",
            "Train step - Step 2170, Loss 0.08471717685461044\n",
            "Train step - Step 2180, Loss 0.09470228105783463\n",
            "Train epoch - Accuracy: 0.8228282828282828 Loss: 0.08864714569816685 Corrects: 4073\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.082990363240242\n",
            "Train step - Step 2200, Loss 0.09213564544916153\n",
            "Train step - Step 2210, Loss 0.10384859144687653\n",
            "Train step - Step 2220, Loss 0.09071431308984756\n",
            "Train epoch - Accuracy: 0.8323232323232324 Loss: 0.08548866361379623 Corrects: 4120\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.08748797327280045\n",
            "Train step - Step 2240, Loss 0.10180266946554184\n",
            "Train step - Step 2250, Loss 0.1054980531334877\n",
            "Train step - Step 2260, Loss 0.07575754821300507\n",
            "Train epoch - Accuracy: 0.8375757575757575 Loss: 0.08410221116711394 Corrects: 4146\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.09036427736282349\n",
            "Train step - Step 2280, Loss 0.07571760565042496\n",
            "Train step - Step 2290, Loss 0.09542329609394073\n",
            "Train step - Step 2300, Loss 0.07594280689954758\n",
            "Train epoch - Accuracy: 0.8294949494949495 Loss: 0.08494963312690908 Corrects: 4106\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.07912111282348633\n",
            "Train step - Step 2320, Loss 0.08348213881254196\n",
            "Train step - Step 2330, Loss 0.08137064427137375\n",
            "Train epoch - Accuracy: 0.8371717171717171 Loss: 0.083963634582481 Corrects: 4144\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.06810619682073593\n",
            "Train step - Step 2350, Loss 0.07274267077445984\n",
            "Train step - Step 2360, Loss 0.07628851383924484\n",
            "Train step - Step 2370, Loss 0.07551579922437668\n",
            "Train epoch - Accuracy: 0.8418181818181818 Loss: 0.08128994381789005 Corrects: 4167\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.06961183995008469\n",
            "Train step - Step 2390, Loss 0.07230933755636215\n",
            "Train step - Step 2400, Loss 0.06981374323368073\n",
            "Train step - Step 2410, Loss 0.0893198624253273\n",
            "Train epoch - Accuracy: 0.8480808080808081 Loss: 0.07855069335662958 Corrects: 4198\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0889735147356987\n",
            "Train step - Step 2430, Loss 0.08181793987751007\n",
            "Train step - Step 2440, Loss 0.07784955948591232\n",
            "Train step - Step 2450, Loss 0.0680379718542099\n",
            "Train epoch - Accuracy: 0.8470707070707071 Loss: 0.07870526665991003 Corrects: 4193\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.07662618905305862\n",
            "Train step - Step 2470, Loss 0.06161161884665489\n",
            "Train step - Step 2480, Loss 0.08194234222173691\n",
            "Train step - Step 2490, Loss 0.08622640371322632\n",
            "Train epoch - Accuracy: 0.8632323232323232 Loss: 0.07310711064724007 Corrects: 4273\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0611485131084919\n",
            "Train step - Step 2510, Loss 0.08395203202962875\n",
            "Train step - Step 2520, Loss 0.07122525572776794\n",
            "Train step - Step 2530, Loss 0.07509396970272064\n",
            "Train epoch - Accuracy: 0.8692929292929293 Loss: 0.07040403602701245 Corrects: 4303\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.06886455416679382\n",
            "Train step - Step 2550, Loss 0.07279904931783676\n",
            "Train step - Step 2560, Loss 0.0725124403834343\n",
            "Train step - Step 2570, Loss 0.0666952133178711\n",
            "Train epoch - Accuracy: 0.86989898989899 Loss: 0.06812021930410404 Corrects: 4306\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.08335327357053757\n",
            "Train step - Step 2590, Loss 0.06581691652536392\n",
            "Train step - Step 2600, Loss 0.06052113696932793\n",
            "Train step - Step 2610, Loss 0.08052919059991837\n",
            "Train epoch - Accuracy: 0.86989898989899 Loss: 0.06811947051924888 Corrects: 4306\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.06291001290082932\n",
            "Train step - Step 2630, Loss 0.06940282881259918\n",
            "Train step - Step 2640, Loss 0.07969838380813599\n",
            "Train step - Step 2650, Loss 0.0678260549902916\n",
            "Train epoch - Accuracy: 0.8707070707070707 Loss: 0.06787054492969706 Corrects: 4310\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.056063711643218994\n",
            "Train step - Step 2670, Loss 0.07340153306722641\n",
            "Train step - Step 2680, Loss 0.06595098972320557\n",
            "Train step - Step 2690, Loss 0.05372442305088043\n",
            "Train epoch - Accuracy: 0.8676767676767677 Loss: 0.0671614236723293 Corrects: 4295\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0521400049328804\n",
            "Train step - Step 2710, Loss 0.0791592225432396\n",
            "Train step - Step 2720, Loss 0.0570225715637207\n",
            "Train epoch - Accuracy: 0.8719191919191919 Loss: 0.06723011649618245 Corrects: 4316\n",
            "Training finished in 238.9890968799591 seconds\n",
            "EVALUATION:  0.74 0.13105522096157074\n",
            "TEST GROUP:  0.781\n",
            "TEST ALL:  0.781\n",
            "GROUP:  2\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.44926175475120544\n",
            "Train step - Step 10, Loss 0.21208377182483673\n",
            "Train step - Step 20, Loss 0.15658564865589142\n",
            "Train step - Step 30, Loss 0.12831299006938934\n",
            "Train epoch - Accuracy: 0.31555555555555553 Loss: 0.1679661063714461 Corrects: 1562\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.11187869310379028\n",
            "Train step - Step 50, Loss 0.09292241930961609\n",
            "Train step - Step 60, Loss 0.1024218201637268\n",
            "Train step - Step 70, Loss 0.08956458419561386\n",
            "Train epoch - Accuracy: 0.5751515151515152 Loss: 0.09502511889344514 Corrects: 2847\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.08192827552556992\n",
            "Train step - Step 90, Loss 0.07927487045526505\n",
            "Train step - Step 100, Loss 0.08467675000429153\n",
            "Train step - Step 110, Loss 0.083372101187706\n",
            "Train epoch - Accuracy: 0.6662626262626262 Loss: 0.07935776242102036 Corrects: 3298\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.0725802332162857\n",
            "Train step - Step 130, Loss 0.071249820291996\n",
            "Train step - Step 140, Loss 0.076332226395607\n",
            "Train step - Step 150, Loss 0.07042566686868668\n",
            "Train epoch - Accuracy: 0.7034343434343434 Loss: 0.07162841699942193 Corrects: 3482\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.05724652484059334\n",
            "Train step - Step 170, Loss 0.06463823467493057\n",
            "Train step - Step 180, Loss 0.07552681118249893\n",
            "Train step - Step 190, Loss 0.06827908009290695\n",
            "Train epoch - Accuracy: 0.7385858585858586 Loss: 0.06555442334726604 Corrects: 3656\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.06176885962486267\n",
            "Train step - Step 210, Loss 0.055333252996206284\n",
            "Train step - Step 220, Loss 0.059058405458927155\n",
            "Train step - Step 230, Loss 0.05637132003903389\n",
            "Train epoch - Accuracy: 0.7642424242424243 Loss: 0.05958365604732976 Corrects: 3783\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.05317750200629234\n",
            "Train step - Step 250, Loss 0.05866730213165283\n",
            "Train step - Step 260, Loss 0.051244474947452545\n",
            "Train step - Step 270, Loss 0.04796231910586357\n",
            "Train epoch - Accuracy: 0.7741414141414141 Loss: 0.056422552747858894 Corrects: 3832\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.04872675985097885\n",
            "Train step - Step 290, Loss 0.0485052764415741\n",
            "Train step - Step 300, Loss 0.06932950764894485\n",
            "Train step - Step 310, Loss 0.06646733731031418\n",
            "Train epoch - Accuracy: 0.7917171717171717 Loss: 0.05361395946656815 Corrects: 3919\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.05152243375778198\n",
            "Train step - Step 330, Loss 0.04717309772968292\n",
            "Train step - Step 340, Loss 0.04236210510134697\n",
            "Train step - Step 350, Loss 0.05719456821680069\n",
            "Train epoch - Accuracy: 0.8121212121212121 Loss: 0.048432052301035984 Corrects: 4020\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.04235883429646492\n",
            "Train step - Step 370, Loss 0.03732331842184067\n",
            "Train step - Step 380, Loss 0.041605472564697266\n",
            "Train epoch - Accuracy: 0.8214141414141414 Loss: 0.04576842960083123 Corrects: 4066\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0357951857149601\n",
            "Train step - Step 400, Loss 0.03160123899579048\n",
            "Train step - Step 410, Loss 0.04146101698279381\n",
            "Train step - Step 420, Loss 0.04378598555922508\n",
            "Train epoch - Accuracy: 0.8327272727272728 Loss: 0.04446840670373705 Corrects: 4122\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.043889302760362625\n",
            "Train step - Step 440, Loss 0.03827795013785362\n",
            "Train step - Step 450, Loss 0.04375752806663513\n",
            "Train step - Step 460, Loss 0.04801900312304497\n",
            "Train epoch - Accuracy: 0.8331313131313132 Loss: 0.04386353048260766 Corrects: 4124\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.027514105662703514\n",
            "Train step - Step 480, Loss 0.05294063314795494\n",
            "Train step - Step 490, Loss 0.041738707572221756\n",
            "Train step - Step 500, Loss 0.04259436950087547\n",
            "Train epoch - Accuracy: 0.8454545454545455 Loss: 0.04145410155407106 Corrects: 4185\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.04132836312055588\n",
            "Train step - Step 520, Loss 0.03728892654180527\n",
            "Train step - Step 530, Loss 0.041488587856292725\n",
            "Train step - Step 540, Loss 0.04221540316939354\n",
            "Train epoch - Accuracy: 0.8452525252525253 Loss: 0.041444436180772204 Corrects: 4184\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.026568938046693802\n",
            "Train step - Step 560, Loss 0.03598810359835625\n",
            "Train step - Step 570, Loss 0.03379831835627556\n",
            "Train step - Step 580, Loss 0.04134569689631462\n",
            "Train epoch - Accuracy: 0.8602020202020202 Loss: 0.03722419210004084 Corrects: 4258\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.04135540872812271\n",
            "Train step - Step 600, Loss 0.02932046912610531\n",
            "Train step - Step 610, Loss 0.04890858754515648\n",
            "Train step - Step 620, Loss 0.04923743009567261\n",
            "Train epoch - Accuracy: 0.8636363636363636 Loss: 0.037137974771586334 Corrects: 4275\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.0420881025493145\n",
            "Train step - Step 640, Loss 0.03767993673682213\n",
            "Train step - Step 650, Loss 0.04210406541824341\n",
            "Train step - Step 660, Loss 0.024966081604361534\n",
            "Train epoch - Accuracy: 0.8707070707070707 Loss: 0.03392590497629811 Corrects: 4310\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.030267834663391113\n",
            "Train step - Step 680, Loss 0.031950999051332474\n",
            "Train step - Step 690, Loss 0.025835314765572548\n",
            "Train step - Step 700, Loss 0.03304162248969078\n",
            "Train epoch - Accuracy: 0.8840404040404041 Loss: 0.03267300652133094 Corrects: 4376\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.032580066472291946\n",
            "Train step - Step 720, Loss 0.0357922725379467\n",
            "Train step - Step 730, Loss 0.02770090103149414\n",
            "Train step - Step 740, Loss 0.029594786465168\n",
            "Train epoch - Accuracy: 0.882020202020202 Loss: 0.031214052821048582 Corrects: 4366\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.0351414792239666\n",
            "Train step - Step 760, Loss 0.024730851873755455\n",
            "Train step - Step 770, Loss 0.03770241513848305\n",
            "Train epoch - Accuracy: 0.8846464646464647 Loss: 0.030787131047309048 Corrects: 4379\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.023715723305940628\n",
            "Train step - Step 790, Loss 0.03639836236834526\n",
            "Train step - Step 800, Loss 0.02334176003932953\n",
            "Train step - Step 810, Loss 0.028967324644327164\n",
            "Train epoch - Accuracy: 0.896969696969697 Loss: 0.028365586835025536 Corrects: 4440\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.023195913061499596\n",
            "Train step - Step 830, Loss 0.02378014475107193\n",
            "Train step - Step 840, Loss 0.024088995531201363\n",
            "Train step - Step 850, Loss 0.021391790360212326\n",
            "Train epoch - Accuracy: 0.9026262626262627 Loss: 0.026124937817303823 Corrects: 4468\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.01856101118028164\n",
            "Train step - Step 870, Loss 0.024375302717089653\n",
            "Train step - Step 880, Loss 0.03308088704943657\n",
            "Train step - Step 890, Loss 0.01983400620520115\n",
            "Train epoch - Accuracy: 0.9042424242424243 Loss: 0.026451481828334355 Corrects: 4476\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.025143301114439964\n",
            "Train step - Step 910, Loss 0.027873778715729713\n",
            "Train step - Step 920, Loss 0.03099416010081768\n",
            "Train step - Step 930, Loss 0.0373285710811615\n",
            "Train epoch - Accuracy: 0.8983838383838384 Loss: 0.02771046556532383 Corrects: 4447\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.023261578753590584\n",
            "Train step - Step 950, Loss 0.028853625059127808\n",
            "Train step - Step 960, Loss 0.027272088453173637\n",
            "Train step - Step 970, Loss 0.02372906170785427\n",
            "Train epoch - Accuracy: 0.9165656565656566 Loss: 0.023114669885900285 Corrects: 4537\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.017558658495545387\n",
            "Train step - Step 990, Loss 0.02285546064376831\n",
            "Train step - Step 1000, Loss 0.029187163338065147\n",
            "Train step - Step 1010, Loss 0.032465483993291855\n",
            "Train epoch - Accuracy: 0.9145454545454546 Loss: 0.0247252621930657 Corrects: 4527\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.032112251967191696\n",
            "Train step - Step 1030, Loss 0.0448802225291729\n",
            "Train step - Step 1040, Loss 0.022639883682131767\n",
            "Train step - Step 1050, Loss 0.020646488294005394\n",
            "Train epoch - Accuracy: 0.9096969696969697 Loss: 0.026054488348238397 Corrects: 4503\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.028143150731921196\n",
            "Train step - Step 1070, Loss 0.020476695150136948\n",
            "Train step - Step 1080, Loss 0.023537952452898026\n",
            "Train step - Step 1090, Loss 0.022286033257842064\n",
            "Train epoch - Accuracy: 0.9175757575757576 Loss: 0.023925498034616913 Corrects: 4542\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.019333211705088615\n",
            "Train step - Step 1110, Loss 0.0185347069054842\n",
            "Train step - Step 1120, Loss 0.017906449735164642\n",
            "Train step - Step 1130, Loss 0.024564845487475395\n",
            "Train epoch - Accuracy: 0.9195959595959596 Loss: 0.0215553172647652 Corrects: 4552\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.012501455843448639\n",
            "Train step - Step 1150, Loss 0.018644703552126884\n",
            "Train step - Step 1160, Loss 0.038765400648117065\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.022127697556608854 Corrects: 4555\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.02156870998442173\n",
            "Train step - Step 1180, Loss 0.029782865196466446\n",
            "Train step - Step 1190, Loss 0.020478568971157074\n",
            "Train step - Step 1200, Loss 0.02044183574616909\n",
            "Train epoch - Accuracy: 0.9264646464646464 Loss: 0.020887510865324675 Corrects: 4586\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.017640370875597\n",
            "Train step - Step 1220, Loss 0.01519112940877676\n",
            "Train step - Step 1230, Loss 0.020447317510843277\n",
            "Train step - Step 1240, Loss 0.02117655985057354\n",
            "Train epoch - Accuracy: 0.9296969696969697 Loss: 0.020437232266471844 Corrects: 4602\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.013175101950764656\n",
            "Train step - Step 1260, Loss 0.026179015636444092\n",
            "Train step - Step 1270, Loss 0.024511214345693588\n",
            "Train step - Step 1280, Loss 0.02083088830113411\n",
            "Train epoch - Accuracy: 0.9290909090909091 Loss: 0.020291619933765343 Corrects: 4599\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.019303498789668083\n",
            "Train step - Step 1300, Loss 0.019120560958981514\n",
            "Train step - Step 1310, Loss 0.02391248568892479\n",
            "Train step - Step 1320, Loss 0.02668469026684761\n",
            "Train epoch - Accuracy: 0.9331313131313131 Loss: 0.018957807641438763 Corrects: 4619\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.014481872320175171\n",
            "Train step - Step 1340, Loss 0.016678759828209877\n",
            "Train step - Step 1350, Loss 0.018816670402884483\n",
            "Train step - Step 1360, Loss 0.0258122980594635\n",
            "Train epoch - Accuracy: 0.935959595959596 Loss: 0.017675246044692366 Corrects: 4633\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.01478028018027544\n",
            "Train step - Step 1380, Loss 0.013731421902775764\n",
            "Train step - Step 1390, Loss 0.016747159883379936\n",
            "Train step - Step 1400, Loss 0.02427443116903305\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.015650548219229236 Corrects: 4698\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.00808781012892723\n",
            "Train step - Step 1420, Loss 0.017357109114527702\n",
            "Train step - Step 1430, Loss 0.01278647780418396\n",
            "Train step - Step 1440, Loss 0.01844829134643078\n",
            "Train epoch - Accuracy: 0.9488888888888889 Loss: 0.015356817624785683 Corrects: 4697\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.013281079940497875\n",
            "Train step - Step 1460, Loss 0.01949872449040413\n",
            "Train step - Step 1470, Loss 0.017194969579577446\n",
            "Train step - Step 1480, Loss 0.02254166267812252\n",
            "Train epoch - Accuracy: 0.9393939393939394 Loss: 0.017823989850403083 Corrects: 4650\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.014679007232189178\n",
            "Train step - Step 1500, Loss 0.02266036719083786\n",
            "Train step - Step 1510, Loss 0.019889604300260544\n",
            "Train step - Step 1520, Loss 0.02568870782852173\n",
            "Train epoch - Accuracy: 0.9387878787878788 Loss: 0.017549658592301186 Corrects: 4647\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.015819374471902847\n",
            "Train step - Step 1540, Loss 0.011802471242845058\n",
            "Train step - Step 1550, Loss 0.015942668542265892\n",
            "Train epoch - Accuracy: 0.9406060606060606 Loss: 0.017300053576778884 Corrects: 4656\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.021033454686403275\n",
            "Train step - Step 1570, Loss 0.024300431832671165\n",
            "Train step - Step 1580, Loss 0.01384078711271286\n",
            "Train step - Step 1590, Loss 0.019919132813811302\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.016350794606136553 Corrects: 4678\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.014819549396634102\n",
            "Train step - Step 1610, Loss 0.024843422695994377\n",
            "Train step - Step 1620, Loss 0.015722444280982018\n",
            "Train step - Step 1630, Loss 0.01505217980593443\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.017527938931804113 Corrects: 4652\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.014867129735648632\n",
            "Train step - Step 1650, Loss 0.021516917273402214\n",
            "Train step - Step 1660, Loss 0.01770995929837227\n",
            "Train step - Step 1670, Loss 0.013624787330627441\n",
            "Train epoch - Accuracy: 0.9478787878787879 Loss: 0.015483809546614536 Corrects: 4692\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.018143972381949425\n",
            "Train step - Step 1690, Loss 0.02162383683025837\n",
            "Train step - Step 1700, Loss 0.01757490448653698\n",
            "Train step - Step 1710, Loss 0.015344438143074512\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.015189111977815629 Corrects: 4698\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.007666230201721191\n",
            "Train step - Step 1730, Loss 0.01736009493470192\n",
            "Train step - Step 1740, Loss 0.011558524332940578\n",
            "Train step - Step 1750, Loss 0.017239529639482498\n",
            "Train epoch - Accuracy: 0.9563636363636364 Loss: 0.013248789104623626 Corrects: 4734\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.01022892165929079\n",
            "Train step - Step 1770, Loss 0.009540293365716934\n",
            "Train step - Step 1780, Loss 0.013485184870660305\n",
            "Train step - Step 1790, Loss 0.011183932423591614\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.012049272221447242 Corrects: 4760\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.01010022684931755\n",
            "Train step - Step 1810, Loss 0.009086198173463345\n",
            "Train step - Step 1820, Loss 0.015506001189351082\n",
            "Train step - Step 1830, Loss 0.023418128490447998\n",
            "Train epoch - Accuracy: 0.9551515151515152 Loss: 0.013376012718436693 Corrects: 4728\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.01680557057261467\n",
            "Train step - Step 1850, Loss 0.014889664016664028\n",
            "Train step - Step 1860, Loss 0.015497389249503613\n",
            "Train step - Step 1870, Loss 0.014566403813660145\n",
            "Train epoch - Accuracy: 0.9535353535353536 Loss: 0.013517454555164081 Corrects: 4720\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.011819752864539623\n",
            "Train step - Step 1890, Loss 0.022377990186214447\n",
            "Train step - Step 1900, Loss 0.01049520168453455\n",
            "Train step - Step 1910, Loss 0.013532388024032116\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.011507322084196287 Corrects: 4760\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.006791840773075819\n",
            "Train step - Step 1930, Loss 0.0095451008528471\n",
            "Train step - Step 1940, Loss 0.008827206678688526\n",
            "Train epoch - Accuracy: 0.9755555555555555 Loss: 0.008028851075831688 Corrects: 4829\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.007073176093399525\n",
            "Train step - Step 1960, Loss 0.006795933935791254\n",
            "Train step - Step 1970, Loss 0.0029295976273715496\n",
            "Train step - Step 1980, Loss 0.00397137925028801\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0051574071082803935 Corrects: 4886\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0020746930968016386\n",
            "Train step - Step 2000, Loss 0.004675812087953091\n",
            "Train step - Step 2010, Loss 0.004129158798605204\n",
            "Train step - Step 2020, Loss 0.0020101608242839575\n",
            "Train epoch - Accuracy: 0.9907070707070708 Loss: 0.004509224096934001 Corrects: 4904\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.005343184340745211\n",
            "Train step - Step 2040, Loss 0.0034179016947746277\n",
            "Train step - Step 2050, Loss 0.0033114522229880095\n",
            "Train step - Step 2060, Loss 0.004101991653442383\n",
            "Train epoch - Accuracy: 0.9929292929292929 Loss: 0.003719129509885203 Corrects: 4915\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0033312754239887\n",
            "Train step - Step 2080, Loss 0.0027728667482733727\n",
            "Train step - Step 2090, Loss 0.0037113360594958067\n",
            "Train step - Step 2100, Loss 0.00291301473043859\n",
            "Train epoch - Accuracy: 0.9935353535353535 Loss: 0.0032649862789784117 Corrects: 4918\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0033123090397566557\n",
            "Train step - Step 2120, Loss 0.0029229503124952316\n",
            "Train step - Step 2130, Loss 0.0028362555895000696\n",
            "Train step - Step 2140, Loss 0.003235605778172612\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.002992225770622191 Corrects: 4916\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0011962909484282136\n",
            "Train step - Step 2160, Loss 0.0016897820169106126\n",
            "Train step - Step 2170, Loss 0.0045096916146576405\n",
            "Train step - Step 2180, Loss 0.0018949101213365793\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0030345635883735887 Corrects: 4917\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0010861203772947192\n",
            "Train step - Step 2200, Loss 0.0017409181455150247\n",
            "Train step - Step 2210, Loss 0.0031818305142223835\n",
            "Train step - Step 2220, Loss 0.0015252860030159354\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0026593839337654187 Corrects: 4928\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0018489258363842964\n",
            "Train step - Step 2240, Loss 0.0028527043759822845\n",
            "Train step - Step 2250, Loss 0.0022786378394812346\n",
            "Train step - Step 2260, Loss 0.0041412971913814545\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0026536779432096568 Corrects: 4931\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.002491225255653262\n",
            "Train step - Step 2280, Loss 0.00601120013743639\n",
            "Train step - Step 2290, Loss 0.0009791076881811023\n",
            "Train step - Step 2300, Loss 0.0015384641010314226\n",
            "Train epoch - Accuracy: 0.9945454545454545 Loss: 0.0025958261276698776 Corrects: 4923\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0032241553999483585\n",
            "Train step - Step 2320, Loss 0.0022152760066092014\n",
            "Train step - Step 2330, Loss 0.001095076440833509\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.002613022836640176 Corrects: 4927\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0016358006978407502\n",
            "Train step - Step 2350, Loss 0.0018020587740465999\n",
            "Train step - Step 2360, Loss 0.0036082379519939423\n",
            "Train step - Step 2370, Loss 0.0034735880326479673\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.002279772367892843 Corrects: 4928\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.002115060808137059\n",
            "Train step - Step 2390, Loss 0.0025131830479949713\n",
            "Train step - Step 2400, Loss 0.0017137108370661736\n",
            "Train step - Step 2410, Loss 0.0006777787930332124\n",
            "Train epoch - Accuracy: 0.9949494949494949 Loss: 0.002501799571516011 Corrects: 4925\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0008403122774325311\n",
            "Train step - Step 2430, Loss 0.0034238339867442846\n",
            "Train step - Step 2440, Loss 0.002096658805385232\n",
            "Train step - Step 2450, Loss 0.0023903220426291227\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0020998982274246336 Corrects: 4932\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.002481449395418167\n",
            "Train step - Step 2470, Loss 0.0020621519070118666\n",
            "Train step - Step 2480, Loss 0.0013686290476471186\n",
            "Train step - Step 2490, Loss 0.0007478948100470006\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0019679322617711745 Corrects: 4936\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0023236614651978016\n",
            "Train step - Step 2510, Loss 0.0013172811595723033\n",
            "Train step - Step 2520, Loss 0.0007305156905204058\n",
            "Train step - Step 2530, Loss 0.0010554223554208875\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0016239832177983992 Corrects: 4941\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.002799209440127015\n",
            "Train step - Step 2550, Loss 0.002209654077887535\n",
            "Train step - Step 2560, Loss 0.0012681320076808333\n",
            "Train step - Step 2570, Loss 0.0014954856596887112\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0018766054748604545 Corrects: 4932\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0027280745562165976\n",
            "Train step - Step 2590, Loss 0.0014606040203943849\n",
            "Train step - Step 2600, Loss 0.00042514430242590606\n",
            "Train step - Step 2610, Loss 0.0032364309299737215\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0017725236219062349 Corrects: 4936\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0029375816229730844\n",
            "Train step - Step 2630, Loss 0.0019352121744304895\n",
            "Train step - Step 2640, Loss 0.001391450292430818\n",
            "Train step - Step 2650, Loss 0.0011095835361629725\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.001678588863702096 Corrects: 4938\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0021721688099205494\n",
            "Train step - Step 2670, Loss 0.0013870698167011142\n",
            "Train step - Step 2680, Loss 0.001707612769678235\n",
            "Train step - Step 2690, Loss 0.0020923472475260496\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0016536056770557405 Corrects: 4941\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0016741823637858033\n",
            "Train step - Step 2710, Loss 0.0025728028267621994\n",
            "Train step - Step 2720, Loss 0.0006759032257832587\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0016315372920397556 Corrects: 4938\n",
            "Training finished in 235.03005194664001 seconds\n",
            "EVALUATION:  0.92 0.018819263204932213\n",
            "TEST GROUP:  0.902\n",
            "TEST ALL:  0.451\n",
            "GROUP:  3\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.3555186092853546\n",
            "Train step - Step 10, Loss 0.13807383179664612\n",
            "Train step - Step 20, Loss 0.08994452655315399\n",
            "Train step - Step 30, Loss 0.08158458024263382\n",
            "Train epoch - Accuracy: 0.32141414141414143 Loss: 0.11351540774106979 Corrects: 1591\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.06757519394159317\n",
            "Train step - Step 50, Loss 0.07000746577978134\n",
            "Train step - Step 60, Loss 0.0686064288020134\n",
            "Train step - Step 70, Loss 0.05558517947793007\n",
            "Train epoch - Accuracy: 0.5773737373737374 Loss: 0.0646030104340929 Corrects: 2858\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.06036753207445145\n",
            "Train step - Step 90, Loss 0.04896504431962967\n",
            "Train step - Step 100, Loss 0.059279102832078934\n",
            "Train step - Step 110, Loss 0.04927011579275131\n",
            "Train epoch - Accuracy: 0.6703030303030303 Loss: 0.05331820080677668 Corrects: 3318\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.0442122146487236\n",
            "Train step - Step 130, Loss 0.0467909574508667\n",
            "Train step - Step 140, Loss 0.05103297159075737\n",
            "Train step - Step 150, Loss 0.041026387363672256\n",
            "Train epoch - Accuracy: 0.7165656565656565 Loss: 0.04663011774420738 Corrects: 3547\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.04847795516252518\n",
            "Train step - Step 170, Loss 0.03887825459241867\n",
            "Train step - Step 180, Loss 0.03613832965493202\n",
            "Train step - Step 190, Loss 0.039732713252305984\n",
            "Train epoch - Accuracy: 0.7486868686868687 Loss: 0.04175336756941044 Corrects: 3706\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.039034925401210785\n",
            "Train step - Step 210, Loss 0.0385700948536396\n",
            "Train step - Step 220, Loss 0.0412088967859745\n",
            "Train step - Step 230, Loss 0.03232405334711075\n",
            "Train epoch - Accuracy: 0.7719191919191919 Loss: 0.039101977200821196 Corrects: 3821\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.03889624401926994\n",
            "Train step - Step 250, Loss 0.030584096908569336\n",
            "Train step - Step 260, Loss 0.03363112732768059\n",
            "Train step - Step 270, Loss 0.03446023911237717\n",
            "Train epoch - Accuracy: 0.7929292929292929 Loss: 0.03586319041071516 Corrects: 3925\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.03704817593097687\n",
            "Train step - Step 290, Loss 0.028530968353152275\n",
            "Train step - Step 300, Loss 0.027129625901579857\n",
            "Train step - Step 310, Loss 0.034489020705223083\n",
            "Train epoch - Accuracy: 0.821010101010101 Loss: 0.031713969952831364 Corrects: 4064\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.027808601036667824\n",
            "Train step - Step 330, Loss 0.03922199457883835\n",
            "Train step - Step 340, Loss 0.029453560709953308\n",
            "Train step - Step 350, Loss 0.039082661271095276\n",
            "Train epoch - Accuracy: 0.824040404040404 Loss: 0.030465151486974772 Corrects: 4079\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.02541627176105976\n",
            "Train step - Step 370, Loss 0.02612961083650589\n",
            "Train step - Step 380, Loss 0.028828376904129982\n",
            "Train epoch - Accuracy: 0.8468686868686869 Loss: 0.027918789346109738 Corrects: 4192\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.025730296969413757\n",
            "Train step - Step 400, Loss 0.03507932275533676\n",
            "Train step - Step 410, Loss 0.02493170276284218\n",
            "Train step - Step 420, Loss 0.023081965744495392\n",
            "Train epoch - Accuracy: 0.8511111111111112 Loss: 0.027231975075120877 Corrects: 4213\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.025606069713830948\n",
            "Train step - Step 440, Loss 0.023079531267285347\n",
            "Train step - Step 450, Loss 0.030807089060544968\n",
            "Train step - Step 460, Loss 0.024728739634156227\n",
            "Train epoch - Accuracy: 0.8543434343434343 Loss: 0.026283016366639524 Corrects: 4229\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.02127799019217491\n",
            "Train step - Step 480, Loss 0.02769698016345501\n",
            "Train step - Step 490, Loss 0.023447521030902863\n",
            "Train step - Step 500, Loss 0.0250734593719244\n",
            "Train epoch - Accuracy: 0.8626262626262626 Loss: 0.024853454266834742 Corrects: 4270\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.024048281833529472\n",
            "Train step - Step 520, Loss 0.021938234567642212\n",
            "Train step - Step 530, Loss 0.019270356744527817\n",
            "Train step - Step 540, Loss 0.024755246937274933\n",
            "Train epoch - Accuracy: 0.8759595959595959 Loss: 0.022471074765228263 Corrects: 4336\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.02021164447069168\n",
            "Train step - Step 560, Loss 0.022562257945537567\n",
            "Train step - Step 570, Loss 0.017470164224505424\n",
            "Train step - Step 580, Loss 0.0214157123118639\n",
            "Train epoch - Accuracy: 0.8816161616161616 Loss: 0.021205252332217765 Corrects: 4364\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.02008752152323723\n",
            "Train step - Step 600, Loss 0.022427592426538467\n",
            "Train step - Step 610, Loss 0.02568136528134346\n",
            "Train step - Step 620, Loss 0.015330619178712368\n",
            "Train epoch - Accuracy: 0.8723232323232323 Loss: 0.02211696759393119 Corrects: 4318\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.019737733528017998\n",
            "Train step - Step 640, Loss 0.01992947794497013\n",
            "Train step - Step 650, Loss 0.01830730400979519\n",
            "Train step - Step 660, Loss 0.03359118476510048\n",
            "Train epoch - Accuracy: 0.8749494949494949 Loss: 0.022907000498639214 Corrects: 4331\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.015756040811538696\n",
            "Train step - Step 680, Loss 0.020961981266736984\n",
            "Train step - Step 690, Loss 0.018773552030324936\n",
            "Train step - Step 700, Loss 0.021390410140156746\n",
            "Train epoch - Accuracy: 0.8878787878787879 Loss: 0.020973056134099912 Corrects: 4395\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.021482182666659355\n",
            "Train step - Step 720, Loss 0.024600878357887268\n",
            "Train step - Step 730, Loss 0.017167016863822937\n",
            "Train step - Step 740, Loss 0.018450146540999413\n",
            "Train epoch - Accuracy: 0.8997979797979798 Loss: 0.019120898681006047 Corrects: 4454\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.016115320846438408\n",
            "Train step - Step 760, Loss 0.019983794540166855\n",
            "Train step - Step 770, Loss 0.01718633621931076\n",
            "Train epoch - Accuracy: 0.8993939393939394 Loss: 0.018088510597896096 Corrects: 4452\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.019714148715138435\n",
            "Train step - Step 790, Loss 0.013829891569912434\n",
            "Train step - Step 800, Loss 0.019126007333397865\n",
            "Train step - Step 810, Loss 0.013774590566754341\n",
            "Train epoch - Accuracy: 0.902020202020202 Loss: 0.01799333507289188 Corrects: 4465\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.011993343010544777\n",
            "Train step - Step 830, Loss 0.015107056125998497\n",
            "Train step - Step 840, Loss 0.016209959983825684\n",
            "Train step - Step 850, Loss 0.013824434019625187\n",
            "Train epoch - Accuracy: 0.9155555555555556 Loss: 0.015970896885852622 Corrects: 4532\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.013900474645197392\n",
            "Train step - Step 870, Loss 0.019781332463026047\n",
            "Train step - Step 880, Loss 0.01938113011419773\n",
            "Train step - Step 890, Loss 0.012856468558311462\n",
            "Train epoch - Accuracy: 0.9088888888888889 Loss: 0.01664455056416266 Corrects: 4499\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.01967361755669117\n",
            "Train step - Step 910, Loss 0.014159336686134338\n",
            "Train step - Step 920, Loss 0.012048103846609592\n",
            "Train step - Step 930, Loss 0.019499830901622772\n",
            "Train epoch - Accuracy: 0.9113131313131313 Loss: 0.01628042836494819 Corrects: 4511\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.014298702590167522\n",
            "Train step - Step 950, Loss 0.008357821963727474\n",
            "Train step - Step 960, Loss 0.01703745126724243\n",
            "Train step - Step 970, Loss 0.00940883718430996\n",
            "Train epoch - Accuracy: 0.9244444444444444 Loss: 0.014270578118963073 Corrects: 4576\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.011817843653261662\n",
            "Train step - Step 990, Loss 0.0164661668241024\n",
            "Train step - Step 1000, Loss 0.014719306491315365\n",
            "Train step - Step 1010, Loss 0.018951889127492905\n",
            "Train epoch - Accuracy: 0.9222222222222223 Loss: 0.014729670820136865 Corrects: 4565\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.01553906686604023\n",
            "Train step - Step 1030, Loss 0.014055977575480938\n",
            "Train step - Step 1040, Loss 0.018117737025022507\n",
            "Train step - Step 1050, Loss 0.00868421234190464\n",
            "Train epoch - Accuracy: 0.9301010101010101 Loss: 0.013751095286523452 Corrects: 4604\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.012697766534984112\n",
            "Train step - Step 1070, Loss 0.011415496468544006\n",
            "Train step - Step 1080, Loss 0.010023954324424267\n",
            "Train step - Step 1090, Loss 0.010563642717897892\n",
            "Train epoch - Accuracy: 0.933939393939394 Loss: 0.013079253674080275 Corrects: 4623\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.01578468456864357\n",
            "Train step - Step 1110, Loss 0.01775846630334854\n",
            "Train step - Step 1120, Loss 0.010322426445782185\n",
            "Train step - Step 1130, Loss 0.026716403663158417\n",
            "Train epoch - Accuracy: 0.9276767676767677 Loss: 0.014488607359052908 Corrects: 4592\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.012010732665657997\n",
            "Train step - Step 1150, Loss 0.012585889548063278\n",
            "Train step - Step 1160, Loss 0.01672498695552349\n",
            "Train epoch - Accuracy: 0.933939393939394 Loss: 0.01296848807371024 Corrects: 4623\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.011767971329391003\n",
            "Train step - Step 1180, Loss 0.012905866838991642\n",
            "Train step - Step 1190, Loss 0.01079693902283907\n",
            "Train step - Step 1200, Loss 0.016270849853754044\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.012423853975429078 Corrects: 4621\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.007470369804650545\n",
            "Train step - Step 1220, Loss 0.00818832777440548\n",
            "Train step - Step 1230, Loss 0.009712942875921726\n",
            "Train step - Step 1240, Loss 0.008492577821016312\n",
            "Train epoch - Accuracy: 0.9442424242424242 Loss: 0.010891829858900923 Corrects: 4674\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.007298607844859362\n",
            "Train step - Step 1260, Loss 0.006414880510419607\n",
            "Train step - Step 1270, Loss 0.01192050613462925\n",
            "Train step - Step 1280, Loss 0.010521442629396915\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.009575462159559582 Corrects: 4711\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.00582609698176384\n",
            "Train step - Step 1300, Loss 0.01685129851102829\n",
            "Train step - Step 1310, Loss 0.010730288922786713\n",
            "Train step - Step 1320, Loss 0.008110581897199154\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.010504264097773667 Corrects: 4690\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.00794412475079298\n",
            "Train step - Step 1340, Loss 0.01222253032028675\n",
            "Train step - Step 1350, Loss 0.007869260385632515\n",
            "Train step - Step 1360, Loss 0.008070607669651508\n",
            "Train epoch - Accuracy: 0.9448484848484848 Loss: 0.0111518626780522 Corrects: 4677\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.007503743749111891\n",
            "Train step - Step 1380, Loss 0.011719413101673126\n",
            "Train step - Step 1390, Loss 0.009867655113339424\n",
            "Train step - Step 1400, Loss 0.012349860742688179\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.010304949936090093 Corrects: 4695\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.010061175562441349\n",
            "Train step - Step 1420, Loss 0.014309915713965893\n",
            "Train step - Step 1430, Loss 0.008020509034395218\n",
            "Train step - Step 1440, Loss 0.008741825819015503\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.010434941837959217 Corrects: 4670\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.01163343247026205\n",
            "Train step - Step 1460, Loss 0.013339389115571976\n",
            "Train step - Step 1470, Loss 0.009055684320628643\n",
            "Train step - Step 1480, Loss 0.025516746565699577\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.010078746029599146 Corrects: 4711\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.014397060498595238\n",
            "Train step - Step 1500, Loss 0.00858133565634489\n",
            "Train step - Step 1510, Loss 0.013535112142562866\n",
            "Train step - Step 1520, Loss 0.00526203541085124\n",
            "Train epoch - Accuracy: 0.9408080808080808 Loss: 0.011247067140848046 Corrects: 4657\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.014191992580890656\n",
            "Train step - Step 1540, Loss 0.009735922329127789\n",
            "Train step - Step 1550, Loss 0.007510497234761715\n",
            "Train epoch - Accuracy: 0.9357575757575758 Loss: 0.012117712837879104 Corrects: 4632\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.009783940389752388\n",
            "Train step - Step 1570, Loss 0.016291573643684387\n",
            "Train step - Step 1580, Loss 0.006337478756904602\n",
            "Train step - Step 1590, Loss 0.012322395108640194\n",
            "Train epoch - Accuracy: 0.9385858585858586 Loss: 0.01199264966779285 Corrects: 4646\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.01071875635534525\n",
            "Train step - Step 1610, Loss 0.012790068052709103\n",
            "Train step - Step 1620, Loss 0.012168394401669502\n",
            "Train step - Step 1630, Loss 0.013597258366644382\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.010239794073682843 Corrects: 4690\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.006243881769478321\n",
            "Train step - Step 1650, Loss 0.005246956367045641\n",
            "Train step - Step 1660, Loss 0.012309818528592587\n",
            "Train step - Step 1670, Loss 0.00810710433870554\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.009585660750215703 Corrects: 4708\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0063878921791911125\n",
            "Train step - Step 1690, Loss 0.009669310413300991\n",
            "Train step - Step 1700, Loss 0.009221657179296017\n",
            "Train step - Step 1710, Loss 0.01012992300093174\n",
            "Train epoch - Accuracy: 0.9573737373737373 Loss: 0.008611265429756557 Corrects: 4739\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.008855138905346394\n",
            "Train step - Step 1730, Loss 0.008220859803259373\n",
            "Train step - Step 1740, Loss 0.007423887029290199\n",
            "Train step - Step 1750, Loss 0.00626417575404048\n",
            "Train epoch - Accuracy: 0.9593939393939394 Loss: 0.00865581958582907 Corrects: 4749\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.009494362398982048\n",
            "Train step - Step 1770, Loss 0.003914559260010719\n",
            "Train step - Step 1780, Loss 0.007972038350999355\n",
            "Train step - Step 1790, Loss 0.007141836918890476\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.007405902548420309 Corrects: 4766\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.012473712675273418\n",
            "Train step - Step 1810, Loss 0.009485620073974133\n",
            "Train step - Step 1820, Loss 0.009191065095365047\n",
            "Train step - Step 1830, Loss 0.0103900833055377\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.008218698215040595 Corrects: 4760\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0074341678991913795\n",
            "Train step - Step 1850, Loss 0.005085096228867769\n",
            "Train step - Step 1860, Loss 0.008336273953318596\n",
            "Train step - Step 1870, Loss 0.004730642307549715\n",
            "Train epoch - Accuracy: 0.9670707070707071 Loss: 0.007104313291910321 Corrects: 4787\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.008064313791692257\n",
            "Train step - Step 1890, Loss 0.006075065582990646\n",
            "Train step - Step 1900, Loss 0.010672328993678093\n",
            "Train step - Step 1910, Loss 0.009451163932681084\n",
            "Train epoch - Accuracy: 0.9660606060606061 Loss: 0.00682802546280201 Corrects: 4782\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.003237366210669279\n",
            "Train step - Step 1930, Loss 0.0035252156667411327\n",
            "Train step - Step 1940, Loss 0.0029564935248345137\n",
            "Train epoch - Accuracy: 0.9854545454545455 Loss: 0.004003853678392867 Corrects: 4878\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.004446463193744421\n",
            "Train step - Step 1960, Loss 0.003691684454679489\n",
            "Train step - Step 1970, Loss 0.0012509117368608713\n",
            "Train step - Step 1980, Loss 0.002147868275642395\n",
            "Train epoch - Accuracy: 0.9925252525252525 Loss: 0.0025506019825586165 Corrects: 4913\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0018592706182971597\n",
            "Train step - Step 2000, Loss 0.0029052384197711945\n",
            "Train step - Step 2010, Loss 0.0018523236503824592\n",
            "Train step - Step 2020, Loss 0.0026211580261588097\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.002013923025341949 Corrects: 4927\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0017728981329128146\n",
            "Train step - Step 2040, Loss 0.0014596671098843217\n",
            "Train step - Step 2050, Loss 0.0013280365383252501\n",
            "Train step - Step 2060, Loss 0.0014725028304383159\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0019195064848684 Corrects: 4927\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0012506330385804176\n",
            "Train step - Step 2080, Loss 0.0015325137646868825\n",
            "Train step - Step 2090, Loss 0.0011364989914000034\n",
            "Train step - Step 2100, Loss 0.0016198853263631463\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0016359408080314445 Corrects: 4938\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0006853505619801581\n",
            "Train step - Step 2120, Loss 0.0010414420394226909\n",
            "Train step - Step 2130, Loss 0.0024703473318368196\n",
            "Train step - Step 2140, Loss 0.0015556163853034377\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0014412730950109586 Corrects: 4937\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.000892091600690037\n",
            "Train step - Step 2160, Loss 0.001153292367234826\n",
            "Train step - Step 2170, Loss 0.0010687927715480328\n",
            "Train step - Step 2180, Loss 0.003326383652165532\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0014001762317117266 Corrects: 4935\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0016188232693821192\n",
            "Train step - Step 2200, Loss 0.0018827716121450067\n",
            "Train step - Step 2210, Loss 0.0012563263298943639\n",
            "Train step - Step 2220, Loss 0.0008911420009098947\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00130191611920982 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0016094526508823037\n",
            "Train step - Step 2240, Loss 0.0009184537339024246\n",
            "Train step - Step 2250, Loss 0.001157658756710589\n",
            "Train step - Step 2260, Loss 0.0017590358620509505\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0012275714467213763 Corrects: 4944\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0008194163092412055\n",
            "Train step - Step 2280, Loss 0.001082942239008844\n",
            "Train step - Step 2290, Loss 0.001101260189898312\n",
            "Train step - Step 2300, Loss 0.0007414467982016504\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0011664296546715755 Corrects: 4945\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0016693046782165766\n",
            "Train step - Step 2320, Loss 0.0006614190642721951\n",
            "Train step - Step 2330, Loss 0.0006882003508508205\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0011294756302694705 Corrects: 4939\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.001070672064088285\n",
            "Train step - Step 2350, Loss 0.0010410966351628304\n",
            "Train step - Step 2360, Loss 0.0015990867977961898\n",
            "Train step - Step 2370, Loss 0.0010569423902779818\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.0010163471933849382 Corrects: 4948\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0006868172786198556\n",
            "Train step - Step 2390, Loss 0.0011108937906101346\n",
            "Train step - Step 2400, Loss 0.000691945489961654\n",
            "Train step - Step 2410, Loss 0.0005935572553426027\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0012232403409187542 Corrects: 4937\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0003931266546715051\n",
            "Train step - Step 2430, Loss 0.0008551943465135992\n",
            "Train step - Step 2440, Loss 0.0012241746298968792\n",
            "Train step - Step 2450, Loss 0.0008154027746059\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0009538054619586528 Corrects: 4944\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0009302667458541691\n",
            "Train step - Step 2470, Loss 0.0007205409929156303\n",
            "Train step - Step 2480, Loss 0.0012981301406398416\n",
            "Train step - Step 2490, Loss 0.0006699316436424851\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0009186279785941647 Corrects: 4943\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0005134809180162847\n",
            "Train step - Step 2510, Loss 0.000568496820051223\n",
            "Train step - Step 2520, Loss 0.00072794797597453\n",
            "Train step - Step 2530, Loss 0.0009529467206448317\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0010191850065056122 Corrects: 4943\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0005486824084073305\n",
            "Train step - Step 2550, Loss 0.0019385687774047256\n",
            "Train step - Step 2560, Loss 0.001243201899342239\n",
            "Train step - Step 2570, Loss 0.0005436119390651584\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0008547515878359778 Corrects: 4943\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0012926447670906782\n",
            "Train step - Step 2590, Loss 0.0007650424377061427\n",
            "Train step - Step 2600, Loss 0.0007099412614479661\n",
            "Train step - Step 2610, Loss 0.0006073093973100185\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0009283523978148069 Corrects: 4942\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0012879305286332965\n",
            "Train step - Step 2630, Loss 0.0013330139918252826\n",
            "Train step - Step 2640, Loss 0.0012429156340658665\n",
            "Train step - Step 2650, Loss 0.000725742953363806\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0009100556676981575 Corrects: 4945\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0007891715504229069\n",
            "Train step - Step 2670, Loss 0.0008942326530814171\n",
            "Train step - Step 2680, Loss 0.000618028047028929\n",
            "Train step - Step 2690, Loss 0.0007787922513671219\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0007872032479270164 Corrects: 4947\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0014607266057282686\n",
            "Train step - Step 2710, Loss 0.0003983874630648643\n",
            "Train step - Step 2720, Loss 0.0006555306608788669\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0008044405239210887 Corrects: 4945\n",
            "Training finished in 240.43073439598083 seconds\n",
            "EVALUATION:  0.9 0.020734135061502457\n",
            "TEST GROUP:  0.865\n",
            "TEST ALL:  0.28833333333333333\n",
            "GROUP:  4\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.2608965039253235\n",
            "Train step - Step 10, Loss 0.11323349922895432\n",
            "Train step - Step 20, Loss 0.07478510588407516\n",
            "Train step - Step 30, Loss 0.06295721232891083\n",
            "Train epoch - Accuracy: 0.3094949494949495 Loss: 0.08927936794179858 Corrects: 1532\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.05036624148488045\n",
            "Train step - Step 50, Loss 0.0479847751557827\n",
            "Train step - Step 60, Loss 0.03435495123267174\n",
            "Train step - Step 70, Loss 0.039935458451509476\n",
            "Train epoch - Accuracy: 0.618989898989899 Loss: 0.04472326577010781 Corrects: 3064\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.03397543355822563\n",
            "Train step - Step 90, Loss 0.03304199501872063\n",
            "Train step - Step 100, Loss 0.033174362033605576\n",
            "Train step - Step 110, Loss 0.02836412750184536\n",
            "Train epoch - Accuracy: 0.7234343434343434 Loss: 0.03427485047340995 Corrects: 3581\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.034957654774188995\n",
            "Train step - Step 130, Loss 0.030921125784516335\n",
            "Train step - Step 140, Loss 0.02635740302503109\n",
            "Train step - Step 150, Loss 0.024259930476546288\n",
            "Train epoch - Accuracy: 0.7682828282828282 Loss: 0.028668072419335142 Corrects: 3803\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.023718008771538734\n",
            "Train step - Step 170, Loss 0.023873165249824524\n",
            "Train step - Step 180, Loss 0.023034268990159035\n",
            "Train step - Step 190, Loss 0.025444984436035156\n",
            "Train epoch - Accuracy: 0.7977777777777778 Loss: 0.02552565746235125 Corrects: 3949\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.018369076773524284\n",
            "Train step - Step 210, Loss 0.022210344672203064\n",
            "Train step - Step 220, Loss 0.01955718733370304\n",
            "Train step - Step 230, Loss 0.02147703804075718\n",
            "Train epoch - Accuracy: 0.8331313131313132 Loss: 0.02218519365847713 Corrects: 4124\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.019556362181901932\n",
            "Train step - Step 250, Loss 0.020209020003676414\n",
            "Train step - Step 260, Loss 0.019816605374217033\n",
            "Train step - Step 270, Loss 0.020153749734163284\n",
            "Train epoch - Accuracy: 0.8438383838383838 Loss: 0.0203280003767724 Corrects: 4177\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.021901393309235573\n",
            "Train step - Step 290, Loss 0.014749469235539436\n",
            "Train step - Step 300, Loss 0.01953924261033535\n",
            "Train step - Step 310, Loss 0.01992098055779934\n",
            "Train epoch - Accuracy: 0.8654545454545455 Loss: 0.018722387130061784 Corrects: 4284\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.02118932455778122\n",
            "Train step - Step 330, Loss 0.014942044392228127\n",
            "Train step - Step 340, Loss 0.019795751199126244\n",
            "Train step - Step 350, Loss 0.01851249672472477\n",
            "Train epoch - Accuracy: 0.8638383838383838 Loss: 0.018396659492693767 Corrects: 4276\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.013353508897125721\n",
            "Train step - Step 370, Loss 0.018446240574121475\n",
            "Train step - Step 380, Loss 0.01241292804479599\n",
            "Train epoch - Accuracy: 0.8848484848484849 Loss: 0.015257193543242686 Corrects: 4380\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.011201036162674427\n",
            "Train step - Step 400, Loss 0.01613299921154976\n",
            "Train step - Step 410, Loss 0.014399182982742786\n",
            "Train step - Step 420, Loss 0.011504321359097958\n",
            "Train epoch - Accuracy: 0.8884848484848484 Loss: 0.01548889578291864 Corrects: 4398\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.013529203832149506\n",
            "Train step - Step 440, Loss 0.01681278459727764\n",
            "Train step - Step 450, Loss 0.013322300277650356\n",
            "Train step - Step 460, Loss 0.011270204558968544\n",
            "Train epoch - Accuracy: 0.8933333333333333 Loss: 0.014079739157900666 Corrects: 4422\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.015307602472603321\n",
            "Train step - Step 480, Loss 0.016052937135100365\n",
            "Train step - Step 490, Loss 0.015141278505325317\n",
            "Train step - Step 500, Loss 0.012144889682531357\n",
            "Train epoch - Accuracy: 0.9066666666666666 Loss: 0.013405819767051273 Corrects: 4488\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.011847074143588543\n",
            "Train step - Step 520, Loss 0.010828266851603985\n",
            "Train step - Step 530, Loss 0.01202948298305273\n",
            "Train step - Step 540, Loss 0.014459818601608276\n",
            "Train epoch - Accuracy: 0.9074747474747474 Loss: 0.01243385183615516 Corrects: 4492\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.010052031837403774\n",
            "Train step - Step 560, Loss 0.011541876010596752\n",
            "Train step - Step 570, Loss 0.011389066465198994\n",
            "Train step - Step 580, Loss 0.011708550155162811\n",
            "Train epoch - Accuracy: 0.9119191919191919 Loss: 0.011762543772958746 Corrects: 4514\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.0102999834343791\n",
            "Train step - Step 600, Loss 0.008458539843559265\n",
            "Train step - Step 610, Loss 0.012982179410755634\n",
            "Train step - Step 620, Loss 0.009127876721322536\n",
            "Train epoch - Accuracy: 0.9185858585858586 Loss: 0.011294984157112511 Corrects: 4547\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.01175291370600462\n",
            "Train step - Step 640, Loss 0.012595045380294323\n",
            "Train step - Step 650, Loss 0.010398471727967262\n",
            "Train step - Step 660, Loss 0.012406385503709316\n",
            "Train epoch - Accuracy: 0.92 Loss: 0.011057575041371764 Corrects: 4554\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.009308177046477795\n",
            "Train step - Step 680, Loss 0.008219094015657902\n",
            "Train step - Step 690, Loss 0.012105653993785381\n",
            "Train step - Step 700, Loss 0.011446203105151653\n",
            "Train epoch - Accuracy: 0.9288888888888889 Loss: 0.01041822936762162 Corrects: 4598\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.010742620564997196\n",
            "Train step - Step 720, Loss 0.006402296479791403\n",
            "Train step - Step 730, Loss 0.010893262922763824\n",
            "Train step - Step 740, Loss 0.01812790520489216\n",
            "Train epoch - Accuracy: 0.9288888888888889 Loss: 0.010369042846741098 Corrects: 4598\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.010808916762471199\n",
            "Train step - Step 760, Loss 0.015058154240250587\n",
            "Train step - Step 770, Loss 0.008984968066215515\n",
            "Train epoch - Accuracy: 0.9284848484848485 Loss: 0.010045208888071956 Corrects: 4596\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.005992574151605368\n",
            "Train step - Step 790, Loss 0.006992465350776911\n",
            "Train step - Step 800, Loss 0.006672290153801441\n",
            "Train step - Step 810, Loss 0.007107994984835386\n",
            "Train epoch - Accuracy: 0.9329292929292929 Loss: 0.009625575941319417 Corrects: 4618\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.004828899633139372\n",
            "Train step - Step 830, Loss 0.005121932830661535\n",
            "Train step - Step 840, Loss 0.011747349984943867\n",
            "Train step - Step 850, Loss 0.007773953024297953\n",
            "Train epoch - Accuracy: 0.943030303030303 Loss: 0.0085656242341631 Corrects: 4668\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.007656367961317301\n",
            "Train step - Step 870, Loss 0.007111002691090107\n",
            "Train step - Step 880, Loss 0.0075165145099163055\n",
            "Train step - Step 890, Loss 0.007675379514694214\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.00845603532938644 Corrects: 4658\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.007954330183565617\n",
            "Train step - Step 910, Loss 0.005736727733165026\n",
            "Train step - Step 920, Loss 0.007793729193508625\n",
            "Train step - Step 930, Loss 0.007314410991966724\n",
            "Train epoch - Accuracy: 0.9341414141414142 Loss: 0.009206758596830898 Corrects: 4624\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.007743183057755232\n",
            "Train step - Step 950, Loss 0.009839995764195919\n",
            "Train step - Step 960, Loss 0.007347284350544214\n",
            "Train step - Step 970, Loss 0.010088570415973663\n",
            "Train epoch - Accuracy: 0.9406060606060606 Loss: 0.00888329887894368 Corrects: 4656\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.008021824061870575\n",
            "Train step - Step 990, Loss 0.008365794084966183\n",
            "Train step - Step 1000, Loss 0.007972453720867634\n",
            "Train step - Step 1010, Loss 0.009212044067680836\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.0077789302181565404 Corrects: 4695\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.006672473158687353\n",
            "Train step - Step 1030, Loss 0.01246829517185688\n",
            "Train step - Step 1040, Loss 0.007615936454385519\n",
            "Train step - Step 1050, Loss 0.005615465342998505\n",
            "Train epoch - Accuracy: 0.9533333333333334 Loss: 0.007210030029857099 Corrects: 4719\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0062868245877325535\n",
            "Train step - Step 1070, Loss 0.005330601241439581\n",
            "Train step - Step 1080, Loss 0.00810398068279028\n",
            "Train step - Step 1090, Loss 0.007531724404543638\n",
            "Train epoch - Accuracy: 0.9513131313131313 Loss: 0.0069244715183822796 Corrects: 4709\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.007453809957951307\n",
            "Train step - Step 1110, Loss 0.0076520973816514015\n",
            "Train step - Step 1120, Loss 0.004542123526334763\n",
            "Train step - Step 1130, Loss 0.01445210911333561\n",
            "Train epoch - Accuracy: 0.9503030303030303 Loss: 0.007477735159824593 Corrects: 4704\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.008496413007378578\n",
            "Train step - Step 1150, Loss 0.007103502284735441\n",
            "Train step - Step 1160, Loss 0.007597610354423523\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.00687381652005092 Corrects: 4724\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.006952914875000715\n",
            "Train step - Step 1180, Loss 0.004760746378451586\n",
            "Train step - Step 1190, Loss 0.0033277024049311876\n",
            "Train step - Step 1200, Loss 0.007591610308736563\n",
            "Train epoch - Accuracy: 0.9505050505050505 Loss: 0.007438179479554446 Corrects: 4705\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0052152457647025585\n",
            "Train step - Step 1220, Loss 0.004899855703115463\n",
            "Train step - Step 1230, Loss 0.00811404176056385\n",
            "Train step - Step 1240, Loss 0.006058677565306425\n",
            "Train epoch - Accuracy: 0.9521212121212121 Loss: 0.006934344230802974 Corrects: 4713\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.004414945840835571\n",
            "Train step - Step 1260, Loss 0.006965510081499815\n",
            "Train step - Step 1270, Loss 0.0027814216446131468\n",
            "Train step - Step 1280, Loss 0.0050401147454977036\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.007015523849939457 Corrects: 4711\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.006952121388167143\n",
            "Train step - Step 1300, Loss 0.009972876869142056\n",
            "Train step - Step 1310, Loss 0.004975836258381605\n",
            "Train step - Step 1320, Loss 0.008891156874597073\n",
            "Train epoch - Accuracy: 0.9541414141414142 Loss: 0.006927026158405675 Corrects: 4723\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.006976579315960407\n",
            "Train step - Step 1340, Loss 0.005080002825707197\n",
            "Train step - Step 1350, Loss 0.005469608120620251\n",
            "Train step - Step 1360, Loss 0.005638397764414549\n",
            "Train epoch - Accuracy: 0.9674747474747475 Loss: 0.005363840780061002 Corrects: 4789\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004707049578428268\n",
            "Train step - Step 1380, Loss 0.002626679604873061\n",
            "Train step - Step 1390, Loss 0.005522281862795353\n",
            "Train step - Step 1400, Loss 0.0034244582056999207\n",
            "Train epoch - Accuracy: 0.972929292929293 Loss: 0.004574870222125842 Corrects: 4816\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0050721550360322\n",
            "Train step - Step 1420, Loss 0.007697220891714096\n",
            "Train step - Step 1430, Loss 0.004537809174507856\n",
            "Train step - Step 1440, Loss 0.0032013796735554934\n",
            "Train epoch - Accuracy: 0.9678787878787879 Loss: 0.005259284362798989 Corrects: 4791\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0038328790105879307\n",
            "Train step - Step 1460, Loss 0.004453297704458237\n",
            "Train step - Step 1470, Loss 0.0035528279840946198\n",
            "Train step - Step 1480, Loss 0.005085522774606943\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.005381739459593187 Corrects: 4790\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0028519651386886835\n",
            "Train step - Step 1500, Loss 0.003778858808800578\n",
            "Train step - Step 1510, Loss 0.005003062542527914\n",
            "Train step - Step 1520, Loss 0.00516884122043848\n",
            "Train epoch - Accuracy: 0.9642424242424242 Loss: 0.005576677621539795 Corrects: 4773\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.004743614699691534\n",
            "Train step - Step 1540, Loss 0.01006790529936552\n",
            "Train step - Step 1550, Loss 0.0032222368754446507\n",
            "Train epoch - Accuracy: 0.9642424242424242 Loss: 0.00564547264402864 Corrects: 4773\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.006656603422015905\n",
            "Train step - Step 1570, Loss 0.00425175903365016\n",
            "Train step - Step 1580, Loss 0.0018960386514663696\n",
            "Train step - Step 1590, Loss 0.00414906395599246\n",
            "Train epoch - Accuracy: 0.9711111111111111 Loss: 0.004735731568488509 Corrects: 4807\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0052078342996537685\n",
            "Train step - Step 1610, Loss 0.0035047479905188084\n",
            "Train step - Step 1620, Loss 0.00676788529381156\n",
            "Train step - Step 1630, Loss 0.007347141392529011\n",
            "Train epoch - Accuracy: 0.9696969696969697 Loss: 0.004897158956813692 Corrects: 4800\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.005603571888059378\n",
            "Train step - Step 1650, Loss 0.0035450446885079145\n",
            "Train step - Step 1660, Loss 0.006295026279985905\n",
            "Train step - Step 1670, Loss 0.006087278015911579\n",
            "Train epoch - Accuracy: 0.9678787878787879 Loss: 0.005044644464635187 Corrects: 4791\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.002498085843399167\n",
            "Train step - Step 1690, Loss 0.004225403070449829\n",
            "Train step - Step 1700, Loss 0.006292040925472975\n",
            "Train step - Step 1710, Loss 0.0056896149180829525\n",
            "Train epoch - Accuracy: 0.9711111111111111 Loss: 0.004866474128205969 Corrects: 4807\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.004401708021759987\n",
            "Train step - Step 1730, Loss 0.00451762555167079\n",
            "Train step - Step 1740, Loss 0.005051370244473219\n",
            "Train step - Step 1750, Loss 0.002984944498166442\n",
            "Train epoch - Accuracy: 0.963030303030303 Loss: 0.0056240068921687624 Corrects: 4767\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.0069117057137191296\n",
            "Train step - Step 1770, Loss 0.005117302294820547\n",
            "Train step - Step 1780, Loss 0.004844212904572487\n",
            "Train step - Step 1790, Loss 0.0034650079905986786\n",
            "Train epoch - Accuracy: 0.9652525252525253 Loss: 0.005164290089160204 Corrects: 4778\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.002972711343318224\n",
            "Train step - Step 1810, Loss 0.00291449879296124\n",
            "Train step - Step 1820, Loss 0.010651372373104095\n",
            "Train step - Step 1830, Loss 0.00605078274384141\n",
            "Train epoch - Accuracy: 0.9686868686868687 Loss: 0.005187298480910484 Corrects: 4795\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.00476006418466568\n",
            "Train step - Step 1850, Loss 0.003180264262482524\n",
            "Train step - Step 1860, Loss 0.0030033213552087545\n",
            "Train step - Step 1870, Loss 0.0060191391967237\n",
            "Train epoch - Accuracy: 0.9717171717171718 Loss: 0.004745974968178104 Corrects: 4810\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.014372250996530056\n",
            "Train step - Step 1890, Loss 0.00445741368457675\n",
            "Train step - Step 1900, Loss 0.007744640111923218\n",
            "Train step - Step 1910, Loss 0.005036347545683384\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.005540503023775539 Corrects: 4758\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.002386016771197319\n",
            "Train step - Step 1930, Loss 0.0026932626497000456\n",
            "Train step - Step 1940, Loss 0.00506429560482502\n",
            "Train epoch - Accuracy: 0.9850505050505051 Loss: 0.0031604355216176823 Corrects: 4876\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.00529279513284564\n",
            "Train step - Step 1960, Loss 0.0011151405051350594\n",
            "Train step - Step 1970, Loss 0.00351539789699018\n",
            "Train step - Step 1980, Loss 0.0012356172082945704\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0016459413749081166 Corrects: 4921\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0017066985601559281\n",
            "Train step - Step 2000, Loss 0.0007929481798782945\n",
            "Train step - Step 2010, Loss 0.001097985776141286\n",
            "Train step - Step 2020, Loss 0.002480743220075965\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0013471978078737404 Corrects: 4927\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0019103024387732148\n",
            "Train step - Step 2040, Loss 0.0014502013800665736\n",
            "Train step - Step 2050, Loss 0.0008033111807890236\n",
            "Train step - Step 2060, Loss 0.0011139194248244166\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0011897774439568471 Corrects: 4931\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0009343604906462133\n",
            "Train step - Step 2080, Loss 0.0006626758840866387\n",
            "Train step - Step 2090, Loss 0.0016423013294115663\n",
            "Train step - Step 2100, Loss 0.0013299387646839023\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0009050319603446758 Corrects: 4941\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0003376725653652102\n",
            "Train step - Step 2120, Loss 0.000615521683357656\n",
            "Train step - Step 2130, Loss 0.002046097768470645\n",
            "Train step - Step 2140, Loss 0.000833813683129847\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.000919715900519731 Corrects: 4938\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0009876637486740947\n",
            "Train step - Step 2160, Loss 0.001049597980454564\n",
            "Train step - Step 2170, Loss 0.0005096737877465785\n",
            "Train step - Step 2180, Loss 0.0006691670860163867\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0009039188108308185 Corrects: 4937\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0010505690006539226\n",
            "Train step - Step 2200, Loss 0.0005771767464466393\n",
            "Train step - Step 2210, Loss 0.0007505806279368699\n",
            "Train step - Step 2220, Loss 0.0008975224918685853\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0008448703926423508 Corrects: 4942\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.000612537085544318\n",
            "Train step - Step 2240, Loss 0.0007061329088173807\n",
            "Train step - Step 2250, Loss 0.0003502879699226469\n",
            "Train step - Step 2260, Loss 0.0014884386910125613\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0008226446405457653 Corrects: 4939\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0013513339217752218\n",
            "Train step - Step 2280, Loss 0.0013219492975622416\n",
            "Train step - Step 2290, Loss 0.0006012312951497734\n",
            "Train step - Step 2300, Loss 0.0006668299320153892\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0007309057928781693 Corrects: 4942\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.00039019566611386836\n",
            "Train step - Step 2320, Loss 0.0006795083172619343\n",
            "Train step - Step 2330, Loss 0.00027316814521327615\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0006663754704229609 Corrects: 4947\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0003410693316254765\n",
            "Train step - Step 2350, Loss 0.0002876959915738553\n",
            "Train step - Step 2360, Loss 0.0005870380555279553\n",
            "Train step - Step 2370, Loss 0.0006280461675487459\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00062666941970361 Corrects: 4945\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0014510279288515449\n",
            "Train step - Step 2390, Loss 0.0024758928921073675\n",
            "Train step - Step 2400, Loss 0.0006368189351633191\n",
            "Train step - Step 2410, Loss 0.00037234817864373326\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0007069087069072394 Corrects: 4943\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00040630900184623897\n",
            "Train step - Step 2430, Loss 0.00071669090539217\n",
            "Train step - Step 2440, Loss 0.0007874352158978581\n",
            "Train step - Step 2450, Loss 0.0005909243482165039\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.000677040280113373 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0003413996601011604\n",
            "Train step - Step 2470, Loss 0.0009270988521166146\n",
            "Train step - Step 2480, Loss 0.0004750474472530186\n",
            "Train step - Step 2490, Loss 0.0007391613908112049\n",
            "Train epoch - Accuracy: 0.9997979797979798 Loss: 0.0005469372787635134 Corrects: 4949\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00042977911652997136\n",
            "Train step - Step 2510, Loss 0.00027659436454996467\n",
            "Train step - Step 2520, Loss 0.0006447960622608662\n",
            "Train step - Step 2530, Loss 0.000627334404271096\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0005989563636801611 Corrects: 4943\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0005036396905779839\n",
            "Train step - Step 2550, Loss 0.0005826945998705924\n",
            "Train step - Step 2560, Loss 0.0003132782003376633\n",
            "Train step - Step 2570, Loss 0.00035935049527324736\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0005637743737021781 Corrects: 4945\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0005403906106948853\n",
            "Train step - Step 2590, Loss 0.001936478540301323\n",
            "Train step - Step 2600, Loss 0.0003971871919929981\n",
            "Train step - Step 2610, Loss 0.0003485076013021171\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.000597543420300659 Corrects: 4947\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0005088350153528154\n",
            "Train step - Step 2630, Loss 0.00034085052902810276\n",
            "Train step - Step 2640, Loss 0.0008997283293865621\n",
            "Train step - Step 2650, Loss 0.0002805460535455495\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0004956090609740579 Corrects: 4946\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0004561564128380269\n",
            "Train step - Step 2670, Loss 0.0006328043527901173\n",
            "Train step - Step 2680, Loss 0.0008699645404703915\n",
            "Train step - Step 2690, Loss 0.0004475967143662274\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0005478465716787285 Corrects: 4946\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0008208476938307285\n",
            "Train step - Step 2710, Loss 0.0003086607903242111\n",
            "Train step - Step 2720, Loss 0.001152730779722333\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0005768792788531029 Corrects: 4945\n",
            "Training finished in 240.50345420837402 seconds\n",
            "EVALUATION:  0.82 0.03526134043931961\n",
            "TEST GROUP:  0.886\n",
            "TEST ALL:  0.2215\n",
            "GROUP:  5\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.24346879124641418\n",
            "Train step - Step 10, Loss 0.09500650316476822\n",
            "Train step - Step 20, Loss 0.05601593852043152\n",
            "Train step - Step 30, Loss 0.04809928685426712\n",
            "Train epoch - Accuracy: 0.2862626262626263 Loss: 0.0752354212255791 Corrects: 1417\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.04185672849416733\n",
            "Train step - Step 50, Loss 0.04051906615495682\n",
            "Train step - Step 60, Loss 0.036282844841480255\n",
            "Train step - Step 70, Loss 0.040908556431531906\n",
            "Train epoch - Accuracy: 0.5458585858585858 Loss: 0.04001551156995272 Corrects: 2702\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.0326821468770504\n",
            "Train step - Step 90, Loss 0.030330628156661987\n",
            "Train step - Step 100, Loss 0.031168684363365173\n",
            "Train step - Step 110, Loss 0.031231578439474106\n",
            "Train epoch - Accuracy: 0.6329292929292929 Loss: 0.033550595048100054 Corrects: 3133\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.03269214928150177\n",
            "Train step - Step 130, Loss 0.029445605352520943\n",
            "Train step - Step 140, Loss 0.030261952430009842\n",
            "Train step - Step 150, Loss 0.030511146411299706\n",
            "Train epoch - Accuracy: 0.6888888888888889 Loss: 0.02981308450000455 Corrects: 3410\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.028041452169418335\n",
            "Train step - Step 170, Loss 0.02398909442126751\n",
            "Train step - Step 180, Loss 0.029998043552041054\n",
            "Train step - Step 190, Loss 0.02669750340282917\n",
            "Train epoch - Accuracy: 0.7173737373737373 Loss: 0.027094048958535146 Corrects: 3551\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.021244434639811516\n",
            "Train step - Step 210, Loss 0.03027522750198841\n",
            "Train step - Step 220, Loss 0.023656319826841354\n",
            "Train step - Step 230, Loss 0.0291342344135046\n",
            "Train epoch - Accuracy: 0.7325252525252526 Loss: 0.0257337450567219 Corrects: 3626\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.019030403345823288\n",
            "Train step - Step 250, Loss 0.023654405027627945\n",
            "Train step - Step 260, Loss 0.023965761065483093\n",
            "Train step - Step 270, Loss 0.0274380911141634\n",
            "Train epoch - Accuracy: 0.7612121212121212 Loss: 0.023432305486816348 Corrects: 3768\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.025074584409594536\n",
            "Train step - Step 290, Loss 0.019710540771484375\n",
            "Train step - Step 300, Loss 0.022349238395690918\n",
            "Train step - Step 310, Loss 0.016778720542788506\n",
            "Train epoch - Accuracy: 0.7886868686868687 Loss: 0.021410377970097042 Corrects: 3904\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.02248762734234333\n",
            "Train step - Step 330, Loss 0.022700846195220947\n",
            "Train step - Step 340, Loss 0.021479301154613495\n",
            "Train step - Step 350, Loss 0.02221429906785488\n",
            "Train epoch - Accuracy: 0.781010101010101 Loss: 0.021555086146249916 Corrects: 3866\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.02075035311281681\n",
            "Train step - Step 370, Loss 0.028228048235177994\n",
            "Train step - Step 380, Loss 0.026020247489213943\n",
            "Train epoch - Accuracy: 0.7981818181818182 Loss: 0.02003405183403179 Corrects: 3951\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.019159777089953423\n",
            "Train step - Step 400, Loss 0.020492715761065483\n",
            "Train step - Step 410, Loss 0.021470895037055016\n",
            "Train step - Step 420, Loss 0.01808609999716282\n",
            "Train epoch - Accuracy: 0.8173737373737374 Loss: 0.018579013462018484 Corrects: 4046\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.015014155767858028\n",
            "Train step - Step 440, Loss 0.017541255801916122\n",
            "Train step - Step 450, Loss 0.015502681024372578\n",
            "Train step - Step 460, Loss 0.01791602373123169\n",
            "Train epoch - Accuracy: 0.8274747474747475 Loss: 0.01784054155452083 Corrects: 4096\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.021496228873729706\n",
            "Train step - Step 480, Loss 0.01323656551539898\n",
            "Train step - Step 490, Loss 0.01461044792085886\n",
            "Train step - Step 500, Loss 0.018137024715542793\n",
            "Train epoch - Accuracy: 0.8309090909090909 Loss: 0.017030742185735942 Corrects: 4113\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.01415189728140831\n",
            "Train step - Step 520, Loss 0.015586723573505878\n",
            "Train step - Step 530, Loss 0.017879322171211243\n",
            "Train step - Step 540, Loss 0.016762783750891685\n",
            "Train epoch - Accuracy: 0.84 Loss: 0.016253357687682816 Corrects: 4158\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.016439590603113174\n",
            "Train step - Step 560, Loss 0.011674460954964161\n",
            "Train step - Step 570, Loss 0.01716739311814308\n",
            "Train step - Step 580, Loss 0.01955266483128071\n",
            "Train epoch - Accuracy: 0.8482828282828283 Loss: 0.01584932420891945 Corrects: 4199\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.016718881204724312\n",
            "Train step - Step 600, Loss 0.01382600236684084\n",
            "Train step - Step 610, Loss 0.013209815137088299\n",
            "Train step - Step 620, Loss 0.014438563026487827\n",
            "Train epoch - Accuracy: 0.8656565656565657 Loss: 0.014451545984155 Corrects: 4285\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.01538056693971157\n",
            "Train step - Step 640, Loss 0.011908630840480328\n",
            "Train step - Step 650, Loss 0.016555313020944595\n",
            "Train step - Step 660, Loss 0.012573771178722382\n",
            "Train epoch - Accuracy: 0.8591919191919192 Loss: 0.014702593027943313 Corrects: 4253\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.010592219419777393\n",
            "Train step - Step 680, Loss 0.011376704089343548\n",
            "Train step - Step 690, Loss 0.01602151431143284\n",
            "Train step - Step 700, Loss 0.01661851815879345\n",
            "Train epoch - Accuracy: 0.8593939393939394 Loss: 0.014830903688615019 Corrects: 4254\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.015342564322054386\n",
            "Train step - Step 720, Loss 0.011525877751410007\n",
            "Train step - Step 730, Loss 0.01036868803203106\n",
            "Train step - Step 740, Loss 0.013221831992268562\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.013522910249203143 Corrects: 4326\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.011125920340418816\n",
            "Train step - Step 760, Loss 0.014972777105867863\n",
            "Train step - Step 770, Loss 0.009613433852791786\n",
            "Train epoch - Accuracy: 0.8870707070707071 Loss: 0.012528662599924236 Corrects: 4391\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.00930423941463232\n",
            "Train step - Step 790, Loss 0.014264973811805248\n",
            "Train step - Step 800, Loss 0.014510031789541245\n",
            "Train step - Step 810, Loss 0.013725606724619865\n",
            "Train epoch - Accuracy: 0.8868686868686869 Loss: 0.012328159524635835 Corrects: 4390\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.008453688584268093\n",
            "Train step - Step 830, Loss 0.011782501824200153\n",
            "Train step - Step 840, Loss 0.010043608956038952\n",
            "Train step - Step 850, Loss 0.013062022626399994\n",
            "Train epoch - Accuracy: 0.8929292929292929 Loss: 0.011652517248735283 Corrects: 4420\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.009720764122903347\n",
            "Train step - Step 870, Loss 0.010599516332149506\n",
            "Train step - Step 880, Loss 0.012875963002443314\n",
            "Train step - Step 890, Loss 0.015688616782426834\n",
            "Train epoch - Accuracy: 0.8840404040404041 Loss: 0.012614218917007399 Corrects: 4376\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.011122406460344791\n",
            "Train step - Step 910, Loss 0.011466402560472488\n",
            "Train step - Step 920, Loss 0.012168421410024166\n",
            "Train step - Step 930, Loss 0.01407710276544094\n",
            "Train epoch - Accuracy: 0.8854545454545455 Loss: 0.012123138433454013 Corrects: 4383\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.01496755238622427\n",
            "Train step - Step 950, Loss 0.010474327951669693\n",
            "Train step - Step 960, Loss 0.010839138180017471\n",
            "Train step - Step 970, Loss 0.01314262393862009\n",
            "Train epoch - Accuracy: 0.8993939393939394 Loss: 0.011418450781793306 Corrects: 4452\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.011208610609173775\n",
            "Train step - Step 990, Loss 0.006318144034594297\n",
            "Train step - Step 1000, Loss 0.007245477754622698\n",
            "Train step - Step 1010, Loss 0.010655398480594158\n",
            "Train epoch - Accuracy: 0.9074747474747474 Loss: 0.010370019881638012 Corrects: 4492\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.008000917732715607\n",
            "Train step - Step 1030, Loss 0.009410611353814602\n",
            "Train step - Step 1040, Loss 0.010120784863829613\n",
            "Train step - Step 1050, Loss 0.009277423843741417\n",
            "Train epoch - Accuracy: 0.9115151515151515 Loss: 0.010149479981022651 Corrects: 4512\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.010067880153656006\n",
            "Train step - Step 1070, Loss 0.00979244988411665\n",
            "Train step - Step 1080, Loss 0.00881761871278286\n",
            "Train step - Step 1090, Loss 0.011555864475667477\n",
            "Train epoch - Accuracy: 0.9042424242424243 Loss: 0.009945302906662526 Corrects: 4476\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.012799439020454884\n",
            "Train step - Step 1110, Loss 0.02006818726658821\n",
            "Train step - Step 1120, Loss 0.014151552692055702\n",
            "Train step - Step 1130, Loss 0.012326451018452644\n",
            "Train epoch - Accuracy: 0.8949494949494949 Loss: 0.011503086218779737 Corrects: 4430\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.009306665509939194\n",
            "Train step - Step 1150, Loss 0.009883514605462551\n",
            "Train step - Step 1160, Loss 0.007083328906446695\n",
            "Train epoch - Accuracy: 0.9086868686868687 Loss: 0.010299769103376552 Corrects: 4498\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.009225436486303806\n",
            "Train step - Step 1180, Loss 0.007681877352297306\n",
            "Train step - Step 1190, Loss 0.01015485543757677\n",
            "Train step - Step 1200, Loss 0.01209558267146349\n",
            "Train epoch - Accuracy: 0.9218181818181819 Loss: 0.009443831738423218 Corrects: 4563\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.006196699570864439\n",
            "Train step - Step 1220, Loss 0.007644440978765488\n",
            "Train step - Step 1230, Loss 0.011815223842859268\n",
            "Train step - Step 1240, Loss 0.012504150159657001\n",
            "Train epoch - Accuracy: 0.9185858585858586 Loss: 0.00911314148606375 Corrects: 4547\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.006452958565205336\n",
            "Train step - Step 1260, Loss 0.008260098285973072\n",
            "Train step - Step 1270, Loss 0.00889797043055296\n",
            "Train step - Step 1280, Loss 0.008512328378856182\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.008811932647544327 Corrects: 4555\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.00767941027879715\n",
            "Train step - Step 1300, Loss 0.017571939155459404\n",
            "Train step - Step 1310, Loss 0.012211914174258709\n",
            "Train step - Step 1320, Loss 0.00880940817296505\n",
            "Train epoch - Accuracy: 0.906060606060606 Loss: 0.010238977472363698 Corrects: 4485\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.009783080779016018\n",
            "Train step - Step 1340, Loss 0.012497675605118275\n",
            "Train step - Step 1350, Loss 0.007590543013066053\n",
            "Train step - Step 1360, Loss 0.009753855876624584\n",
            "Train epoch - Accuracy: 0.9321212121212121 Loss: 0.008360909341712191 Corrects: 4614\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004421229939907789\n",
            "Train step - Step 1380, Loss 0.005734867881983519\n",
            "Train step - Step 1390, Loss 0.006961696781218052\n",
            "Train step - Step 1400, Loss 0.004566482733935118\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.007389644079211385 Corrects: 4652\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.004946400411427021\n",
            "Train step - Step 1420, Loss 0.008882428519427776\n",
            "Train step - Step 1430, Loss 0.010023853741586208\n",
            "Train step - Step 1440, Loss 0.008850899524986744\n",
            "Train epoch - Accuracy: 0.9286868686868687 Loss: 0.007886111836391266 Corrects: 4597\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.007030413020402193\n",
            "Train step - Step 1460, Loss 0.007313818670809269\n",
            "Train step - Step 1470, Loss 0.006022936664521694\n",
            "Train step - Step 1480, Loss 0.007756122387945652\n",
            "Train epoch - Accuracy: 0.936969696969697 Loss: 0.007179160601450036 Corrects: 4638\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.007950259372591972\n",
            "Train step - Step 1500, Loss 0.005878607276827097\n",
            "Train step - Step 1510, Loss 0.004901852924376726\n",
            "Train step - Step 1520, Loss 0.008908177725970745\n",
            "Train epoch - Accuracy: 0.9444444444444444 Loss: 0.006626040673993453 Corrects: 4675\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.007629668340086937\n",
            "Train step - Step 1540, Loss 0.00962307769805193\n",
            "Train step - Step 1550, Loss 0.006176813505589962\n",
            "Train epoch - Accuracy: 0.936969696969697 Loss: 0.007642456179465911 Corrects: 4638\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.006099835969507694\n",
            "Train step - Step 1570, Loss 0.008617664687335491\n",
            "Train step - Step 1580, Loss 0.009193037636578083\n",
            "Train step - Step 1590, Loss 0.012486794032156467\n",
            "Train epoch - Accuracy: 0.9072727272727272 Loss: 0.010057819480396281 Corrects: 4491\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.009574844501912594\n",
            "Train step - Step 1610, Loss 0.005666179582476616\n",
            "Train step - Step 1620, Loss 0.009572708979249\n",
            "Train step - Step 1630, Loss 0.009902802295982838\n",
            "Train epoch - Accuracy: 0.927070707070707 Loss: 0.00825098738902145 Corrects: 4589\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.005981911905109882\n",
            "Train step - Step 1650, Loss 0.008572731167078018\n",
            "Train step - Step 1660, Loss 0.007527533452957869\n",
            "Train step - Step 1670, Loss 0.006242492236196995\n",
            "Train epoch - Accuracy: 0.9365656565656566 Loss: 0.007627361844472512 Corrects: 4636\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.005287107080221176\n",
            "Train step - Step 1690, Loss 0.005317969247698784\n",
            "Train step - Step 1700, Loss 0.008325382135808468\n",
            "Train step - Step 1710, Loss 0.00729983439669013\n",
            "Train epoch - Accuracy: 0.94 Loss: 0.007006262234515614 Corrects: 4653\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.011587527580559254\n",
            "Train step - Step 1730, Loss 0.005624506156891584\n",
            "Train step - Step 1740, Loss 0.0054560815915465355\n",
            "Train step - Step 1750, Loss 0.007577481213957071\n",
            "Train epoch - Accuracy: 0.9351515151515152 Loss: 0.007454485479328367 Corrects: 4629\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.009111878462135792\n",
            "Train step - Step 1770, Loss 0.006029487121850252\n",
            "Train step - Step 1780, Loss 0.006963391788303852\n",
            "Train step - Step 1790, Loss 0.00442893011495471\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.006745103712786328 Corrects: 4670\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.007462714333087206\n",
            "Train step - Step 1810, Loss 0.00561577919870615\n",
            "Train step - Step 1820, Loss 0.00856475718319416\n",
            "Train step - Step 1830, Loss 0.007534979376941919\n",
            "Train epoch - Accuracy: 0.9442424242424242 Loss: 0.006532737970201656 Corrects: 4674\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.005540394224226475\n",
            "Train step - Step 1850, Loss 0.006619706749916077\n",
            "Train step - Step 1860, Loss 0.004684052430093288\n",
            "Train step - Step 1870, Loss 0.004720683209598064\n",
            "Train epoch - Accuracy: 0.9553535353535354 Loss: 0.005657164452954977 Corrects: 4729\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.006875856313854456\n",
            "Train step - Step 1890, Loss 0.008879100903868675\n",
            "Train step - Step 1900, Loss 0.003974215593189001\n",
            "Train step - Step 1910, Loss 0.00615736236795783\n",
            "Train epoch - Accuracy: 0.9480808080808081 Loss: 0.0061251916158756225 Corrects: 4693\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.005170452408492565\n",
            "Train step - Step 1930, Loss 0.003218540223315358\n",
            "Train step - Step 1940, Loss 0.0048247515223920345\n",
            "Train epoch - Accuracy: 0.9725252525252526 Loss: 0.0038270507658822368 Corrects: 4814\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0028007172513753176\n",
            "Train step - Step 1960, Loss 0.00309816375374794\n",
            "Train step - Step 1970, Loss 0.001474746153689921\n",
            "Train step - Step 1980, Loss 0.0012815027730539441\n",
            "Train epoch - Accuracy: 0.9888888888888889 Loss: 0.0022310172685073935 Corrects: 4895\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.00214620353654027\n",
            "Train step - Step 2000, Loss 0.0013937830226495862\n",
            "Train step - Step 2010, Loss 0.0037906644865870476\n",
            "Train step - Step 2020, Loss 0.002324128756299615\n",
            "Train epoch - Accuracy: 0.9915151515151515 Loss: 0.0019174574743580036 Corrects: 4908\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0015587926609441638\n",
            "Train step - Step 2040, Loss 0.002265797695145011\n",
            "Train step - Step 2050, Loss 0.0013043088838458061\n",
            "Train step - Step 2060, Loss 0.0019791871309280396\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0017396238470694634 Corrects: 4916\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0012606080854311585\n",
            "Train step - Step 2080, Loss 0.0014026390854269266\n",
            "Train step - Step 2090, Loss 0.0017681119497865438\n",
            "Train step - Step 2100, Loss 0.0011780665954574943\n",
            "Train epoch - Accuracy: 0.9949494949494949 Loss: 0.0014260224077963467 Corrects: 4925\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0012839409755542874\n",
            "Train step - Step 2120, Loss 0.001779344049282372\n",
            "Train step - Step 2130, Loss 0.0010959262726828456\n",
            "Train step - Step 2140, Loss 0.0007824936183169484\n",
            "Train epoch - Accuracy: 0.9951515151515151 Loss: 0.0013591671269857371 Corrects: 4926\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0006623392691835761\n",
            "Train step - Step 2160, Loss 0.001422565896064043\n",
            "Train step - Step 2170, Loss 0.0008860171656124294\n",
            "Train step - Step 2180, Loss 0.0008219829760491848\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.001271826235525724 Corrects: 4927\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0014515010407194495\n",
            "Train step - Step 2200, Loss 0.0014653750695288181\n",
            "Train step - Step 2210, Loss 0.0020645095501095057\n",
            "Train step - Step 2220, Loss 0.002139293123036623\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0012080019939634385 Corrects: 4927\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0010943009983748198\n",
            "Train step - Step 2240, Loss 0.0010303116869181395\n",
            "Train step - Step 2250, Loss 0.0011991866631433368\n",
            "Train step - Step 2260, Loss 0.002042581792920828\n",
            "Train epoch - Accuracy: 0.9945454545454545 Loss: 0.0012524216462190103 Corrects: 4923\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0012430851347744465\n",
            "Train step - Step 2280, Loss 0.0006073637050576508\n",
            "Train step - Step 2290, Loss 0.000646251137368381\n",
            "Train step - Step 2300, Loss 0.0009828121401369572\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0011032960140569643 Corrects: 4927\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0012768082087859511\n",
            "Train step - Step 2320, Loss 0.0006487834034487605\n",
            "Train step - Step 2330, Loss 0.0009812744101509452\n",
            "Train epoch - Accuracy: 0.9959595959595959 Loss: 0.0010874818881616147 Corrects: 4930\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.0007073166780173779\n",
            "Train step - Step 2350, Loss 0.0008817158523015678\n",
            "Train step - Step 2360, Loss 0.0006350481417030096\n",
            "Train step - Step 2370, Loss 0.0005764490342698991\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0009710649328395687 Corrects: 4935\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.0006326268194243312\n",
            "Train step - Step 2390, Loss 0.0010038417531177402\n",
            "Train step - Step 2400, Loss 0.0004839583416469395\n",
            "Train step - Step 2410, Loss 0.0010217728558927774\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0009762001968920231 Corrects: 4936\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0007695955573581159\n",
            "Train step - Step 2430, Loss 0.0005958191468380392\n",
            "Train step - Step 2440, Loss 0.001671177102252841\n",
            "Train step - Step 2450, Loss 0.0003799102851189673\n",
            "Train epoch - Accuracy: 0.9955555555555555 Loss: 0.0010925446368396433 Corrects: 4928\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0004268662305548787\n",
            "Train step - Step 2470, Loss 0.0008561645518057048\n",
            "Train step - Step 2480, Loss 0.0006128755630925298\n",
            "Train step - Step 2490, Loss 0.0009691641898825765\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.000922242529793746 Corrects: 4932\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0006725828279741108\n",
            "Train step - Step 2510, Loss 0.0006831549690105021\n",
            "Train step - Step 2520, Loss 0.000993276247754693\n",
            "Train step - Step 2530, Loss 0.000932842493057251\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0009636232967610763 Corrects: 4939\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0004748816427309066\n",
            "Train step - Step 2550, Loss 0.0016801763558760285\n",
            "Train step - Step 2560, Loss 0.0007654793444089592\n",
            "Train step - Step 2570, Loss 0.0010355866979807615\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0009798245243916306 Corrects: 4932\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0006603103829547763\n",
            "Train step - Step 2590, Loss 0.000871410476975143\n",
            "Train step - Step 2600, Loss 0.0005484889261424541\n",
            "Train step - Step 2610, Loss 0.0011640394804999232\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0008735978602422307 Corrects: 4939\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.0007329517393372953\n",
            "Train step - Step 2630, Loss 0.0006579892942681909\n",
            "Train step - Step 2640, Loss 0.0005637254798784852\n",
            "Train step - Step 2650, Loss 0.0010636486113071442\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0007800554805858569 Corrects: 4938\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0006142997299320996\n",
            "Train step - Step 2670, Loss 0.0005240323371253908\n",
            "Train step - Step 2680, Loss 0.0007213249919004738\n",
            "Train step - Step 2690, Loss 0.0004763207398355007\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.0008139822724265883 Corrects: 4938\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0005521021666936576\n",
            "Train step - Step 2710, Loss 0.0006356863304972649\n",
            "Train step - Step 2720, Loss 0.0006314599304459989\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0007952065658614491 Corrects: 4942\n",
            "Training finished in 238.4515950679779 seconds\n",
            "EVALUATION:  0.84 0.014452937059104443\n",
            "TEST GROUP:  0.828\n",
            "TEST ALL:  0.1656\n",
            "GROUP:  6\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.1684623807668686\n",
            "Train step - Step 10, Loss 0.07661537826061249\n",
            "Train step - Step 20, Loss 0.05264335125684738\n",
            "Train step - Step 30, Loss 0.04122552275657654\n",
            "Train epoch - Accuracy: 0.2991919191919192 Loss: 0.05925572524919654 Corrects: 1481\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.03215416148304939\n",
            "Train step - Step 50, Loss 0.03365394100546837\n",
            "Train step - Step 60, Loss 0.029930250719189644\n",
            "Train step - Step 70, Loss 0.03127005323767662\n",
            "Train epoch - Accuracy: 0.5985858585858586 Loss: 0.030627426444882096 Corrects: 2963\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.023004373535513878\n",
            "Train step - Step 90, Loss 0.024162672460079193\n",
            "Train step - Step 100, Loss 0.024804236367344856\n",
            "Train step - Step 110, Loss 0.022619176656007767\n",
            "Train epoch - Accuracy: 0.7105050505050505 Loss: 0.024009367368287512 Corrects: 3517\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.020805971696972847\n",
            "Train step - Step 130, Loss 0.0188364889472723\n",
            "Train step - Step 140, Loss 0.016519254073500633\n",
            "Train step - Step 150, Loss 0.017055703327059746\n",
            "Train epoch - Accuracy: 0.7814141414141414 Loss: 0.01934781945376384 Corrects: 3868\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.01624245010316372\n",
            "Train step - Step 170, Loss 0.019761057570576668\n",
            "Train step - Step 180, Loss 0.014738697558641434\n",
            "Train step - Step 190, Loss 0.015162779949605465\n",
            "Train epoch - Accuracy: 0.8135353535353536 Loss: 0.016864732167109698 Corrects: 4027\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.011838363483548164\n",
            "Train step - Step 210, Loss 0.016400642693042755\n",
            "Train step - Step 220, Loss 0.015378380194306374\n",
            "Train step - Step 230, Loss 0.017010800540447235\n",
            "Train epoch - Accuracy: 0.8337373737373738 Loss: 0.014600771965101511 Corrects: 4127\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.011150008998811245\n",
            "Train step - Step 250, Loss 0.010638076812028885\n",
            "Train step - Step 260, Loss 0.015293287113308907\n",
            "Train step - Step 270, Loss 0.012779326178133488\n",
            "Train epoch - Accuracy: 0.8563636363636363 Loss: 0.012857114900317457 Corrects: 4239\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.010002977214753628\n",
            "Train step - Step 290, Loss 0.009697530418634415\n",
            "Train step - Step 300, Loss 0.014745733700692654\n",
            "Train step - Step 310, Loss 0.014086266979575157\n",
            "Train epoch - Accuracy: 0.8684848484848485 Loss: 0.012197882719714233 Corrects: 4299\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.010345467366278172\n",
            "Train step - Step 330, Loss 0.008357667364180088\n",
            "Train step - Step 340, Loss 0.013855040073394775\n",
            "Train step - Step 350, Loss 0.012683034874498844\n",
            "Train epoch - Accuracy: 0.8733333333333333 Loss: 0.011303007739285628 Corrects: 4323\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.00939587689936161\n",
            "Train step - Step 370, Loss 0.011221736669540405\n",
            "Train step - Step 380, Loss 0.012928035110235214\n",
            "Train epoch - Accuracy: 0.8696969696969697 Loss: 0.011615614108364992 Corrects: 4305\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.013281691819429398\n",
            "Train step - Step 400, Loss 0.010307759046554565\n",
            "Train step - Step 410, Loss 0.009477037936449051\n",
            "Train step - Step 420, Loss 0.008773564361035824\n",
            "Train epoch - Accuracy: 0.8852525252525253 Loss: 0.010440958511799273 Corrects: 4382\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.010115028358995914\n",
            "Train step - Step 440, Loss 0.010592209175229073\n",
            "Train step - Step 450, Loss 0.009055791422724724\n",
            "Train step - Step 460, Loss 0.01043718308210373\n",
            "Train epoch - Accuracy: 0.8884848484848484 Loss: 0.009781428150682137 Corrects: 4398\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.00849848985671997\n",
            "Train step - Step 480, Loss 0.010869390331208706\n",
            "Train step - Step 490, Loss 0.009731805883347988\n",
            "Train step - Step 500, Loss 0.011259432882070541\n",
            "Train epoch - Accuracy: 0.8923232323232323 Loss: 0.009489704836348091 Corrects: 4417\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.00981084629893303\n",
            "Train step - Step 520, Loss 0.006470039952546358\n",
            "Train step - Step 530, Loss 0.009663911536335945\n",
            "Train step - Step 540, Loss 0.011203770525753498\n",
            "Train epoch - Accuracy: 0.9022222222222223 Loss: 0.0092406097265205 Corrects: 4466\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.0058666132390499115\n",
            "Train step - Step 560, Loss 0.00862165167927742\n",
            "Train step - Step 570, Loss 0.008935388177633286\n",
            "Train step - Step 580, Loss 0.00866607204079628\n",
            "Train epoch - Accuracy: 0.9167676767676768 Loss: 0.008074027197905863 Corrects: 4538\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.008058153092861176\n",
            "Train step - Step 600, Loss 0.007902120240032673\n",
            "Train step - Step 610, Loss 0.008368108421564102\n",
            "Train step - Step 620, Loss 0.007381466683000326\n",
            "Train epoch - Accuracy: 0.914949494949495 Loss: 0.007963704726461207 Corrects: 4529\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.006936478894203901\n",
            "Train step - Step 640, Loss 0.005757045932114124\n",
            "Train step - Step 650, Loss 0.004852918442338705\n",
            "Train step - Step 660, Loss 0.008182676509022713\n",
            "Train epoch - Accuracy: 0.924040404040404 Loss: 0.007477714001492719 Corrects: 4574\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.01131630502641201\n",
            "Train step - Step 680, Loss 0.005536940880119801\n",
            "Train step - Step 690, Loss 0.004797021858394146\n",
            "Train step - Step 700, Loss 0.007130446378141642\n",
            "Train epoch - Accuracy: 0.9181818181818182 Loss: 0.007703677022622691 Corrects: 4545\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.00631181662902236\n",
            "Train step - Step 720, Loss 0.005505361594259739\n",
            "Train step - Step 730, Loss 0.007535090669989586\n",
            "Train step - Step 740, Loss 0.008288647048175335\n",
            "Train epoch - Accuracy: 0.924040404040404 Loss: 0.00708362990294141 Corrects: 4574\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.006753689609467983\n",
            "Train step - Step 760, Loss 0.005340477917343378\n",
            "Train step - Step 770, Loss 0.008408725261688232\n",
            "Train epoch - Accuracy: 0.9327272727272727 Loss: 0.00659933847779728 Corrects: 4617\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.004081620369106531\n",
            "Train step - Step 790, Loss 0.008528081700205803\n",
            "Train step - Step 800, Loss 0.005161612294614315\n",
            "Train step - Step 810, Loss 0.006702912040054798\n",
            "Train epoch - Accuracy: 0.9337373737373738 Loss: 0.006580441273523099 Corrects: 4622\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.005145119968801737\n",
            "Train step - Step 830, Loss 0.006842718925327063\n",
            "Train step - Step 840, Loss 0.0062181539833545685\n",
            "Train step - Step 850, Loss 0.004585241433233023\n",
            "Train epoch - Accuracy: 0.9383838383838384 Loss: 0.00607142186864759 Corrects: 4645\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.003515040036290884\n",
            "Train step - Step 870, Loss 0.009950883686542511\n",
            "Train step - Step 880, Loss 0.0069207395426929\n",
            "Train step - Step 890, Loss 0.003980171401053667\n",
            "Train epoch - Accuracy: 0.9321212121212121 Loss: 0.006370855557045551 Corrects: 4614\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.007616872899234295\n",
            "Train step - Step 910, Loss 0.003455281723290682\n",
            "Train step - Step 920, Loss 0.005166863091289997\n",
            "Train step - Step 930, Loss 0.008778143674135208\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.005790485422493833 Corrects: 4658\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.005287380889058113\n",
            "Train step - Step 950, Loss 0.00455269031226635\n",
            "Train step - Step 960, Loss 0.0033769698347896338\n",
            "Train step - Step 970, Loss 0.006836956366896629\n",
            "Train epoch - Accuracy: 0.9476767676767677 Loss: 0.00512320746978124 Corrects: 4691\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.006633953657001257\n",
            "Train step - Step 990, Loss 0.0021018011029809713\n",
            "Train step - Step 1000, Loss 0.004500658251345158\n",
            "Train step - Step 1010, Loss 0.006726494058966637\n",
            "Train epoch - Accuracy: 0.944040404040404 Loss: 0.005575587891531412 Corrects: 4673\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.007286660373210907\n",
            "Train step - Step 1030, Loss 0.005432202480733395\n",
            "Train step - Step 1040, Loss 0.0032692207023501396\n",
            "Train step - Step 1050, Loss 0.004240481182932854\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.005314059105391304 Corrects: 4690\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.008208739571273327\n",
            "Train step - Step 1070, Loss 0.0068520051427185535\n",
            "Train step - Step 1080, Loss 0.007939956150949001\n",
            "Train step - Step 1090, Loss 0.007933261804282665\n",
            "Train epoch - Accuracy: 0.9367676767676768 Loss: 0.00631176634418844 Corrects: 4637\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.006723683327436447\n",
            "Train step - Step 1110, Loss 0.005683714058250189\n",
            "Train step - Step 1120, Loss 0.004983908496797085\n",
            "Train step - Step 1130, Loss 0.0029345182701945305\n",
            "Train epoch - Accuracy: 0.9335353535353536 Loss: 0.006216587177807032 Corrects: 4621\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.00564737431704998\n",
            "Train step - Step 1150, Loss 0.004388721194118261\n",
            "Train step - Step 1160, Loss 0.004741201177239418\n",
            "Train epoch - Accuracy: 0.955959595959596 Loss: 0.004590154070821073 Corrects: 4732\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.005265211220830679\n",
            "Train step - Step 1180, Loss 0.0030460632406175137\n",
            "Train step - Step 1190, Loss 0.004890416748821735\n",
            "Train step - Step 1200, Loss 0.0033371211029589176\n",
            "Train epoch - Accuracy: 0.9531313131313132 Loss: 0.004589928460467343 Corrects: 4718\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.006108345929533243\n",
            "Train step - Step 1220, Loss 0.004446431994438171\n",
            "Train step - Step 1230, Loss 0.005794290918856859\n",
            "Train step - Step 1240, Loss 0.0031753545626997948\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.004925631128176294 Corrects: 4706\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.005093304440379143\n",
            "Train step - Step 1260, Loss 0.0049111866392195225\n",
            "Train step - Step 1270, Loss 0.004304856061935425\n",
            "Train step - Step 1280, Loss 0.006853287573903799\n",
            "Train epoch - Accuracy: 0.9511111111111111 Loss: 0.0049614067294757175 Corrects: 4708\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.004122429993003607\n",
            "Train step - Step 1300, Loss 0.00463942950591445\n",
            "Train step - Step 1310, Loss 0.0047606551088392735\n",
            "Train step - Step 1320, Loss 0.0023935919161885977\n",
            "Train epoch - Accuracy: 0.9638383838383838 Loss: 0.004012775312582351 Corrects: 4771\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.003295422997325659\n",
            "Train step - Step 1340, Loss 0.004967028275132179\n",
            "Train step - Step 1350, Loss 0.005649734754115343\n",
            "Train step - Step 1360, Loss 0.004214740823954344\n",
            "Train epoch - Accuracy: 0.9541414141414142 Loss: 0.00458169827764534 Corrects: 4723\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.004659314174205065\n",
            "Train step - Step 1380, Loss 0.004421117249876261\n",
            "Train step - Step 1390, Loss 0.003080108668655157\n",
            "Train step - Step 1400, Loss 0.004024517722427845\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.004251347281734901 Corrects: 4738\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.0026135093066841364\n",
            "Train step - Step 1420, Loss 0.0028312173672020435\n",
            "Train step - Step 1430, Loss 0.005048057995736599\n",
            "Train step - Step 1440, Loss 0.005246778484433889\n",
            "Train epoch - Accuracy: 0.964040404040404 Loss: 0.004020078215146004 Corrects: 4772\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0031949994154274464\n",
            "Train step - Step 1460, Loss 0.003305075690150261\n",
            "Train step - Step 1470, Loss 0.002573310863226652\n",
            "Train step - Step 1480, Loss 0.006028519012033939\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.0039315201300713755 Corrects: 4758\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.004104582592844963\n",
            "Train step - Step 1500, Loss 0.004556572530418634\n",
            "Train step - Step 1510, Loss 0.004212253727018833\n",
            "Train step - Step 1520, Loss 0.007429973222315311\n",
            "Train epoch - Accuracy: 0.9523232323232323 Loss: 0.004481399954494202 Corrects: 4714\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.004983981139957905\n",
            "Train step - Step 1540, Loss 0.0025987299159169197\n",
            "Train step - Step 1550, Loss 0.003508086549118161\n",
            "Train epoch - Accuracy: 0.9622222222222222 Loss: 0.004006624132996858 Corrects: 4763\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0039064111188054085\n",
            "Train step - Step 1570, Loss 0.005713318940252066\n",
            "Train step - Step 1580, Loss 0.002953173825517297\n",
            "Train step - Step 1590, Loss 0.004107961896806955\n",
            "Train epoch - Accuracy: 0.9583838383838383 Loss: 0.0041447467276017474 Corrects: 4744\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0019125856924802065\n",
            "Train step - Step 1610, Loss 0.005493929143995047\n",
            "Train step - Step 1620, Loss 0.004566035699099302\n",
            "Train step - Step 1630, Loss 0.002726576756685972\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.003724321372468363 Corrects: 4769\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0013577506178990006\n",
            "Train step - Step 1650, Loss 0.00404726155102253\n",
            "Train step - Step 1660, Loss 0.005392864812165499\n",
            "Train step - Step 1670, Loss 0.0047163330018520355\n",
            "Train epoch - Accuracy: 0.9723232323232324 Loss: 0.003320134838459769 Corrects: 4813\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.002381274476647377\n",
            "Train step - Step 1690, Loss 0.004552466794848442\n",
            "Train step - Step 1700, Loss 0.0032296020071953535\n",
            "Train step - Step 1710, Loss 0.003974109888076782\n",
            "Train epoch - Accuracy: 0.9652525252525253 Loss: 0.0034211288164887163 Corrects: 4778\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0037553799338638783\n",
            "Train step - Step 1730, Loss 0.004868552554398775\n",
            "Train step - Step 1740, Loss 0.0015635652234777808\n",
            "Train step - Step 1750, Loss 0.005381214432418346\n",
            "Train epoch - Accuracy: 0.9626262626262626 Loss: 0.004070693950328713 Corrects: 4765\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.004333291668444872\n",
            "Train step - Step 1770, Loss 0.003239238867536187\n",
            "Train step - Step 1780, Loss 0.002515304135158658\n",
            "Train step - Step 1790, Loss 0.005501079838722944\n",
            "Train epoch - Accuracy: 0.9642424242424242 Loss: 0.0037358253893226083 Corrects: 4773\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.002841126173734665\n",
            "Train step - Step 1810, Loss 0.002153958659619093\n",
            "Train step - Step 1820, Loss 0.002594235586002469\n",
            "Train step - Step 1830, Loss 0.0037500744219869375\n",
            "Train epoch - Accuracy: 0.9664646464646465 Loss: 0.0034642773536457255 Corrects: 4784\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.004734286107122898\n",
            "Train step - Step 1850, Loss 0.0011830837465822697\n",
            "Train step - Step 1860, Loss 0.003930778242647648\n",
            "Train step - Step 1870, Loss 0.006956483703106642\n",
            "Train epoch - Accuracy: 0.9765656565656565 Loss: 0.0026973378623017306 Corrects: 4834\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0018688786076381803\n",
            "Train step - Step 1890, Loss 0.002893306314945221\n",
            "Train step - Step 1900, Loss 0.0016093561425805092\n",
            "Train step - Step 1910, Loss 0.0010094644967466593\n",
            "Train epoch - Accuracy: 0.9793939393939394 Loss: 0.0023675650669581663 Corrects: 4848\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.001234720228239894\n",
            "Train step - Step 1930, Loss 0.001195377204567194\n",
            "Train step - Step 1940, Loss 0.0010632309131324291\n",
            "Train epoch - Accuracy: 0.9868686868686869 Loss: 0.0016989694096411418 Corrects: 4885\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0012844059383496642\n",
            "Train step - Step 1960, Loss 0.002177432645112276\n",
            "Train step - Step 1970, Loss 0.002147552091628313\n",
            "Train step - Step 1980, Loss 0.0016089435666799545\n",
            "Train epoch - Accuracy: 0.9941414141414141 Loss: 0.0010172498330116423 Corrects: 4921\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0007123589748516679\n",
            "Train step - Step 2000, Loss 0.0007405393989756703\n",
            "Train step - Step 2010, Loss 0.0011144065065309405\n",
            "Train step - Step 2020, Loss 0.0003022929304279387\n",
            "Train epoch - Accuracy: 0.9961616161616161 Loss: 0.0008151822508726682 Corrects: 4931\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0006497841677628458\n",
            "Train step - Step 2040, Loss 0.0009659007773734629\n",
            "Train step - Step 2050, Loss 0.0007801676401868463\n",
            "Train step - Step 2060, Loss 0.0004683879087679088\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0007829567092715415 Corrects: 4932\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0006771090556867421\n",
            "Train step - Step 2080, Loss 0.0005455329082906246\n",
            "Train step - Step 2090, Loss 0.0008116490207612514\n",
            "Train step - Step 2100, Loss 0.0003334435459692031\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0007019112498094939 Corrects: 4933\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0009339709067717195\n",
            "Train step - Step 2120, Loss 0.0003745188005268574\n",
            "Train step - Step 2130, Loss 0.0009615636663511395\n",
            "Train step - Step 2140, Loss 0.0011245625792071223\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0006721442663745785 Corrects: 4935\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.00041567409061826766\n",
            "Train step - Step 2160, Loss 0.0006814302178099751\n",
            "Train step - Step 2170, Loss 0.0009673676686361432\n",
            "Train step - Step 2180, Loss 0.0007708905031904578\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.0006436324982452348 Corrects: 4936\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.000981986173428595\n",
            "Train step - Step 2200, Loss 0.0004542125971056521\n",
            "Train step - Step 2210, Loss 0.0004618655366357416\n",
            "Train step - Step 2220, Loss 0.0002814665494952351\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0005618227293921841 Corrects: 4943\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0004738573916256428\n",
            "Train step - Step 2240, Loss 0.000461763673229143\n",
            "Train step - Step 2250, Loss 0.0006155786104500294\n",
            "Train step - Step 2260, Loss 0.0010213913628831506\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0005221614276877407 Corrects: 4942\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0004661149869207293\n",
            "Train step - Step 2280, Loss 0.0005462205735966563\n",
            "Train step - Step 2290, Loss 0.00045090654748491943\n",
            "Train step - Step 2300, Loss 0.00040230114245787263\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0004834831077746595 Corrects: 4945\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0002253303537145257\n",
            "Train step - Step 2320, Loss 0.0004551866149995476\n",
            "Train step - Step 2330, Loss 0.000549387710634619\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00041541390367924716 Corrects: 4948\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00045476792729459703\n",
            "Train step - Step 2350, Loss 0.00037961077759973705\n",
            "Train step - Step 2360, Loss 0.00038838916225358844\n",
            "Train step - Step 2370, Loss 0.00040279122185893357\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0004168982839804481 Corrects: 4947\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00022223179985303432\n",
            "Train step - Step 2390, Loss 0.00034379021963104606\n",
            "Train step - Step 2400, Loss 0.0006078990991227329\n",
            "Train step - Step 2410, Loss 0.00030324069666676223\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00042882852656108263 Corrects: 4944\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00024449214106425643\n",
            "Train step - Step 2430, Loss 0.00028404645854607224\n",
            "Train step - Step 2440, Loss 0.0006354042561724782\n",
            "Train step - Step 2450, Loss 0.0002880192769225687\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00043976493360888626 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0005287143867462873\n",
            "Train step - Step 2470, Loss 0.0002032746997429058\n",
            "Train step - Step 2480, Loss 0.00044823120697401464\n",
            "Train step - Step 2490, Loss 0.0001667991018621251\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.0003500230214676133 Corrects: 4947\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0003102758782915771\n",
            "Train step - Step 2510, Loss 0.0002680294564925134\n",
            "Train step - Step 2520, Loss 0.0008093435899354517\n",
            "Train step - Step 2530, Loss 0.00033550531952641904\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0004032620320724549 Corrects: 4946\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00028618433861993253\n",
            "Train step - Step 2550, Loss 0.0003993607242591679\n",
            "Train step - Step 2560, Loss 0.00036524212919175625\n",
            "Train step - Step 2570, Loss 0.0005916913505643606\n",
            "Train epoch - Accuracy: 1.0 Loss: 0.0003535025734325043 Corrects: 4950\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002957393298856914\n",
            "Train step - Step 2590, Loss 0.0002826194104272872\n",
            "Train step - Step 2600, Loss 0.00021726715203840286\n",
            "Train step - Step 2610, Loss 0.000373530900105834\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.000381132788142434 Corrects: 4948\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00036703149089589715\n",
            "Train step - Step 2630, Loss 0.0003189400886185467\n",
            "Train step - Step 2640, Loss 0.00040698712109588087\n",
            "Train step - Step 2650, Loss 0.001244267332367599\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.000405867742339262 Corrects: 4946\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00027950172079727054\n",
            "Train step - Step 2670, Loss 0.0002406125422567129\n",
            "Train step - Step 2680, Loss 0.0003881195734720677\n",
            "Train step - Step 2690, Loss 0.00029925868147984147\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0003845124184436193 Corrects: 4946\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0002503312425687909\n",
            "Train step - Step 2710, Loss 0.0004993024631403387\n",
            "Train step - Step 2720, Loss 0.0002723905781749636\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00036488210584267487 Corrects: 4948\n",
            "Training finished in 236.90812301635742 seconds\n",
            "EVALUATION:  0.86 0.01205222774296999\n",
            "TEST GROUP:  0.889\n",
            "TEST ALL:  0.14816666666666667\n",
            "GROUP:  7\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.19210156798362732\n",
            "Train step - Step 10, Loss 0.07300921529531479\n",
            "Train step - Step 20, Loss 0.04102465137839317\n",
            "Train step - Step 30, Loss 0.03832554817199707\n",
            "Train epoch - Accuracy: 0.2397979797979798 Loss: 0.05705710027555023 Corrects: 1187\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.034117694944143295\n",
            "Train step - Step 50, Loss 0.02937178686261177\n",
            "Train step - Step 60, Loss 0.025757720693945885\n",
            "Train step - Step 70, Loss 0.025108588859438896\n",
            "Train epoch - Accuracy: 0.5535353535353535 Loss: 0.028456836505369707 Corrects: 2740\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.022209979593753815\n",
            "Train step - Step 90, Loss 0.021760378032922745\n",
            "Train step - Step 100, Loss 0.015431281179189682\n",
            "Train step - Step 110, Loss 0.02113148756325245\n",
            "Train epoch - Accuracy: 0.6894949494949495 Loss: 0.019856735482962445 Corrects: 3413\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.019945135340094566\n",
            "Train step - Step 130, Loss 0.01675332710146904\n",
            "Train step - Step 140, Loss 0.015169636346399784\n",
            "Train step - Step 150, Loss 0.017135262489318848\n",
            "Train epoch - Accuracy: 0.7359595959595959 Loss: 0.01679589886933264 Corrects: 3643\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.017123375087976456\n",
            "Train step - Step 170, Loss 0.01462564803659916\n",
            "Train step - Step 180, Loss 0.013538029044866562\n",
            "Train step - Step 190, Loss 0.012395326048135757\n",
            "Train epoch - Accuracy: 0.7638383838383839 Loss: 0.015569798842524038 Corrects: 3781\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.015538735315203667\n",
            "Train step - Step 210, Loss 0.014173916541039944\n",
            "Train step - Step 220, Loss 0.011470864526927471\n",
            "Train step - Step 230, Loss 0.014818048104643822\n",
            "Train epoch - Accuracy: 0.786060606060606 Loss: 0.014244688855051393 Corrects: 3891\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.01292947307229042\n",
            "Train step - Step 250, Loss 0.012535219080746174\n",
            "Train step - Step 260, Loss 0.011967962607741356\n",
            "Train step - Step 270, Loss 0.01111604180186987\n",
            "Train epoch - Accuracy: 0.8195959595959595 Loss: 0.0124536539173939 Corrects: 4057\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.011831577867269516\n",
            "Train step - Step 290, Loss 0.014171293936669827\n",
            "Train step - Step 300, Loss 0.01353652123361826\n",
            "Train step - Step 310, Loss 0.013453638181090355\n",
            "Train epoch - Accuracy: 0.842020202020202 Loss: 0.011338728788976718 Corrects: 4168\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.008421888574957848\n",
            "Train step - Step 330, Loss 0.009840117767453194\n",
            "Train step - Step 340, Loss 0.010838551446795464\n",
            "Train step - Step 350, Loss 0.010109961032867432\n",
            "Train epoch - Accuracy: 0.8498989898989899 Loss: 0.010592837574506046 Corrects: 4207\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.007350889965891838\n",
            "Train step - Step 370, Loss 0.007975982502102852\n",
            "Train step - Step 380, Loss 0.00805975217372179\n",
            "Train epoch - Accuracy: 0.8561616161616161 Loss: 0.010077920279117546 Corrects: 4238\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.009280861355364323\n",
            "Train step - Step 400, Loss 0.011890750378370285\n",
            "Train step - Step 410, Loss 0.008590562269091606\n",
            "Train step - Step 420, Loss 0.010212752036750317\n",
            "Train epoch - Accuracy: 0.8757575757575757 Loss: 0.009273687526583672 Corrects: 4335\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.007576901465654373\n",
            "Train step - Step 440, Loss 0.007945745252072811\n",
            "Train step - Step 450, Loss 0.011116545647382736\n",
            "Train step - Step 460, Loss 0.010238918475806713\n",
            "Train epoch - Accuracy: 0.86989898989899 Loss: 0.009275178640253014 Corrects: 4306\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.007836764678359032\n",
            "Train step - Step 480, Loss 0.010564968921244144\n",
            "Train step - Step 490, Loss 0.00801767036318779\n",
            "Train step - Step 500, Loss 0.006729462184011936\n",
            "Train epoch - Accuracy: 0.881010101010101 Loss: 0.008717022938183461 Corrects: 4361\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.006688591558486223\n",
            "Train step - Step 520, Loss 0.011755657382309437\n",
            "Train step - Step 530, Loss 0.0061634378507733345\n",
            "Train step - Step 540, Loss 0.007202585227787495\n",
            "Train epoch - Accuracy: 0.8896969696969697 Loss: 0.008379418832259346 Corrects: 4404\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.008413242176175117\n",
            "Train step - Step 560, Loss 0.007991067133843899\n",
            "Train step - Step 570, Loss 0.008769530802965164\n",
            "Train step - Step 580, Loss 0.00886556226760149\n",
            "Train epoch - Accuracy: 0.8832323232323233 Loss: 0.008464464635936298 Corrects: 4372\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.006010348908603191\n",
            "Train step - Step 600, Loss 0.007925755344331264\n",
            "Train step - Step 610, Loss 0.006786607671529055\n",
            "Train step - Step 620, Loss 0.006158995442092419\n",
            "Train epoch - Accuracy: 0.9038383838383839 Loss: 0.007291182784194296 Corrects: 4474\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.008132756687700748\n",
            "Train step - Step 640, Loss 0.005772977136075497\n",
            "Train step - Step 650, Loss 0.008065301924943924\n",
            "Train step - Step 660, Loss 0.010164586827158928\n",
            "Train epoch - Accuracy: 0.895959595959596 Loss: 0.007699052008113476 Corrects: 4435\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.009097944013774395\n",
            "Train step - Step 680, Loss 0.005539994221180677\n",
            "Train step - Step 690, Loss 0.007804900407791138\n",
            "Train step - Step 700, Loss 0.005996147636324167\n",
            "Train epoch - Accuracy: 0.9084848484848485 Loss: 0.007093473941162981 Corrects: 4497\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.008686746470630169\n",
            "Train step - Step 720, Loss 0.006023692898452282\n",
            "Train step - Step 730, Loss 0.008625374175608158\n",
            "Train step - Step 740, Loss 0.008636035025119781\n",
            "Train epoch - Accuracy: 0.9129292929292929 Loss: 0.0066908735488400315 Corrects: 4519\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.005175075959414244\n",
            "Train step - Step 760, Loss 0.007111407816410065\n",
            "Train step - Step 770, Loss 0.007005448918789625\n",
            "Train epoch - Accuracy: 0.9143434343434343 Loss: 0.00669684787704186 Corrects: 4526\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.006482348777353764\n",
            "Train step - Step 790, Loss 0.006932229734957218\n",
            "Train step - Step 800, Loss 0.006884322036057711\n",
            "Train step - Step 810, Loss 0.0064946673810482025\n",
            "Train epoch - Accuracy: 0.9157575757575758 Loss: 0.006471724893822513 Corrects: 4533\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.006006421986967325\n",
            "Train step - Step 830, Loss 0.0051763891242444515\n",
            "Train step - Step 840, Loss 0.007625309284776449\n",
            "Train step - Step 850, Loss 0.006292537320405245\n",
            "Train epoch - Accuracy: 0.918989898989899 Loss: 0.006302509145303206 Corrects: 4549\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.0057603297755122185\n",
            "Train step - Step 870, Loss 0.006502203643321991\n",
            "Train step - Step 880, Loss 0.005894097499549389\n",
            "Train step - Step 890, Loss 0.007762742228806019\n",
            "Train epoch - Accuracy: 0.924040404040404 Loss: 0.005835356654392348 Corrects: 4574\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.009847601875662804\n",
            "Train step - Step 910, Loss 0.004835821222513914\n",
            "Train step - Step 920, Loss 0.007426715921610594\n",
            "Train step - Step 930, Loss 0.006409232039004564\n",
            "Train epoch - Accuracy: 0.9222222222222223 Loss: 0.006072739845122954 Corrects: 4565\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.0048867142759263515\n",
            "Train step - Step 950, Loss 0.005463422276079655\n",
            "Train step - Step 960, Loss 0.004709422588348389\n",
            "Train step - Step 970, Loss 0.00468048732727766\n",
            "Train epoch - Accuracy: 0.927070707070707 Loss: 0.005809165042157125 Corrects: 4589\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0043853153474628925\n",
            "Train step - Step 990, Loss 0.005914856214076281\n",
            "Train step - Step 1000, Loss 0.005814577918499708\n",
            "Train step - Step 1010, Loss 0.004391242749989033\n",
            "Train epoch - Accuracy: 0.9280808080808081 Loss: 0.0054739453831706385 Corrects: 4594\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0059026088565588\n",
            "Train step - Step 1030, Loss 0.005041694268584251\n",
            "Train step - Step 1040, Loss 0.005407134536653757\n",
            "Train step - Step 1050, Loss 0.0037255806382745504\n",
            "Train epoch - Accuracy: 0.9327272727272727 Loss: 0.005372395498696903 Corrects: 4617\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0032640951685607433\n",
            "Train step - Step 1070, Loss 0.0046543278731405735\n",
            "Train step - Step 1080, Loss 0.004641085863113403\n",
            "Train step - Step 1090, Loss 0.0050421892665326595\n",
            "Train epoch - Accuracy: 0.9301010101010101 Loss: 0.005606330775025517 Corrects: 4604\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.005678065586835146\n",
            "Train step - Step 1110, Loss 0.004972909111529589\n",
            "Train step - Step 1120, Loss 0.007894839160144329\n",
            "Train step - Step 1130, Loss 0.006392414681613445\n",
            "Train epoch - Accuracy: 0.925050505050505 Loss: 0.005804045029135063 Corrects: 4579\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.006625812966376543\n",
            "Train step - Step 1150, Loss 0.003133039688691497\n",
            "Train step - Step 1160, Loss 0.0032772591803222895\n",
            "Train epoch - Accuracy: 0.942020202020202 Loss: 0.004787194915303979 Corrects: 4663\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.004925761837512255\n",
            "Train step - Step 1180, Loss 0.005677504930645227\n",
            "Train step - Step 1190, Loss 0.004463524091988802\n",
            "Train step - Step 1200, Loss 0.004495078697800636\n",
            "Train epoch - Accuracy: 0.9434343434343434 Loss: 0.004603615673352973 Corrects: 4670\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.004380133468657732\n",
            "Train step - Step 1220, Loss 0.0038646177854388952\n",
            "Train step - Step 1230, Loss 0.004564193543046713\n",
            "Train step - Step 1240, Loss 0.00320733105763793\n",
            "Train epoch - Accuracy: 0.9507070707070707 Loss: 0.0040812809140694266 Corrects: 4706\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0037682014517486095\n",
            "Train step - Step 1260, Loss 0.003115255618467927\n",
            "Train step - Step 1270, Loss 0.004644824657589197\n",
            "Train step - Step 1280, Loss 0.00510433642193675\n",
            "Train epoch - Accuracy: 0.938989898989899 Loss: 0.004696682587341227 Corrects: 4648\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.007781958673149347\n",
            "Train step - Step 1300, Loss 0.003382885130122304\n",
            "Train step - Step 1310, Loss 0.0039778053760528564\n",
            "Train step - Step 1320, Loss 0.0030379733070731163\n",
            "Train epoch - Accuracy: 0.9464646464646465 Loss: 0.004440411844413088 Corrects: 4685\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0042914231307804585\n",
            "Train step - Step 1340, Loss 0.004947292152792215\n",
            "Train step - Step 1350, Loss 0.004736623726785183\n",
            "Train step - Step 1360, Loss 0.005172508768737316\n",
            "Train epoch - Accuracy: 0.9474747474747475 Loss: 0.0043474589720970454 Corrects: 4690\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0057098763063549995\n",
            "Train step - Step 1380, Loss 0.004003917798399925\n",
            "Train step - Step 1390, Loss 0.004624946508556604\n",
            "Train step - Step 1400, Loss 0.0031852833926677704\n",
            "Train epoch - Accuracy: 0.9505050505050505 Loss: 0.004103973014938711 Corrects: 4705\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002514416817575693\n",
            "Train step - Step 1420, Loss 0.0039503625594079494\n",
            "Train step - Step 1430, Loss 0.004108837805688381\n",
            "Train step - Step 1440, Loss 0.004666339140385389\n",
            "Train epoch - Accuracy: 0.9494949494949495 Loss: 0.003954954543009852 Corrects: 4700\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.003412902355194092\n",
            "Train step - Step 1460, Loss 0.0044813938438892365\n",
            "Train step - Step 1470, Loss 0.003798939986154437\n",
            "Train step - Step 1480, Loss 0.003090611891821027\n",
            "Train epoch - Accuracy: 0.9585858585858585 Loss: 0.003611747771877833 Corrects: 4745\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.0025000236928462982\n",
            "Train step - Step 1500, Loss 0.00316044595092535\n",
            "Train step - Step 1510, Loss 0.002032452030107379\n",
            "Train step - Step 1520, Loss 0.00714458804577589\n",
            "Train epoch - Accuracy: 0.9569696969696969 Loss: 0.003503469819146575 Corrects: 4737\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.006214768625795841\n",
            "Train step - Step 1540, Loss 0.005948908627033234\n",
            "Train step - Step 1550, Loss 0.005550246685743332\n",
            "Train epoch - Accuracy: 0.9533333333333334 Loss: 0.004024224435026296 Corrects: 4719\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.003861393313854933\n",
            "Train step - Step 1570, Loss 0.004360876977443695\n",
            "Train step - Step 1580, Loss 0.0028021589387208223\n",
            "Train step - Step 1590, Loss 0.0031172530725598335\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.004104548663352475 Corrects: 4695\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.003811209462583065\n",
            "Train step - Step 1610, Loss 0.005158091429620981\n",
            "Train step - Step 1620, Loss 0.005141228437423706\n",
            "Train step - Step 1630, Loss 0.0057846917770802975\n",
            "Train epoch - Accuracy: 0.9543434343434344 Loss: 0.003721777165703701 Corrects: 4724\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.004037585575133562\n",
            "Train step - Step 1650, Loss 0.005053344648331404\n",
            "Train step - Step 1660, Loss 0.0037337355315685272\n",
            "Train step - Step 1670, Loss 0.004006045404821634\n",
            "Train epoch - Accuracy: 0.96 Loss: 0.003386537641324479 Corrects: 4752\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.002652835100889206\n",
            "Train step - Step 1690, Loss 0.004015746526420116\n",
            "Train step - Step 1700, Loss 0.002438213676214218\n",
            "Train step - Step 1710, Loss 0.002661788370460272\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.0031623805745156727 Corrects: 4760\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0022798841819167137\n",
            "Train step - Step 1730, Loss 0.004230746533721685\n",
            "Train step - Step 1740, Loss 0.004113790113478899\n",
            "Train step - Step 1750, Loss 0.0024808053858578205\n",
            "Train epoch - Accuracy: 0.9632323232323232 Loss: 0.003135083464886805 Corrects: 4768\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002964147599413991\n",
            "Train step - Step 1770, Loss 0.0032845463138073683\n",
            "Train step - Step 1780, Loss 0.00236469111405313\n",
            "Train step - Step 1790, Loss 0.003034010296687484\n",
            "Train epoch - Accuracy: 0.9616161616161616 Loss: 0.0033257719748324218 Corrects: 4760\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.007231669966131449\n",
            "Train step - Step 1810, Loss 0.0037047015503048897\n",
            "Train step - Step 1820, Loss 0.0041825780645012856\n",
            "Train step - Step 1830, Loss 0.0030838127713650465\n",
            "Train epoch - Accuracy: 0.9531313131313132 Loss: 0.003898870444320368 Corrects: 4718\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.0033168925438076258\n",
            "Train step - Step 1850, Loss 0.0019634480122476816\n",
            "Train step - Step 1860, Loss 0.001790288370102644\n",
            "Train step - Step 1870, Loss 0.002197293797507882\n",
            "Train epoch - Accuracy: 0.9583838383838383 Loss: 0.0034564482428208745 Corrects: 4744\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.002650356385856867\n",
            "Train step - Step 1890, Loss 0.0021040798164904118\n",
            "Train step - Step 1900, Loss 0.0025715543888509274\n",
            "Train step - Step 1910, Loss 0.004627462476491928\n",
            "Train epoch - Accuracy: 0.9557575757575758 Loss: 0.003610307334950476 Corrects: 4731\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0015019831480458379\n",
            "Train step - Step 1930, Loss 0.002548921387642622\n",
            "Train step - Step 1940, Loss 0.0016097172629088163\n",
            "Train epoch - Accuracy: 0.9806060606060606 Loss: 0.0020361508591796714 Corrects: 4854\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0021250545978546143\n",
            "Train step - Step 1960, Loss 0.0012689318973571062\n",
            "Train step - Step 1970, Loss 0.0008966806926764548\n",
            "Train step - Step 1980, Loss 0.0013313018716871738\n",
            "Train epoch - Accuracy: 0.9894949494949495 Loss: 0.001297397722650056 Corrects: 4898\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.000743397104088217\n",
            "Train step - Step 2000, Loss 0.0010423521744087338\n",
            "Train step - Step 2010, Loss 0.0009369660983793437\n",
            "Train step - Step 2020, Loss 0.0005828032735735178\n",
            "Train epoch - Accuracy: 0.9939393939393939 Loss: 0.0009301990775786566 Corrects: 4920\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0007274702657014132\n",
            "Train step - Step 2040, Loss 0.000795823463704437\n",
            "Train step - Step 2050, Loss 0.0011569233611226082\n",
            "Train step - Step 2060, Loss 0.0005513843498192728\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0007584895685108172 Corrects: 4935\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0010385274654254317\n",
            "Train step - Step 2080, Loss 0.001168358139693737\n",
            "Train step - Step 2090, Loss 0.0003342566196806729\n",
            "Train step - Step 2100, Loss 0.0005821675877086818\n",
            "Train epoch - Accuracy: 0.9951515151515151 Loss: 0.0007520440339952745 Corrects: 4926\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.000463691569166258\n",
            "Train step - Step 2120, Loss 0.00047090506996028125\n",
            "Train step - Step 2130, Loss 0.0004329824587330222\n",
            "Train step - Step 2140, Loss 0.0005395045736804605\n",
            "Train epoch - Accuracy: 0.9957575757575757 Loss: 0.0007274963233074305 Corrects: 4929\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0003594800364226103\n",
            "Train step - Step 2160, Loss 0.0004407983797136694\n",
            "Train step - Step 2170, Loss 0.0008896773215383291\n",
            "Train step - Step 2180, Loss 0.0007984499097801745\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0006302361854474351 Corrects: 4937\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0005360037321224809\n",
            "Train step - Step 2200, Loss 0.0007694361265748739\n",
            "Train step - Step 2210, Loss 0.0003589654224924743\n",
            "Train step - Step 2220, Loss 0.0004231563361827284\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0005813742993220762 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.00042274087900295854\n",
            "Train step - Step 2240, Loss 0.0006239533540792763\n",
            "Train step - Step 2250, Loss 0.000324604770867154\n",
            "Train step - Step 2260, Loss 0.0008699289173819125\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0006049351423809474 Corrects: 4933\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0006006649928167462\n",
            "Train step - Step 2280, Loss 0.00047749749501235783\n",
            "Train step - Step 2290, Loss 0.0003159939660690725\n",
            "Train step - Step 2300, Loss 0.0006617981707677245\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0005117387362671169 Corrects: 4939\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0004769079387187958\n",
            "Train step - Step 2320, Loss 0.0004525650874711573\n",
            "Train step - Step 2330, Loss 0.00040692565380595624\n",
            "Train epoch - Accuracy: 0.9971717171717172 Loss: 0.000559571931053969 Corrects: 4936\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00027144025079905987\n",
            "Train step - Step 2350, Loss 0.00019922891806345433\n",
            "Train step - Step 2360, Loss 0.00023402510851155967\n",
            "Train step - Step 2370, Loss 0.0007677432731725276\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0004375878448546347 Corrects: 4941\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00044315450941212475\n",
            "Train step - Step 2390, Loss 0.0004194337234366685\n",
            "Train step - Step 2400, Loss 0.0008167112828232348\n",
            "Train step - Step 2410, Loss 0.0003268665459472686\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0005139531029124904 Corrects: 4937\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.0004549262812361121\n",
            "Train step - Step 2430, Loss 0.00029663596069440246\n",
            "Train step - Step 2440, Loss 0.00028129396378062665\n",
            "Train step - Step 2450, Loss 0.0003270531306043267\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00038899119385997906 Corrects: 4943\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00021563866175711155\n",
            "Train step - Step 2470, Loss 0.00017395005852449685\n",
            "Train step - Step 2480, Loss 0.00040651229210197926\n",
            "Train step - Step 2490, Loss 0.0002712093701120466\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0004363826365031377 Corrects: 4941\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00020646015764214098\n",
            "Train step - Step 2510, Loss 0.00017752630810718983\n",
            "Train step - Step 2520, Loss 0.00027435884112492204\n",
            "Train step - Step 2530, Loss 0.0009357628296129405\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00043290722272076615 Corrects: 4940\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0003002654993906617\n",
            "Train step - Step 2550, Loss 0.00028540732455439866\n",
            "Train step - Step 2560, Loss 0.0003009890206158161\n",
            "Train step - Step 2570, Loss 0.00038888672133907676\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.00036164276885113333 Corrects: 4946\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002512607607059181\n",
            "Train step - Step 2590, Loss 0.00023540365509688854\n",
            "Train step - Step 2600, Loss 0.000584084598813206\n",
            "Train step - Step 2610, Loss 0.000292893877485767\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00041404124125932353 Corrects: 4942\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00015720499504823238\n",
            "Train step - Step 2630, Loss 0.00025921614724211395\n",
            "Train step - Step 2640, Loss 0.00047082756645977497\n",
            "Train step - Step 2650, Loss 0.0003283766855020076\n",
            "Train epoch - Accuracy: 0.9993939393939394 Loss: 0.00035024093835605213 Corrects: 4947\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.000910756119992584\n",
            "Train step - Step 2670, Loss 0.00017600769933778793\n",
            "Train step - Step 2680, Loss 0.0002987806801684201\n",
            "Train step - Step 2690, Loss 0.00028129940619692206\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0003363133731034744 Corrects: 4944\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00029686465859413147\n",
            "Train step - Step 2710, Loss 0.000667656131554395\n",
            "Train step - Step 2720, Loss 0.00021877909603063017\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0003447849042313832 Corrects: 4946\n",
            "Training finished in 234.72998571395874 seconds\n",
            "EVALUATION:  0.84 0.018496444448828697\n",
            "TEST GROUP:  0.882\n",
            "TEST ALL:  0.126\n",
            "GROUP:  8\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.15287235379219055\n",
            "Train step - Step 10, Loss 0.06099393591284752\n",
            "Train step - Step 20, Loss 0.03482365235686302\n",
            "Train step - Step 30, Loss 0.030614301562309265\n",
            "Train epoch - Accuracy: 0.301010101010101 Loss: 0.04718249968582332 Corrects: 1490\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.0237742867320776\n",
            "Train step - Step 50, Loss 0.024505237117409706\n",
            "Train step - Step 60, Loss 0.01904546655714512\n",
            "Train step - Step 70, Loss 0.017568496987223625\n",
            "Train epoch - Accuracy: 0.675959595959596 Loss: 0.02044189751750291 Corrects: 3346\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.015190544538199902\n",
            "Train step - Step 90, Loss 0.014196410775184631\n",
            "Train step - Step 100, Loss 0.013653161935508251\n",
            "Train step - Step 110, Loss 0.010625320486724377\n",
            "Train epoch - Accuracy: 0.7903030303030303 Loss: 0.01427641904376673 Corrects: 3912\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.014517015777528286\n",
            "Train step - Step 130, Loss 0.01566370762884617\n",
            "Train step - Step 140, Loss 0.008592667058110237\n",
            "Train step - Step 150, Loss 0.009106074459850788\n",
            "Train epoch - Accuracy: 0.8301010101010101 Loss: 0.011654751771552996 Corrects: 4109\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.011471739038825035\n",
            "Train step - Step 170, Loss 0.01266789622604847\n",
            "Train step - Step 180, Loss 0.01059616357088089\n",
            "Train step - Step 190, Loss 0.011984797194600105\n",
            "Train epoch - Accuracy: 0.8549494949494949 Loss: 0.009999560332960553 Corrects: 4232\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.009217659942805767\n",
            "Train step - Step 210, Loss 0.008429561741650105\n",
            "Train step - Step 220, Loss 0.01194543857127428\n",
            "Train step - Step 230, Loss 0.007977784611284733\n",
            "Train epoch - Accuracy: 0.8705050505050506 Loss: 0.008762380074182846 Corrects: 4309\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00785566121339798\n",
            "Train step - Step 250, Loss 0.008600175380706787\n",
            "Train step - Step 260, Loss 0.006283040624111891\n",
            "Train step - Step 270, Loss 0.008382178843021393\n",
            "Train epoch - Accuracy: 0.8838383838383839 Loss: 0.007895968230535285 Corrects: 4375\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.010903234593570232\n",
            "Train step - Step 290, Loss 0.00834383349865675\n",
            "Train step - Step 300, Loss 0.008333878591656685\n",
            "Train step - Step 310, Loss 0.007384873926639557\n",
            "Train epoch - Accuracy: 0.8909090909090909 Loss: 0.00761792802900979 Corrects: 4410\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.008423247374594212\n",
            "Train step - Step 330, Loss 0.005598131567239761\n",
            "Train step - Step 340, Loss 0.00806940346956253\n",
            "Train step - Step 350, Loss 0.0055251410230994225\n",
            "Train epoch - Accuracy: 0.9040404040404041 Loss: 0.006750369296606743 Corrects: 4475\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.010776246897876263\n",
            "Train step - Step 370, Loss 0.0058189439587295055\n",
            "Train step - Step 380, Loss 0.005688570439815521\n",
            "Train epoch - Accuracy: 0.9076767676767676 Loss: 0.006525868000556725 Corrects: 4493\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.005125769879668951\n",
            "Train step - Step 400, Loss 0.004036699887365103\n",
            "Train step - Step 410, Loss 0.004836235195398331\n",
            "Train step - Step 420, Loss 0.004537707660347223\n",
            "Train epoch - Accuracy: 0.9119191919191919 Loss: 0.0060590483050680525 Corrects: 4514\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.003593454835936427\n",
            "Train step - Step 440, Loss 0.0053554982878267765\n",
            "Train step - Step 450, Loss 0.004208590369671583\n",
            "Train step - Step 460, Loss 0.0050436886958777905\n",
            "Train epoch - Accuracy: 0.925050505050505 Loss: 0.005419580970110014 Corrects: 4579\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.003959041088819504\n",
            "Train step - Step 480, Loss 0.005574698094278574\n",
            "Train step - Step 490, Loss 0.003607428865507245\n",
            "Train step - Step 500, Loss 0.006026438903063536\n",
            "Train epoch - Accuracy: 0.92 Loss: 0.005736440328899959 Corrects: 4554\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.003848848631605506\n",
            "Train step - Step 520, Loss 0.005557899363338947\n",
            "Train step - Step 530, Loss 0.0030983334872871637\n",
            "Train step - Step 540, Loss 0.005908515769988298\n",
            "Train epoch - Accuracy: 0.933939393939394 Loss: 0.00502742389969603 Corrects: 4623\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.004902686458081007\n",
            "Train step - Step 560, Loss 0.0038218952249735594\n",
            "Train step - Step 570, Loss 0.003930594772100449\n",
            "Train step - Step 580, Loss 0.0053487503901124\n",
            "Train epoch - Accuracy: 0.9309090909090909 Loss: 0.004868214339902154 Corrects: 4608\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.004624083172529936\n",
            "Train step - Step 600, Loss 0.005696508567780256\n",
            "Train step - Step 610, Loss 0.0036447462625801563\n",
            "Train step - Step 620, Loss 0.0036501921713352203\n",
            "Train epoch - Accuracy: 0.9363636363636364 Loss: 0.004765144345548117 Corrects: 4635\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.0032670118380337954\n",
            "Train step - Step 640, Loss 0.0025917289312928915\n",
            "Train step - Step 650, Loss 0.004777586553245783\n",
            "Train step - Step 660, Loss 0.0037670712918043137\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.003710511697625572 Corrects: 4696\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.0038944350089877844\n",
            "Train step - Step 680, Loss 0.0038758006412535906\n",
            "Train step - Step 690, Loss 0.003926763776689768\n",
            "Train step - Step 700, Loss 0.0037927806843072176\n",
            "Train epoch - Accuracy: 0.9454545454545454 Loss: 0.004084102157315221 Corrects: 4680\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.0032652930822223425\n",
            "Train step - Step 720, Loss 0.007038432639092207\n",
            "Train step - Step 730, Loss 0.005027072969824076\n",
            "Train step - Step 740, Loss 0.0041990079917013645\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.0038243719798070615 Corrects: 4687\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.00355354486964643\n",
            "Train step - Step 760, Loss 0.004621411673724651\n",
            "Train step - Step 770, Loss 0.004139667376875877\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.004071541398650769 Corrects: 4678\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.0037319455295801163\n",
            "Train step - Step 790, Loss 0.0031669330783188343\n",
            "Train step - Step 800, Loss 0.00324164517223835\n",
            "Train step - Step 810, Loss 0.004470379091799259\n",
            "Train epoch - Accuracy: 0.9458585858585858 Loss: 0.003897485067653987 Corrects: 4682\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.0031787471380084753\n",
            "Train step - Step 830, Loss 0.0034049847163259983\n",
            "Train step - Step 840, Loss 0.0034024789929389954\n",
            "Train step - Step 850, Loss 0.004022581037133932\n",
            "Train epoch - Accuracy: 0.9480808080808081 Loss: 0.003949228360345869 Corrects: 4693\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.0025540764909237623\n",
            "Train step - Step 870, Loss 0.0031520482152700424\n",
            "Train step - Step 880, Loss 0.004506799392402172\n",
            "Train step - Step 890, Loss 0.004367444198578596\n",
            "Train epoch - Accuracy: 0.9569696969696969 Loss: 0.0031734848325375956 Corrects: 4737\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.003971584141254425\n",
            "Train step - Step 910, Loss 0.00242160283960402\n",
            "Train step - Step 920, Loss 0.0028080642223358154\n",
            "Train step - Step 930, Loss 0.0034495890140533447\n",
            "Train epoch - Accuracy: 0.9579797979797979 Loss: 0.0031025703850606776 Corrects: 4742\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.0021849223412573338\n",
            "Train step - Step 950, Loss 0.002493001287803054\n",
            "Train step - Step 960, Loss 0.002508930629119277\n",
            "Train step - Step 970, Loss 0.0028758221305906773\n",
            "Train epoch - Accuracy: 0.9581818181818181 Loss: 0.003067584872772597 Corrects: 4743\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.002267373027279973\n",
            "Train step - Step 990, Loss 0.003009539796039462\n",
            "Train step - Step 1000, Loss 0.004176025278866291\n",
            "Train step - Step 1010, Loss 0.0023235396947711706\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.003084560422734781 Corrects: 4738\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0016724109882488847\n",
            "Train step - Step 1030, Loss 0.00111490860581398\n",
            "Train step - Step 1040, Loss 0.0013796428684145212\n",
            "Train step - Step 1050, Loss 0.0018774804193526506\n",
            "Train epoch - Accuracy: 0.9656565656565657 Loss: 0.0027181883132781346 Corrects: 4780\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0023765077348798513\n",
            "Train step - Step 1070, Loss 0.0031792912632226944\n",
            "Train step - Step 1080, Loss 0.005152581259608269\n",
            "Train step - Step 1090, Loss 0.0025637440849095583\n",
            "Train epoch - Accuracy: 0.9579797979797979 Loss: 0.0030244098294225307 Corrects: 4742\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.002658079843968153\n",
            "Train step - Step 1110, Loss 0.0015946573112159967\n",
            "Train step - Step 1120, Loss 0.0017286468064412475\n",
            "Train step - Step 1130, Loss 0.0029596821404993534\n",
            "Train epoch - Accuracy: 0.9660606060606061 Loss: 0.0024988637772398164 Corrects: 4782\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.003009974490851164\n",
            "Train step - Step 1150, Loss 0.00439070351421833\n",
            "Train step - Step 1160, Loss 0.0016331812366843224\n",
            "Train epoch - Accuracy: 0.9668686868686869 Loss: 0.0025037241192779154 Corrects: 4786\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0013175877975299954\n",
            "Train step - Step 1180, Loss 0.0030265876557677984\n",
            "Train step - Step 1190, Loss 0.001885027508251369\n",
            "Train step - Step 1200, Loss 0.002207809826359153\n",
            "Train epoch - Accuracy: 0.9680808080808081 Loss: 0.002603121368741297 Corrects: 4792\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0034627579152584076\n",
            "Train step - Step 1220, Loss 0.0030968363862484694\n",
            "Train step - Step 1230, Loss 0.00281234341673553\n",
            "Train step - Step 1240, Loss 0.0030279955826699734\n",
            "Train epoch - Accuracy: 0.9604040404040404 Loss: 0.0030331694746785092 Corrects: 4754\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0012295531341806054\n",
            "Train step - Step 1260, Loss 0.0022563335951417685\n",
            "Train step - Step 1270, Loss 0.0016894128639250994\n",
            "Train step - Step 1280, Loss 0.0029907887801527977\n",
            "Train epoch - Accuracy: 0.9634343434343434 Loss: 0.0025773255139438793 Corrects: 4769\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.002935628639534116\n",
            "Train step - Step 1300, Loss 0.0026383136864751577\n",
            "Train step - Step 1310, Loss 0.0018686869880184531\n",
            "Train step - Step 1320, Loss 0.0041503612883389\n",
            "Train epoch - Accuracy: 0.9626262626262626 Loss: 0.002702142202173068 Corrects: 4765\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0027535229455679655\n",
            "Train step - Step 1340, Loss 0.004005958791822195\n",
            "Train step - Step 1350, Loss 0.0032618322875350714\n",
            "Train step - Step 1360, Loss 0.004591536242514849\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.002858467922461304 Corrects: 4766\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0035823385696858168\n",
            "Train step - Step 1380, Loss 0.0025747125037014484\n",
            "Train step - Step 1390, Loss 0.003119882894679904\n",
            "Train step - Step 1400, Loss 0.004019235260784626\n",
            "Train epoch - Accuracy: 0.9698989898989899 Loss: 0.0025757520579065035 Corrects: 4801\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.004708901979029179\n",
            "Train step - Step 1420, Loss 0.0014880754752084613\n",
            "Train step - Step 1430, Loss 0.0030200944747775793\n",
            "Train step - Step 1440, Loss 0.0028805523179471493\n",
            "Train epoch - Accuracy: 0.9622222222222222 Loss: 0.0028440051523009034 Corrects: 4763\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.0021549207158386707\n",
            "Train step - Step 1460, Loss 0.003021782962605357\n",
            "Train step - Step 1470, Loss 0.0038497212808579206\n",
            "Train step - Step 1480, Loss 0.0027285378891974688\n",
            "Train epoch - Accuracy: 0.9612121212121212 Loss: 0.0028097946771580462 Corrects: 4758\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.001752882613800466\n",
            "Train step - Step 1500, Loss 0.0024711843580007553\n",
            "Train step - Step 1510, Loss 0.003562367055565119\n",
            "Train step - Step 1520, Loss 0.002949964487925172\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.0027593551797209064 Corrects: 4766\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.0022419504821300507\n",
            "Train step - Step 1540, Loss 0.001964929746463895\n",
            "Train step - Step 1550, Loss 0.0019740965217351913\n",
            "Train epoch - Accuracy: 0.9749494949494949 Loss: 0.0019931422295801416 Corrects: 4826\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0012185516534373164\n",
            "Train step - Step 1570, Loss 0.002353393705561757\n",
            "Train step - Step 1580, Loss 0.001996074104681611\n",
            "Train step - Step 1590, Loss 0.0015713233733549714\n",
            "Train epoch - Accuracy: 0.9763636363636363 Loss: 0.0018594523211658905 Corrects: 4833\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0018889611819759011\n",
            "Train step - Step 1610, Loss 0.0024186258669942617\n",
            "Train step - Step 1620, Loss 0.001210240414366126\n",
            "Train step - Step 1630, Loss 0.0028021582402288914\n",
            "Train epoch - Accuracy: 0.9751515151515151 Loss: 0.001928584487882979 Corrects: 4827\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0006687596323899925\n",
            "Train step - Step 1650, Loss 0.0016684308648109436\n",
            "Train step - Step 1660, Loss 0.0016817189753055573\n",
            "Train step - Step 1670, Loss 0.0018961317837238312\n",
            "Train epoch - Accuracy: 0.9737373737373738 Loss: 0.002006470959991066 Corrects: 4820\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0018673116574063897\n",
            "Train step - Step 1690, Loss 0.0023977842647582293\n",
            "Train step - Step 1700, Loss 0.0021893265657126904\n",
            "Train step - Step 1710, Loss 0.0018300444353371859\n",
            "Train epoch - Accuracy: 0.9723232323232324 Loss: 0.00205230216599173 Corrects: 4813\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.003331247018650174\n",
            "Train step - Step 1730, Loss 0.00216515245847404\n",
            "Train step - Step 1740, Loss 0.0028650148306041956\n",
            "Train step - Step 1750, Loss 0.003459267783910036\n",
            "Train epoch - Accuracy: 0.9692929292929293 Loss: 0.002354055257664636 Corrects: 4798\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002644659485667944\n",
            "Train step - Step 1770, Loss 0.0033775854390114546\n",
            "Train step - Step 1780, Loss 0.0014346957905218005\n",
            "Train step - Step 1790, Loss 0.0017972014611586928\n",
            "Train epoch - Accuracy: 0.9715151515151516 Loss: 0.0022451907200644714 Corrects: 4809\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0008372798911295831\n",
            "Train step - Step 1810, Loss 0.003673345549032092\n",
            "Train step - Step 1820, Loss 0.0016424946952611208\n",
            "Train step - Step 1830, Loss 0.001805650070309639\n",
            "Train epoch - Accuracy: 0.9735353535353536 Loss: 0.002004649615517319 Corrects: 4819\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.003216681769117713\n",
            "Train step - Step 1850, Loss 0.0025341545697301626\n",
            "Train step - Step 1860, Loss 0.0014683095505461097\n",
            "Train step - Step 1870, Loss 0.0014660506276413798\n",
            "Train epoch - Accuracy: 0.9793939393939394 Loss: 0.0017917001426144682 Corrects: 4848\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0018019855488091707\n",
            "Train step - Step 1890, Loss 0.0013014235300943255\n",
            "Train step - Step 1900, Loss 0.0016722086584195495\n",
            "Train step - Step 1910, Loss 0.0026196895632892847\n",
            "Train epoch - Accuracy: 0.9751515151515151 Loss: 0.0020201532771302894 Corrects: 4827\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0010956068290397525\n",
            "Train step - Step 1930, Loss 0.0013641270343214273\n",
            "Train step - Step 1940, Loss 0.0010952567681670189\n",
            "Train epoch - Accuracy: 0.9870707070707071 Loss: 0.0012237361506229698 Corrects: 4886\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.000774425221607089\n",
            "Train step - Step 1960, Loss 0.0005076783709228039\n",
            "Train step - Step 1970, Loss 0.0007858442259021103\n",
            "Train step - Step 1980, Loss 0.0003598957846406847\n",
            "Train epoch - Accuracy: 0.9943434343434343 Loss: 0.0006842628756368702 Corrects: 4922\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.0005553549854084849\n",
            "Train step - Step 2000, Loss 0.0006813904037699103\n",
            "Train step - Step 2010, Loss 0.000487588724354282\n",
            "Train step - Step 2020, Loss 0.00038673364906571805\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0005262824360544634 Corrects: 4932\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0004180177056696266\n",
            "Train step - Step 2040, Loss 0.0006779280374757946\n",
            "Train step - Step 2050, Loss 0.0013224398717284203\n",
            "Train step - Step 2060, Loss 0.00039586410275660455\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0004599604367118592 Corrects: 4937\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0008352877921424806\n",
            "Train step - Step 2080, Loss 0.0003326180449221283\n",
            "Train step - Step 2090, Loss 0.0007634996436536312\n",
            "Train step - Step 2100, Loss 0.0003850230132229626\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00041803402052439676 Corrects: 4938\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.0002621857274789363\n",
            "Train step - Step 2120, Loss 0.00028353926609270275\n",
            "Train step - Step 2130, Loss 0.00021523782925214618\n",
            "Train step - Step 2140, Loss 0.0005725621012970805\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00041526471713858873 Corrects: 4939\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0004723961465060711\n",
            "Train step - Step 2160, Loss 0.0002265906223328784\n",
            "Train step - Step 2170, Loss 0.00025070318952202797\n",
            "Train step - Step 2180, Loss 0.00016731249343138188\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00032782279631132354 Corrects: 4945\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00020853569731116295\n",
            "Train step - Step 2200, Loss 0.00047084802645258605\n",
            "Train step - Step 2210, Loss 0.00048614965635351837\n",
            "Train step - Step 2220, Loss 0.00038292130921036005\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.000325432670599019 Corrects: 4941\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0003046675701625645\n",
            "Train step - Step 2240, Loss 0.00024016258248593658\n",
            "Train step - Step 2250, Loss 0.00020172835502307862\n",
            "Train step - Step 2260, Loss 0.000287004018900916\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.0003163799560379538 Corrects: 4943\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.0009846690809354186\n",
            "Train step - Step 2280, Loss 0.00019588382565416396\n",
            "Train step - Step 2290, Loss 0.00024238396144937724\n",
            "Train step - Step 2300, Loss 0.00022659987735096365\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.0003518731048920973 Corrects: 4939\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0003089676611125469\n",
            "Train step - Step 2320, Loss 0.0005311873974278569\n",
            "Train step - Step 2330, Loss 0.00013712543295696378\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002855675341326254 Corrects: 4946\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00019365077605471015\n",
            "Train step - Step 2350, Loss 0.0001870504202088341\n",
            "Train step - Step 2360, Loss 0.00026367383543401957\n",
            "Train step - Step 2370, Loss 0.0005090802442282438\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.00027267140186993836 Corrects: 4944\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00022381372400559485\n",
            "Train step - Step 2390, Loss 0.0002138722047675401\n",
            "Train step - Step 2400, Loss 0.0004259651177562773\n",
            "Train step - Step 2410, Loss 0.0002449628373142332\n",
            "Train epoch - Accuracy: 0.9987878787878788 Loss: 0.0002568036965400244 Corrects: 4944\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00039145510527305305\n",
            "Train step - Step 2430, Loss 0.00022371379600372165\n",
            "Train step - Step 2440, Loss 0.00023790002160239965\n",
            "Train step - Step 2450, Loss 0.00017406766710337251\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002604111398551425 Corrects: 4946\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.00015312960022129118\n",
            "Train step - Step 2470, Loss 0.0006333217024803162\n",
            "Train step - Step 2480, Loss 0.0001609109458513558\n",
            "Train step - Step 2490, Loss 0.0002720736665651202\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.0002746944193436642 Corrects: 4945\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00018593603454064578\n",
            "Train step - Step 2510, Loss 0.0001408289826940745\n",
            "Train step - Step 2520, Loss 0.0002446494472678751\n",
            "Train step - Step 2530, Loss 0.00023436204355675727\n",
            "Train epoch - Accuracy: 0.998989898989899 Loss: 0.00023708296358829946 Corrects: 4945\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00017526361625641584\n",
            "Train step - Step 2550, Loss 0.0002613484102766961\n",
            "Train step - Step 2560, Loss 0.00016933998267631978\n",
            "Train step - Step 2570, Loss 0.00027770621818490326\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00023719049356360402 Corrects: 4948\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.00020675701671279967\n",
            "Train step - Step 2590, Loss 0.0001306314516114071\n",
            "Train step - Step 2600, Loss 0.0003504631749819964\n",
            "Train step - Step 2610, Loss 0.00017034128541126847\n",
            "Train epoch - Accuracy: 0.9995959595959596 Loss: 0.00021704299981009704 Corrects: 4948\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.000441134674474597\n",
            "Train step - Step 2630, Loss 0.00022185943089425564\n",
            "Train step - Step 2640, Loss 0.00013391264656092972\n",
            "Train step - Step 2650, Loss 0.00019970005087088794\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002743727560954714 Corrects: 4946\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00028405687771737576\n",
            "Train step - Step 2670, Loss 0.000166264406288974\n",
            "Train step - Step 2680, Loss 0.0002058808458968997\n",
            "Train step - Step 2690, Loss 0.00015084419283084571\n",
            "Train epoch - Accuracy: 1.0 Loss: 0.00023925709562855912 Corrects: 4950\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.0001702414738247171\n",
            "Train step - Step 2710, Loss 0.00014125586312729865\n",
            "Train step - Step 2720, Loss 0.00017080202815122902\n",
            "Train epoch - Accuracy: 1.0 Loss: 0.00020445379323909304 Corrects: 4950\n",
            "Training finished in 237.8252911567688 seconds\n",
            "EVALUATION:  0.86 0.008703310042619705\n",
            "TEST GROUP:  0.909\n",
            "TEST ALL:  0.113625\n",
            "GROUP:  9\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.12499027699232101\n",
            "Train step - Step 10, Loss 0.049289967864751816\n",
            "Train step - Step 20, Loss 0.031144320964813232\n",
            "Train step - Step 30, Loss 0.024399450048804283\n",
            "Train epoch - Accuracy: 0.3109090909090909 Loss: 0.039004727235496646 Corrects: 1539\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.021379925310611725\n",
            "Train step - Step 50, Loss 0.019566822797060013\n",
            "Train step - Step 60, Loss 0.01730971783399582\n",
            "Train step - Step 70, Loss 0.016166456043720245\n",
            "Train epoch - Accuracy: 0.6462626262626263 Loss: 0.018174265001458353 Corrects: 3199\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.016407260671257973\n",
            "Train step - Step 90, Loss 0.012745354324579239\n",
            "Train step - Step 100, Loss 0.014179307967424393\n",
            "Train step - Step 110, Loss 0.013095098547637463\n",
            "Train epoch - Accuracy: 0.7327272727272728 Loss: 0.014364661882546814 Corrects: 3627\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.012768274173140526\n",
            "Train step - Step 130, Loss 0.012878172099590302\n",
            "Train step - Step 140, Loss 0.011765106581151485\n",
            "Train step - Step 150, Loss 0.011654170230031013\n",
            "Train epoch - Accuracy: 0.7941414141414141 Loss: 0.011817710050052464 Corrects: 3931\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.0098880585283041\n",
            "Train step - Step 170, Loss 0.013190418481826782\n",
            "Train step - Step 180, Loss 0.009760596789419651\n",
            "Train step - Step 190, Loss 0.007556477561593056\n",
            "Train epoch - Accuracy: 0.8171717171717172 Loss: 0.010510219657661938 Corrects: 4045\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.008350073359906673\n",
            "Train step - Step 210, Loss 0.00966149102896452\n",
            "Train step - Step 220, Loss 0.008540757931768894\n",
            "Train step - Step 230, Loss 0.009366648271679878\n",
            "Train epoch - Accuracy: 0.8432323232323232 Loss: 0.009326693763711837 Corrects: 4174\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00939270667731762\n",
            "Train step - Step 250, Loss 0.010601235553622246\n",
            "Train step - Step 260, Loss 0.008470986969769001\n",
            "Train step - Step 270, Loss 0.011752751655876637\n",
            "Train epoch - Accuracy: 0.8464646464646465 Loss: 0.00889761092912669 Corrects: 4190\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.009168417192995548\n",
            "Train step - Step 290, Loss 0.008452925831079483\n",
            "Train step - Step 300, Loss 0.007460222113877535\n",
            "Train step - Step 310, Loss 0.007048029452562332\n",
            "Train epoch - Accuracy: 0.8622222222222222 Loss: 0.008025799049346735 Corrects: 4268\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.007316826842725277\n",
            "Train step - Step 330, Loss 0.003765013301745057\n",
            "Train step - Step 340, Loss 0.00659256661310792\n",
            "Train step - Step 350, Loss 0.006960741244256496\n",
            "Train epoch - Accuracy: 0.8739393939393939 Loss: 0.007404746448226048 Corrects: 4326\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.006034411955624819\n",
            "Train step - Step 370, Loss 0.007335227448493242\n",
            "Train step - Step 380, Loss 0.007791799958795309\n",
            "Train epoch - Accuracy: 0.8777777777777778 Loss: 0.0073929732785833 Corrects: 4345\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.0064524514600634575\n",
            "Train step - Step 400, Loss 0.007575794123113155\n",
            "Train step - Step 410, Loss 0.00692939106374979\n",
            "Train step - Step 420, Loss 0.0070231007412076\n",
            "Train epoch - Accuracy: 0.8816161616161616 Loss: 0.007034612915883161 Corrects: 4364\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.007438029162585735\n",
            "Train step - Step 440, Loss 0.0060809520073235035\n",
            "Train step - Step 450, Loss 0.007532939780503511\n",
            "Train step - Step 460, Loss 0.007647937163710594\n",
            "Train epoch - Accuracy: 0.9008080808080808 Loss: 0.00610117725821005 Corrects: 4459\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.00442828144878149\n",
            "Train step - Step 480, Loss 0.00359207671135664\n",
            "Train step - Step 490, Loss 0.0064259860664606094\n",
            "Train step - Step 500, Loss 0.005694315303117037\n",
            "Train epoch - Accuracy: 0.9040404040404041 Loss: 0.005891400441301591 Corrects: 4475\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.00572613999247551\n",
            "Train step - Step 520, Loss 0.0038645085878670216\n",
            "Train step - Step 530, Loss 0.007536806631833315\n",
            "Train step - Step 540, Loss 0.007544344291090965\n",
            "Train epoch - Accuracy: 0.897979797979798 Loss: 0.006341119343508976 Corrects: 4445\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.006449379026889801\n",
            "Train step - Step 560, Loss 0.004267864394932985\n",
            "Train step - Step 570, Loss 0.005708664655685425\n",
            "Train step - Step 580, Loss 0.004738964606076479\n",
            "Train epoch - Accuracy: 0.9062626262626262 Loss: 0.0057030850948032105 Corrects: 4486\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.003194694872945547\n",
            "Train step - Step 600, Loss 0.0038720397278666496\n",
            "Train step - Step 610, Loss 0.0036039615515619516\n",
            "Train step - Step 620, Loss 0.0037540618795901537\n",
            "Train epoch - Accuracy: 0.9248484848484848 Loss: 0.0048992105631741 Corrects: 4578\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.005805222317576408\n",
            "Train step - Step 640, Loss 0.005305573344230652\n",
            "Train step - Step 650, Loss 0.003629975952208042\n",
            "Train step - Step 660, Loss 0.005663860589265823\n",
            "Train epoch - Accuracy: 0.9228282828282828 Loss: 0.004873702321389709 Corrects: 4568\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.004072798881679773\n",
            "Train step - Step 680, Loss 0.00535992905497551\n",
            "Train step - Step 690, Loss 0.004847415257245302\n",
            "Train step - Step 700, Loss 0.004285489674657583\n",
            "Train epoch - Accuracy: 0.9157575757575758 Loss: 0.005103893278335983 Corrects: 4533\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.00447709858417511\n",
            "Train step - Step 720, Loss 0.0071805305778980255\n",
            "Train step - Step 730, Loss 0.004960217978805304\n",
            "Train step - Step 740, Loss 0.004346081987023354\n",
            "Train epoch - Accuracy: 0.9226262626262626 Loss: 0.0048424675601600395 Corrects: 4567\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.004752031993120909\n",
            "Train step - Step 760, Loss 0.002949187997728586\n",
            "Train step - Step 770, Loss 0.003363068215548992\n",
            "Train epoch - Accuracy: 0.9262626262626262 Loss: 0.004529666246827504 Corrects: 4585\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.002047027228400111\n",
            "Train step - Step 790, Loss 0.003509129397571087\n",
            "Train step - Step 800, Loss 0.0043539563193917274\n",
            "Train step - Step 810, Loss 0.0038856735918670893\n",
            "Train epoch - Accuracy: 0.9315151515151515 Loss: 0.0044377556326563915 Corrects: 4611\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.0029045874252915382\n",
            "Train step - Step 830, Loss 0.004623533226549625\n",
            "Train step - Step 840, Loss 0.0033294472377747297\n",
            "Train step - Step 850, Loss 0.004059060011059046\n",
            "Train epoch - Accuracy: 0.9367676767676768 Loss: 0.004001390668140216 Corrects: 4637\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.00367117952555418\n",
            "Train step - Step 870, Loss 0.004106714390218258\n",
            "Train step - Step 880, Loss 0.005523976404219866\n",
            "Train step - Step 890, Loss 0.0037587471306324005\n",
            "Train epoch - Accuracy: 0.9353535353535354 Loss: 0.004161474665043631 Corrects: 4630\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.0037876050919294357\n",
            "Train step - Step 910, Loss 0.004243895411491394\n",
            "Train step - Step 920, Loss 0.004331817850470543\n",
            "Train step - Step 930, Loss 0.0026770245749503374\n",
            "Train epoch - Accuracy: 0.938989898989899 Loss: 0.003793149340916613 Corrects: 4648\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.0035837888717651367\n",
            "Train step - Step 950, Loss 0.004113274160772562\n",
            "Train step - Step 960, Loss 0.0038217983674257994\n",
            "Train step - Step 970, Loss 0.004305736161768436\n",
            "Train epoch - Accuracy: 0.9484848484848485 Loss: 0.0033846774098999573 Corrects: 4695\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.002724915510043502\n",
            "Train step - Step 990, Loss 0.0038623695727437735\n",
            "Train step - Step 1000, Loss 0.004533261060714722\n",
            "Train step - Step 1010, Loss 0.006591561250388622\n",
            "Train epoch - Accuracy: 0.9446464646464646 Loss: 0.003527659322182187 Corrects: 4676\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.0031517082825303078\n",
            "Train step - Step 1030, Loss 0.004278792534023523\n",
            "Train step - Step 1040, Loss 0.003436984261497855\n",
            "Train step - Step 1050, Loss 0.004219201393425465\n",
            "Train epoch - Accuracy: 0.9311111111111111 Loss: 0.004161884626655867 Corrects: 4609\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.004488368984311819\n",
            "Train step - Step 1070, Loss 0.0038780695758759975\n",
            "Train step - Step 1080, Loss 0.004739913623780012\n",
            "Train step - Step 1090, Loss 0.0027423345018178225\n",
            "Train epoch - Accuracy: 0.9383838383838384 Loss: 0.0039883879820505775 Corrects: 4645\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.004023020155727863\n",
            "Train step - Step 1110, Loss 0.0032737632282078266\n",
            "Train step - Step 1120, Loss 0.002468068851158023\n",
            "Train step - Step 1130, Loss 0.0034983220975846052\n",
            "Train epoch - Accuracy: 0.9468686868686869 Loss: 0.0034815289464901495 Corrects: 4687\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.00226053805090487\n",
            "Train step - Step 1150, Loss 0.004815421998500824\n",
            "Train step - Step 1160, Loss 0.003726630238816142\n",
            "Train epoch - Accuracy: 0.9496969696969697 Loss: 0.0033609593294636167 Corrects: 4701\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.0036114947870373726\n",
            "Train step - Step 1180, Loss 0.0028169944416731596\n",
            "Train step - Step 1190, Loss 0.004054272081702948\n",
            "Train step - Step 1200, Loss 0.002566081937402487\n",
            "Train epoch - Accuracy: 0.9488888888888889 Loss: 0.003410469779951705 Corrects: 4697\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0033841340336948633\n",
            "Train step - Step 1220, Loss 0.004557391162961721\n",
            "Train step - Step 1230, Loss 0.003949455916881561\n",
            "Train step - Step 1240, Loss 0.0033714636228978634\n",
            "Train epoch - Accuracy: 0.946060606060606 Loss: 0.0032927329589923222 Corrects: 4683\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.0029045080300420523\n",
            "Train step - Step 1260, Loss 0.00268315221183002\n",
            "Train step - Step 1270, Loss 0.0029117807280272245\n",
            "Train step - Step 1280, Loss 0.0029390116687864065\n",
            "Train epoch - Accuracy: 0.9458585858585858 Loss: 0.003569982798036301 Corrects: 4682\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0034023835323750973\n",
            "Train step - Step 1300, Loss 0.0023040762171149254\n",
            "Train step - Step 1310, Loss 0.0036363406106829643\n",
            "Train step - Step 1320, Loss 0.003638745052739978\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.0032689392301395084 Corrects: 4689\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.0034767091274261475\n",
            "Train step - Step 1340, Loss 0.003001920413225889\n",
            "Train step - Step 1350, Loss 0.0017195085529237986\n",
            "Train step - Step 1360, Loss 0.0031128611881285906\n",
            "Train epoch - Accuracy: 0.9486868686868687 Loss: 0.0032209542926137495 Corrects: 4696\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0026628340128809214\n",
            "Train step - Step 1380, Loss 0.0024919514544308186\n",
            "Train step - Step 1390, Loss 0.0043901922181248665\n",
            "Train step - Step 1400, Loss 0.001193698146380484\n",
            "Train epoch - Accuracy: 0.955959595959596 Loss: 0.002865640642874018 Corrects: 4732\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002183574251830578\n",
            "Train step - Step 1420, Loss 0.003958611283451319\n",
            "Train step - Step 1430, Loss 0.003751221811398864\n",
            "Train step - Step 1440, Loss 0.002626110101118684\n",
            "Train epoch - Accuracy: 0.954949494949495 Loss: 0.002937899527488032 Corrects: 4727\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.003338147886097431\n",
            "Train step - Step 1460, Loss 0.003661173628643155\n",
            "Train step - Step 1470, Loss 0.0038604994770139456\n",
            "Train step - Step 1480, Loss 0.0032592921052128077\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.0032559370452707463 Corrects: 4689\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.002296360209584236\n",
            "Train step - Step 1500, Loss 0.0025863852351903915\n",
            "Train step - Step 1510, Loss 0.002577364444732666\n",
            "Train step - Step 1520, Loss 0.0013368746731430292\n",
            "Train epoch - Accuracy: 0.9569696969696969 Loss: 0.0028742355502426927 Corrects: 4737\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.003921410068869591\n",
            "Train step - Step 1540, Loss 0.0020385836251080036\n",
            "Train step - Step 1550, Loss 0.0020295591093599796\n",
            "Train epoch - Accuracy: 0.9555555555555556 Loss: 0.002935499299336413 Corrects: 4730\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0025172741152346134\n",
            "Train step - Step 1570, Loss 0.003518209559842944\n",
            "Train step - Step 1580, Loss 0.003037143498659134\n",
            "Train step - Step 1590, Loss 0.0019155654590576887\n",
            "Train epoch - Accuracy: 0.963030303030303 Loss: 0.0025195405590865347 Corrects: 4767\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.0017504259012639523\n",
            "Train step - Step 1610, Loss 0.0021001333370804787\n",
            "Train step - Step 1620, Loss 0.001153315999545157\n",
            "Train step - Step 1630, Loss 0.0019894482102245092\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.002200458414683288 Corrects: 4790\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.003346846206113696\n",
            "Train step - Step 1650, Loss 0.0030368617735803127\n",
            "Train step - Step 1660, Loss 0.0026213519740849733\n",
            "Train step - Step 1670, Loss 0.003979061730206013\n",
            "Train epoch - Accuracy: 0.9676767676767677 Loss: 0.0023219640178116733 Corrects: 4790\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0012269595172256231\n",
            "Train step - Step 1690, Loss 0.0019889657851308584\n",
            "Train step - Step 1700, Loss 0.0022461891639977694\n",
            "Train step - Step 1710, Loss 0.0016357218846678734\n",
            "Train epoch - Accuracy: 0.9688888888888889 Loss: 0.0022668195229889167 Corrects: 4796\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0016195211792364717\n",
            "Train step - Step 1730, Loss 0.0032624960877001286\n",
            "Train step - Step 1740, Loss 0.002297718310728669\n",
            "Train step - Step 1750, Loss 0.0028895444702357054\n",
            "Train epoch - Accuracy: 0.963030303030303 Loss: 0.0023029215983820686 Corrects: 4767\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.002252931473776698\n",
            "Train step - Step 1770, Loss 0.0013410892570391297\n",
            "Train step - Step 1780, Loss 0.0044523016549646854\n",
            "Train step - Step 1790, Loss 0.003850968088954687\n",
            "Train epoch - Accuracy: 0.9595959595959596 Loss: 0.002650019087207814 Corrects: 4750\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0019453895511105657\n",
            "Train step - Step 1810, Loss 0.0032309924717992544\n",
            "Train step - Step 1820, Loss 0.001642788527533412\n",
            "Train step - Step 1830, Loss 0.0033097367268055677\n",
            "Train epoch - Accuracy: 0.9577777777777777 Loss: 0.0027697624313184105 Corrects: 4741\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.003086199052631855\n",
            "Train step - Step 1850, Loss 0.0037286891601979733\n",
            "Train step - Step 1860, Loss 0.0016092280857264996\n",
            "Train step - Step 1870, Loss 0.003109901212155819\n",
            "Train epoch - Accuracy: 0.9591919191919192 Loss: 0.0026951156513332717 Corrects: 4748\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0027388029266148806\n",
            "Train step - Step 1890, Loss 0.0015364150749519467\n",
            "Train step - Step 1900, Loss 0.0027223380748182535\n",
            "Train step - Step 1910, Loss 0.0027947472408413887\n",
            "Train epoch - Accuracy: 0.9670707070707071 Loss: 0.0022364904238569615 Corrects: 4787\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.0014574845554307103\n",
            "Train step - Step 1930, Loss 0.0014743275241926312\n",
            "Train step - Step 1940, Loss 0.0008264594944193959\n",
            "Train epoch - Accuracy: 0.981010101010101 Loss: 0.0013927162067748306 Corrects: 4856\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0005387425771914423\n",
            "Train step - Step 1960, Loss 0.0008194475085474551\n",
            "Train step - Step 1970, Loss 0.0005602744640782475\n",
            "Train step - Step 1980, Loss 0.0004921926301904023\n",
            "Train epoch - Accuracy: 0.9927272727272727 Loss: 0.0007979259432782654 Corrects: 4914\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.000706799328327179\n",
            "Train step - Step 2000, Loss 0.0006911470554769039\n",
            "Train step - Step 2010, Loss 0.000538414460606873\n",
            "Train step - Step 2020, Loss 0.0009486221824772656\n",
            "Train epoch - Accuracy: 0.9931313131313131 Loss: 0.0007704569096912188 Corrects: 4916\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0009189675329253078\n",
            "Train step - Step 2040, Loss 0.0006794002838432789\n",
            "Train step - Step 2050, Loss 0.0004258920962456614\n",
            "Train step - Step 2060, Loss 0.0009470895165577531\n",
            "Train epoch - Accuracy: 0.9943434343434343 Loss: 0.0006560240271313097 Corrects: 4922\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.001786783686839044\n",
            "Train step - Step 2080, Loss 0.0005958260735496879\n",
            "Train step - Step 2090, Loss 0.0003565928782336414\n",
            "Train step - Step 2100, Loss 0.0005332326982170343\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0006552698085263296 Corrects: 4917\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.00046266152639873326\n",
            "Train step - Step 2120, Loss 0.000601009523961693\n",
            "Train step - Step 2130, Loss 0.0005069182952865958\n",
            "Train step - Step 2140, Loss 0.0005571506917476654\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.00047997424009754654 Corrects: 4934\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0005226001958362758\n",
            "Train step - Step 2160, Loss 0.0003354829386807978\n",
            "Train step - Step 2170, Loss 0.000790830235928297\n",
            "Train step - Step 2180, Loss 0.0006848208722658455\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.00048730692123015874 Corrects: 4933\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.0003624847740866244\n",
            "Train step - Step 2200, Loss 0.00039184835623018444\n",
            "Train step - Step 2210, Loss 0.000571381242480129\n",
            "Train step - Step 2220, Loss 0.000590806535910815\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.0004631850255107639 Corrects: 4937\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.00032544834539294243\n",
            "Train step - Step 2240, Loss 0.0003524418279994279\n",
            "Train step - Step 2250, Loss 0.0006875250255689025\n",
            "Train step - Step 2260, Loss 0.0004835827276110649\n",
            "Train epoch - Accuracy: 0.9975757575757576 Loss: 0.00044207153291526166 Corrects: 4938\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.00025695175281725824\n",
            "Train step - Step 2280, Loss 0.0003395004605408758\n",
            "Train step - Step 2290, Loss 0.00029383134096860886\n",
            "Train step - Step 2300, Loss 0.00021002073481213301\n",
            "Train epoch - Accuracy: 0.9973737373737374 Loss: 0.00042640563703231474 Corrects: 4937\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.00018838507821783423\n",
            "Train step - Step 2320, Loss 0.0003316996153444052\n",
            "Train step - Step 2330, Loss 0.00026755270664580166\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003709291909101673 Corrects: 4942\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00018398062093183398\n",
            "Train step - Step 2350, Loss 0.00045465206494554877\n",
            "Train step - Step 2360, Loss 0.0003650604048743844\n",
            "Train step - Step 2370, Loss 0.00038735478301532567\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00039545645529281986 Corrects: 4939\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00023277077707462013\n",
            "Train step - Step 2390, Loss 0.0002924176515080035\n",
            "Train step - Step 2400, Loss 0.00039079884300008416\n",
            "Train step - Step 2410, Loss 0.0002441949909552932\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.0003499213187729545 Corrects: 4941\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.00024055539688561112\n",
            "Train step - Step 2430, Loss 0.00014475318312179297\n",
            "Train step - Step 2440, Loss 0.0005755641614086926\n",
            "Train step - Step 2450, Loss 0.00024849502369761467\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003603853465815197 Corrects: 4942\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0003524952626321465\n",
            "Train step - Step 2470, Loss 0.00023250251251738518\n",
            "Train step - Step 2480, Loss 0.00028742491849698126\n",
            "Train step - Step 2490, Loss 0.0003833267546724528\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00034400413143260386 Corrects: 4940\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.0003295590286143124\n",
            "Train step - Step 2510, Loss 0.0002280695625813678\n",
            "Train step - Step 2520, Loss 0.00023761866032145917\n",
            "Train step - Step 2530, Loss 0.00033456285018473864\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00037375106547977966 Corrects: 4940\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.00025638696388341486\n",
            "Train step - Step 2550, Loss 0.000270380376605317\n",
            "Train step - Step 2560, Loss 0.00031887053046375513\n",
            "Train step - Step 2570, Loss 0.0003338068490847945\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003430725151033263 Corrects: 4942\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.0002906637091655284\n",
            "Train step - Step 2590, Loss 0.00028550694696605206\n",
            "Train step - Step 2600, Loss 0.00021213630679994822\n",
            "Train step - Step 2610, Loss 0.00031400175066664815\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.000342180632628651 Corrects: 4939\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00028265416040085256\n",
            "Train step - Step 2630, Loss 0.00036902635474689305\n",
            "Train step - Step 2640, Loss 0.0007758034626021981\n",
            "Train step - Step 2650, Loss 0.00023580675770062953\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00032598278559321027 Corrects: 4942\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.00029628604534082115\n",
            "Train step - Step 2670, Loss 0.00027281278744339943\n",
            "Train step - Step 2680, Loss 0.00029152852948755026\n",
            "Train step - Step 2690, Loss 0.00024804010172374547\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00035601896293828206 Corrects: 4940\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00022331638319883496\n",
            "Train step - Step 2710, Loss 0.00015608149988111109\n",
            "Train step - Step 2720, Loss 0.0003195146273355931\n",
            "Train epoch - Accuracy: 0.9977777777777778 Loss: 0.00033506566264685433 Corrects: 4939\n",
            "Training finished in 241.97172713279724 seconds\n",
            "EVALUATION:  0.92 0.004867006558924913\n",
            "TEST GROUP:  0.882\n",
            "TEST ALL:  0.098\n",
            "GROUP:  10\n",
            "Starting epoch 1/70, LR = [2]\n",
            "Train step - Step 0, Loss 0.09725315123796463\n",
            "Train step - Step 10, Loss 0.04134760797023773\n",
            "Train step - Step 20, Loss 0.030064985156059265\n",
            "Train step - Step 30, Loss 0.02269906923174858\n",
            "Train epoch - Accuracy: 0.3058585858585859 Loss: 0.03432978967072988 Corrects: 1514\n",
            "Starting epoch 2/70, LR = [2]\n",
            "Train step - Step 40, Loss 0.021793818101286888\n",
            "Train step - Step 50, Loss 0.01774175651371479\n",
            "Train step - Step 60, Loss 0.017726724967360497\n",
            "Train step - Step 70, Loss 0.016231127083301544\n",
            "Train epoch - Accuracy: 0.5959595959595959 Loss: 0.01798098317601464 Corrects: 2950\n",
            "Starting epoch 3/70, LR = [2]\n",
            "Train step - Step 80, Loss 0.015392439439892769\n",
            "Train step - Step 90, Loss 0.01420984510332346\n",
            "Train step - Step 100, Loss 0.015523106791079044\n",
            "Train step - Step 110, Loss 0.01346998754888773\n",
            "Train epoch - Accuracy: 0.7018181818181818 Loss: 0.014482678623512537 Corrects: 3474\n",
            "Starting epoch 4/70, LR = [2]\n",
            "Train step - Step 120, Loss 0.01607729308307171\n",
            "Train step - Step 130, Loss 0.011378264054656029\n",
            "Train step - Step 140, Loss 0.011140245944261551\n",
            "Train step - Step 150, Loss 0.012758735567331314\n",
            "Train epoch - Accuracy: 0.7583838383838384 Loss: 0.01232465497396811 Corrects: 3754\n",
            "Starting epoch 5/70, LR = [2]\n",
            "Train step - Step 160, Loss 0.011563523672521114\n",
            "Train step - Step 170, Loss 0.00980246253311634\n",
            "Train step - Step 180, Loss 0.00912050623446703\n",
            "Train step - Step 190, Loss 0.010359865613281727\n",
            "Train epoch - Accuracy: 0.798989898989899 Loss: 0.010572273223237557 Corrects: 3955\n",
            "Starting epoch 6/70, LR = [2]\n",
            "Train step - Step 200, Loss 0.01028791069984436\n",
            "Train step - Step 210, Loss 0.0093643544241786\n",
            "Train step - Step 220, Loss 0.009242012165486813\n",
            "Train step - Step 230, Loss 0.011199905537068844\n",
            "Train epoch - Accuracy: 0.8058585858585858 Loss: 0.00983539129748489 Corrects: 3989\n",
            "Starting epoch 7/70, LR = [2]\n",
            "Train step - Step 240, Loss 0.00739949569106102\n",
            "Train step - Step 250, Loss 0.008951796218752861\n",
            "Train step - Step 260, Loss 0.00977287907153368\n",
            "Train step - Step 270, Loss 0.009376415982842445\n",
            "Train epoch - Accuracy: 0.8333333333333334 Loss: 0.00878108589637159 Corrects: 4125\n",
            "Starting epoch 8/70, LR = [2]\n",
            "Train step - Step 280, Loss 0.007035528309643269\n",
            "Train step - Step 290, Loss 0.009578499011695385\n",
            "Train step - Step 300, Loss 0.00782548077404499\n",
            "Train step - Step 310, Loss 0.006592242978513241\n",
            "Train epoch - Accuracy: 0.8484848484848485 Loss: 0.008084553182313237 Corrects: 4200\n",
            "Starting epoch 9/70, LR = [2]\n",
            "Train step - Step 320, Loss 0.01028105802834034\n",
            "Train step - Step 330, Loss 0.008204445242881775\n",
            "Train step - Step 340, Loss 0.009039788506925106\n",
            "Train step - Step 350, Loss 0.006640514358878136\n",
            "Train epoch - Accuracy: 0.8593939393939394 Loss: 0.007526980862021446 Corrects: 4254\n",
            "Starting epoch 10/70, LR = [2]\n",
            "Train step - Step 360, Loss 0.006709843873977661\n",
            "Train step - Step 370, Loss 0.005013517569750547\n",
            "Train step - Step 380, Loss 0.007523739244788885\n",
            "Train epoch - Accuracy: 0.8725252525252525 Loss: 0.006858535548389861 Corrects: 4319\n",
            "Starting epoch 11/70, LR = [2]\n",
            "Train step - Step 390, Loss 0.006082171108573675\n",
            "Train step - Step 400, Loss 0.007005976513028145\n",
            "Train step - Step 410, Loss 0.0061792335473001\n",
            "Train step - Step 420, Loss 0.006369731854647398\n",
            "Train epoch - Accuracy: 0.8785858585858586 Loss: 0.0066044417625725875 Corrects: 4349\n",
            "Starting epoch 12/70, LR = [2]\n",
            "Train step - Step 430, Loss 0.0060400282964110374\n",
            "Train step - Step 440, Loss 0.007070292253047228\n",
            "Train step - Step 450, Loss 0.006216431502252817\n",
            "Train step - Step 460, Loss 0.006739972624927759\n",
            "Train epoch - Accuracy: 0.8848484848484849 Loss: 0.006217846221130605 Corrects: 4380\n",
            "Starting epoch 13/70, LR = [2]\n",
            "Train step - Step 470, Loss 0.006464974954724312\n",
            "Train step - Step 480, Loss 0.004395715426653624\n",
            "Train step - Step 490, Loss 0.0070349727757275105\n",
            "Train step - Step 500, Loss 0.006988074630498886\n",
            "Train epoch - Accuracy: 0.8907070707070707 Loss: 0.005973350383868121 Corrects: 4409\n",
            "Starting epoch 14/70, LR = [2]\n",
            "Train step - Step 510, Loss 0.005167176481336355\n",
            "Train step - Step 520, Loss 0.005715963896363974\n",
            "Train step - Step 530, Loss 0.007889971137046814\n",
            "Train step - Step 540, Loss 0.004672096576541662\n",
            "Train epoch - Accuracy: 0.8939393939393939 Loss: 0.005980395572542241 Corrects: 4425\n",
            "Starting epoch 15/70, LR = [2]\n",
            "Train step - Step 550, Loss 0.005476543214172125\n",
            "Train step - Step 560, Loss 0.00440839771181345\n",
            "Train step - Step 570, Loss 0.00586355896666646\n",
            "Train step - Step 580, Loss 0.0037339217960834503\n",
            "Train epoch - Accuracy: 0.9056565656565656 Loss: 0.005374842483945417 Corrects: 4483\n",
            "Starting epoch 16/70, LR = [2]\n",
            "Train step - Step 590, Loss 0.004377644043415785\n",
            "Train step - Step 600, Loss 0.005179948173463345\n",
            "Train step - Step 610, Loss 0.005253072828054428\n",
            "Train step - Step 620, Loss 0.006425741594284773\n",
            "Train epoch - Accuracy: 0.9052525252525252 Loss: 0.0052508707568425725 Corrects: 4481\n",
            "Starting epoch 17/70, LR = [2]\n",
            "Train step - Step 630, Loss 0.005010281223803759\n",
            "Train step - Step 640, Loss 0.0061635361053049564\n",
            "Train step - Step 650, Loss 0.009384408593177795\n",
            "Train step - Step 660, Loss 0.005380908027291298\n",
            "Train epoch - Accuracy: 0.8917171717171717 Loss: 0.0058377255559569656 Corrects: 4414\n",
            "Starting epoch 18/70, LR = [2]\n",
            "Train step - Step 670, Loss 0.006289947312325239\n",
            "Train step - Step 680, Loss 0.0063524493016302586\n",
            "Train step - Step 690, Loss 0.006936217192560434\n",
            "Train step - Step 700, Loss 0.004528412129729986\n",
            "Train epoch - Accuracy: 0.9034343434343435 Loss: 0.005141980768830487 Corrects: 4472\n",
            "Starting epoch 19/70, LR = [2]\n",
            "Train step - Step 710, Loss 0.0043050069361925125\n",
            "Train step - Step 720, Loss 0.004834096413105726\n",
            "Train step - Step 730, Loss 0.005409653298556805\n",
            "Train step - Step 740, Loss 0.004567463416606188\n",
            "Train epoch - Accuracy: 0.9094949494949495 Loss: 0.004967407470362054 Corrects: 4502\n",
            "Starting epoch 20/70, LR = [2]\n",
            "Train step - Step 750, Loss 0.00382500933483243\n",
            "Train step - Step 760, Loss 0.004024076275527477\n",
            "Train step - Step 770, Loss 0.005247593391686678\n",
            "Train epoch - Accuracy: 0.9151515151515152 Loss: 0.004578441806288079 Corrects: 4530\n",
            "Starting epoch 21/70, LR = [2]\n",
            "Train step - Step 780, Loss 0.003934032749384642\n",
            "Train step - Step 790, Loss 0.002912284107878804\n",
            "Train step - Step 800, Loss 0.003287652740254998\n",
            "Train step - Step 810, Loss 0.0043866331689059734\n",
            "Train epoch - Accuracy: 0.9202020202020202 Loss: 0.0044108339782917136 Corrects: 4555\n",
            "Starting epoch 22/70, LR = [2]\n",
            "Train step - Step 820, Loss 0.003991167061030865\n",
            "Train step - Step 830, Loss 0.0032596206292510033\n",
            "Train step - Step 840, Loss 0.004104334395378828\n",
            "Train step - Step 850, Loss 0.0026778157334774733\n",
            "Train epoch - Accuracy: 0.9315151515151515 Loss: 0.003850428361746699 Corrects: 4611\n",
            "Starting epoch 23/70, LR = [2]\n",
            "Train step - Step 860, Loss 0.001891522784717381\n",
            "Train step - Step 870, Loss 0.005719611421227455\n",
            "Train step - Step 880, Loss 0.0032459020148962736\n",
            "Train step - Step 890, Loss 0.007436002139002085\n",
            "Train epoch - Accuracy: 0.918989898989899 Loss: 0.004271597710786143 Corrects: 4549\n",
            "Starting epoch 24/70, LR = [2]\n",
            "Train step - Step 900, Loss 0.0057450816966593266\n",
            "Train step - Step 910, Loss 0.0025987662374973297\n",
            "Train step - Step 920, Loss 0.005041562952101231\n",
            "Train step - Step 930, Loss 0.005009551532566547\n",
            "Train epoch - Accuracy: 0.916969696969697 Loss: 0.004468829131901565 Corrects: 4539\n",
            "Starting epoch 25/70, LR = [2]\n",
            "Train step - Step 940, Loss 0.00393068790435791\n",
            "Train step - Step 950, Loss 0.004098524805158377\n",
            "Train step - Step 960, Loss 0.005679577589035034\n",
            "Train step - Step 970, Loss 0.003231953363865614\n",
            "Train epoch - Accuracy: 0.9246464646464646 Loss: 0.004287192302407941 Corrects: 4577\n",
            "Starting epoch 26/70, LR = [2]\n",
            "Train step - Step 980, Loss 0.0037425884511321783\n",
            "Train step - Step 990, Loss 0.0030235981103032827\n",
            "Train step - Step 1000, Loss 0.002694187918677926\n",
            "Train step - Step 1010, Loss 0.0024698367342352867\n",
            "Train epoch - Accuracy: 0.9363636363636364 Loss: 0.003630114575339989 Corrects: 4635\n",
            "Starting epoch 27/70, LR = [2]\n",
            "Train step - Step 1020, Loss 0.003435717662796378\n",
            "Train step - Step 1030, Loss 0.003888027975335717\n",
            "Train step - Step 1040, Loss 0.0033401502296328545\n",
            "Train step - Step 1050, Loss 0.0034738408867269754\n",
            "Train epoch - Accuracy: 0.9397979797979797 Loss: 0.0036219757123652735 Corrects: 4652\n",
            "Starting epoch 28/70, LR = [2]\n",
            "Train step - Step 1060, Loss 0.0035768321249634027\n",
            "Train step - Step 1070, Loss 0.0035032848827540874\n",
            "Train step - Step 1080, Loss 0.002963375998660922\n",
            "Train step - Step 1090, Loss 0.0033461377024650574\n",
            "Train epoch - Accuracy: 0.937979797979798 Loss: 0.003508446818556298 Corrects: 4643\n",
            "Starting epoch 29/70, LR = [2]\n",
            "Train step - Step 1100, Loss 0.0036555486731231213\n",
            "Train step - Step 1110, Loss 0.0037667995784431696\n",
            "Train step - Step 1120, Loss 0.003379977773874998\n",
            "Train step - Step 1130, Loss 0.004281825851649046\n",
            "Train epoch - Accuracy: 0.945050505050505 Loss: 0.003400186222949714 Corrects: 4678\n",
            "Starting epoch 30/70, LR = [2]\n",
            "Train step - Step 1140, Loss 0.0037154224701225758\n",
            "Train step - Step 1150, Loss 0.002318941056728363\n",
            "Train step - Step 1160, Loss 0.002407738473266363\n",
            "Train epoch - Accuracy: 0.9418181818181818 Loss: 0.0034089474601087847 Corrects: 4662\n",
            "Starting epoch 31/70, LR = [2]\n",
            "Train step - Step 1170, Loss 0.003104554954916239\n",
            "Train step - Step 1180, Loss 0.002667094813659787\n",
            "Train step - Step 1190, Loss 0.0027493464294821024\n",
            "Train step - Step 1200, Loss 0.0035253698006272316\n",
            "Train epoch - Accuracy: 0.9571717171717171 Loss: 0.0026425855452514658 Corrects: 4738\n",
            "Starting epoch 32/70, LR = [2]\n",
            "Train step - Step 1210, Loss 0.0025995627511292696\n",
            "Train step - Step 1220, Loss 0.002786224940791726\n",
            "Train step - Step 1230, Loss 0.002466743579134345\n",
            "Train step - Step 1240, Loss 0.0034144637174904346\n",
            "Train epoch - Accuracy: 0.9553535353535354 Loss: 0.002690548893685142 Corrects: 4729\n",
            "Starting epoch 33/70, LR = [2]\n",
            "Train step - Step 1250, Loss 0.002985217608511448\n",
            "Train step - Step 1260, Loss 0.0032114218920469284\n",
            "Train step - Step 1270, Loss 0.002538044471293688\n",
            "Train step - Step 1280, Loss 0.004882053472101688\n",
            "Train epoch - Accuracy: 0.941010101010101 Loss: 0.0032542922496419362 Corrects: 4658\n",
            "Starting epoch 34/70, LR = [2]\n",
            "Train step - Step 1290, Loss 0.0027991067618131638\n",
            "Train step - Step 1300, Loss 0.005198942497372627\n",
            "Train step - Step 1310, Loss 0.0019548065029084682\n",
            "Train step - Step 1320, Loss 0.0030696731992065907\n",
            "Train epoch - Accuracy: 0.9395959595959597 Loss: 0.0035341113033431648 Corrects: 4651\n",
            "Starting epoch 35/70, LR = [2]\n",
            "Train step - Step 1330, Loss 0.003419408807530999\n",
            "Train step - Step 1340, Loss 0.0029721646569669247\n",
            "Train step - Step 1350, Loss 0.0041975718922913074\n",
            "Train step - Step 1360, Loss 0.00401299586519599\n",
            "Train epoch - Accuracy: 0.9472727272727273 Loss: 0.0030469853692979675 Corrects: 4689\n",
            "Starting epoch 36/70, LR = [2]\n",
            "Train step - Step 1370, Loss 0.0036677096504718065\n",
            "Train step - Step 1380, Loss 0.002749806037172675\n",
            "Train step - Step 1390, Loss 0.0025882513727992773\n",
            "Train step - Step 1400, Loss 0.0020463222172111273\n",
            "Train epoch - Accuracy: 0.9494949494949495 Loss: 0.002936606906975309 Corrects: 4700\n",
            "Starting epoch 37/70, LR = [2]\n",
            "Train step - Step 1410, Loss 0.002506477991119027\n",
            "Train step - Step 1420, Loss 0.003197559155523777\n",
            "Train step - Step 1430, Loss 0.0035602960269898176\n",
            "Train step - Step 1440, Loss 0.004130025859922171\n",
            "Train epoch - Accuracy: 0.9490909090909091 Loss: 0.002815140575603253 Corrects: 4698\n",
            "Starting epoch 38/70, LR = [2]\n",
            "Train step - Step 1450, Loss 0.004241573624312878\n",
            "Train step - Step 1460, Loss 0.0016647864831611514\n",
            "Train step - Step 1470, Loss 0.004230645950883627\n",
            "Train step - Step 1480, Loss 0.0015481465961784124\n",
            "Train epoch - Accuracy: 0.9547474747474748 Loss: 0.00274317147577125 Corrects: 4726\n",
            "Starting epoch 39/70, LR = [2]\n",
            "Train step - Step 1490, Loss 0.002272082259878516\n",
            "Train step - Step 1500, Loss 0.003950697835534811\n",
            "Train step - Step 1510, Loss 0.0023685074411332607\n",
            "Train step - Step 1520, Loss 0.0028037920128554106\n",
            "Train epoch - Accuracy: 0.9501010101010101 Loss: 0.0028923694007663113 Corrects: 4703\n",
            "Starting epoch 40/70, LR = [2]\n",
            "Train step - Step 1530, Loss 0.0031779396813362837\n",
            "Train step - Step 1540, Loss 0.0034869404044002295\n",
            "Train step - Step 1550, Loss 0.0013202548725530505\n",
            "Train epoch - Accuracy: 0.9545454545454546 Loss: 0.0028517699095825053 Corrects: 4725\n",
            "Starting epoch 41/70, LR = [2]\n",
            "Train step - Step 1560, Loss 0.0008032628102228045\n",
            "Train step - Step 1570, Loss 0.0019764616154134274\n",
            "Train step - Step 1580, Loss 0.002480978611856699\n",
            "Train step - Step 1590, Loss 0.0027718706987798214\n",
            "Train epoch - Accuracy: 0.9577777777777777 Loss: 0.0025094283049493424 Corrects: 4741\n",
            "Starting epoch 42/70, LR = [2]\n",
            "Train step - Step 1600, Loss 0.00201245560310781\n",
            "Train step - Step 1610, Loss 0.004267151467502117\n",
            "Train step - Step 1620, Loss 0.0033173044212162495\n",
            "Train step - Step 1630, Loss 0.0026124189607799053\n",
            "Train epoch - Accuracy: 0.9547474747474748 Loss: 0.002630591897124594 Corrects: 4726\n",
            "Starting epoch 43/70, LR = [2]\n",
            "Train step - Step 1640, Loss 0.0022068291436880827\n",
            "Train step - Step 1650, Loss 0.0019792078528553247\n",
            "Train step - Step 1660, Loss 0.0028388649225234985\n",
            "Train step - Step 1670, Loss 0.0032222061417996883\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.0026474517041986637 Corrects: 4722\n",
            "Starting epoch 44/70, LR = [2]\n",
            "Train step - Step 1680, Loss 0.0027048198971897364\n",
            "Train step - Step 1690, Loss 0.0017218781867995858\n",
            "Train step - Step 1700, Loss 0.0015132860280573368\n",
            "Train step - Step 1710, Loss 0.0018845739541575313\n",
            "Train epoch - Accuracy: 0.9575757575757575 Loss: 0.0026244690511940103 Corrects: 4740\n",
            "Starting epoch 45/70, LR = [2]\n",
            "Train step - Step 1720, Loss 0.0015919822035357356\n",
            "Train step - Step 1730, Loss 0.0024437904357910156\n",
            "Train step - Step 1740, Loss 0.0026229482609778643\n",
            "Train step - Step 1750, Loss 0.0015589690301567316\n",
            "Train epoch - Accuracy: 0.9628282828282828 Loss: 0.002280803696073667 Corrects: 4766\n",
            "Starting epoch 46/70, LR = [2]\n",
            "Train step - Step 1760, Loss 0.001872871071100235\n",
            "Train step - Step 1770, Loss 0.002441286575049162\n",
            "Train step - Step 1780, Loss 0.002585819223895669\n",
            "Train step - Step 1790, Loss 0.0035228352062404156\n",
            "Train epoch - Accuracy: 0.961010101010101 Loss: 0.002380463864202752 Corrects: 4757\n",
            "Starting epoch 47/70, LR = [2]\n",
            "Train step - Step 1800, Loss 0.0020989759359508753\n",
            "Train step - Step 1810, Loss 0.003919144626706839\n",
            "Train step - Step 1820, Loss 0.0020204433239996433\n",
            "Train step - Step 1830, Loss 0.0045059784315526485\n",
            "Train epoch - Accuracy: 0.9517171717171717 Loss: 0.0028343158089226546 Corrects: 4711\n",
            "Starting epoch 48/70, LR = [2]\n",
            "Train step - Step 1840, Loss 0.002331314841285348\n",
            "Train step - Step 1850, Loss 0.001597125781700015\n",
            "Train step - Step 1860, Loss 0.0038759601302444935\n",
            "Train step - Step 1870, Loss 0.001497387420386076\n",
            "Train epoch - Accuracy: 0.9567676767676768 Loss: 0.002538800496194098 Corrects: 4736\n",
            "Starting epoch 49/70, LR = [2]\n",
            "Train step - Step 1880, Loss 0.0025786650367081165\n",
            "Train step - Step 1890, Loss 0.0016347133787348866\n",
            "Train step - Step 1900, Loss 0.002028403338044882\n",
            "Train step - Step 1910, Loss 0.002807632787153125\n",
            "Train epoch - Accuracy: 0.953939393939394 Loss: 0.00265680647869077 Corrects: 4722\n",
            "Starting epoch 50/70, LR = [0.08000000000000002]\n",
            "Train step - Step 1920, Loss 0.003049207152798772\n",
            "Train step - Step 1930, Loss 0.0013552563032135367\n",
            "Train step - Step 1940, Loss 0.0009222569642588496\n",
            "Train epoch - Accuracy: 0.9781818181818182 Loss: 0.001524002111206452 Corrects: 4842\n",
            "Starting epoch 51/70, LR = [0.4]\n",
            "Train step - Step 1950, Loss 0.0011427189456298947\n",
            "Train step - Step 1960, Loss 0.0004892530268989503\n",
            "Train step - Step 1970, Loss 0.0004891370190307498\n",
            "Train step - Step 1980, Loss 0.0005353307351469994\n",
            "Train epoch - Accuracy: 0.9915151515151515 Loss: 0.000904335527577334 Corrects: 4908\n",
            "Starting epoch 52/70, LR = [0.4]\n",
            "Train step - Step 1990, Loss 0.001304435427300632\n",
            "Train step - Step 2000, Loss 0.0003319570969324559\n",
            "Train step - Step 2010, Loss 0.0007611496839672327\n",
            "Train step - Step 2020, Loss 0.0009016010444611311\n",
            "Train epoch - Accuracy: 0.9921212121212121 Loss: 0.000773922231217677 Corrects: 4911\n",
            "Starting epoch 53/70, LR = [0.4]\n",
            "Train step - Step 2030, Loss 0.0009955313289538026\n",
            "Train step - Step 2040, Loss 0.0006471441593021154\n",
            "Train step - Step 2050, Loss 0.0008473115158267319\n",
            "Train step - Step 2060, Loss 0.0004753855464514345\n",
            "Train epoch - Accuracy: 0.9933333333333333 Loss: 0.0006699935945146012 Corrects: 4917\n",
            "Starting epoch 54/70, LR = [0.4]\n",
            "Train step - Step 2070, Loss 0.0011530376505106688\n",
            "Train step - Step 2080, Loss 0.00046316938824020326\n",
            "Train step - Step 2090, Loss 0.0006326693692244589\n",
            "Train step - Step 2100, Loss 0.0004764024924952537\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0006237018776521313 Corrects: 4927\n",
            "Starting epoch 55/70, LR = [0.4]\n",
            "Train step - Step 2110, Loss 0.00042017720988951623\n",
            "Train step - Step 2120, Loss 0.0005962526774965227\n",
            "Train step - Step 2130, Loss 0.00027733753086067736\n",
            "Train step - Step 2140, Loss 0.0004110837762709707\n",
            "Train epoch - Accuracy: 0.996969696969697 Loss: 0.0004987354847282698 Corrects: 4935\n",
            "Starting epoch 56/70, LR = [0.4]\n",
            "Train step - Step 2150, Loss 0.0005121348658576608\n",
            "Train step - Step 2160, Loss 0.0006180790369398892\n",
            "Train step - Step 2170, Loss 0.0007912802393548191\n",
            "Train step - Step 2180, Loss 0.00041013507870957255\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.00050615660073071 Corrects: 4927\n",
            "Starting epoch 57/70, LR = [0.4]\n",
            "Train step - Step 2190, Loss 0.00034283087006770074\n",
            "Train step - Step 2200, Loss 0.0004562288522720337\n",
            "Train step - Step 2210, Loss 0.00036397462827153504\n",
            "Train step - Step 2220, Loss 0.0007146531715989113\n",
            "Train epoch - Accuracy: 0.9965656565656565 Loss: 0.0004853821160845609 Corrects: 4933\n",
            "Starting epoch 58/70, LR = [0.4]\n",
            "Train step - Step 2230, Loss 0.0004853098653256893\n",
            "Train step - Step 2240, Loss 0.0003888392820954323\n",
            "Train step - Step 2250, Loss 0.0009261009399779141\n",
            "Train step - Step 2260, Loss 0.0002309097326360643\n",
            "Train epoch - Accuracy: 0.9953535353535353 Loss: 0.0005513920603000155 Corrects: 4927\n",
            "Starting epoch 59/70, LR = [0.4]\n",
            "Train step - Step 2270, Loss 0.00028519643819890916\n",
            "Train step - Step 2280, Loss 0.00040480506140738726\n",
            "Train step - Step 2290, Loss 0.0003534035349730402\n",
            "Train step - Step 2300, Loss 0.0007817688747309148\n",
            "Train epoch - Accuracy: 0.9957575757575757 Loss: 0.0005002285018234015 Corrects: 4929\n",
            "Starting epoch 60/70, LR = [0.4]\n",
            "Train step - Step 2310, Loss 0.0002988077758345753\n",
            "Train step - Step 2320, Loss 0.0005854006740264595\n",
            "Train step - Step 2330, Loss 0.0005189475486986339\n",
            "Train epoch - Accuracy: 0.9963636363636363 Loss: 0.0004612998603349269 Corrects: 4932\n",
            "Starting epoch 61/70, LR = [0.4]\n",
            "Train step - Step 2340, Loss 0.00025215381174348295\n",
            "Train step - Step 2350, Loss 0.0003074023697990924\n",
            "Train step - Step 2360, Loss 0.0001904155215015635\n",
            "Train step - Step 2370, Loss 0.00041095251799561083\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00037692177044745123 Corrects: 4940\n",
            "Starting epoch 62/70, LR = [0.4]\n",
            "Train step - Step 2380, Loss 0.00036619562888517976\n",
            "Train step - Step 2390, Loss 0.0008386079571209848\n",
            "Train step - Step 2400, Loss 0.0002938139659818262\n",
            "Train step - Step 2410, Loss 0.00033113188692368567\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.00038848234839135347 Corrects: 4941\n",
            "Starting epoch 63/70, LR = [0.4]\n",
            "Train step - Step 2420, Loss 0.000498841458465904\n",
            "Train step - Step 2430, Loss 0.0008121086284518242\n",
            "Train step - Step 2440, Loss 0.0003750960750039667\n",
            "Train step - Step 2450, Loss 0.0006187772378325462\n",
            "Train epoch - Accuracy: 0.9967676767676767 Loss: 0.00039841473155485634 Corrects: 4934\n",
            "Starting epoch 64/70, LR = [0.016000000000000004]\n",
            "Train step - Step 2460, Loss 0.0004096418560948223\n",
            "Train step - Step 2470, Loss 0.0005969117628410459\n",
            "Train step - Step 2480, Loss 0.00048726052045822144\n",
            "Train step - Step 2490, Loss 0.0003386599419172853\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00035699070545355555 Corrects: 4942\n",
            "Starting epoch 65/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2500, Loss 0.00017369339184369892\n",
            "Train step - Step 2510, Loss 0.00025301225832663476\n",
            "Train step - Step 2520, Loss 0.0003167487739119679\n",
            "Train step - Step 2530, Loss 0.0002679734898265451\n",
            "Train epoch - Accuracy: 0.9991919191919192 Loss: 0.0002987217666661235 Corrects: 4946\n",
            "Starting epoch 66/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2540, Loss 0.0003443145251367241\n",
            "Train step - Step 2550, Loss 0.0004949638387188315\n",
            "Train step - Step 2560, Loss 0.00033779567456804216\n",
            "Train step - Step 2570, Loss 0.0002102079160977155\n",
            "Train epoch - Accuracy: 0.9981818181818182 Loss: 0.00036879799516890385 Corrects: 4941\n",
            "Starting epoch 67/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2580, Loss 0.00023593723017256707\n",
            "Train step - Step 2590, Loss 0.0009111301624216139\n",
            "Train step - Step 2600, Loss 0.00027571822283789515\n",
            "Train step - Step 2610, Loss 0.00022564578102901578\n",
            "Train epoch - Accuracy: 0.997979797979798 Loss: 0.00033816600050259795 Corrects: 4940\n",
            "Starting epoch 68/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2620, Loss 0.00025909554096870124\n",
            "Train step - Step 2630, Loss 0.00024250087153632194\n",
            "Train step - Step 2640, Loss 0.00038425123784691095\n",
            "Train step - Step 2650, Loss 0.00025855202693492174\n",
            "Train epoch - Accuracy: 0.9985858585858586 Loss: 0.00032810509411825077 Corrects: 4943\n",
            "Starting epoch 69/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2660, Loss 0.0002392565947957337\n",
            "Train step - Step 2670, Loss 0.000331090617692098\n",
            "Train step - Step 2680, Loss 0.00037770465132780373\n",
            "Train step - Step 2690, Loss 0.00021094211842864752\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.0003146062893416695 Corrects: 4942\n",
            "Starting epoch 70/70, LR = [0.08000000000000002]\n",
            "Train step - Step 2700, Loss 0.00031801272416487336\n",
            "Train step - Step 2710, Loss 0.00021011776698287576\n",
            "Train step - Step 2720, Loss 0.00018526057829149067\n",
            "Train epoch - Accuracy: 0.9983838383838384 Loss: 0.00035551808720379316 Corrects: 4942\n",
            "Training finished in 245.86927103996277 seconds\n",
            "EVALUATION:  0.96 0.0029134987853467464\n",
            "TEST GROUP:  0.898\n",
            "TEST ALL:  0.0898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BCQoMhtWDJH",
        "colab_type": "text"
      },
      "source": [
        "**Results fine tuning (catastrophic learning)**<br>\n",
        "What we expect is a dramatic drop in the perfomances with repsect to the Joint Training and the incapacity to learn new things without forgetting the old ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz",
        "colab_type": "code",
        "outputId": "ef78d58c-5bd4-46df-9adb-27b5def3dc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 786
        }
      },
      "source": [
        "method = \"finetuning\"\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABI8AAAG5CAYAAAAH7hQVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7itZV0v/O9PlgSoeYilKaDYFg/oTlQiTbeaWIEHyEMK5ancorswbbsrq73ZyPu2387mW5Thzq15QqA0NPIQmpYpcfDEQQoNBURFBVFIOfjbf4xn6WQ677XmRMYac671+VzXvNZ4nnHPZ3zHeNbiWuvLfd+zujsAAAAAsJJbLToAAAAAAOuX8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgHATqCqfqaq3nULXevvq+o/3xLXYj6q6ryqevQqx3ZV3WvOkQCADUx5BAA7iKp6RFX9U1V9paq+XFUfqKofSpLufkN3//g6yLhrVR1TVRdW1TVVdVlV/W1VLTxbklTV/avqXdPnd1VVnV1Vj1t0rq2pqtdU1f+79Fx337+7//4Wfo0bququt9Q1AYCNQ3kEADuAqvreJG9P8kdJ7pRkryQvS/KNReZawSlJDk/yrCR3THLPJK9I8viVBlfVpu0XLUnytiTvTvL9Se6c5BeTXL2dM6wrVXWbJE9J8pUkz9jOr7297z8AsALlEQDsGO6dJN39pu6+sbv/vbvf1d0fS5Kqek5V/eOWwdNSpRdU1b9OM2yOr6qantulqn6/qr5YVf9WVUdP41f8h3xV/VxVXVBVV1bVO6vqHoNxj03yY0kO7+4zuvu66esd3f2iJeMurqpfraqPJbmmqjZV1WHTUqyrpmVz91v2Xu615PhbM3Gq6tFVdWlV/fr0fi6uqp8Z5NszszLrVUuyfaC7l35uT6iqj0w5/qmqfnDJcw+qqnOq6qtV9eaqOnFJjpt8/stzV9X3VNXvVdVnqurzVfXKqtp92Xt4SVV9oaour6qfnZ47KsnPJPmVqvpaVb1tyWf42OnxQVX1wSnz5VX1x1W160qfwcBTklyV5Lgkz172Hu5UVf+nqj473f+3Lnnu8OmzurqqPllVhyzPNh0fW1Wvnx7vO30uz62qzyR5z3T+5Kr63DSr7v1Vdf8l37/79Pv109Pz/zid+5uqeuGyvB+rqiet4b0DAFEeAcCO4l+S3FhVr62qQ6vqjqv4nick+aEkP5jkaUl+Yjr/vCSHJjkgyYOT/OToAlV1eJJfT/LkJJuT/EOSNw2GPzbJGd196SqyHZnZbKQ7JPmB6Zovnl7jtCRvW0MB8v1J9sxsNtazk5xQVfdZYdyXklyU5PVV9ZNVdZelT1bVg5K8Osnzk3xfkj9LcupU/Oya5K1JXpfZzK+TMytdVuu3MisAD0hyrynrMcvew+2n889NcnxV3bG7T0jyhiS/09237e4nrnDtG5P80vQZPCzJwUl+fg3Znp3Z539ikvtW1UOWPPe6JHskuX9mM7VenswKqyR/keSXM7uHj0xy8Rpe81FJ7pdv/5782yT7Ta9xTmbveYvfS/KQJD+S2Wf/K0m+meS1WTJTqqoemNnn9zdryAEARHkEADuE7r46ySOSdJJXJbmiqk5dXoAs81vdfVV3fybJezMrLpJZkfSK7r60u6/MrNgYeUGS/6+7L+juG5L8ryQHDGYf7Znkc1sOplkrV02zRb6+bOz/392XdPe/J3l6kr/p7nd39/WZlQW7Z1YWrNb/6O5vdPf7MisPnrZ8QHd3kh/NrOT4/SSXT7Nc9puGHJXkz6ZZUzd292szWxb40Onr1kn+sLuv7+5Tkpy5mmBVVdO1f6m7v9zdX83sczxiybDrkxw3Xfu0JF9LslIB9h26++zu/lB339DdF2dWej1qldnuntln8sbu/nyS0zNbcpia7X90aJIXdPeVU7b3Td/63CSvnu7ZN7v7su7+xGpec3Jsd18z3f9096u7+6vd/Y0kxyZ5YFXdvqpuleTnkrxoeo0bu/ufpnGnJrn3kvv3zCRv7u7r1pADAIjyCAB2GFOB85zu3jvJA5LcLckfbuVbPrfk8bVJbjs9vluSS5Y8t/TxcvdI8oqpBLoqyZeTVGYzPJb7UpJvbbg8FSV3yGzWyPcsG7v0Ne+W5NNLvu+b0/MrvcZKruzua5Ycf3q65neYCrOju/s/TO/tmsxm0GQ6fsmW9zq9332ma90tyWVTAbX0dVZjc2azd85ect13TOe3+NJUzm2x9H5tVVXdu6rePi37ujqzYmrPVWZ7ZpILuvsj0/Ebkvx0Vd06s/f+5algXG6fJJ9c5Wus5Fv3v2bLKH9rWvp2db49g2nP6Wu3lV6ru7+e5M1JnjGVTEdmNlMKAFgj5REA7ICmWR6vyaxEWqvLk+y95HifrYy9JMnzu/sOS7527+5/WmHs6Ul+qKr2XuG55ZaWMJ/NrLhJ8q2ZOvskuWw6dW1m5csW37/sWnes2abPW9x9uubWA3RfkuT4fPszvCTJby57r3t095sy+8z2mrItfZ0trlmasaqWZvxikn9Pcv8l1719d6+qHMpNP6uV/GmSTyTZr7u/N7NlhrX1b/mWZyX5gal4+lySP8issHlcZp/HnarqDit83yVJ/sPgmjf5LPKd9yu56Xv66cw2WX9sZkv39p3OV2af3de38lqvzWxPqIOTXNvdHxyMAwC2QnkEADuAqrrvtKHy3tPxPpnNtPjQzbjcSUleVFV7TcXAr25l7CuT/NqWDYynpUQ/tdLA7n5XZsvj3lpVP1xVu04zWB66ijyPr6qDp/EvyWy52JaC6iOZzYbZZdqUeaUlWS+bXu8/ZbbX08nLB1TVHavqZVV1r6q6Vc020P65fPszfFWSF0zZq6puU1WPr6rbJflgkhuS/GJV3bqqnpzkoCWX/2iS+1fVAVW1W2ZLr7Z8Lt+crv3yqrrzlGWvqvqJrM7nM9sXauR2mf3EuK9V1X2T/JfVXLSqHpZZKXNQZksaD8isSHtjkmd19+WZ7UX0J9Nnd+uqeuT07X+e5Gene3ar6f3cd3ruI0mOmMYfmOSp24hyu8zu95cyK53+15Ynps/u1Un+oKruNv0eeFhVfc/0/Acz2//o92PWEQDcbMojANgxfDXJDyc5o6quyazwODezomWtXpXkXUk+luTDmW1QfUNmGy/fRHe/JclvJzlxWlJ0bmb74Iw8Kcnbk7w+s5/g9W+ZzQwZFiXdfWFmGx//UWYzTZ6Y5IlL9q550XTuqulab112ic8luTKz2UZvyGyPnpX237kus1ktf5dZ2XJuZqXFc6YcZ2W2mfgfT9e7aMlz12W2afhzMlu69/Qkf7XkPfxLZj+t7O+S/GuSm/zktcwKuouSfGj6HP8uq9zTKLOiZv9pydvy954k/y2z2TtfzezevnmV1312kr/u7o939+e2fCV5RZInVNWdMlvWdn1mM5u+kNmm5unuf07ys5ltoP2VJO/Lt2eP/Y/MSqkrk7wsszJqa/4isyWAlyU5P99ZiP63JB/PbI+pL2f2+/FWy77/P2b2ew4AuBnqpkvzAQBuqqoOTfLK7l5pE+x1raoeneT10z5Q2/u1X5Pk0u7+79v7tfm2qnpWkqO6+xGLzgIAG5WZRwDATVTV7lX1uKraVFV7JfmfSd6y6FywVlW1R5KfT3LCorMAwEamPAIAlqvMlhNdmdmytQuSHLPQRLBG055RV2S2J9S2lsYBAFth2RoAAAAAQ2YeAQAAADC0adEB1mrPPffsfffdd9ExAAAAAHYYZ5999he7e/NKz2248mjffffNWWedtegYAAAAADuMqvr06DnL1gAAAAAYUh4BAAAAMKQ8AgAAAGBIeQQAAADAkPIIAAAAgCHlEQAAAABDyiMAAAAAhpRHAAAAAAwpjwAAAAAYUh4BAAAAMKQ8AgAAAGBIeQQAAADAkPIIAAAAgCHlEQAAAABDyiMAAAAAhpRHAAAAAAxtWnQAAACARTn22GMXHWGn4HOGjc3MIwAAAACGlEcAAAAADFm2xrr1meP+46Ij7PDufszHFx0BAACAdc7MIwAAAACGzDwCAAAAtrsHnvLORUfY4X30qT9xi1zHzCMAAAAAhpRHAAAAAAxZtgYAsA785jOeuugIO4XfeP0pi44AABuOmUcAAAAADJl5BMBNvO+Rj1p0hB3eo97/vkVHAACAVVMeAQDAd+mC33zPoiPs8O73G49ZdATWoZNOPmjREXZ4T/upf150BNYBy9YAAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ5sWHQDY8Tz8jx6+6Ag7hQ+88AOLjgAAAOwEzDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADG1adAAA4Jbzxy9526Ij7PCO/v0nLjoCAMB2ZeYRAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMDQXMujqjqkqi6sqouq6qUrPH/3qnpvVX24qj5WVY+bZx4AAAAA1mZu5VFV7ZLk+CSHJtk/yZFVtf+yYf89yUnd/aAkRyT5k3nlAQAAAGDt5jnz6KAkF3X3p7r7uiQnJjl82ZhO8r3T49sn+ewc8wAAAACwRvMsj/ZKcsmS40unc0sdm+QZVXVpktOSvHClC1XVUVV1VlWddcUVV8wjKwAAAAArWPSG2UcmeU13753kcUleV1Xfkam7T+juA7v7wM2bN2/3kAAAAAA7q3mWR5cl2WfJ8d7TuaWem+SkJOnuDybZLcmec8wEAAAAwBrMszw6M8l+VXXPqto1sw2xT1025jNJDk6SqrpfZuWRdWkAAAAA68TcyqPuviHJ0UnemeSCzH6q2nlVdVxVHTYNe0mS51XVR5O8KclzurvnlQkAAACAtdk0z4t392mZbYS99NwxSx6fn+Th88wAAAAAwM236A2zAQAAAFjH5jrzaNEe8st/segIO4Wzf/dZi44AAAAAzImZRwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAAAAAIaURwAAAAAMKY8AAAAAGFIeAQAAADCkPAIAAABgSHkEAAAAwNBcy6OqOqSqLqyqi6rqpYMxT6uq86vqvKp64zzzAAAAALA2m+Z14araJcnxSX4syaVJzqyqU7v7/CVj9kvya0ke3t1XVtWd55UHAAAAgLWb58yjg5Jc1N2f6u7rkpyY5PBlY56X5PjuvjJJuvsLc8wDAAAAwBrNszzaK8klS44vnc4tde8k966qD1TVh6rqkJUuVFVHVdVZVXXWFVdcMae4AAAAACy36A2zNyXZL8mjkxyZ5FVVdYflg7r7hO4+sLsP3Lx583aOCAAAALDzmmd5dFmSfZYc7z2dW+rSJKd29/Xd/W9J/iWzMgkAAACAdWCe5dGZSfarqntW1a5Jjkhy6rIxb81s1lGqas/MlrF9ao6ZAAAAAFiDuZVH3X1DkqOTvDPJBUlO6u7zquq4qjpsGvbOJF+qqvOTvDfJL3f3l+aVCQAAAIC12TTPi3f3aUlOW3bumCWPO8l/nb4AAAAAWGcWvWE2AAAAAOuY8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABjaZnlUVU+sKiUTAAAAwE5oNaXQ05P8a1X9TlXdd96BAAAAAFg/tlkedfczkjwoySeTvKaqPlhVR1XV7eaeDgAAAICFWtVytO6+OskpSU5MctckT0pyTlW9cI7ZAAAAAFiw1ex5dFhVvSXJ3ye5dZKDuvvQJA9M8pL5xgMAAABgkTatYsxTkry8u9+/9GR3X1tVz51PLAAAAADWg9WUR8cmuXzLQVXtnuQu3X1xd58+r2AAAAAALN5q9jw6Ock3lxzfOJ0DAAAAYAe3mvJoU3dft+Vgerzr/CIBAAAAsF6spjy6oqoO23JQVYcn+eL8IgEAAACwXqxmz6MXJHlDVf1xkkpySZJnzTUVAAAAAOvCNsuj7v5kkodW1W2n46/NPRUAAAAA68JqZh6lqh6f5P5JdquqJEl3HzfHXAAAAACsA9vc86iqXpnk6UlemNmytZ9Kco855wIAAABgHVjNhtk/0t3PSnJld78sycOS3Hu+sQAAAABYD1ZTHn19+vXaqrpbkuuT3HV+kQAAAABYL1az59HbquoOSX43yTlJOsmr5poKAAAAgHVhq+VRVd0qyendfVWSv6yqtyfZrbu/sl3SAQAAALBQW1221t3fTHL8kuNvKI4AAAAAdh6r2fPo9Kp6SlXV3NMAAAAAsK6spjx6fpKTk3yjqq6uqq9W1dVzzgUAAADAOrDNDbO7+3bbIwgAAAAA6882y6OqeuRK57v7/bd8HAAAAADWk22WR0l+ecnj3ZIclOTsJI+ZSyIAAAAA1o3VLFt74tLjqtonyR/OLREAAAAA68ZqNsxe7tIk97ulgwAAAACw/qxmz6M/StLT4a2SHJDknHmGAgAAAGB9WM2eR2cteXxDkjd19wfmlAcAAACAdWQ15dEpSb7e3TcmSVXtUlV7dPe1840GAAAAwKKtZs+j05PsvuR49yR/N584AAAAAKwnqymPduvur205mB7vMb9IAAAAAKwXqymPrqmqB285qKqHJPn3+UUCAAAAYL1YzZ5HL05yclV9Nkkl+f4kT59rKgAAAADWhW2WR919ZlXdN8l9plMXdvf1840FAAAAwHqwzWVrVfULSW7T3ed297lJbltVPz//aAAAAAAs2mr2PHped1+15aC7r0zyvPlFAgAAAGC9WE15tEtV1ZaDqtolya7ziwQAAADAerGaDbPfkeTNVfVn0/Hzk/zt/CIBAAAAsF6spjz61SRHJXnBdPyxzH7iGgAAAAA7uG0uW+vubyY5I8nFSQ5K8pgkF8w3FgAAAADrwXDmUVXdO8mR09cXk7w5Sbr7R7dPNAAAAAAWbWvL1j6R5B+SPKG7L0qSqvql7ZIKAAAAgHVha8vWnpzk8iTvrapXVdXBSWor4wEAAADYwQzLo+5+a3cfkeS+Sd6b5MVJ7lxVf1pVP769AgIAAACwOKvZMPua7n5jdz8xyd5JPpzZT2ADAAAAYAe3zfJoqe6+srtP6O6D5xUIAAAAgPVjTeURAAAAADsX5REAAAAAQ3Mtj6rqkKq6sKouqqqXbmXcU6qqq+rAeeYBAAAAYG3mVh5V1S5Jjk9yaJL9kxxZVfuvMO52SV6U5Ix5ZQEAAADg5pnnzKODklzU3Z/q7uuSnJjk8BXG/T9JfjvJ1+eYBQAAAICbYZ7l0V5JLllyfOl07luq6sFJ9unuv9naharqqKo6q6rOuuKKK275pAAAAACsaGEbZlfVrZL8QZKXbGtsd5/Q3Qd294GbN2+efzgAAAAAksy3PLosyT5Ljveezm1xuyQPSPL3VXVxkocmOdWm2QAAAADrxzzLozOT7FdV96yqXZMckeTULU9291e6e8/u3re7903yoSSHdfdZc8wEAAAAwBrMrTzq7huSHJ3knUkuSHJSd59XVcdV1WHzel0AAAAAbjmb5nnx7j4tyWnLzh0zGPvoeWYBAAAAYO0WtmE2AAAAAOuf8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwNNfyqKoOqaoLq+qiqnrpCs//16o6v6o+VlWnV9U95pkHAAAAgLWZW3lUVbskOT7JoUn2T3JkVe2/bNiHkxzY3T+Y5JQkvzOvPAAAAACs3TxnHh2U5KLu/lR3X5fkxCSHLx3Q3e/t7munww8l2XuOeQAAAABYo3mWR3sluWTJ8aXTuZHnJvnblZ6oqqOq6qyqOuuKK664BSMCAAAAsDXrYsPsqnpGkgOT/O5Kz3f3Cd19YHcfuHnz5u0bDgAAAGAntmmO174syT5Ljveezt1EVT02yW8keVR3f2OOeQAAAABYo3nOPDozyX5Vdc+q2jXJEUlOXTqgqh6U5M+SHNbdX5hjFgAAAABuhrmVR919Q5Kjk7wzyQVJTuru86rquKo6bBr2u0lum+TkqvpIVZ06uBwAAAAACzDPZWvp7tOSnLbs3DFLHj92nq8PAAAAwHdnXWyYDQAAAMD6pDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMCQ8ggAAACAIeURAAAAAEPKIwAAAACGlEcAAAAADM21PKqqQ6rqwqq6qKpeusLz31NVb56eP6Oq9p1nHgAAAADWZm7lUVXtkuT4JIcm2T/JkVW1/7Jhz01yZXffK8nLk/z2vPIAAAAAsHbznHl0UJKLuvtT3X1dkhOTHL5szOFJXjs9PiXJwVVVc8wEAAAAwBpUd8/nwlVPTXJId//n6fiZSX64u49eMubcacyl0/EnpzFfXHato5IcNR3eJ8mFcwm9PuyZ5IvbHMV65N5tbO7fxub+bVzu3cbm/m1c7t3G5v5tbO7fxrWj37t7dPfmlZ7YtL2T3BzdfUKSExadY3uoqrO6+8BF52Dt3LuNzf3b2Ny/jcu929jcv43LvdvY3L+Nzf3buHbmezfPZWuXJdlnyfHe07kVx1TVpiS3T/KlOWYCAAAAYA3mWR6dmWS/qrpnVe2a5Igkpy4bc2qSZ0+Pn5rkPT2vdXQAAAAArNnclq119w1VdXSSdybZJcmru/u8qjouyVndfWqSP0/yuqq6KMmXMyuYdnY7xfK8HZR7t7G5fxub+7dxuXcbm/u3cbl3G5v7t7G5fxvXTnvv5rZhNgAAAAAb3zyXrQEAAACwwSmPAAAAABhSHq0TVfXqqvpCVZ276CysTVXtU1Xvrarzq+q8qnrRojOxelW1W1X9c1V9dLp/L1t0Jtamqnapqg9X1dsXnYW1qaqLq+rjVfWRqjpr0XlYvaq6Q1WdUlWfqKoLquphi87E6lTVfaY/c1u+rq6qFy86F6tXVb80/Z3l3Kp6U1XttuhMrE5VvWi6b+f5c7f+rfRv9Kq6U1W9u6r+dfr1jovMuD0pj9aP1yQ5ZNEhuFluSPKS7t4/yUOT/EJV7b/gTKzeN5I8prsfmOSAJIdU1UMXnIm1eVGSCxYdgpvtR7v7gO4+cNFBWJNXJHlHd983yQPjz+CG0d0XTn/mDoP8zyQAAAWrSURBVEjykCTXJnnLgmOxSlW1V5JfTHJgdz8gsx9M5IcObQBV9YAkz0tyUGb/3XxCVd1rsanYhtfkO/+N/tIkp3f3fklOn453CsqjdaK735/ZT5xjg+nuy7v7nOnxVzP7C/Rei03FavXM16bDW09ffpLABlFVeyd5fJL/vegssLOoqtsneWRmPzU33X1dd1+12FTcTAcn+WR3f3rRQViTTUl2r6pNSfZI8tkF52F17pfkjO6+trtvSPK+JE9ecCa2YvBv9MOTvHZ6/NokP7ldQy2Q8ghuQVW1b5IHJTljsUlYi2nZ00eSfCHJu7vb/ds4/jDJryT55qKDcLN0kndV1dlVddSiw7Bq90xyRZL/My0Z/d9VdZtFh+JmOSLJmxYdgtXr7suS/F6SzyS5PMlXuvtdi03FKp2b5D9V1fdV1R5JHpdknwVnYu3u0t2XT48/l+QuiwyzPSmP4BZSVbdN8pdJXtzdVy86D6vX3TdO0/f3TnLQNK2Yda6qnpDkC9199qKzcLM9orsfnOTQzJb8PnLRgViVTUkenORPu/tBSa7JTjRtf0dRVbsmOSzJyYvOwupN+6scnlmJe7ckt6mqZyw2FavR3Rck+e0k70ryjiQfSXLjQkPxXenuzk60YkF5BLeAqrp1ZsXRG7r7rxadh5tnWnbx3th/bKN4eJLDquriJCcmeUxVvX6xkViL6f+gp7u/kNmeKwctNhGrdGmSS5fM0jwlszKJjeXQJOd09+cXHYQ1eWySf+vuK7r7+iR/leRHFpyJVeruP+/uh3T3I5NcmeRfFp2JNft8Vd01SaZfv7DgPNuN8gi+S1VVme37cEF3/8Gi87A2VbW5qu4wPd49yY8l+cRiU7Ea3f1r3b13d++b2dKL93S3//u6QVTVbarqdlseJ/nxzKb0s8519+eSXFJV95lOHZzk/AVG4uY5MpasbUSfSfLQqtpj+jvowbFh/YZRVXeefr17ZvsdvXGxibgZTk3y7Onxs5P89QKzbFebFh2Amap6U5JHJ9mzqi5N8j+7+88Xm4pVeniSZyb5+LRvTpL8eneftsBMrN5dk7y2qnbJrFA/qbv9yHeYv7skecvs3z7ZlOSN3f2OxUZiDV6Y5A3T0qdPJfnZBedhDabC9seSPH/RWVib7j6jqk5Jck5mP/H3w0lOWGwq1uAvq+r7klyf5Bf8sIH1baV/oyf5rSQnVdVzk3w6ydMWl3D7qtkyPQAAAAD4TpatAQAAADCkPAIAAABgSHkEAAAAwJDyCAAAAIAh5REAAAAAQ8ojAIBtqKq7VNUbq+pTVXV2VX2wqp606FwAANuD8ggAYCuqqpK8Ncn7u/sHuvshSY5IsveycZsWkQ8AYN6quxedAQBg3aqqg5Mc092PWuG55yR5cpLbJtklyZOSvDrJDyS5NslR3f2xqjo2yde6+/em7zs3yROmy7wjydlJHpzkvCTP6u5r5/meAADWwswjAICtu3+Sc7by/IOTPHUql16W5MPd/YNJfj3JX6zi+vdJ8ifdfb8kVyf5+e8yLwDALUp5BACwBlV1fFV9tKrOnE69u7u/PD1+RJLXJUl3vyfJ91XV927jkpd09wemx6+frgEAsG4ojwAAtu68zGYXJUm6+xeSHJxk83TqmlVc44bc9O9duy15vHwPAXsKAADrivIIAGDr3pNkt6r6L0vO7TEY+w9JfiZJqurRSb7Y3VcnuThTAVVVD05yzyXfc/eqetj0+KeT/OMtlhwA4BZgw2wAgG2oqrsmeXmSH05yRWazjV6ZZPckB3b30dO4O2XlDbN3T/LXSfZKckaShyU5dLr8O5KcleQhSc5P8kwbZgMA64nyCABgQapq3yRv7+4HLDgKAMCQZWsAAAAADJl5BAAAAMCQmUcAAAAADCmPAAAAABhSHgEAAAAwpDwCAAAAYEh5BAAAAMDQ/wUyf0osJGeIiQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI",
        "colab_type": "code",
        "outputId": "aed68e56-9dcc-44bc-e9f3-2eab0f85e0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "\"\"\"num_classes_seen = 100\n",
        "dif_accuracies=printAccuracyDifference(net,old_accuracies, num_classes_seen)\n",
        "dif_accuracies\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.784, 0.0),\n",
              " (2, 0.902, 0.0),\n",
              " (3, 0.865, 0.0),\n",
              " (4, 0.904, 0.0),\n",
              " (5, 0.843, 0.0),\n",
              " (6, 0.891, 0.0),\n",
              " (7, 0.89, 0.0),\n",
              " (8, 0.918, 0.0),\n",
              " (9, 0.884, 0.0),\n",
              " (10, 0.888, 0.888)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjGRIqDtNQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}