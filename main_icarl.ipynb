{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_icarl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMSxfKS2gIKU",
        "colab_type": "code",
        "outputId": "cccbb1fe-d162-4a04-ac84-2254f7fe6734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\"\n",
        "# !pip install --upgrade wandb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiz6sjyFgQFs",
        "colab_type": "code",
        "outputId": "4cf95dfc-f298-4209-dd90-45074acff55a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "#from torchvision.models import alexnet # resnet18, resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ceByn7qgSCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "NUM_CLASSES = 10 \n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 2           # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 70       # Total number of training epochs (iterations over dataset)\n",
        "#STEP_SIZE = 49       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "LR_DECAY_EPOCHS = [48, 62]\n",
        "GAMMA = 0.1           # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "RANDOM_SEED = 30 # implement this! It will be more easy to do 3 different trials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Raa-DyJgUwV",
        "colab_type": "text"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxhdzcVgWmO",
        "colab_type": "code",
        "outputId": "17b120c1-e1e3-4bad-8c73-780251aa48e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 200, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/200)\u001b[K\rremote: Counting objects:   1% (2/200)\u001b[K\rremote: Counting objects:   2% (4/200)\u001b[K\rremote: Counting objects:   3% (6/200)\u001b[K\rremote: Counting objects:   4% (8/200)\u001b[K\rremote: Counting objects:   5% (10/200)\u001b[K\rremote: Counting objects:   6% (12/200)\u001b[K\rremote: Counting objects:   7% (14/200)\u001b[K\rremote: Counting objects:   8% (16/200)\u001b[K\rremote: Counting objects:   9% (18/200)\u001b[K\rremote: Counting objects:  10% (20/200)\u001b[K\rremote: Counting objects:  11% (22/200)\u001b[K\rremote: Counting objects:  12% (24/200)\u001b[K\rremote: Counting objects:  13% (26/200)\u001b[K\rremote: Counting objects:  14% (28/200)\u001b[K\rremote: Counting objects:  15% (30/200)\u001b[K\rremote: Counting objects:  16% (32/200)\u001b[K\rremote: Counting objects:  17% (34/200)\u001b[K\rremote: Counting objects:  18% (36/200)\u001b[K\rremote: Counting objects:  19% (38/200)\u001b[K\rremote: Counting objects:  20% (40/200)\u001b[K\rremote: Counting objects:  21% (42/200)\u001b[K\rremote: Counting objects:  22% (44/200)\u001b[K\rremote: Counting objects:  23% (46/200)\u001b[K\rremote: Counting objects:  24% (48/200)\u001b[K\rremote: Counting objects:  25% (50/200)\u001b[K\rremote: Counting objects:  26% (52/200)\u001b[K\rremote: Counting objects:  27% (54/200)\u001b[K\rremote: Counting objects:  28% (56/200)\u001b[K\rremote: Counting objects:  29% (58/200)\u001b[K\rremote: Counting objects:  30% (60/200)\u001b[K\rremote: Counting objects:  31% (62/200)\u001b[K\rremote: Counting objects:  32% (64/200)\u001b[K\rremote: Counting objects:  33% (66/200)\u001b[K\rremote: Counting objects:  34% (68/200)\u001b[K\rremote: Counting objects:  35% (70/200)\u001b[K\rremote: Counting objects:  36% (72/200)\u001b[K\rremote: Counting objects:  37% (74/200)\u001b[K\rremote: Counting objects:  38% (76/200)\u001b[K\rremote: Counting objects:  39% (78/200)\u001b[K\rremote: Counting objects:  40% (80/200)\u001b[K\rremote: Counting objects:  41% (82/200)\u001b[K\rremote: Counting objects:  42% (84/200)\u001b[K\rremote: Counting objects:  43% (86/200)\u001b[K\rremote: Counting objects:  44% (88/200)\u001b[K\rremote: Counting objects:  45% (90/200)\u001b[K\rremote: Counting objects:  46% (92/200)\u001b[K\rremote: Counting objects:  47% (94/200)\u001b[K\rremote: Counting objects:  48% (96/200)\u001b[K\rremote: Counting objects:  49% (98/200)\u001b[K\rremote: Counting objects:  50% (100/200)\u001b[K\rremote: Counting objects:  51% (102/200)\u001b[K\rremote: Counting objects:  52% (104/200)\u001b[K\rremote: Counting objects:  53% (106/200)\u001b[K\rremote: Counting objects:  54% (108/200)\u001b[K\rremote: Counting objects:  55% (110/200)\u001b[K\rremote: Counting objects:  56% (112/200)\u001b[K\rremote: Counting objects:  57% (114/200)\u001b[K\rremote: Counting objects:  58% (116/200)\u001b[K\rremote: Counting objects:  59% (118/200)\u001b[K\rremote: Counting objects:  60% (120/200)\u001b[K\rremote: Counting objects:  61% (122/200)\u001b[K\rremote: Counting objects:  62% (124/200)\u001b[K\rremote: Counting objects:  63% (126/200)\u001b[K\rremote: Counting objects:  64% (128/200)\u001b[K\rremote: Counting objects:  65% (130/200)\u001b[K\rremote: Counting objects:  66% (132/200)\u001b[K\rremote: Counting objects:  67% (134/200)\u001b[K\rremote: Counting objects:  68% (136/200)\u001b[K\rremote: Counting objects:  69% (138/200)\u001b[K\rremote: Counting objects:  70% (140/200)\u001b[K\rremote: Counting objects:  71% (142/200)\u001b[K\rremote: Counting objects:  72% (144/200)\u001b[K\rremote: Counting objects:  73% (146/200)\u001b[K\rremote: Counting objects:  74% (148/200)\u001b[K\rremote: Counting objects:  75% (150/200)\u001b[K\rremote: Counting objects:  76% (152/200)\u001b[K\rremote: Counting objects:  77% (154/200)\u001b[K\rremote: Counting objects:  78% (156/200)\u001b[K\rremote: Counting objects:  79% (158/200)\u001b[K\rremote: Counting objects:  80% (160/200)\u001b[K\rremote: Counting objects:  81% (162/200)\u001b[K\rremote: Counting objects:  82% (164/200)\u001b[K\rremote: Counting objects:  83% (166/200)\u001b[K\rremote: Counting objects:  84% (168/200)\u001b[K\rremote: Counting objects:  85% (170/200)\u001b[K\rremote: Counting objects:  86% (172/200)\u001b[K\rremote: Counting objects:  87% (174/200)\u001b[K\rremote: Counting objects:  88% (176/200)\u001b[K\rremote: Counting objects:  89% (178/200)\u001b[K\rremote: Counting objects:  90% (180/200)\u001b[K\rremote: Counting objects:  91% (182/200)\u001b[K\rremote: Counting objects:  92% (184/200)\u001b[K\rremote: Counting objects:  93% (186/200)\u001b[K\rremote: Counting objects:  94% (188/200)\u001b[K\rremote: Counting objects:  95% (190/200)\u001b[K\rremote: Counting objects:  96% (192/200)\u001b[K\rremote: Counting objects:  97% (194/200)\u001b[K\rremote: Counting objects:  98% (196/200)\u001b[K\rremote: Counting objects:  99% (198/200)\u001b[K\rremote: Counting objects: 100% (200/200)\u001b[K\rremote: Counting objects: 100% (200/200), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 200 (delta 91), reused 188 (delta 79), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (200/200), 3.65 MiB | 27.29 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjIXkQbKgZH3",
        "colab_type": "code",
        "outputId": "60618e4f-b5b0-43e8-e25d-54da6851bb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-23 09:50:12--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  76.6MB/s    in 2.1s    \n",
            "\n",
            "2020-05-23 09:50:14 (76.6 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnOcQlG_ga8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.Pad(4),         # Add padding\n",
        "                                      transforms.RandomCrop(32), # Crops a random squares of the image  \n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
        "                                      ])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                 \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHXbDzgjgk_B",
        "colab_type": "code",
        "outputId": "74297c37-a1e9-4b5e-da78-9c50e23f176f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85q6ZMLgsC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgY-syfF3WRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=30)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsFyMkAyguQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJcPeH0cgxN5",
        "colab_type": "code",
        "outputId": "e72c15d4-e51b-4b96-d280-dced17b799b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "# to upd\n",
        "from Cifar100.resnet import resnet34\n",
        "\n",
        "def getResNet34(output_size):\n",
        "    net = resnet34(num_classes=output_size)\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet34(10)\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "    return optimizer, scheduler\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# to upd\\nfrom Cifar100.resnet import resnet34\\n\\ndef getResNet34(output_size):\\n    net = resnet34(num_classes=output_size)\\n    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\\n\\n    criterion = nn.CrossEntropyLoss()\\n    parameters_to_optimize = net.parameters()\\n    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\\n\\n    return net, criterion, optimizer, scheduler\\n\\ndef addOutputs(net, num):\\n    net.addOutputNodes(num)\\n\\ndef getNet():\\n    return getResNet34(10)\\n\\ndef getSchedulerOptimizer(net):\\n    parameters_to_optimize = net.parameters()\\n    optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\\n    return optimizer, scheduler'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axANZYKXg6wn",
        "colab_type": "text"
      },
      "source": [
        "**Exemplars management**<br>\n",
        "From iCaRL. We have an exemplar set for each class that we have seen so far. The cardinality of each exemplar set is constant and it is equal, at any time, to m = K/t. Where K is a constraint equal to the amount of memory we're allocating for the exemplars and t is the number of classes that has been seen so far. Implementing iCaRL, whenever a group of (10) classes is trained, it is trained on the train data for those classes (as before) + the current exemplars sets.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx0Woq8uhXyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# default params\n",
        "\n",
        "K = 2000\n",
        "total_classes = 100\n",
        "classes_group = 10\n",
        "\n",
        "from Cifar100.icarl_model import ICaRL\n",
        "\n",
        "# to upd\n",
        "icarl = ICaRL(2048, 1)\n",
        "#icarl.cuda() # is it useful?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wupANuY0g1pn",
        "colab_type": "code",
        "outputId": "7686e033-118c-4f0e-ebb1-50dae1488f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "def incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, K):\n",
        "    \n",
        "    train_set = None\n",
        "    test_set = None\n",
        "\n",
        "    # exemplars new params => embedded in the model\n",
        "    #classes_seen = 0 # number of classes seen so far (useful in the computation of the exemplar sets cardinality)\n",
        "    #tot_num_classes = 100 \n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "\n",
        "        #if train_set is None:\n",
        "        #    train_set = train_subset\n",
        "        # else:\n",
        "        #    train_set = joinSubsets(train_dataset, [train_set, train_subset])\n",
        "        #optimizer, scheduler = getSchedulerOptimizer(net) # Should this be updated????????\n",
        "\n",
        "        # not used yet\n",
        "        #train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        #val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "        #test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "\n",
        "        ####### EXEMPLARS MANAGEMENT (following alg. 2,3,4,5 on icarl paper) ##################\n",
        "        # compute the cardinality of each exemplar set\n",
        "        \n",
        "        new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        # 1 - update representation of the net \n",
        "        # alg. 3 icarl\n",
        "        # (here the trainset will be augmented with the exemplars too)\n",
        "        # (here the classes are incremented too)\n",
        "        # @todo\n",
        "        icarl.update_representation(train_subset, new_classes_examined)\n",
        "\n",
        "        # 2 - update m (number of images per class in the exemplar set corresponding to that class)\n",
        "        m = K/icarl.n_classes\n",
        "\n",
        "        # 3 - reduce exemplar set for all the previously seen classes\n",
        "        # alg.5 icarl\n",
        "        icarl.reduce_exemplar_sets(m)\n",
        "\n",
        "        # retrieve the 10 classes in the current subset\n",
        "        # NBBBB. Here there will be exemplars too! (if i do not want use new_classes_examined)\n",
        "        classes_current_subset = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        # 4 - construct the exemplar set for the new classes\n",
        "        for y in classes_current_subset: # for each class in the current subset\n",
        "          print(\"Constructing exemplar set for class-%d...\" %(y))\n",
        "          \n",
        "          # extract all the imgs in the train subset that are linked to this class\n",
        "          images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data'] #they're TENSORS NOT IMAGES (the conversion will be done later)         \n",
        "          imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "          class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "\n",
        "          # alg. 4 icarl\n",
        "          icarl.construct_exemplar_set(class_train_subset,m, eval_transform) # why eval? ref: https://github.com/donlee90/icarl/blob/master/main.py\n",
        "\n",
        "        # update the num classes seen so far\n",
        "        icarl.n_known = icarl.n_classes #n_classes is incremented in 1: updateRepresentation\n",
        "\n",
        "        # start classifier ....\n",
        "\n",
        "        # update the train-set => in update representation\n",
        "\n",
        "    \n",
        "\n",
        "K = 2000 # total amount of memory we allocate for exemplars\n",
        "incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, K)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0a2cac2d13a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;31m# total amount of memory we allocate for exemplars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mincrementalTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micarl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-0a2cac2d13a2>\u001b[0m in \u001b[0;36mincrementalTraining\u001b[0;34m(icarl, train_subsets, val_subsets, test_subsets, eval_transform, K)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# (here the classes are incremented too)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# @todo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0micarl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_classes_examined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 2 - update m (number of images per class in the exemplar set corresponding to that class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cifar100/icarl_model.py\u001b[0m in \u001b[0;36mupdate_representation\u001b[0;34m(self, dataset, new_classes)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#CHECK IF THIS IS OK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n\u001b[1;32m    152\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:47"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_B01Oa82wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}