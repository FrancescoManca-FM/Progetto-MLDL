{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_icarl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/master/main_icarl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Tkq4Z64NfD",
        "colab_type": "code",
        "outputId": "88af2f81-d5a8-48aa-92a5-aadab8c21fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "  Following the iCaRL paper specifications.\n",
        "  ...documentation ...\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Following the iCaRL paper specifications.\\n  ...documentation ...\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMSxfKS2gIKU",
        "colab_type": "code",
        "outputId": "a6a85079-cdb3-436c-ed5f-c01fa2ad50b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\"\n",
        "# !pip install --upgrade wandb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiz6sjyFgQFs",
        "colab_type": "code",
        "outputId": "d0c5da12-b176-4264-ae64-d12211cbf25a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BToWlSKc4km7",
        "colab_type": "code",
        "outputId": "643f5715-352c-4f4e-e435-050c355a58e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 311, done.\u001b[K\n",
            "remote: Counting objects: 100% (311/311), done.\u001b[K\n",
            "remote: Compressing objects: 100% (213/213), done.\u001b[K\n",
            "remote: Total 2043 (delta 167), reused 226 (delta 89), pack-reused 1732\u001b[K\n",
            "Receiving objects: 100% (2043/2043), 13.67 MiB | 16.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1222/1222), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Raa-DyJgUwV",
        "colab_type": "text"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTxhdzcVgWmO",
        "colab_type": "code",
        "outputId": "f70058f9-b229-4633-be7c-f8f367da28f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}/cifar-100-python'.format(DATA_DIR)):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-12 12:25:14--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz.11’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  22.4MB/s    in 6.6s    \n",
            "\n",
            "2020-06-12 12:25:21 (24.4 MB/s) - ‘cifar-100-python.tar.gz.11’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjIXkQbKgZH3",
        "colab_type": "code",
        "outputId": "dcef5685-e399-46ee-9942-7d1e3a9a15b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from Cifar100 import utils\n",
        "\n",
        "\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = dictHyperparams[\"SEED\"]\n",
        "\n",
        "# icarl params\n",
        "herding = True # if false random exemplars, if true nme (herding)\n",
        "classifier = \"SVC\" # NCM, FCC, KNN, SVC, COS"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 66, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnOcQlG_ga8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHXbDzgjgk_B",
        "colab_type": "code",
        "outputId": "8caa7ee2-2db0-46ac-cf51-97fb9af70245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m85q6ZMLgsC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgY-syfF3WRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=1, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsFyMkAyguQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    #val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    #val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10): # for each group of classes\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axANZYKXg6wn",
        "colab_type": "text"
      },
      "source": [
        "**Exemplars management**<br>\n",
        "From iCaRL. We have an exemplar set for each class that we have seen so far. The cardinality of each exemplar set is constant and it is equal, at any time, to m = K/t. Where K is a constraint equal to the amount of memory we're allocating for the exemplars and t is the number of classes that has been seen so far. Implementing iCaRL, whenever a group of (10) classes is trained, it is trained on the train data for those classes (as before) + the current exemplars sets.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx0Woq8uhXyR",
        "colab_type": "code",
        "outputId": "60cf1745-c824-4844-8a39-b5b11d0d7b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from Cifar100.icarl_model import ICaRL\n",
        "\n",
        "# default params\n",
        "\n",
        "K = 2000\n",
        "n_classes = 0\n",
        "feature_size = 2048\n",
        "\n",
        "icarl = ICaRL(feature_size, n_classes, BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE,MILESTONES,MOMENTUM, K, herding, outputs_labels_mapping)\n",
        "icarl.cuda() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ICaRL(\n",
              "  (net): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=64, out_features=0, bias=True)\n",
              "  )\n",
              "  (feature_extractor): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Sequential()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppBh08iGBARC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeAccuracy(method, net, loader, reverse_index, dataset, all_preds_cm, all_labels_cm):\n",
        "  total = 0.0\n",
        "  correct = 0.0\n",
        "  for indices, images, labels in loader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "     \n",
        "        # add other classifiers\n",
        "        if classifier == 'NCM':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.classify(images)\n",
        "        elif classifier == 'FCC':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.FCC_classify(images)\n",
        "        elif classifier == 'KNN' or classifier == 'SVC':\n",
        "          preds = net.KNN_SVC_classify(images)\n",
        "          preds = preds.to(DEVICE)\n",
        "        elif classifier == 'COS':\n",
        "          labels = reverse_index.getNodes(labels)\n",
        "          preds = net.COS_classify(images)\n",
        "\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "  accuracy = correct/len(dataset)\n",
        "  if method == 'test':\n",
        "    all_preds_cm.extend(preds.tolist())\n",
        "    all_labels_cm.extend(labels.data.tolist())\n",
        "  return accuracy, all_preds_cm, all_labels_cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wupANuY0g1pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, reverse_index, K):\n",
        "    \n",
        "    all_accuracies = []\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "    group_id=1\n",
        "    test_set = None\n",
        "\n",
        "    #for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "    for train_subset, test_subset in zip(train_subsets, test_subsets):\n",
        "        print(\"GROUP: \",group_id)\n",
        "        if test_set is None:\n",
        "          test_set = test_subset\n",
        "          train_set_big = train_subset\n",
        "        else:\n",
        "          test_set = utils.joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "        train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "        #val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "        test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "\n",
        "        ####### iCaRL implementation(following alg. 2,3,4,5 on icarl paper) ##################\n",
        "        \n",
        "        new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        # 1 - update representation of the net \n",
        "        #  alg. 3 icarl\n",
        "        # (here the trainset will be augmented with the exemplars too)\n",
        "        # (here the classes are incremented too)\n",
        "        icarl.update_representation(train_subset, train_dataset, new_classes_examined)\n",
        "\n",
        "        # 2 - update m (number of images per class in the exemplar set corresponding to that class)\n",
        "        m = int(math.ceil(K/icarl.n_classes))\n",
        "\n",
        "        print(\"Reducing each exemplar set to size: {}\".format(m))\n",
        "\n",
        "        # 3 - reduce exemplar set for all the previously seen classes\n",
        "        # alg.5 icarl\n",
        "        icarl.reduce_exemplar_sets(m)\n",
        "\n",
        "        # retrieve the 10 classes in the current subset\n",
        "        # NB. Here there will be exemplars too! (if i do not want that, use new_classes_examined)\n",
        "        classes_current_subset = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "        \n",
        "        print(\"Constructing exemplar sets class...\")\n",
        "        \n",
        "        # 4 - construct the exemplar set for the new classes\n",
        "        for y in new_classes_examined: # for each class in the current subset\n",
        "          \n",
        "          \n",
        "          # extract all the imgs in the train subset that are linked to this class\n",
        "          images_current_class = train_subset.dataset.df.loc[train_dataset.df['labels'] == y, 'data'] #they're TENSORS NOT IMAGES (the conversion will be done later)         \n",
        "          imgs_idxs = images_current_class.index # the indexes of all the images in the current classe being considered 0...49k\n",
        "          class_train_subset = Subset(train_dataset, imgs_idxs)#subset of the train dataset where i have all the imgs of class y\n",
        "\n",
        "          # alg. 4 icarl\n",
        "          icarl.construct_exemplar_set(class_train_subset,m,y)\n",
        "\n",
        "        # update the num classes seen so far\n",
        "        icarl.n_known = icarl.n_classes #n_classes is incremented in 1: updateRepresentation\n",
        "\n",
        "        print(\"Performing classification...\")\n",
        "\n",
        "        # start classifier\n",
        "        icarl.computeMeans()\n",
        "\n",
        "        # common training on exemplars for KNN and SVC classifier\n",
        "        if classifier == 'KNN':\n",
        "          K_nn = int(math.ceil(m/10))\n",
        "          #print(K_nn)\n",
        "          #K_nn = 5\n",
        "          icarl.modelTrain(classifier, K_nn)\n",
        "        elif classifier == 'SVC':\n",
        "          icarl.modelTrain(classifier)\n",
        "\n",
        "        #train accuracy\n",
        "        train_accuracy, _, _ = computeAccuracy('train',icarl, train_dataloader, reverse_index, train_subset,all_preds_cm, all_labels_cm)\n",
        "        print ('Train Accuracy (on current group): %.2f\\n' % (100.0 * train_accuracy))\n",
        "\n",
        "        # --- not used\n",
        "        #val_accuracy, _, _ = computeAccuracy('val',icarl, val_dataloader, reverse_index, val_subset)\n",
        "        #print ('Val Accuracy (on current group): %.2f\\n' % (100.0 * val_accuracy))\n",
        "\n",
        "        #test\n",
        "        test_accuracy, all_preds_cm, all_labels_cm = computeAccuracy('test',icarl, test_dataloader, reverse_index, test_set, all_preds_cm, all_labels_cm)\n",
        "        all_accuracies.append(test_accuracy)\n",
        "        print ('Test Accuracy (all groups seen so far): %.2f\\n' % (100.0 * test_accuracy))\n",
        "\n",
        "        print (\"the model knows %d classes:\\n \" % icarl.n_known)\n",
        "\n",
        "        group_id+=1\n",
        "        \n",
        "    return all_accuracies, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmxtCL8AvYD",
        "colab_type": "code",
        "outputId": "046fca44-08bc-4403-a35c-6a68f3c08191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "accuracies, all_preds_cm, all_labels_cm = incrementalTraining(icarl, train_subsets, val_subsets, test_subsets,eval_transform, outputs_labels_mapping, K)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.3254559636116028\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.32659783959388733\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.32063281536102295\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.3136973977088928\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.2964448034763336\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.2965240180492401\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.29977136850357056\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.2895151972770691\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.28493979573249817\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.2949928641319275\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.2719312608242035\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.26768621802330017\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.2657068967819214\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.24802885949611664\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.26013651490211487\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.25629863142967224\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.23540286719799042\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.25202399492263794\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.22424831986427307\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.22741234302520752\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.2079186886548996\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.23103106021881104\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.23142199218273163\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.2241198569536209\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.21110379695892334\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.22472429275512695\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.20224641263484955\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.19720977544784546\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.2111363410949707\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.20129482448101044\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.20077131688594818\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.18848197162151337\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.21269376575946808\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.1927943080663681\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.17692969739437103\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.17014680802822113\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.1927502304315567\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.17885808646678925\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.16006676852703094\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.14659099280834198\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.14717887341976166\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.14278554916381836\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.13719984889030457\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.15057851374149323\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.1295340657234192\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.15746180713176727\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.1529557704925537\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.12370526790618896\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.11952445656061172\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.07760800421237946\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.09549151360988617\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.07119067758321762\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.09200816601514816\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.08832088857889175\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.0683920606970787\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.07538361102342606\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.05162717029452324\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.07480788230895996\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.05629255995154381\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.07348009198904037\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.04751717671751976\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.05871936306357384\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.06897777318954468\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.07167593389749527\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.04588072746992111\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.0477357842028141\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.03953086584806442\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.04751400649547577\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.03830838203430176\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.04916929081082344\n",
            "Reducing each exemplar set to size: 200\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 93.86\n",
            "\n",
            "Test Accuracy (all groups seen so far): 79.80\n",
            "\n",
            "the model knows 10 classes:\n",
            " \n",
            "GROUP:  2\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.14796198904514313\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.1415189951658249\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.14378391206264496\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.14451323449611664\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.12480480968952179\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.12251361459493637\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.12671251595020294\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.11219771206378937\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.1104230061173439\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.11677660048007965\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.11449924856424332\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.10776562988758087\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.10390400141477585\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.1260218769311905\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.09613273292779922\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.1006370559334755\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.0987127423286438\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.10098083317279816\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.10091026872396469\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.09473303705453873\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.09281691908836365\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.09698724746704102\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.09309951215982437\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.1052577868103981\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.10633476078510284\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.08965219557285309\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.09007210284471512\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.10959676653146744\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.0922958180308342\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.08622709661722183\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.08517781645059586\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.0916561484336853\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08612865209579468\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.09704839438199997\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.07581336796283722\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.08338655531406403\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.09807474911212921\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.08064211905002594\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.08453785628080368\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.08243117481470108\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.08257126063108444\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.08696787059307098\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.07944022864103317\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.0900917574763298\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.08131837099790573\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.07483847439289093\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.08424016088247299\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.07034889608621597\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.07677029818296432\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.06726838648319244\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.06366027891635895\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.05947602912783623\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.061382245272397995\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.053365856409072876\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.056946076452732086\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.059012509882450104\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.06320575624704361\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.0582064650952816\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.05742323398590088\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.0559808574616909\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.053857654333114624\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.05417485162615776\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.05780947208404541\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.050415944308042526\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.057656604796648026\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.05208327993750572\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.0594642348587513\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.0507948063313961\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.05561601743102074\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.05425386503338814\n",
            "Reducing each exemplar set to size: 100\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 97.58\n",
            "\n",
            "Test Accuracy (all groups seen so far): 73.75\n",
            "\n",
            "the model knows 20 classes:\n",
            " \n",
            "GROUP:  3\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.10795382410287857\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.10286153852939606\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.10304436087608337\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.09359496831893921\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.08887738734483719\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.09479472786188126\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.09180957823991776\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.09144286066293716\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.09130378067493439\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.08946884423494339\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.08831894397735596\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08040259033441544\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08555641770362854\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.08564107120037079\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.0828186646103859\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.08255095779895782\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.0818432867527008\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08145561814308167\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.0782797709107399\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08117882907390594\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.07945123314857483\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.0850386694073677\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.07340757548809052\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.08050061762332916\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.07545561343431473\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.07303287088871002\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.07868731766939163\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.07284914702177048\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.07874093949794769\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.07836014032363892\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.07836619019508362\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.0824117437005043\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.07346773892641068\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.07444217056035995\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.07243064045906067\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.07471893727779388\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.07279451936483383\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.07395242154598236\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.07512510567903519\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.07548025250434875\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.06958826631307602\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.07790891826152802\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.07277623564004898\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.07377215474843979\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.07291002571582794\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.07985169440507889\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.07004475593566895\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.07027836889028549\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.07356265187263489\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.0654868558049202\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.0600859634578228\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.05635950714349747\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.061033155769109726\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.05827367678284645\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.06128907576203346\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.05844401195645332\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.05903765186667442\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.06099516153335571\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.0567004568874836\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.057382043451070786\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.061244480311870575\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.05693262070417404\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.05888954922556877\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.06047068536281586\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.053023334592580795\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.050556544214487076\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.05628858879208565\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.0595974326133728\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.05701291933655739\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.05423100292682648\n",
            "Reducing each exemplar set to size: 67\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 96.32\n",
            "\n",
            "Test Accuracy (all groups seen so far): 68.67\n",
            "\n",
            "the model knows 30 classes:\n",
            " \n",
            "GROUP:  4\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.10288631916046143\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.10267648845911026\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.09047500789165497\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.09319766610860825\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.08912929147481918\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.0963088795542717\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.08879473060369492\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.09114735573530197\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.08228590339422226\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.09044253826141357\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.08627791702747345\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.09686626493930817\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08878618478775024\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.09441230446100235\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.08731599152088165\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.08277976512908936\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.09175143390893936\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08256995677947998\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08487357199192047\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08416111767292023\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.08144114166498184\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08681381493806839\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.08257418870925903\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.07940932363271713\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.0853089988231659\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.0877114087343216\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08330108970403671\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.08376579731702805\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.08324218541383743\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.07976144552230835\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.07965409010648727\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.08320766687393188\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.07965946942567825\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.0734015628695488\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.08075568825006485\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.07832614332437515\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.0812378004193306\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.08674729615449905\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.07549005001783371\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.07640143483877182\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.08310598134994507\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.07589814811944962\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.08707933872938156\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.07916209846735\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.07433026283979416\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.07365192472934723\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.07171173393726349\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.08312534540891647\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.07792415469884872\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.06884988397359848\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.06627576798200607\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.06290554255247116\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.0682745948433876\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.06324554234743118\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.06323488801717758\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.06439023464918137\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.06534110009670258\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.06463928520679474\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.06446978449821472\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.06282017379999161\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.0620570182800293\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.06435105949640274\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.06353934854269028\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.062491655349731445\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.06311722844839096\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.06214931234717369\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.061284471303224564\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.0634634792804718\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.06015467643737793\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.060927797108888626\n",
            "Reducing each exemplar set to size: 50\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 94.80\n",
            "\n",
            "Test Accuracy (all groups seen so far): 61.35\n",
            "\n",
            "the model knows 40 classes:\n",
            " \n",
            "GROUP:  5\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.09166564792394638\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.09280896931886673\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.0899927094578743\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.08760949969291687\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.09192293882369995\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.09038475155830383\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.08450300246477127\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.08244085311889648\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.08531272411346436\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.08384881168603897\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.0857149213552475\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08170245587825775\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08497349917888641\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.08870605379343033\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.0819634348154068\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.07894575595855713\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.08111535757780075\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08169005811214447\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08174022287130356\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.07886610925197601\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.08087282627820969\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08359753340482712\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.08173869550228119\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.07987278699874878\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.0839657410979271\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.08259998261928558\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08002672344446182\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.08135972172021866\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.07465172559022903\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.08107691258192062\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.0822230875492096\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.07858613133430481\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08008912950754166\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.07834446430206299\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.07594123482704163\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.07705511152744293\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.0833917185664177\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.07737208157777786\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.07590015232563019\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.08069828152656555\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.07901820540428162\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.07705322653055191\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.08016066253185272\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.07772864401340485\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.0791202038526535\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.07928231358528137\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.07842404395341873\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.07662275433540344\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.07579324394464493\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.07099086791276932\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.07025100290775299\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.06973721832036972\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.06936874985694885\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.06967943906784058\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.06795103847980499\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.06734439730644226\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.06821203231811523\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.06782238185405731\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.06808416545391083\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.06777177006006241\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.06596913933753967\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.06758605688810349\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.0642792135477066\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.06634661555290222\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.06600995361804962\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.06773008406162262\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.06537799537181854\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.07137232273817062\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.0660763531923294\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.0649581253528595\n",
            "Reducing each exemplar set to size: 40\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 92.68\n",
            "\n",
            "Test Accuracy (all groups seen so far): 56.98\n",
            "\n",
            "the model knows 50 classes:\n",
            " \n",
            "GROUP:  6\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.08956293016672134\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.09009517729282379\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.087058886885643\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.08522169291973114\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.08532532304525375\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.08296774327754974\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.08859070390462875\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.08685000985860825\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.08223917335271835\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.08897712081670761\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.08367027342319489\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08523094654083252\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08684681355953217\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.08288802206516266\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.08214064687490463\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.08095681667327881\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.0801042765378952\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08120498061180115\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08336670696735382\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08178317546844482\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.08124416321516037\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08346209675073624\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.0793042704463005\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.08216726779937744\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.08050099015235901\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.08228285610675812\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08031906187534332\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.08249957859516144\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.0792074054479599\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.07801897823810577\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.08162060379981995\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.08381497859954834\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08135344088077545\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.08016971498727798\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.07967723906040192\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.07979193329811096\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.07972589135169983\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.08248487114906311\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.0768318623304367\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.07921834290027618\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.0809953436255455\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.08268570899963379\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.08192110806703568\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.07861832529306412\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.07578050345182419\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.07957287132740021\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.07647135108709335\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.07627677172422409\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.07740408927202225\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.07190874218940735\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.07263192534446716\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.07446622103452682\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.07206926494836807\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.07078422605991364\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.07163483649492264\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.07016250491142273\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.07069678604602814\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.07317664474248886\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.07140693813562393\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.07060132920742035\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.0694454237818718\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.06979512423276901\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.07027043402194977\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.06838072836399078\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.07029382139444351\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.06799669563770294\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.07101237773895264\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.06990502774715424\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.07019262760877609\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.06939249485731125\n",
            "Reducing each exemplar set to size: 34\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 91.46\n",
            "\n",
            "Test Accuracy (all groups seen so far): 54.10\n",
            "\n",
            "the model knows 60 classes:\n",
            " \n",
            "GROUP:  7\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.085719995200634\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.08682906627655029\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.08473259210586548\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.08422809094190598\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.08254384249448776\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.08620083332061768\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.08636881411075592\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.08451996743679047\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.08251695334911346\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.0863960012793541\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.0803268551826477\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08158648759126663\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08246631175279617\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.07923708856105804\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.08126048743724823\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.08245973289012909\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.08303550630807877\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08409067243337631\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08434414863586426\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08193434029817581\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.0784410759806633\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08060204982757568\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.0828980877995491\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.08008289337158203\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.08208348602056503\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.0830652043223381\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08391869813203812\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.07979153841733932\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.08170203864574432\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.07933348417282104\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.0837579295039177\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.08212997019290924\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08146864175796509\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.07884896546602249\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.08042886853218079\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.08296646177768707\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.08280760049819946\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.08195389062166214\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.08037887513637543\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.07890783250331879\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.08478795737028122\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.08014114946126938\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.08023156225681305\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.07916092127561569\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.08140828460454941\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.07778699696063995\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.08104575425386429\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.07940857857465744\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.08038788288831711\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.07520648837089539\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.075584776699543\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.07456286251544952\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.07468817383050919\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.0743933618068695\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.07592684775590897\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.07418294250965118\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.0755000114440918\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.07442761957645416\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.07304449379444122\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.07390568405389786\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.07351278513669968\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.0728948563337326\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.07232418656349182\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.07439406216144562\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.07069652527570724\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.07458016276359558\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.0716073140501976\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.07258745282888412\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.07276066392660141\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.07223928719758987\n",
            "Reducing each exemplar set to size: 29\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 92.80\n",
            "\n",
            "Test Accuracy (all groups seen so far): 50.43\n",
            "\n",
            "the model knows 70 classes:\n",
            " \n",
            "GROUP:  8\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.09283497929573059\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.09237948805093765\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.0893649235367775\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.08966922014951706\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.0862700566649437\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.08436115086078644\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.08686696738004684\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.08708595484495163\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.08539430797100067\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.08780180662870407\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.08756037056446075\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08799942582845688\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08584021776914597\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.08572294563055038\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.08413359522819519\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.082820825278759\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.08374200016260147\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08435928821563721\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08550732582807541\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08558179438114166\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.08468105643987656\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08547709882259369\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.08145574480295181\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.08492839336395264\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.08129703998565674\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.08245263248682022\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08313452452421188\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.08675258606672287\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.08202268183231354\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.08287680894136429\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.0825391411781311\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.08523290604352951\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08198841661214828\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.0835203155875206\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.08035977184772491\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.0815860778093338\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.08150919526815414\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.08243399858474731\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.08282706886529922\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.08240056037902832\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.08341455459594727\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.0816999226808548\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.08387911319732666\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.08319209516048431\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.08027326315641403\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.08265101164579391\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.08119886368513107\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.08269204199314117\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.081507109105587\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.07668622583150864\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.07740085572004318\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.07556327432394028\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.07663551717996597\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.07557445019483566\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.07406415790319443\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.07680263370275497\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.07498931884765625\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.07464566081762314\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.07449375838041306\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.07305262237787247\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.07493297010660172\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.07611027359962463\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.07305093109607697\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.07438120245933533\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.07419361919164658\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.07475261390209198\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.07558819651603699\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.07225532829761505\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.07486645877361298\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.0747133269906044\n",
            "Reducing each exemplar set to size: 25\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 92.60\n",
            "\n",
            "Test Accuracy (all groups seen so far): 46.84\n",
            "\n",
            "the model knows 80 classes:\n",
            " \n",
            "GROUP:  9\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.09269711375236511\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.09257947653532028\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.0868113562464714\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.08964085578918457\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.08595727384090424\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.08921710401773453\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.0855802521109581\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.08811662346124649\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.08795573562383652\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.08329478651285172\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.08713749051094055\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08841157704591751\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08363015949726105\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.08370696008205414\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.08549518883228302\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.08200760930776596\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.08685804903507233\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08196807652711868\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08448756486177444\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08446034044027328\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.08491893857717514\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08551990240812302\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.0804515928030014\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.0826798677444458\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.08081415295600891\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.08348333835601807\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08258626610040665\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.08445294201374054\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.0817478597164154\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.08546353876590729\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.08419454842805862\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.08434152603149414\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08266769349575043\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.0830165445804596\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.08479895442724228\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.08397067338228226\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.08394663780927658\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.0842202752828598\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.08527126163244247\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.08358784019947052\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.08212285488843918\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.08415002375841141\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.0832512155175209\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.08443694561719894\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.08115797489881516\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.08402570337057114\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.07981498539447784\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.08300091326236725\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.08279116451740265\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.07738793641328812\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.07766973972320557\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.07861651480197906\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.0773014947772026\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.07832975685596466\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.0787605419754982\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.07628539204597473\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.07870778441429138\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.07798013091087341\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.07623880356550217\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.079426109790802\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.07726313173770905\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.07472892850637436\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.07878873497247696\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.07644248008728027\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.07613304257392883\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.07710175961256027\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.07648966461420059\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.07682745158672333\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.07626031339168549\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.07576698809862137\n",
            "Reducing each exemplar set to size: 23\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 92.24\n",
            "\n",
            "Test Accuracy (all groups seen so far): 45.06\n",
            "\n",
            "the model knows 90 classes:\n",
            " \n",
            "GROUP:  10\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  0.0902949869632721\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  0.09061484783887863\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  0.08872638642787933\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  0.0877954289317131\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  0.08841823041439056\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  0.08816279470920563\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  0.08790967613458633\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  0.0841006264090538\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  0.0883760079741478\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  0.0877000093460083\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  0.08667496591806412\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  0.08720260113477707\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  0.08967819064855576\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  0.08801543712615967\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  0.08712800592184067\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  0.08762060105800629\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  0.08720609545707703\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  0.08655756711959839\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  0.08735380321741104\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  0.08526072651147842\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  0.08727357536554337\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  0.08729545027017593\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  0.08692148327827454\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  0.08494117856025696\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  0.0850282534956932\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  0.08479508012533188\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  0.08732904493808746\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  0.08634087443351746\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  0.08615818619728088\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  0.08445867151021957\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  0.08425698429346085\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  0.08579418063163757\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  0.08655808866024017\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  0.08536403626203537\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  0.08424937725067139\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  0.08689717948436737\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  0.08208739012479782\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  0.08648519217967987\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  0.08502732962369919\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  0.0848475843667984\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  0.08501943200826645\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  0.0849202498793602\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  0.08556006848812103\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  0.0837612897157669\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  0.08664736896753311\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  0.08216939866542816\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  0.08313938230276108\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  0.0856952965259552\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  0.0812486931681633\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  0.08154582977294922\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  0.07982639223337173\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  0.08161567151546478\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  0.08136823773384094\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  0.07978423684835434\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  0.08080558478832245\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  0.07920481264591217\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  0.08044157177209854\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  0.07795249670743942\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  0.07884044200181961\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  0.07779097557067871\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  0.08017588406801224\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  0.07849178463220596\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  0.07751095294952393\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  0.08022323250770569\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  0.079782634973526\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  0.07741183042526245\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  0.07807572931051254\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  0.07905379682779312\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  0.07978831976652145\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  0.07951732724905014\n",
            "Reducing each exemplar set to size: 20\n",
            "Constructing exemplar sets class...\n",
            "Performing classification...\n",
            "Train Accuracy (on current group): 90.50\n",
            "\n",
            "Test Accuracy (all groups seen so far): 41.75\n",
            "\n",
            "the model knows 100 classes:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q_B01Oa82wF",
        "colab_type": "code",
        "outputId": "c27e3502-d6ac-4a90-d539-0c2970f3dbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if herding:\n",
        "  method = 'iCaRL_{}_herding'.format(classifier)\n",
        "else:\n",
        "  method = 'iCaRL_{}_random'.format(classifier)\n",
        "\n",
        "print(\"metrics iCaRL for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "# accuracy \n",
        "data_plot_line=[]\n",
        "\n",
        "classes_per_group = 10\n",
        "for group_classes in range(0,10):\n",
        "    data_plot_line.append(((group_classes + 1)*classes_per_group, accuracies[group_classes]))\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write to JSON file\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "metrics iCaRL for seed 66\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtGxWw4fyzyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}