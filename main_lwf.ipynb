{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_lwf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdBV7JDGhwdSccavDlVV+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/lwf/main_lwf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Cpfl5JiceY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6cc96d03-4c6b-4c03-ee30-86fe263997a7"
      },
      "source": [
        "\"\"\"\n",
        "  Following the iCaRL paper specifications,\n",
        "  LwF is implemented simirality to iCaRL itself.\n",
        "  The differences are:\n",
        "  - No exemplars management\n",
        "  - For classification, it is used the network output values themselves\n",
        "  (ref. iCaRL paper section 4.1)\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Following the iCaRL paper specifications,\\n  LwF is implemented simirality to iCaRL itself.\\n  The differences are:\\n  - No exemplars management\\n  - For classification, it is used the network output values themselves\\n  (ref. iCaRL paper section 4.1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhl89o9xjPsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dbdc4edd-6f6f-4b41-dca2-7fe81cc910df"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJJMer62jTbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' # 'cuda' or 'cpu'\n",
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "NUM_CLASSES = 10 \n",
        "\n",
        "BATCH_SIZE = 128     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 2           # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = 70       # Total number of training epochs (iterations over dataset)\n",
        "MILESTONES = [49, 63] # when the LR decreases, according to icarl\n",
        "GAMMA = 0.1           # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10\n",
        "\n",
        "RANDOM_SEED = 30 # implement this! It will be easier to do 3 different trials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juvZ4mFgjZ8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "01c3baa1-f97f-45fb-9ebe-388fb32caa7a"
      },
      "source": [
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone -b lwf https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/266)\u001b[K\rremote: Counting objects:   1% (3/266)\u001b[K\rremote: Counting objects:   2% (6/266)\u001b[K\rremote: Counting objects:   3% (8/266)\u001b[K\rremote: Counting objects:   4% (11/266)\u001b[K\rremote: Counting objects:   5% (14/266)\u001b[K\rremote: Counting objects:   6% (16/266)\u001b[K\rremote: Counting objects:   7% (19/266)\u001b[K\rremote: Counting objects:   8% (22/266)\u001b[K\rremote: Counting objects:   9% (24/266)\u001b[K\rremote: Counting objects:  10% (27/266)\u001b[K\rremote: Counting objects:  11% (30/266)\u001b[K\rremote: Counting objects:  12% (32/266)\u001b[K\rremote: Counting objects:  13% (35/266)\u001b[K\rremote: Counting objects:  14% (38/266)\u001b[K\rremote: Counting objects:  15% (40/266)\u001b[K\rremote: Counting objects:  16% (43/266)\u001b[K\rremote: Counting objects:  17% (46/266)\u001b[K\rremote: Counting objects:  18% (48/266)\u001b[K\rremote: Counting objects:  19% (51/266)\u001b[K\rremote: Counting objects:  20% (54/266)\u001b[K\rremote: Counting objects:  21% (56/266)\u001b[K\rremote: Counting objects:  22% (59/266)\u001b[K\rremote: Counting objects:  23% (62/266)\u001b[K\rremote: Counting objects:  24% (64/266)\u001b[K\rremote: Counting objects:  25% (67/266)\u001b[K\rremote: Counting objects:  26% (70/266)\u001b[K\rremote: Counting objects:  27% (72/266)\u001b[K\rremote: Counting objects:  28% (75/266)\u001b[K\rremote: Counting objects:  29% (78/266)\u001b[K\rremote: Counting objects:  30% (80/266)\u001b[K\rremote: Counting objects:  31% (83/266)\u001b[K\rremote: Counting objects:  32% (86/266)\u001b[K\rremote: Counting objects:  33% (88/266)\u001b[K\rremote: Counting objects:  34% (91/266)\u001b[K\rremote: Counting objects:  35% (94/266)\u001b[K\rremote: Counting objects:  36% (96/266)\u001b[K\rremote: Counting objects:  37% (99/266)\u001b[K\rremote: Counting objects:  38% (102/266)\u001b[K\rremote: Counting objects:  39% (104/266)\u001b[K\rremote: Counting objects:  40% (107/266)\u001b[K\rremote: Counting objects:  41% (110/266)\u001b[K\rremote: Counting objects:  42% (112/266)\u001b[K\rremote: Counting objects:  43% (115/266)\u001b[K\rremote: Counting objects:  44% (118/266)\u001b[K\rremote: Counting objects:  45% (120/266)\u001b[K\rremote: Counting objects:  46% (123/266)\u001b[K\rremote: Counting objects:  47% (126/266)\u001b[K\rremote: Counting objects:  48% (128/266)\u001b[K\rremote: Counting objects:  49% (131/266)\u001b[K\rremote: Counting objects:  50% (133/266)\u001b[K\rremote: Counting objects:  51% (136/266)\u001b[K\rremote: Counting objects:  52% (139/266)\u001b[K\rremote: Counting objects:  53% (141/266)\u001b[K\rremote: Counting objects:  54% (144/266)\u001b[K\rremote: Counting objects:  55% (147/266)\u001b[K\rremote: Counting objects:  56% (149/266)\u001b[K\rremote: Counting objects:  57% (152/266)\u001b[K\rremote: Counting objects:  58% (155/266)\u001b[K\rremote: Counting objects:  59% (157/266)\u001b[K\rremote: Counting objects:  60% (160/266)\u001b[K\rremote: Counting objects:  61% (163/266)\u001b[K\rremote: Counting objects:  62% (165/266)\u001b[K\rremote: Counting objects:  63% (168/266)\u001b[K\rremote: Counting objects:  64% (171/266)\u001b[K\rremote: Counting objects:  65% (173/266)\u001b[K\rremote: Counting objects:  66% (176/266)\u001b[K\rremote: Counting objects:  67% (179/266)\u001b[K\rremote: Counting objects:  68% (181/266)\u001b[K\rremote: Counting objects:  69% (184/266)\u001b[K\rremote: Counting objects:  70% (187/266)\u001b[K\rremote: Counting objects:  71% (189/266)\u001b[K\rremote: Counting objects:  72% (192/266)\u001b[K\rremote: Counting objects:  73% (195/266)\u001b[K\rremote: Counting objects:  74% (197/266)\u001b[K\rremote: Counting objects:  75% (200/266)\u001b[K\rremote: Counting objects:  76% (203/266)\u001b[K\rremote: Counting objects:  77% (205/266)\u001b[K\rremote: Counting objects:  78% (208/266)\u001b[K\rremote: Counting objects:  79% (211/266)\u001b[K\rremote: Counting objects:  80% (213/266)\u001b[K\rremote: Counting objects:  81% (216/266)\u001b[K\rremote: Counting objects:  82% (219/266)\u001b[K\rremote: Counting objects:  83% (221/266)\u001b[K\rremote: Counting objects:  84% (224/266)\u001b[K\rremote: Counting objects:  85% (227/266)\u001b[K\rremote: Counting objects:  86% (229/266)\u001b[K\rremote: Counting objects:  87% (232/266)\u001b[K\rremote: Counting objects:  88% (235/266)\u001b[K\rremote: Counting objects:  89% (237/266)\u001b[K\rremote: Counting objects:  90% (240/266)\u001b[K\rremote: Counting objects:  91% (243/266)\u001b[K\rremote: Counting objects:  92% (245/266)\u001b[K\rremote: Counting objects:  93% (248/266)\u001b[K\rremote: Counting objects:  94% (251/266)\u001b[K\rremote: Counting objects:  95% (253/266)\u001b[K\rremote: Counting objects:  96% (256/266)\u001b[K\rremote: Counting objects:  97% (259/266)\u001b[K\rremote: Counting objects:  98% (261/266)\u001b[K\rremote: Counting objects:  99% (264/266)\u001b[K\rremote: Counting objects: 100% (266/266)\u001b[K\rremote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects:   0% (1/150)\u001b[K\rremote: Compressing objects:   1% (2/150)\u001b[K\rremote: Compressing objects:   2% (3/150)\u001b[K\rremote: Compressing objects:   3% (5/150)\u001b[K\rremote: Compressing objects:   4% (6/150)\u001b[K\rremote: Compressing objects:   5% (8/150)\u001b[K\rremote: Compressing objects:   6% (9/150)\u001b[K\rremote: Compressing objects:   7% (11/150)\u001b[K\rremote: Compressing objects:   8% (12/150)\u001b[K\rremote: Compressing objects:   9% (14/150)\u001b[K\rremote: Compressing objects:  10% (15/150)\u001b[K\rremote: Compressing objects:  11% (17/150)\u001b[K\rremote: Compressing objects:  12% (18/150)\u001b[K\rremote: Compressing objects:  13% (20/150)\u001b[K\rremote: Compressing objects:  14% (21/150)\u001b[K\rremote: Compressing objects:  15% (23/150)\u001b[K\rremote: Compressing objects:  16% (24/150)\u001b[K\rremote: Compressing objects:  17% (26/150)\u001b[K\rremote: Compressing objects:  18% (27/150)\u001b[K\rremote: Compressing objects:  19% (29/150)\u001b[K\rremote: Compressing objects:  20% (30/150)\u001b[K\rremote: Compressing objects:  21% (32/150)\u001b[K\rremote: Compressing objects:  22% (33/150)\u001b[K\rremote: Compressing objects:  23% (35/150)\u001b[K\rremote: Compressing objects:  24% (36/150)\u001b[K\rremote: Compressing objects:  25% (38/150)\u001b[K\rremote: Compressing objects:  26% (39/150)\u001b[K\rremote: Compressing objects:  27% (41/150)\u001b[K\rremote: Compressing objects:  28% (42/150)\u001b[K\rremote: Compressing objects:  29% (44/150)\u001b[K\rremote: Compressing objects:  30% (45/150)\u001b[K\rremote: Compressing objects:  31% (47/150)\u001b[K\rremote: Compressing objects:  32% (48/150)\u001b[K\rremote: Compressing objects:  33% (50/150)\u001b[K\rremote: Compressing objects:  34% (51/150)\u001b[K\rremote: Compressing objects:  35% (53/150)\u001b[K\rremote: Compressing objects:  36% (54/150)\u001b[K\rremote: Compressing objects:  37% (56/150)\u001b[K\rremote: Compressing objects:  38% (57/150)\u001b[K\rremote: Compressing objects:  39% (59/150)\u001b[K\rremote: Compressing objects:  40% (60/150)\u001b[K\rremote: Compressing objects:  41% (62/150)\u001b[K\rremote: Compressing objects:  42% (63/150)\u001b[K\rremote: Compressing objects:  43% (65/150)\u001b[K\rremote: Compressing objects:  44% (66/150)\u001b[K\rremote: Compressing objects:  45% (68/150)\u001b[K\rremote: Compressing objects:  46% (69/150)\u001b[K\rremote: Compressing objects:  47% (71/150)\u001b[K\rremote: Compressing objects:  48% (72/150)\u001b[K\rremote: Compressing objects:  49% (74/150)\u001b[K\rremote: Compressing objects:  50% (75/150)\u001b[K\rremote: Compressing objects:  51% (77/150)\u001b[K\rremote: Compressing objects:  52% (78/150)\u001b[K\rremote: Compressing objects:  53% (80/150)\u001b[K\rremote: Compressing objects:  54% (81/150)\u001b[K\rremote: Compressing objects:  55% (83/150)\u001b[K\rremote: Compressing objects:  56% (84/150)\u001b[K\rremote: Compressing objects:  57% (86/150)\u001b[K\rremote: Compressing objects:  58% (87/150)\u001b[K\rremote: Compressing objects:  59% (89/150)\u001b[K\rremote: Compressing objects:  60% (90/150)\u001b[K\rremote: Compressing objects:  61% (92/150)\u001b[K\rremote: Compressing objects:  62% (93/150)\u001b[K\rremote: Compressing objects:  63% (95/150)\u001b[K\rremote: Compressing objects:  64% (96/150)\u001b[K\rremote: Compressing objects:  65% (98/150)\u001b[K\rremote: Compressing objects:  66% (99/150)\u001b[K\rremote: Compressing objects:  67% (101/150)\u001b[K\rremote: Compressing objects:  68% (102/150)\u001b[K\rremote: Compressing objects:  69% (104/150)\u001b[K\rremote: Compressing objects:  70% (105/150)\u001b[K\rremote: Compressing objects:  71% (107/150)\u001b[K\rremote: Compressing objects:  72% (108/150)\u001b[K\rremote: Compressing objects:  73% (110/150)\u001b[K\rremote: Compressing objects:  74% (111/150)\u001b[K\rremote: Compressing objects:  75% (113/150)\u001b[K\rremote: Compressing objects:  76% (114/150)\u001b[K\rremote: Compressing objects:  77% (116/150)\u001b[K\rremote: Compressing objects:  78% (117/150)\u001b[K\rremote: Compressing objects:  79% (119/150)\u001b[K\rremote: Compressing objects:  80% (120/150)\u001b[K\rremote: Compressing objects:  81% (122/150)\u001b[K\rremote: Compressing objects:  82% (123/150)\u001b[K\rremote: Compressing objects:  83% (125/150)\u001b[K\rremote: Compressing objects:  84% (126/150)\u001b[K\rremote: Compressing objects:  85% (128/150)\u001b[K\rremote: Compressing objects:  86% (129/150)\u001b[K\rremote: Compressing objects:  87% (131/150)\u001b[K\rremote: Compressing objects:  88% (132/150)\u001b[K\rremote: Compressing objects:  89% (134/150)\u001b[K\rremote: Compressing objects:  90% (135/150)\u001b[K\rremote: Compressing objects:  91% (137/150)\u001b[K\rremote: Compressing objects:  92% (138/150)\u001b[K\rremote: Compressing objects:  93% (140/150)\u001b[K\rremote: Compressing objects:  94% (141/150)\u001b[K\rremote: Compressing objects:  95% (143/150)\u001b[K\rremote: Compressing objects:  96% (144/150)\u001b[K\rremote: Compressing objects:  97% (146/150)\u001b[K\rremote: Compressing objects:  98% (147/150)\u001b[K\rremote: Compressing objects:  99% (149/150)\u001b[K\rremote: Compressing objects: 100% (150/150)\u001b[K\rremote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "Receiving objects:   0% (1/266)   \rReceiving objects:   1% (3/266)   \rReceiving objects:   2% (6/266)   \rReceiving objects:   3% (8/266)   \rReceiving objects:   4% (11/266)   \rReceiving objects:   5% (14/266)   \rReceiving objects:   6% (16/266)   \rReceiving objects:   7% (19/266)   \rReceiving objects:   8% (22/266)   \rReceiving objects:   9% (24/266)   \rReceiving objects:  10% (27/266)   \rReceiving objects:  11% (30/266)   \rReceiving objects:  12% (32/266)   \rReceiving objects:  13% (35/266)   \rReceiving objects:  14% (38/266)   \rReceiving objects:  15% (40/266)   \rReceiving objects:  16% (43/266)   \rReceiving objects:  17% (46/266)   \rReceiving objects:  18% (48/266)   \rReceiving objects:  19% (51/266)   \rReceiving objects:  20% (54/266)   \rReceiving objects:  21% (56/266)   \rReceiving objects:  22% (59/266)   \rReceiving objects:  23% (62/266)   \rReceiving objects:  24% (64/266)   \rReceiving objects:  25% (67/266)   \rReceiving objects:  26% (70/266)   \rReceiving objects:  27% (72/266)   \rReceiving objects:  28% (75/266)   \rReceiving objects:  29% (78/266)   \rReceiving objects:  30% (80/266)   \rReceiving objects:  31% (83/266)   \rReceiving objects:  32% (86/266)   \rReceiving objects:  33% (88/266)   \rReceiving objects:  34% (91/266)   \rReceiving objects:  35% (94/266)   \rReceiving objects:  36% (96/266)   \rReceiving objects:  36% (98/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  37% (99/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  38% (102/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  39% (104/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  40% (107/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  41% (110/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  42% (112/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  43% (115/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  44% (118/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  45% (120/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  46% (123/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  47% (126/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  48% (128/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  49% (131/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  50% (133/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  51% (136/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  52% (139/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  53% (141/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  54% (144/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  55% (147/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  56% (149/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  57% (152/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  58% (155/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  59% (157/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  60% (160/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  61% (163/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  62% (165/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  63% (168/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  64% (171/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  65% (173/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  66% (176/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  67% (179/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  68% (181/266), 1.68 MiB | 1.62 MiB/s   \rremote: Total 266 (delta 133), reused 220 (delta 97), pack-reused 0\u001b[K\n",
            "Receiving objects:  69% (184/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  70% (187/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  71% (189/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  72% (192/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  73% (195/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  74% (197/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  75% (200/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  76% (203/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  77% (205/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  78% (208/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  79% (211/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  80% (213/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  81% (216/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  82% (219/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  83% (221/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  84% (224/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  85% (227/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  86% (229/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  87% (232/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  88% (235/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  89% (237/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  90% (240/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  91% (243/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  92% (245/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  93% (248/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  94% (251/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  95% (253/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  96% (256/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  97% (259/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  98% (261/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects:  99% (264/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects: 100% (266/266), 1.68 MiB | 1.62 MiB/s   \rReceiving objects: 100% (266/266), 3.74 MiB | 3.07 MiB/s, done.\n",
            "Resolving deltas:   0% (0/133)   \rResolving deltas:   9% (12/133)   \rResolving deltas:  20% (27/133)   \rResolving deltas:  21% (29/133)   \rResolving deltas:  23% (31/133)   \rResolving deltas:  26% (35/133)   \rResolving deltas:  27% (36/133)   \rResolving deltas:  30% (41/133)   \rResolving deltas:  49% (66/133)   \rResolving deltas:  51% (69/133)   \rResolving deltas:  54% (72/133)   \rResolving deltas:  67% (90/133)   \rResolving deltas:  71% (95/133)   \rResolving deltas:  72% (96/133)   \rResolving deltas:  84% (113/133)   \rResolving deltas:  87% (117/133)   \rResolving deltas:  91% (122/133)   \rResolving deltas:  93% (124/133)   \rResolving deltas: 100% (133/133)   \rResolving deltas: 100% (133/133), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmqlWIxXjldh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a557fe0b-5243-467a-d980-cb736cc9c96b"
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-24 20:14:14--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  16.9MB/s    in 11s     \n",
            "\n",
            "2020-05-24 20:14:26 (14.9 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKXMsUQ2oPS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i could use cifar100 mean and std\n",
        "\n",
        "# Define transforms for training phase\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.Pad(4),         # Add padding\n",
        "                                      transforms.RandomCrop(32), # Crops a random squares of the image  \n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
        "                                      ])\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                 \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xM_JUJoP-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c51f5b46-2ad8-4aa8-f83d-4843017e5ff6"
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owLONCmOoZUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ONNgtszoa26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=30)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlDVHznwocr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2J8c2SaohuJ",
        "colab_type": "text"
      },
      "source": [
        "**LWF implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7fwVxB7oefq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# default params\n",
        "total_classes = 100\n",
        "\n",
        "from Cifar100.lwf_model import LWF\n",
        "\n",
        "feature_size = 64\n",
        "n_classes = 0\n",
        "lwf = LWF(feature_size, n_classes, BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE,MILESTONES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H60xMfbW2R3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incrementalTraining(net, train_subsets, val_subsets, test_subsets,eval_transform):\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "\n",
        "      train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "      val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE,shuffle=False, num_workers=4)\n",
        "      test_dataloader = DataLoader(test_subset, batch_size=BATCH_SIZE,shuffle=False, num_workers=4)\n",
        "      \n",
        "      new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "      \n",
        "      net.train()\n",
        "\n",
        "      # update representation\n",
        "      net.update_representation(train_subset, new_classes_examined)\n",
        "\n",
        "      net.n_known = net.n_classes\n",
        "\n",
        "      # evaluation on the train set\n",
        "\n",
        "      net.eval()\n",
        "\n",
        "      print (\"the model knows %d classes:\\n \" % net.n_known)\n",
        "  \n",
        "      #Evaluating on train set\n",
        "      total = 0.0\n",
        "      correct = 0.0\n",
        "\n",
        "      for images, labels, indices in train_dataloader:\n",
        "        images = images.to(self.DEVICE)\n",
        "        preds = net.classify(images)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds.data.cpu() == labels).sum()\n",
        "\n",
        "      # Train Accuracy\n",
        "      print ('Train Accuracy : %.2f\\n' % (100.0 * correct / total))\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TXVwGceM6gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "680ada33-2206-4460-bcaa-dda8a7e0ac00"
      },
      "source": [
        "incrementalTraining(lwf, train_subsets, val_subsets, test_subsets,eval_transform)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ab1c7e664726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mincrementalTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlwf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_subsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_subsets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-4564205b7a2b>\u001b[0m in \u001b[0;36mincrementalTraining\u001b[0;34m(net, train_subsets, val_subsets, test_subsets, eval_transform)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m# update representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_classes_examined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_known\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cifar100/lwf_model.py\u001b[0m in \u001b[0;36mupdate_representation\u001b[0;34m(self, dataset, new_classes)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mq_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cifar100/lwf_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Cifar100/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    345\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 346\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBpsSTfGNM1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}