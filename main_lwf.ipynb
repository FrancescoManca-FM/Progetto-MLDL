{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_lwf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/Progetto-MLDL/blob/lwf/main_lwf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Cpfl5JiceY",
        "colab_type": "code",
        "outputId": "2e857b40-dde2-4d50-a1b7-63327a54b843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "  Following the iCaRL paper specifications,\n",
        "  LwF is implemented simirality to iCaRL itself.\n",
        "  The differences are:\n",
        "  - No exemplars management\n",
        "  - For classification, it is used the network output values themselves\n",
        "  (ref. iCaRL paper section 4.1)\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Following the iCaRL paper specifications,\\n  LwF is implemented simirality to iCaRL itself.\\n  The differences are:\\n  - No exemplars management\\n  - For classification, it is used the network output values themselves\\n  (ref. iCaRL paper section 4.1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhl89o9xjPsT",
        "colab_type": "code",
        "outputId": "49933bef-10c7-4904-8f1e-38f77896b363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juvZ4mFgjZ8t",
        "colab_type": "code",
        "outputId": "6a3c4bc8-3b62-4d17-ee15-a5e31ed5c5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "#!rm -r $DATA_DIR\n",
        "#!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone -b lwf https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 570 (delta 42), reused 45 (delta 21), pack-reused 502\u001b[K\n",
            "Receiving objects: 100% (570/570), 3.99 MiB | 2.49 MiB/s, done.\n",
            "Resolving deltas: 100% (328/328), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmqlWIxXjldh",
        "colab_type": "code",
        "outputId": "2b074bd5-8549-4bff-853b-024be3973b28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-26 22:12:55--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  14.0MB/s    in 13s     \n",
            "\n",
            "2020-05-26 22:13:09 (12.3 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "mv: cannot move 'cifar-100-python' to 'DATA/cifar-100-python/cifar-100-python': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-LUNWGgSYwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8b0e7b59-cfa3-4bca-cac7-49e506db6f9e"
      },
      "source": [
        "from Cifar100 import utils\n",
        "\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = dictHyperparams[\"SEED\"]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 30, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKXMsUQ2oPS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xM_JUJoP-l",
        "colab_type": "code",
        "outputId": "4db27a10-04b7-429a-d796-6ec511585bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owLONCmOoZUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ONNgtszoa26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlDVHznwocr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2J8c2SaohuJ",
        "colab_type": "text"
      },
      "source": [
        "**LWF implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7fwVxB7oefq",
        "colab_type": "code",
        "outputId": "a58ba035-8d6f-4756-e00d-e9d61ea349af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# default params\n",
        "from Cifar100.lwf_model import LWF\n",
        "\n",
        "feature_size = 2048\n",
        "n_classes = 0\n",
        "lwf = LWF(feature_size, n_classes, BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE,MILESTONES,MOMENTUM, outputs_labels_mapping)\n",
        "lwf.cuda()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LWF(\n",
              "  (feature_extractor): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=64, out_features=2048, bias=True)\n",
              "  )\n",
              "  (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "  (ReLU): ReLU()\n",
              "  (fc): Linear(in_features=2048, out_features=0, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4l0ELnTxI2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H60xMfbW2R3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incrementalTraining(net, train_subsets, val_subsets, test_subsets,eval_transform, reverse_index):\n",
        "    #groups_accuracies=[] not used right now, use it if you want test on single groups\n",
        "    all_accuracies = []\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "    group_id=1\n",
        "    test_set = None\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      print(\"GROUP: \",group_id)\n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "      train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "      val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE,shuffle=False, num_workers=4)\n",
        "      test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=False, num_workers=4)\n",
        "      \n",
        "      #net.train()\n",
        "\n",
        "      new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "\n",
        "      # update representation\n",
        "      net.update_representation(train_subset, new_classes_examined)\n",
        "\n",
        "      # evaluation on the train set\n",
        "      net.eval()\n",
        "      total = 0.0\n",
        "      correct = 0.0\n",
        "\n",
        "      for indices, images, labels in train_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        labels = reverse_index.getNodes(labels)\n",
        "        preds = net.classify(images)\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # Train Accuracy\n",
        "      print ('Train Accuracy (on current group): %.2f\\n' % (100.0 * correct / len(train_subset)))\n",
        "\n",
        "      # evaluation on all the previous groups\n",
        "      #net.eval()\n",
        "      total = 0.0\n",
        "      correct = 0.0\n",
        "\n",
        "      for indices, images, labels in test_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        labels = reverse_index.getNodes(labels)\n",
        "        preds = net.classify(images)\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "      \n",
        "      all_preds_cm.extend(preds.tolist())\n",
        "      all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "      accuracy = correct / len(test_set)\n",
        "      all_accuracies.append(accuracy)\n",
        "      # Train Accuracy\n",
        "      print ('Test Accuracy (all groups seen so far): %.2f\\n' % (100.0 * accuracy))\n",
        "\n",
        "      net.n_known = net.n_classes\n",
        "      print (\"the model knows %d classes:\\n \" % net.n_known)\n",
        "\n",
        "      group_id+=1\n",
        "    \n",
        "    return all_accuracies, np.array(all_preds_cm), np.array(all_labels_cm)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TXVwGceM6gN",
        "colab_type": "code",
        "outputId": "f851aa0a-48b9-4cf7-b5fb-18f0ea3d7236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "accuracies, all_preds_cm, all_labels_cm = incrementalTraining(lwf, train_subsets, val_subsets, test_subsets,eval_transform, outputs_labels_mapping)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.3102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2278, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2204, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1600, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1799, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1567, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1427, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1334, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1509, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1470, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1359, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1396, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1252, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1027, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1403, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1428, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1242, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1199, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.0982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1124, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.0947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1248, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.0953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.0931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.0908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.0656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.0754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.0928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.0698, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.0619, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.0826, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.0831, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.0731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.0756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.0883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.0793, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.0583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.0398, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.0473, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.0554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.0503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.0368, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.0430, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.0350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.0296, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.0383, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.0462, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.0300, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.0376, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.0290, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.0177, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.0287, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.0319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.0211, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.0208, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.0294, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.0260, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 97.92\n",
            "\n",
            "Test Accuracy (all groups seen so far): 83.80\n",
            "\n",
            "the model knows 10 classes:\n",
            " \n",
            "GROUP:  2\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2431, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2154, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1773, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1701, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1775, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1695, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1702, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1684, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1611, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1446, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1545, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1501, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1493, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1498, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1482, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1391, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1389, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1447, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1484, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1412, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1507, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1378, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1496, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1437, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1309, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1414, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1345, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1262, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1281, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1280, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1317, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1310, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1222, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1338, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1192, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1187, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1251, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1295, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1201, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1227, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1432, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1217, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 65.23\n",
            "\n",
            "Test Accuracy (all groups seen so far): 67.70\n",
            "\n",
            "the model knows 20 classes:\n",
            " \n",
            "GROUP:  3\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2135, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.1956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.1824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.1865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.1841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1739, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1764, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1694, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1747, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1615, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1646, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1684, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1678, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1621, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1610, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1572, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1650, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1638, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1622, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1648, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1608, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1624, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1692, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1535, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1661, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1615, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1614, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1677, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1601, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1563, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1584, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1642, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1591, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1570, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1554, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1547, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1526, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1569, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1511, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1573, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1512, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1561, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1615, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1533, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1592, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1623, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1533, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1522, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1575, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1533, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 43.31\n",
            "\n",
            "Test Accuracy (all groups seen so far): 53.43\n",
            "\n",
            "the model knows 30 classes:\n",
            " \n",
            "GROUP:  4\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.1956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.1979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.1949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1893, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1776, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1801, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1788, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1867, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1742, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1770, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1854, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1843, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1780, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1730, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1830, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1740, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1794, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1787, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1752, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1736, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1718, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1718, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1711, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1703, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1683, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1703, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1741, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1755, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1772, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1681, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1722, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1710, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1735, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1670, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1704, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1715, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1751, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1699, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1699, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1617, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 41.13\n",
            "\n",
            "Test Accuracy (all groups seen so far): 43.97\n",
            "\n",
            "the model knows 40 classes:\n",
            " \n",
            "GROUP:  5\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2159, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2098, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.1999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1889, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1888, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1849, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1910, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1860, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1825, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1884, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1850, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1857, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1796, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1878, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1877, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 28.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 37.14\n",
            "\n",
            "the model knows 50 classes:\n",
            " \n",
            "GROUP:  6\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2121, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2043, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1868, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1881, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1871, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1841, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1840, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 22.12\n",
            "\n",
            "Test Accuracy (all groups seen so far): 31.93\n",
            "\n",
            "the model knows 60 classes:\n",
            " \n",
            "GROUP:  7\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2202, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1955, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1923, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1882, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1885, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1910, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1883, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 30.16\n",
            "\n",
            "Test Accuracy (all groups seen so far): 29.11\n",
            "\n",
            "the model knows 70 classes:\n",
            " \n",
            "GROUP:  8\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.2037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.2009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.2019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1978, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.2024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.2011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1913, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1911, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1955, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1932, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1949, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1907, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 32.02\n",
            "\n",
            "Test Accuracy (all groups seen so far): 27.65\n",
            "\n",
            "the model knows 80 classes:\n",
            " \n",
            "GROUP:  9\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2122, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.2074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.2011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.2032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1941, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1984, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.2031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.2003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.2022, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.2035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1976, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.2002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1956, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.2023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.2020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.2019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.2032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.2019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.2004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.2014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 23.05\n",
            "\n",
            "Test Accuracy (all groups seen so far): 24.96\n",
            "\n",
            "the model knows 90 classes:\n",
            " \n",
            "GROUP:  10\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2197, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2168, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2146, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2142, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2080, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2092, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2106, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2115, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.2049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.2096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.2108, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.2110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2136, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.2056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.2088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.2034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.2079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.2084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.2063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.2054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.2073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.2060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.2082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.2066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.2069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.2031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.2055, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.2006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.2078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.2079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.2075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.2096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.2076, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.2068, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.2044, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.2070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.2081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.2073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.2007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.2049, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.2034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.2040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.2034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.2030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.2070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.2024, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.2051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.2029, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.2095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.2047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.2082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.2056, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.2045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.2104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.2054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.2036, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.2037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.2067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.2082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 22.69\n",
            "\n",
            "Test Accuracy (all groups seen so far): 23.05\n",
            "\n",
            "the model knows 100 classes:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBpsSTfGNM1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9622ca73-7682-4bab-f6fa-5ce53104e713"
      },
      "source": [
        "# metrics\n",
        "\n",
        "# accuracy \n",
        "data_plot_line=[]\n",
        "\n",
        "for id in range(0,10):\n",
        "    data_plot_line.append(((id+1)*10, accuracies[id]))\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(data_plot_line)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(confusionMatrixData)\n",
        "\n",
        "# write to file\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "utils.writeMetrics('lwf', RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "metrics FINETUNING for seed 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d818f1212f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# write to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metrics FINETUNING for seed {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lwf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusionMatrixData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Cifar100/utils.py\u001b[0m in \u001b[0;36mwriteMetrics\u001b[0;34m(method, seed, accuracies, confusionMatrixData)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mclass_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#rows of the cm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mclass_num\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mconfusionMatrixData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 96 is out of bounds for axis 0 with size 96"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkehScacOAm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a255c447-68ac-4890-d5ee-3ba5e7c3719f"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 46,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 60,\n",
              " 61,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 81,\n",
              " 82,\n",
              " 85,\n",
              " 86,\n",
              " 88,\n",
              " 89,\n",
              " 96,\n",
              " 98}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUZrq-ETM0Ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}